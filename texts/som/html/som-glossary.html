<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1" />
    <link href="http://fonts.googleapis.com/css?family=Arvo:400,700" 
          rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:400,400italic' 
          rel='stylesheet' type='text/css'>
	  <link rel="stylesheet" type="text/css" href="./mind.css" />
<title>The Society of Mind Text & Video Archive</title>


</head>
<body>
<div class='chapnav'><span class='prev'>Previous: <a href='./som-postscript.html'>postscript</a></span><span class='contents'><a href='index.html'>Contents</a></span><div class='titlebar'><h1>Society of Mind</h1></div></div>
    <h1 class="endmatter" id="glossary">Glossary and bibliography</h1>


    <p>
      Because I thought this theory of the mind might interest not only
      specialists but everyone who thinks, I favored ordinary words over
      the technical language of psychology. This was rarely any sacrifice
      because so many psychological terms already stood for obsolete
      ideas.  But since I also wished to speak to specialists, I tried to
      hide more technical ideas between the lines; I hope this second
      level does not show. However there still were certain points at
      which no ordinary words seemed satisfactory, and I had to invent new
      terms or assign new meanings to old ones.</p>

    <p>
      <h3 name="accumulation">Accumulation</h3>
      (<a href="som-12.6.html">12.6</a>) A type of learning based on
      collecting examples of an idea without attempting to describe
      what they have in common. Contrast
      with <a href="#uniframe">Uniframe</a>.</p>

    <p>
      <h3 name="agency">Agency</h3> (<a href="som-1.6.html">1.6</a>) Any assembly of
      parts considered in terms of what it can accomplish as a unit,
      without regard to what each of its parts does by itself.</p>

    <p>
      <h3 name="agent">Agent</h3> (<a href="som-1.4.html">1.4</a>) Any
      part or process of the mind that by itself is simple enough to
      understand &mdash; even though the interactions among groups of
      such agents may produce phenomena that are much harder to
      understand.</p>

    <p>
      <h3 name="artificial-intelligence">Artificial Intelligence</h3>
      (<a href="som-7.4.html">7.4</a>) The field of research concerned
      with making machines do things that people consider to require
      intelligence. There is no clear boundary between psychology and
      Artificial Intelligence because the brain itself is a kind of
      machine. For an introduction to this field, I recommend Patrick
      Winston&#39;s textbook Artificial Intelligence, Addison-Wesley,
      1984.  For more connections with psychology, see Roger Schank
      and Kenneth Colby (eds.), Computer Models of Thought and
      Language, Freeman, 1973. Some influential early ideas about
      brains and machines can be seen in Warren McCulloch&#39;s
      Embodiments of Mind, MIT Press, Cambridge, Mass.,
      1966. See <a href="#intelligence">Intelligence</a>.</p>

    <p>
      <h3 name="attachment-learning">Attachment Learning</h3>
      (<a href="som-17.2.html">17.2</a>) The specific theory, proposed
      in this book, that the presence of someone to whom we are
      emotionally attached has a special effect on how we learn,
      especially in infancy. Attachment learning tends to cause us to
      modify our goals &mdash; rather than merely improve our methods
      for achieving the goals we already have.</p>

    <p>
      <h3 name="b-brain">B-Brain</h3> (<a href="som-6.4.html">6.4</a>)
      Any part of the brain connected not to the outside world, but
      only to another part of the same brain. Like a manager, a
      B-brain can supervise an A-brain without understanding either
      how the A-brain works or the problems with which the A-brain is
      involved &mdash; for example, by recognizing patterns of
      activity that indicate the A-brain is confused, wasting time in
      repetitive activity, or focused on an unproductive level of
      detail.</p>

    <p>
      <h3 name="block-arch">Block-Arch</h3> (<a href="som-12.1.html">12.1</a>) A
      scenario adapted from Patrick Winston&#39;s doctoral
      thesis, <em>Learning Structural Descriptions by Examples,</em>
      in <i>The Psychology of Computer Vision</i>, P. H. Winston
      (ed.), McGraw-Hill, 1975. The study of the world of
      children&#39;s building-blocks may at first seem childishly
      simple, but it has been one of the most productive areas of
      research about Artificial Intelligence, child psychology, and
      modern robotics engineering.</p>

    <p>
      <h3>Censor</h3> (<a href="som-27.2.html">27.2</a>) An agent that
      inhibits or suppresses the operation of other agents. Censorlike
      agents are involved with how we learn from our mistakes. This
      idea played a prominent role in Freud&#39;s theories but has
      been virtually ignored by modern experimental psychologists
      &mdash; presumably because it is hard to study what people do
      not think. See Freud&#39;s 1905 book Jokes and Their Relation to
      the Unconscious. I suspect censorlike agents may constitute the
      larger part of human memory. The discussion of censors and jokes
      in chapter 27 is based on my essay <em>Jokes and Their Relation
      to the Cognitive Unconscious,</em> published in Cognitive
      Constraints on Communication, Representations and Processes,
      L. Vaina and J.K.K. Hintikka (eds.), . Reidel, 1981. See
      <a href="#suppressors">Suppressors</a>.</p>

    <p>
      <h3>Challenger, Professor</h3> (<a href="som-4.4.html">4.4</a>) A rival of mine, disguised as the
      treacherous archaeologist in Arthur Conan Doyle&#39;s novel The Lost
      World, who resembles Sherlock Holmes&#39;s nemesis, the mathematician
      Moriarty, except for being somewhat more honorable.</p>

    <p>
      <h3>Closing the Ring</h3> (<a href="som-19.10.html">19.10</a>) A technique by which an agency can recall many
      details of a memory from being given only a few <em>cues.</em></p>

    <p>
      <h3>Common Sense</h3> (<a href="som-1.5.html">1.5</a>) The mental skills that most people share.
      Commonsense thinking is actually more complex than many of the
      intellectual accomplishments that attract more attention and respect,
      because the mental skills we call <em>expertise</em> often engage large
      amounts of knowledge but usually employ only a few types of
      representations. In contrast, common sense involves many different kinds
      of representations and thus requires a larger range of different skills.</p>

    <p>
      <h3>Computer Science</h3> (<a href="som-6.8.html">6.8</a>) A
      science still in its infancy. While other sciences study how
      particular types of objects interact, computer science studies
      how interactions work in general &mdash; that is, how societies
      of parts can accomplish what those parts cannot do
      separately. Although computer science began with the study of
      serial computers &mdash; that is, of machines that could do only
      one thing at a time &mdash; it has grown to the point of
      studying the sorts of interconnected networks of processes that
      must go on inside societies of mind. (For an introduction to the
      theory of single-process machines, see my book <i>Computation:
      Finite and Infinite Machines</i>, Prentice-Hall, 1967.)</p>

    <p>
      <h3>Consciousness</h3> (<a href="som-6.1.html">6.1</a>) In this
      book, the word is used mainly for the myth that human minds
      are <em>self-aware</em> in the sense of perceiving what happens
      inside themselves. I maintain that human consciousness can never
      represent what is occurring at the present moment, but only a
      little of the recent past &mdash; partly because each agency has
      a limited capacity to represent what happened recently and
      partly because it takes time for agencies to communicate with
      one another. Consciousness is peculiarly hard to describe
      because each attempt to examine temporary memories distorts the
      very records it is trying to inspect. The description of
      consciousness in section <a href="som-6.1.html">6.1</a> was
      adapted from my epilogue to Vernor Vinge&#39;s novel <i>True Names</i>,
      Bluejay Books, New York, 1984.</p>

    <p>
      <h3>Context</h3> (<a href="som-20.2.html">20.2</a>) The effect upon one&#39;s state of mind of all the
      influences present at the time. At each moment, the context within which
      each agency works is determined by the activity of the nemes that reach
      that agency. See <a href="#neme">Neme</a>.</p>

    <p>
      <h3>Cross-Exclusion</h3> (<a href="som-16.4.html">16.4</a>) An arrangement in which each of several agents is
      connected so as to inhibit all the others &mdash; so that only one of
      them can remain active at a time.</p>

    <p>
      <h3>Cross-Realm Correspondence</h3> (<a href="som-29.4.html">29.4</a>) A structure that has useful
      applications in two or more different mental realms. Such
      correspondences sometimes enable us to transfer knowledge and skill from
      one domain to another &mdash; without needing to accumulate experience
      in that other realm. This is the basis of certain important kinds of
      analogies and metaphors.</p>

    <p>
      <h3>Creativity</h3> (<a href="som-7.10.html">7.10</a>) The myth that the production of novel ideas, artistic
      or otherwise, comes from some distinctive form of thought. I recommend
      the discussion of this subject in the chapter
      <em>Variations on a Theme as the Crux of Creativity,</em> in Douglas
      Hofstadter&#39;s <i>Metamagical Themas</i>, Basic Books, 1985.</p>

    <p>
      <h3>Default Assumption</h3>
      (<a href="som-8.5.html">8.5</a>, <a href="som-12.12.html">12.12</a>)
      The kind of assumption we make when we lack reasons to think
      otherwise. For example, we assume <em>by default</em> that an
      unfamiliar individual who belongs to a familiar class will think
      and act like a <em>typical</em> member of that class. Default
      assumptions are more than mere conveniences; they constitute our
      most productive way to make generalizations. Although such
      assumptions are frequently wrong, they usually do little harm
      because they are automatically displaced when more specific
      information becomes available. However, they can do incalculable
      harm when they are held too rigidly.</p>

    <p>
      <h3>Demon</h3> (<a href="som-27.1.html">27.1</a>) An agent that
      constantly watches for a certain condition and intervenes when
      it occurs. Our discussion of demons is partly based on Eugene
      Charniak&#39;s doctoral thesis,
      <em>Toward a Model of Children&#39;s Story Comprehension,</em>
      MIT, 1972.</p>

    <p>
      <h3>Difference-Engine</h3> (<a href="som-7.8.html">7.8</a>) An
      agency whose actions tend to make the present state of affairs
      more like some goal or <em>desired state</em> whose description
      is represented in that agency. This idea was developed by Allen
      Newell, C. J. Shaw, and Herbert A. Simon into an important
      theory about human problem solving. See G.  Ernst and Allen
      Newell, <i>GPS, A Case Study in Generality and Problem
      Solving</i>, Academic Press, 1969.</p>

    <p>
      <h3>Direction-Neme</h3> (<a href="som-24.6.html">24.6</a>) An
      agent associated with a particular direction or region in
      space. I suspect that bundles of direction-nemes are used inside
      our brains for representing not only spatial locations and
      directions, but also for representing many nonspatial
      concepts. Direction-nemes resemble isonomes in spatial realms
      but more resemble polynemes in other realms.
      See <a href="#interaction-square">Interaction-Square</a> and
      <a href="#frame-array">Frame-Array</a>.</p>

    <p>
      <h3>Distributed Memory</h3> (<a href="som-20.9.html">20.9</a>) A
      representation in which each fragment of information is stored,
      not by making a single, substantial change in one agent, but by
      making small changes in many different agents. Many theorists
      have been led to believe that the construction of distributed
      memory-systems must involve
      <em>nondigital</em> devices such as holograms; that this is not so was
      shown by P. J. Willshaw, 0. P. Buneman, and H. C.  Longuet-Higgins
      in <em>Non-Holographic Associative Memory,</em> Nature, 222, 1969. See
      <a href="#memorizers">Memorizers</a>.</p>

    <p>
      <h3>Duplication Problem</h3> (<a href="som-23.2.html">23.2</a>)
      The question of how a mind could compare two similar ideas
      without possessing two identical agencies for representing both
      of them at the same time. This problem was never recognized in
      older theories of psychology, and I suspect it will be the
      downfall of most <em>holistic</em> theories of higher-level
      thought. See <a href="#time-blinking">Time Blinking</a>.</p>

    <p>
      <h3>Emotion</h3> (<a href="som-16.1.html">16.1</a>) A term used
      for too many different purposes. There is a popular view that
      emotions are inherently more complex and harder to understand
      than other aspects of human thought. I maintain that infantile
      emotions are comparatively simple in character and that the
      complexity of adult emotions results from accumulating networks
      of mutual exploitations. In adults, these networks eventually
      become indescribably complicated, but no more so than the
      networks of our adult <em>intellectual</em> structures.  Beyond
      a certain point, to distinguish between the emotional and
      intellectual structures of an adult is merely to describe the
      same structures from different points of view. See
      <a href="#proto-specialist">Proto-specialist</a>.</p>

    <p>
      <h3>Exploitation</h3> (<a href="som-4.5.html">4.5</a>) The act of one agency making use of the activity of
      another agency, without understanding how it works.  Exploitation is the
      most usual relationship among agencies because it is so difficult for
      them to understand one another.</p>

    <p>
      <h3>Exception Principle</h3> (<a href="som-12.9.html">12.9</a>) The concept that it may not pay to change a
      well-established skill in order to accommodate an exception.  The more
      one builds upon a certain foundation, the greater the disruption upon
      changing it. A system&#39;s growth will tend to cease, past the point at
      which the damage caused by any change outweighs the immediate gain. See
      <a href="#investment-principle">Investment Principle</a>.</p>

    <p>
      <h3>Frame</h3> (<a href="som-24.2.html">24.2</a>) A
      representation based on a set of terminals to which other
      structures can be attached. Normally, each terminal is connected
      to a default assumption, which is easily displaced by more
      specific information. Other ideas about frames that are not
      discussed within this book were published in my chapter <em>A
      Framework for Representing Knowledge,</em> in Psychology of
      Computer Vision, P. H. Winston (ed.), McGraw-Hill,
      1975. See <a href="#picture-frames">Picture-Frames</a>, <a href="#trans-frame">Trans-frame</a>.</p>

    <p>
      <h3>Frame-Array</h3> (<a href="som-25.2.html">25.2</a>) A family
      of frames that share the same terminals.  Information attached
      to any terminal of a frame-array automatically becomes available
      to all the frames of that array.  This makes it easy to change
      perspective, not only in regard to a physical viewpoint, but in
      other mental realms as well.  Frame-arrays are often controlled
      by bundles of direction-nemes.</p>

    <p>
      <h3>Functional Autonomy</h3> (<a href="som-17.4.html">17.4</a>)
      The idea that specific goals can lead to subgoals of broader
      character. For example, in order to please another individual, a
      child might develop more general goals of acquiring knowledge,
      power, or wealth &mdash; yet the very same subgoals might serve
      equally well an initial wish to injure that other
      individual. The term <em>functional autonomy</em> derives from
      Gordon Allport, who was one of my professors at Harvard.</p>
    <p>
      <h3>Functional Definition</h3>
      (<a href="som-12.4.html">12.4</a>) Specifying something in terms
      of how it might be used, rather than in terms of its parts and
      their
      relationships. See <a href="#structural-definition">Structural
      Definition</a>.</p>

    <p>
      <h3>Generate and Test</h3> (<a href="som-7.3.html">7.3</a>)
      Solving a problem by trial and error &mdash; that is, by
      proposing solutions recklessly, then rejecting those that do not
      work.</p>

    <p>
      <h3>Genius</h3> (<a href="som-7.10.html">7.10</a>) An individual of
      prodigious mental accomplishment.  Although even the most
      outstanding human prodigies rarely develop even twice as quickly
      as their peers, many people feel that their existence demands a
      special explanation. I suspect that the answer is to be found
      not in the superficial skills such people learn, but in the
      early accidents that lead them into learning better ways to
      learn.</p>

    <p>
      <h3>Goal</h3> (<a href="som-7.8.html">7.8</a>) The representation in a difference-engine of an imagined
      final state of affairs. This definition of goal may at first seem too
      impersonal because it does not explain either the elation that comes
      with achieving a human goal or the frustration that accompanies
      failure. However, we should not expect to explain such complicated
      phenomena of adult psychology directly in terms of simple principles,
      since they also depend on many other aspects of our mental
      architecture. Basing our concept of goal on the difference-engine idea
      helps us to avoid the single-agent fallacy by permitting us to speak
      about a goal without needing to refer to the person who entertains that
      goal; a person&#39;s many agencies may each have different goals &mdash;
      without that person being <em>aware</em> of them.</p>

    <p>
      <h3>Grammar-Tactic</h3> (<a href="som-22.10.html">22.10</a>) An
      operation involved with speech that corresponds to a step in a
      process of constructing a mental representation. Grammar-tactics
      are not the same as <em>grammar rules,</em> although these have
      a close relation. The difference is that grammar rules are both
      superficial and subjective &mdash; in the sense that they
      purport to describe regularities in one person&#39;s behavior as
      observed by someone else &mdash; while grammar-tactics are
      objective in the sense that they are defined to be the
      underlying processes that actually produce speech. Although it
      may be more difficult to discover just what those processes do,
      it is better to speculate on how language is produced and used
      than merely to describe its observed, external forms.</p>

    <p>
      <h3>Homunculus</h3> (<a href="som-5.2.html">5.2</a>) Literally, a tiny person. In psychology, the
      unproductive and paradoxical idea that a person&#39;s behavior depends
      upon the behavior of another personlike entity located deeper inside
      that person.</p>

    <p>
      <h3 name="interaction-square">Interaction-Square</h3>
      (<a href="som-14.9.html">14.9</a>) The idea of representing the
      interaction between two processes by linking pairs of examples
      to direction-nemes. We can use this same technique not only for
      representing spatial relationships, but for causal, temporal,
      and many other kinds of interactions. This makes the
      interaction-square idea a powerful scheme for representing
      cross-realm correspondences.</p>

    <p>
      <h3>Interaction</h3> (<a href="som-2.1.html">2.1</a>) The effect
      of one part of a system upon another part.  It is remarkable
      that in the history of science virtually all phenomena have
      eventually been explained in terms of interactions between parts
      taken two at a time. For example, Newton&#39;s law of gravity,
      which describes the mutual attraction of two particles, enables
      us to predict the motions of all the planets, stars, and
      galaxies &mdash; without any need to consider three or more
      objects at a time! One could conceive of a universe in which
      whenever three stars formed an equilateral triangle, one of them
      would instantly disappear &mdash; but virtually no three-part
      interactions have ever been observed in the physical world.</p>

    <p>
      <h3>Interruption</h3> (<a href="som-15.9.html">15.9</a>) A term
      used in this book to refer to any process that can be suspended
      while the agency involved can do some other job &mdash; yet
      later return to where it left off. The ability to do this
      requires some sort of temporary
      memory. See <a href="#recursion-principle">Recursion
      Principle</a>.</p>

    <p>
      <h3>Intelligence</h3> (<a href="som-7.1.html">7.1</a>) A term frequently
      used to express the myth that some single entity or element is
      responsible for the quality of a person&#39;s ability to
      reason. I prefer to think of this word as representing not any
      particular power or phenomenon, but simply all the mental skills
      that, at any particular moment, we admire but don&#39;t yet
      understand.</p>

    <p>
      <h3>Introspection</h3> (<a href="som-6.5.html">6.5</a>) The myth
      that our minds possess the ability directly to perceive or
      apprehend their own operations.</p>

    <p>
      <h3>Intuition</h3> (<a href="som-12.10.html">12.10</a>) The myth that the mind possesses some immediate (and
      hence inexplicable) abilities to solve problems or perceive truths. This
      belief is based on naive views of how we get ideas.  For example, we
      often experience a moment of excitement or exhilaration at the moment of
      completing a complex and pro longed but nonconscious analysis of a
      problem. The myth of intuition wrongly attributes the solution to what
      happened in that final moment. As for being able directly to apprehend
      what is true, we simply forget how frequently our <em>intuitions</em>
      turn out wrong.</p>

    <p>
      <h3>Investment Principle</h3> (<a href="som-14.6.html">14.6</a>)
      The tendency of any well-developed skill to retard the growth of
      similar skills because the latter work less well in their early
      forms &mdash; and hence are used so infrequently that they never
      reach maturity. Because of this, we tend to invest most of our
      time and effort on elaborating a comparatively few techniques,
      rather than on accumulating many different ones. This can lead,
      at the same time, both to the formation of a coherent and
      effective personal style and to a decline in flexibility that
      may be wrongly attributed to
      aging. See <a href="#exception-principle">Exception
      Principle</a>.</p>

    <p>
      <h3>Isonome</h3> (<a href="som-22.1.html">22.1</a>) A signal or
      pathway in the brain that has similar effects on several
      different agencies.</p>

    <p>
      <h3>K-Line</h3> (<a href="som-8.1.html">8.1</a>) The theory that
      certain kinds of memories are based on turning on sets of agents
      that reactivate one&#39;s previous partial mental states. This
      idea was first described in my essay <em>K-lines: A Theory of
      Memory,</em> Cognitive Science, 4 (2), April 1980.</p>

    <p>
      <h3>Learning</h3> (<a href="som-7.5.html">7.5</a>) An omnibus
      word for all the processes that lead to long-term changes in our
      minds.</p>

    <p>
      <h3>Level-Band</h3> (<a href="som-8.5.html">8.5</a>) The idea that a typical mental process tends to
      operate, at each moment, only within a certain range or portion of the
      structure of each agency. This makes it possible for one process to work
      on small details without disrupting other processes that are concerned
      with large-scale plans.</p>

    <p>
      <h3>Logical Thinking</h3> (<a href="som-18.1.html">18.1</a>) The
      popular but unsound theory that much of human reasoning proceeds
      in accord with clear-cut rules that lead to foolproof
      conclusions. In my view, we employ logical reasoning only in
      special forms of adult thought, which are used mainly to
      summarize what has already been discovered. Most of our ordinary
      mental work &mdash; that is, our commonsense reasoning &mdash;
      is based more on <em>thinking by analogy</em> &mdash; that is,
      applying to our present circumstances our representations of
      seemingly similar previous experiences.</p>

    <p>
      <h3>Memorizer</h3> (<a href="som-19.5.html">19.5</a>) An agent
      that can reset an agency into some previously useful state. See
      <a href="#recognizer">Recognizer</a>
      and <a href="#distributed-memory">Distributed Memory</a>.</p>
      
    <p>
      <h3>Memory</h3> (<a href="som-15.3.html">15.3</a>) An omnibus
      term for a great many structures and processes that have
      ill-defined boundaries in both everyday and technical
      psychology; these include what we call
      <em>re-membering,</em> <em>re-collecting,</em> <em>re-minding,</em> and
      <em>recognizing.</em> This book suggests that what these share in common
      is their involvement with how we reproduce our former partial mental
      states.</p>
      
      <p><h3>Mental State</h3> (<a href="som-8.4.html">8.4</a>) The
      condition of activity of a group of agents at a certain
      moment. In this book we have assumed that every agent, at any
      moment, is either completely aroused or completely quiescent; in
      other words, we ignore the possibility of different degrees of
      arousal. This kind of <em>two-state</em> or <em>digital</em>
      assumption is characteristic of computer science and, at first,
      may seem too simplistic. However, experience has shown that the
      so-called analog theories that are alleged to be more realistic
      quickly become so complicated that, in the end, the simpler
      two-state models actually lead to deeper understandings &mdash;
      at least about basic
      principles. See <a href="#partial-mental-state">Partial Mental
      State</a>.</p>

    <p>
      <h3>Metaphor</h3> (<a href="som-29.8.html">29.8</a>) The myth
      that there is a clear distinction between representations that
      are <em>realistic</em> and those that are merely suggestive. In
      their book Metaphors We Live By, University of Chicago Press,
      1980, Mark Johnson and George Lakoff demonstrate that metaphor
      is no mere special device of literary expression but permeates
      virtually every aspect of human thought.</p>

    <p>
      <h3>Micromemory</h3> (<a href="som-15.8.html">15.8</a>) The
      smallest components of our short-term memory-systems.
    </p>
    <p>
      <h3>Microneme</h3> (<a href="som-20.5.html">20.5</a>) A neme
      involved with agents at a relatively low
      level. See <a href="#neme">Neme</a>.</p>
    <p>
      <h3>Model</h3> (<a href="som-30.3.html">30.3</a>) Any structure
      that a person can use to simulate or anticipate the behavior of
      something else.</p>

    <p>
      <h3 name="neme">Neme</h3> (<a href="som-25.6.html">25.6</a>) An
      agent whose output represents a fragment of an idea or state of
      mind. The <em>context</em> within which a typical agent works is
      largely determined by the activity of the nemes that reach it. I
      called nemes <em>C-lines</em> in <em>Plain Talk About Neuro-
      developmental Epistemology,</em> in Proceedings of the Fifth
      International Joint Conference on Artificial Intelligence,
      Cambridge, Mass., 1977; the description in section 20. 5 is also
      based on the idea of <em>microfeature</em> developed by David
      L.Waltz and Jordan Pollack in <em>Massively Parallel
      Parsing,</em> Cognitive Science, 9 (1).</p>

    <p>
      <h3 name="nome">Nome</h3> (<a href="som-25.6.html">25.6</a>) An
      agent whose outputs affect an agency in some predetermined
      manner, such as a pronome, isonome, or paranome; an agent whose
      effect depends more on genetic architecture than on learning
      from experience. The suffix -nome was chosen to suggest an
      atom-like, unchanging quality.</p>

    <p>
      <h3 name="noncompromise-principle">Noncompromise Principle</h3>
      (<a href="som-3.2.html">3.2</a>) The idea that when two agencies
      conflict it may be better to ignore them both and yield control
      to yet another, independent agency.</p>

    <p>
      <h3 name="papert's-principle">Papert&#39;s Principle</h3>
      (<a href="som-10.4.html">10.4</a>) The hypothesis that many
      steps in mental growth are based less on the acquisition of new
      skills than on building new administrative systems for managing
      already established abilities.</p>

    <p>
      <h3 name="paranome">Paranome</h3>
      (<a href="som-29.3.html">29.3</a>) An agent that operates on
      agencies of several different mental realms at once, with
      similar effects on all of them.</p>

    <p>
      <h3 name="partial-mental-state">Partial Mental State</h3>
      (<a href="som-8.4.html">8.4</a>) A description of the state of
      activity of some particular group of mental agents. This
      technical but simple idea makes it easy to understand how one
      can entertain and combine several ideas at the same time. See
      <a href="#mental-state">Mental State</a>.</p>

    <p>
      <h3 name="perceptron">Perceptron</h3>
      (<a href="som-19.7.html">19.7</a>) A type of recognition machine
      that learns to weigh evidence. Invented by Frank Rosenblatt in
      the late 1950s, Perceptrons use singularly simple procedures for
      learning which weights to assign to various fragments of
      evidence. Seymour Papert and I analyzed this type of machine in
      the book <i>Perceptrons</i>, MIT Press, 1969, and showed that
      the simplest kinds of Perceptrons cannot do very much by
      themselves. However, they can do much more when arranged into
      societies so that some of them can then learn to recognize
      relations among the patterns recognized by the others. It seems
      quite likely that some types of brain cells use similar
      principles.</p>

    <p>
      <h3 name="picture-frames">Picture-Frames</h3>
      (<a href="som-24.7.html">24.7</a>) A type of frame whose
      terminals are controlled by direction-nemes. Picture-frames are
      particularly suited to representing certain kinds of spatial
      information.</p>

    <p>
      <h3 name="polyneme">Polyneme</h3>
      (<a href="som-19.5.html">19.5</a>) An agent that arouses
      different activities, at the same time, in different agencies
      &mdash; as a result of learning from experience. Contrast with
      <a href="#isonome">Isonome</a>.</p>

    <p>
      <h3 name="pronome">Pronome</h3> (<a href="som-21.1.html">21.1</a> ) A type of agent associated with a
      particular <em>role</em> or aspect of a representation &mdash;
      corresponding, for example, to the Actor, Trajectory, or Cause of some
      action. Pronome agents frequently control the attachments of terminals
      of frames to other frames; to do this, a pronome must possess some
      temporary memory.</p>

    <p>
      <h3 name="proto-specialist">Proto-specialist</h3>
      (<a href="som-16.3.html">16.3</a>) One of the genetically
      constructed subsystems responsible for some of an
      animal&#39;s <em>instinctive</em> behavior.  Large portions of
      our minds start out as almost separate proto-specialists, and we
      interpret their activity as manifesting different, primitive
      emotions. Later, as agencies become more interconnected and
      learn to exploit one another, these differences grow less
      distinct. This conception is based on the societylike theory
      proposed by Niko Tinbergen in The Study of Instinct, Oxford
      University Press, 1951.</p>

    <p>
      <h3 name="puzzle-principle">Puzzle Principle</h3>
      (<a href="som-7.3.html">7.3</a>) The idea that any problem can
      be solved by trial and error &mdash; provided one already has
      some way to recognize a solution when one is
      found. See <a href="#generate-and-test">Generate and
      Test</a>.</p>

    <p>
      <h3 name="mental-realm">Realm, Mental</h3>
      (<a href="som-29.1.html">29.1</a>) A division of the mind that
      deals with some distinct variety of concern by using distinct
      mechanisms and representations.</p>

    <p>
      <h3 name="recognizer">Recognizer</h3>
      (<a href="som-19.6.html">19.6</a>) An agent that becomes active
      in response to a particular pattern of input signals.</p>

    <p>
      <h3 name="recursion-principle">Recursion Principle</h3>
      ( <a href="som-15.11.html">15.11</a> ) The idea that no society,
      however large, can overcome every limitation &mdash; unless it
      has some way to reuse the same agents, over and over again, for
      different purposes. See <a href="#interruption">Interruption</a>.</p>

    <p>
      <h3 name="reformulation">Reformulation</h3>
      (<a href="som-13.1.html">13.1</a>) Replacing one representation
      of something by another, different type of representation.</p>

    <p>
      <h3 name="representation">Representation</h3>
      (<a href="som-21.6.html">21.6</a>) A structure that can be used
      as a substitute for something else, for a certain purpose, as
      one can use a map as a substitute for an actual city. See
      <a href="#functional-definition">Functional Definition</a> and
      <a href="#model">Model</a>.</p>

    <p>
      <h3>Re-duplication Theory of Speech</h3>
      (<a href="som-22.10.html">22.10</a>) My conjecture about what
      happens when a speaker explains an idea to a listener. A
      difference-enginelike process tries to construct a second copy
      of the idea&#39;s representation inside the speaker&#39;s
      mind. Each mental operation used in the course of that
      duplication process activates a corresponding grammar-tactic in
      the language- agency, and these lead to a stream of speech. This
      will result in communication to the extent that suitably matched
      <em>inverse grammar-tactics</em> construct, inside the listener&#39;s
      mind, an equivalent representation.</p>

    <p>
      <h3 name="script">Script</h3> (<a href="som-13.5.html">13.5</a>)
      A sequence of actions produced so automatically that it can be
      performed without disturbing the activities of many other
      agencies. The action script in
      section <a href="som-21.7.html">21.7</a> accomplishes this by
      eliminating all the higher-level managers like Put and Get. A
      script-based skill tends to be inflexible because it lacks
      bureaucracy; one gains speed by removing higher-level anchor
      points but loses access to alternatives when things go wrong;
      script-based experts run the risk of becoming inarticulate. The
      book by Roger Schank and Robert Abelson, Scripts, Goals, Plans
      and Understanding, Erlbaum Associates, 1977, speculates about
      the human use of scripts.</p>

    <p>
     <h3 name="self">Self</h3> (<a href="som-4.1.html">4.1</a>) In
      this book, when written <em>Self,</em> the myth that each of us
      contains some special part that embodies the essence of the
      mind. When written as <em>self,</em> the word has the ordinary
      sense of a person&#39;s individuality. See <a href="#single-agent-fallacy">Single-Agent
      Fallacy</a>.</p>

    <p>
      <h3 name="single-agent-fallacy">Single-Agent Fallacy</h3>
      (<a href="som-4.1.html">4.1</a>) The idea that a person&#39;s
      thought, will, decisions, and actions originate in some single
      center of control, instead of emerging from the activity of
      complex societies of processes.</p>

    <p>
      <h3 name="simulation">Simulation</h3>
      (<a href="som-2.4.html">2.4</a>) A situation in which one system
      mimics the behavior of another. In principle, a modern computer
      can be used to simulate any other kind of machine. This is
      important for psychology, because in the past, there was usually
      no way for scientists to confirm their expectations about the
      consequences of a complicated theory or mechanism. The theories
      in this book have not yet been simulated, partly because they
      are not specified clearly enough and partly because the older
      computers lacked enough capacity and speed to simulate enough
      agents.  Such machines have recently become available; for an
      example, see W. Daniel Hillis&#39;s doctoral thesis, <em>The
      Connection Machine,</em> MIT Press, Cambridge, Mass., 1985.</p>

    <p>
      <h3 name="simulus">Simulus</h3>
      (<a href="som-16.8.html">16.8</a>) An illusion that a certain
      thing is present, caused by a process that evokes, at higher
      levels of the mind, a state resembling the state of mind that
      would be caused by that thing&#39;s actual presence. (A new
      word. )</p>

    <p>
      <h3 name="society">Society</h3> (<a href="som-1.1.html">1.1</a>)
      In this book, an organization of parts of a mind. I reserved the
      term <em>community</em> for referring to organizations of people
      because I did not want to suggest that a human mind resembles a
      human community in any particular way.</p>

    <p>
      <h3 name="society-of-more">Society of More</h3>
      (<a href="som-10.2.html">10.2</a>) The agents used by a mind to
      make comparisons of quantities.</p>

    <p>
      <h3 name="stage-of-development">Stage of Development</h3>
      (<a href="som-16.2.html">16.2</a>) An episode in the growth of a
      mind.  <a href="som-17.html">Chapter 17</a> offers several
      reasons why complicated systems tend to grow in sequences of
      episodes, rather than through processes of steady change.</p>

    <p>
      <h3 name="state-of-mind">State of Mind</h3>
      (<a href="som-8.4.html">8.4</a>)
      See <a href="#mental-state">Mental State</a>.</p>

    <p>
      <h3 name="structural-definition">Structural Definition</h3>
      (<a href="som-12.4.html">12.4</a>) Describing something in terms
      of the relationships among its parts. Contrast
      with <a href="#functional-definition">Functional Definition</a>.
      </p><p>
      <h3 name="suppressor">Suppressor</h3>
      (<a href="som-27.2.html">27.2</a>) A censorlike agent that works
      by disrupting a mental state that has already
      occurred. Suppressors are easier to construct than censors, and
      require less memory, but are much less efficient.</p>

    <p>
      <h3 name="time-blinking">Time Blinking</h3>
      (<a href="som-23.3.html">23.3</a>) Finding differences between
      two mental states by activating them in rapid succession and
      noticing which agents change their states. I suspect it is by
      using this method that our brains avoid the duplication problem
      mentioned in section <a href="som-23.2.html">23.2</a>.  Time
      blinking might be one of the synchronized activities of brain
      cells that gives rise to <em>brain waves.</em></p>

    <p>
      <h3 name="trajectory">Trajectory</h3>
      (<a href="som-21.6.html">21.6</a>) Literally, the path or route
      of an action or activity.  However, we use this word not only
      for a path in space, but, by analogy, for other realms of
      thought. See <a href="#pronome">Pronome</a>.</p>

    <p>
      <h3 name="trans-frame">Trans-Frame</h3>
      (<a href="som-21.3.html">21.3</a>) A particular type of frame
      that is centered around the trajectory between two situations,
      one for <em>before</em> and the other for <em>after.</em> The
      theories in this book about Trans-frames owe much to Roger
      Schank. See his book, <i>Conceptual Information Processing</i>,
      North-Holland, 1975.</p>

    <p>
      <h3 name="unconscious">Unconscious</h3>
      (<a href="som-17.10.html">17.10</a>) A term often used, in
      common-sense psychology, to refer to areas of thought that are
      actively barred or censored against introspection. In this book
      we take <em>conscious</em> to mean aspects of our mental
      activity of which we are aware.  But since there are very few
      such processes, we must consider virtually everything done by
      the mind to be unconscious.</p>

    <p>
      <h3 name="uniframe">Uniframe</h3>
      (<a href="som-12.3.html">12.3</a>) A description designed to
      represent whichever common aspects of a group of things can be
      used to distinguish them from other things.</p>

    <p>
      <h3 name="freedom-of-will">Will, Freedom of</h3>
      (<a href="som-30.6.html">30.6</a>) The myth that human volition
      is based upon some third alternative to either causality or
      chance.</p>




<!--     <\!-- <p> -\-> -->
<!--     <\!--   Because I thought this theory of the mind might interest not only -\-> -->
<!--     <\!--   specialists but everyone who thinks, I favored ordinary words over -\-> -->
<!--     <\!--   the technical language of psychology. This was rarely any sacrifice -\-> -->
<!--     <\!--   because so many psychological terms already stood for obsolete -\-> -->
<!--     <\!--   ideas.  But since I also wished to speak to specialists, I tried to -\-> -->
<!--     <\!--   hide more technical ideas between the lines; I hope this second -\-> -->
<!--     <\!--   level does not show. However there still were certain points at -\-> -->
<!--     <\!--   which no ordinary words seemed satisfactory, and I had to invent new -\-> -->
<!--     <\!--   terms or assign new meanings to old ones.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Accumulation (12.6) A type of learning based on collecting examples -\-> -->
<!--     <\!--   of an idea without attempting to describe what they have in -\-> -->
<!--     <\!--   common. Contrast with Uniframe.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Agency (1.6) Any assembly of parts considered in terms of what it -\-> -->
<!--     <\!--   can</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   accomplish as a unit, without regard to what each of its parts does -\-> -->
<!--     <\!--   by itself.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Agent (1.4) Any part or process of the mind that by itself is simple -\-> -->
<!--     <\!--   enough to understand &mdash; even though the interactions among -\-> -->
<!--     <\!--   groups of such agents may produce phenomena that are much harder to -\-> -->
<!--     <\!--   understand.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Artificial Intelligence (7.4) The field of research concerned -\-> -->
<!--     <\!--   with making machines do things that people consider to require -\-> -->
<!--     <\!--   intelligence. There is no clear boundary between psychology and -\-> -->
<!--     <\!--   Artificial Intelligence because the brain itself is a kind of -\-> -->
<!--     <\!--   machine. For an introduction to this field, I recommend Patrick -\-> -->
<!--     <\!--   Winston&#39;s textbook Artificial Intelligence, Addison-Wesley, -\-> -->
<!--     <\!--   1984.  For more connections with psychology, see Roger Schank -\-> -->
<!--     <\!--   and Kenneth Colby (eds.), Computer Models of Thought and -\-> -->
<!--     <\!--   Language, Freeman, 1973. Some influential early ideas about -\-> -->
<!--     <\!--   brains and machines can be seen in Warren McCulloch&#39;s -\-> -->
<!--     <\!--   Embodiments of Mind, MIT Press, Cambridge, Mass., -\-> -->
<!--     <\!--   1966. See <a href="#intelligence">Intelligence</a>.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Attachment Learning (17.2) The specific theory, proposed in this -\-> -->
<!--     <\!--   book, that the presence of someone to whom we are emotionally -\-> -->
<!--     <\!--   attached has a special effect on how we learn, especially in -\-> -->
<!--     <\!--   infancy. Attachment learning tends to cause us to modify our goals -\-> -->
<!--     <\!--   &mdash; rather than merely improve our methods for achieving the -\-> -->
<!--     <\!--   goals we already have.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   B-Brain (6.4) Any part of the brain connected not to the outside -\-> -->
<!--     <\!--   world, but only to another part of the same brain. Like a manager, a -\-> -->
<!--     <\!--   B-brain can supervise an A-brain without understanding either how -\-> -->
<!--     <\!--   the A-brain works or the problems with which the A-brain is involved -\-> -->
<!--     <\!--   &mdash; for example, by recognizing patterns of activity that -\-> -->
<!--     <\!--   indicate the A-brain is confused, wasting time in repetitive -\-> -->
<!--     <\!--   activity, or focused on an unproductive level of detail.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Block-Arch (12.1) A scenario adapted from Patrick Winston&#39;s -\-> -->
<!--     <\!--   doctoral thesis, <em>Learning Structural Descriptions by -\-> -->
<!--     <\!-- 	Examples,</em> in The Psychology of Computer Vision, P. H. Winston</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   (ed.), McGraw-Hill, 1975. The study of the world of children&#39;s -\-> -->
<!--     <\!--   building-blocks may at first seem childishly simple, but it has been -\-> -->
<!--     <\!--   one of the most productive areas of research about Artificial -\-> -->
<!--     <\!--   Intelligence, child psychology, and modern robotics engineering.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Censor (27.2) An agent that inhibits or suppresses the operation of other -\-> -->
<!--     <\!--   agents. Censorlike agents are involved with how we learn from our -\-> -->
<!--     <\!--   mistakes. This idea played a prominent role in Freud&#39;s theories but -\-> -->
<!--     <\!--   has been virtually ignored by modern experimental psychologists &mdash; -\-> -->
<!--     <\!--   presumably because it is hard to study what people do not think. See -\-> -->
<!--     <\!--   Freud&#39;s 1905 book Jokes and Their Relation to the Unconscious. I -\-> -->
<!--     <\!--   suspect censorlike agents may constitute the larger part of human -\-> -->
<!--     <\!--   memory. The discussion of censors and jokes in chapter 27 is based on my -\-> -->
<!--     <\!--   essay <em>Jokes and Their Relation to the Cognitive Unconscious,</em> -\-> -->
<!--     <\!--   published in Cognitive Constraints on Communication, Representations and -\-> -->
<!--     <\!--   Processes, L. Vaina and J.K.K. Hintikka (eds.), . Reidel, 1981. See -\-> -->
<!--     <\!--   Suppressors.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Challenger, Professor (4.4) A rival of mine, disguised as the -\-> -->
<!--     <\!--   treacherous archaeologist in Arthur Conan Doyle&#39;s novel The Lost -\-> -->
<!--     <\!--   World, who resembles Sherlock Holmes&#39;s nemesis, the mathematician -\-> -->
<!--     <\!--   Moriarty, except for being somewhat more honorable.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Closing the Ring (19.10) A technique by which an agency can recall many -\-> -->
<!--     <\!--   details of a memory from being given only a few <em>cues.</em></p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Common Sense (1.5) The mental skills that most people share. -\-> -->
<!--     <\!--   Commonsense thinking is actually more complex than many of the -\-> -->
<!--     <\!--   intellectual accomplishments that attract more attention and respect, -\-> -->
<!--     <\!--   because the mental skills we call <em>expertise</em> often engage large -\-> -->
<!--     <\!--   amounts of knowledge but usually employ only a few types of -\-> -->
<!--     <\!--   representations. In contrast, common sense involves many different kinds -\-> -->
<!--     <\!--   of representations and thus requires a larger range of different skills.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Computer Science (6.8) A science still in its infancy. While other -\-> -->
<!--     <\!--   sciences study how particular types of objects interact, computer</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   science studies how interactions work in general &mdash; that is, how -\-> -->
<!--     <\!--   societies of parts can accomplish what those parts cannot do -\-> -->
<!--     <\!--   separately. Although computer science began with the study of serial -\-> -->
<!--     <\!--   computers &mdash; that is, of machines that could do only one thing at a -\-> -->
<!--     <\!--   time &mdash; it has grown to the point of studying the sorts of -\-> -->
<!--     <\!--   interconnected networks of processes that must go on inside societies of -\-> -->
<!--     <\!--   mind. (For an introduction to the theory of single-process machines, see -\-> -->
<!--     <\!--   my book Computation: Finite and Infinite Machines, Prentice-Hall, 1967.)</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Consciousness (6.1) In this book, the word is used mainly for the myth -\-> -->
<!--     <\!--   that human minds are <em>self-aware</em> in the sense of perceiving what -\-> -->
<!--     <\!--   happens inside themselves. I maintain that human consciousness can never -\-> -->
<!--     <\!--   represent what is occurring at the present moment, but only a little of -\-> -->
<!--     <\!--   the recent past &mdash; partly because each agency has a limited -\-> -->
<!--     <\!--   capacity to represent what happened recently and partly because it takes -\-> -->
<!--     <\!--   time for agencies to communicate with one another. Consciousness is -\-> -->
<!--     <\!--   peculiarly hard to describe because each attempt to examine temporary -\-> -->
<!--     <\!--   memories distorts the very records it is trying to inspect. The</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   description of consciousness in section 6.1 was adapted from my epilogue -\-> -->
<!--     <\!--   to Vernor Vinge&#39;s novel True Names, Bluejay Books, New York, 1984.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Context (20.2) The effect upon one&#39;s state of mind of all the -\-> -->
<!--     <\!--   influences present at the time. At each moment, the context within which -\-> -->
<!--     <\!--   each agency works is determined by the activity of the nemes that reach -\-> -->
<!--     <\!--   that agency. See Neme.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Cross-Exclusion (16.4) An arrangement in which each of several agents is -\-> -->
<!--     <\!--   connected so as to inhibit all the others &mdash; so that only one of -\-> -->
<!--     <\!--   them can remain active at a time.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Cross-Realm Correspondence (29.4) A structure that has useful -\-> -->
<!--     <\!--   applications in two or more different mental realms. Such -\-> -->
<!--     <\!--   correspondences sometimes enable us to transfer knowledge and skill from -\-> -->
<!--     <\!--   one domain to another &mdash; without needing to accumulate experience -\-> -->
<!--     <\!--   in that other realm. This is the basis of certain important kinds of -\-> -->
<!--     <\!--   analogies and metaphors.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Creativity (7.10) The myth that the production of novel ideas, artistic -\-> -->
<!--     <\!--   or otherwise, comes from some distinctive form of thought. I recommend -\-> -->
<!--     <\!--   the discussion of this subject in the chapter -\-> -->
<!--     <\!--   <em>Variations on a Theme as the Crux of Creativity,</em> in Douglas -\-> -->
<!--     <\!--   Hofstadter&#39;s Metamagical Themas, Basic Books, 1985.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Default Assumption (8.5, 12.12) The kind of assumption we make when we -\-> -->
<!--     <\!--   lack reasons to think otherwise. For example, we assume <em>by -\-> -->
<!--     <\!-- 	default</em> that an unfamiliar individual who belongs to a familiar -\-> -->
<!--     <\!--   class will think and act like a <em>typical</em> member of that -\-> -->
<!--     <\!--   class. Default assumptions are more than mere conveniences; they -\-> -->
<!--     <\!--   constitute our most productive way to make generalizations. Although -\-> -->
<!--     <\!--   such assumptions are frequently wrong, they usually do little harm -\-> -->
<!--     <\!--   because they are automatically displaced when more specific information -\-> -->
<!--     <\!--   becomes available. However, they can do incalculable harm when they are -\-> -->
<!--     <\!--   held too rigidly.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Demon (27.1) An agent that constantly watches for a certain condition -\-> -->
<!--     <\!--   and intervenes when it occurs. Our discussion of</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   demons is partly based on Eugene Charniak&#39;s doctoral thesis, -\-> -->
<!--     <\!--   <em>Toward a Model of Children&#39;s Story Comprehension,</em> MIT, -\-> -->
<!--     <\!--   1972.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Difference-Engine (7.8) An agency whose actions tend to make the present -\-> -->
<!--     <\!--   state of affairs more like some goal or <em>desired state</em> whose -\-> -->
<!--     <\!--   description is represented in that agency. This idea was developed by -\-> -->
<!--     <\!--   Allen Newell, C. J. Shaw, and Herbert A. Simon into an important theory -\-> -->
<!--     <\!--   about human problem solving. See G.  Ernst and Allen Newell, GPS, A Case -\-> -->
<!--     <\!--   Study in Generality and Problem Solving, Academic Press, 1969.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Direction-Neme (24.6) An agent associated with a particular direction or -\-> -->
<!--     <\!--   region in space. I suspect that bundles of direction-nemes are used -\-> -->
<!--     <\!--   inside our brains for representing not only spatial locations and -\-> -->
<!--     <\!--   directions, but also for representing many nonspatial -\-> -->
<!--     <\!--   concepts. Direction-nemes resemble isonomes in spatial realms but more -\-> -->
<!--     <\!--   resemble polynemes in other realms.  See Interaction-Square and -\-> -->
<!--     <\!--   Frame-Array.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Distributed Memory (20. 9) A representation in which each fragment</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   of information is stored, not by making a single, substantial change in -\-> -->
<!--     <\!--   one agent, but by making small changes in many different agents. Many -\-> -->
<!--     <\!--   theorists have been led to believe that the construction of distributed -\-> -->
<!--     <\!--   memory-systems must involve -\-> -->
<!--     <\!--   <em>nondigital</em> devices such as holograms; that this is not so was -\-> -->
<!--     <\!--   shown by P. J. Willshaw, 0. P. Buneman, and H. C.  Longuet-Higgins -\-> -->
<!--     <\!--   in <em>Non-Holographic Associative Memory,</em> Nature, 222, 1969. See -\-> -->
<!--     <\!--   Memorizers.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Duplication Problem (23.2) The question of how a mind could compare two -\-> -->
<!--     <\!--   similar ideas without possessing two identical agencies for representing -\-> -->
<!--     <\!--   both of them at the same time. This problem was never recognized in -\-> -->
<!--     <\!--   older theories of psychology, and I suspect it will be the downfall of -\-> -->
<!--     <\!--   most <em>holistic</em> theories of higher-level thought. See Time -\-> -->
<!--     <\!--   Blinking.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Emotion (16.1) A term used for too many different purposes. There is a -\-> -->
<!--     <\!--   popular view that emotions are inherently more complex and harder to -\-> -->
<!--     <\!--   understand than other aspects of human thought. I maintain that -\-> -->
<!--     <\!--   infantile emotions are comparatively simple in</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   character and that the complexity of adult emotions results from -\-> -->
<!--     <\!--   accumulating networks of mutual exploitations. In adults, these networks -\-> -->
<!--     <\!--   eventually become indescribably complicated, but no more so than the -\-> -->
<!--     <\!--   networks of our adult <em>intellectual</em> structures.  Beyond a -\-> -->
<!--     <\!--   certain point, to distinguish between the emotional and intellectual -\-> -->
<!--     <\!--   structures of an adult is merely to describe the same structures from -\-> -->
<!--     <\!--   different points of view. See Proto-specialist.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Exploitation (4.5) The act of one agency making use of the activity of -\-> -->
<!--     <\!--   another agency, without understanding how it works.  Exploitation is the -\-> -->
<!--     <\!--   most usual relationship among agencies because it is so difficult for -\-> -->
<!--     <\!--   them to understand one another.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Exception Principle (12.9) The concept that it may not pay to change a -\-> -->
<!--     <\!--   well-established skill in order to accommodate an exception.  The more -\-> -->
<!--     <\!--   one builds upon a certain foundation, the greater the disruption upon -\-> -->
<!--     <\!--   changing it. A system&#39;s growth will tend to cease, past the point at -\-> -->
<!--     <\!--   which the damage caused by any change outweighs the immediate gain. See -\-> -->
<!--     <\!--   Investment Principle.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Frame (24.2) A representation based on a set of terminals to which other -\-> -->
<!--     <\!--   structures can be attached. Normally, each terminal is connected to a -\-> -->
<!--     <\!--   default assumption, which is easily displaced by more specific -\-> -->
<!--     <\!--   information. Other ideas about frames that are not discussed within this -\-> -->
<!--     <\!--   book were published in my chapter <em>A Framework for Representing -\-> -->
<!--     <\!-- 	Knowledge,</em> in Psychology of Computer Vision, P. H. Winston (ed.), -\-> -->
<!--     <\!--   McGraw-Hill, 1975. See Picture-Frames, Trans-frame.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Frame-Array (25.2) A family of frames that share the same terminals. -\-> -->
<!--     <\!--   Information attached to any terminal of a frame-array automatically -\-> -->
<!--     <\!--   becomes available to all the frames of that array.  This makes it easy -\-> -->
<!--     <\!--   to change perspective, not only in regard to a physical viewpoint, but -\-> -->
<!--     <\!--   in other mental realms as well.  Frame-arrays are often controlled by -\-> -->
<!--     <\!--   bundles of direction-nemes.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Functional Autonomy (17.4) The idea that specific goals can lead to -\-> -->
<!--     <\!--   subgoals of broader character. For example, in order to please</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   another individual, a child might develop more general goals of -\-> -->
<!--     <\!--   acquiring knowledge, power, or wealth &mdash; yet the very same subgoals -\-> -->
<!--     <\!--   might serve equally well an initial wish to injure that other -\-> -->
<!--     <\!--   individual. The term <em>functional autonomy</em> derives from Gordon -\-> -->
<!--     <\!--   Allport, who was one of my professors at Harvard.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Functional Definition (12.4) Specifying something in terms of how it -\-> -->
<!--     <\!--   might be used, rather than in terms of its parts and their -\-> -->
<!--     <\!--   relationships. See Structural Definition.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Generate and Test (7.3) Solving a problem by trial and error &mdash; -\-> -->
<!--     <\!--   that is, by proposing solutions recklessly, then rejecting those that do -\-> -->
<!--     <\!--   not work.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Genius (7.10) An individual of prodigious mental accomplishment. -\-> -->
<!--     <\!--   Although even the most outstanding human prodigies rarely develop even -\-> -->
<!--     <\!--   twice as quickly as their peers, many people feel that their existence -\-> -->
<!--     <\!--   demands a special explanation. I suspect that the answer is to be found -\-> -->
<!--     <\!--   not in the superficial skills such people learn, but in the early -\-> -->
<!--     <\!--   accidents that lead them into</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   learning better ways to learn.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Goal (7.8) The representation in a difference-engine of an imagined -\-> -->
<!--     <\!--   final state of affairs. This definition of goal may at first seem too -\-> -->
<!--     <\!--   impersonal because it does not explain either the elation that comes -\-> -->
<!--     <\!--   with achieving a human goal or the frustration that accompanies -\-> -->
<!--     <\!--   failure. However, we should not expect to explain such complicated -\-> -->
<!--     <\!--   phenomena of adult psychology directly in terms of simple principles, -\-> -->
<!--     <\!--   since they also depend on many other aspects of our mental -\-> -->
<!--     <\!--   architecture. Basing our concept of goal on the difference-engine idea -\-> -->
<!--     <\!--   helps us to avoid the single-agent fallacy by permitting us to speak -\-> -->
<!--     <\!--   about a goal without needing to refer to the person who entertains that -\-> -->
<!--     <\!--   goal; a person&#39;s many agencies may each have different goals &mdash; -\-> -->
<!--     <\!--   without that person being <em>aware</em> of them.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Grammar-Tactic (22.10) An operation involved with speech that -\-> -->
<!--     <\!--   corresponds to a step in a process of constructing a mental -\-> -->
<!--     <\!--   representation. Grammar-tactics are not the same as <em>grammar -\-> -->

<!--     <\!-- 	<p> -\-> -->
<!--     <\!-- 	  rules,</em> although these have a close relation. The difference is -\-> -->
<!--     <\!--   that grammar rules are both superficial and subjective &mdash; in the -\-> -->
<!--     <\!--   sense that they purport to describe regularities in one person&#39;s -\-> -->
<!--     <\!--   behavior as observed by someone else &mdash; while grammar-tactics are -\-> -->
<!--     <\!--   objective in the sense that they are defined to be the underlying -\-> -->
<!--     <\!--   processes that actually produce speech. Although it may be more -\-> -->
<!--     <\!--   difficult to discover just what those processes do, it is better to -\-> -->
<!--     <\!--   speculate on how language is produced and used than merely to describe -\-> -->
<!--     <\!--   its observed, external forms.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Homunculus (5.2) Literally, a tiny person. In psychology, the -\-> -->
<!--     <\!--   unproductive and paradoxical idea that a person&#39;s behavior depends -\-> -->
<!--     <\!--   upon the behavior of another personlike entity located deeper inside -\-> -->
<!--     <\!--   that person.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Interaction-Square (14.9) The idea of representing the interaction -\-> -->
<!--     <\!--   between two processes by linking pairs of examples to -\-> -->
<!--     <\!--   direction-nemes. We can use this same technique not only for -\-> -->
<!--     <\!--   representing spatial relationships, but for causal, temporal, and many -\-> -->
<!--     <\!--   other kinds of interactions. This makes the</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   interaction-square idea a powerful scheme for representing cross-realm -\-> -->
<!--     <\!--   correspondences.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Interaction (2.1) The effect of one part of a system upon another part. -\-> -->
<!--     <\!--   It is remarkable that in the history of science virtually all phenomena -\-> -->
<!--     <\!--   have eventually been explained in terms of interactions between parts -\-> -->
<!--     <\!--   taken two at a time. For example, Newton&#39;s law of gravity, which -\-> -->
<!--     <\!--   describes the mutual attraction of two particles, enables us to predict -\-> -->
<!--     <\!--   the motions of all the planets, stars, and galaxies &mdash; without any -\-> -->
<!--     <\!--   need to consider three or more objects at a time! One could conceive of -\-> -->
<!--     <\!--   a universe in which whenever three stars formed an equilateral triangle, -\-> -->
<!--     <\!--   one of them would instantly disappear &mdash; but virtually no -\-> -->
<!--     <\!--   three-part interactions have ever been observed in the physical world.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Interruption (15.9) A term used in this book to refer to any process -\-> -->
<!--     <\!--   that can be suspended while the agency involved can do some other job -\-> -->
<!--     <\!--   &mdash; yet later return to where it left off. The ability to do this -\-> -->
<!--     <\!--   requires some sort of temporary memory. See Recursion Principle.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Intelligence (7.1) A term frequently used to express the myth that some -\-> -->
<!--     <\!--   single entity or element is responsible for the quality of a -\-> -->
<!--     <\!--   person&#39;s ability to reason. I prefer to think of this word as -\-> -->
<!--     <\!--   representing not any particular power or phenomenon, but simply all the -\-> -->
<!--     <\!--   mental skills that, at any particular moment, we admire but don&#39;t -\-> -->
<!--     <\!--   yet understand.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Introspection (6.5) The myth that our minds possess the ability directly -\-> -->
<!--     <\!--   to perceive or apprehend their own operations.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Intuition (12.10) The myth that the mind possesses some immediate (and -\-> -->
<!--     <\!--   hence inexplicable) abilities to solve problems or perceive truths. This -\-> -->
<!--     <\!--   belief is based on naive views of how we get ideas.  For example, we -\-> -->
<!--     <\!--   often experience a moment of excitement or exhilaration at the moment of -\-> -->
<!--     <\!--   completing a complex and pro longed but nonconscious analysis of a -\-> -->
<!--     <\!--   problem. The myth of intuition wrongly attributes the solution to what -\-> -->
<!--     <\!--   happened in that final moment. As for being able directly to apprehend -\-> -->
<!--     <\!--   what is true, we simply forget how frequently our <em>intuitions</em> -\-> -->
<!--     <\!--   turn out wrong.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Investment Principle (14.6) The tendency of any well-developed skill to -\-> -->
<!--     <\!--   retard the growth of similar skills because the latter work less well in -\-> -->
<!--     <\!--   their early forms &mdash; and hence are used so infrequently that they -\-> -->
<!--     <\!--   never reach maturity. Because of this, we tend to invest most of our -\-> -->
<!--     <\!--   time and effort on elaborating a comparatively few techniques, rather -\-> -->
<!--     <\!--   than on accumulating many different ones. This can lead, at the same -\-> -->
<!--     <\!--   time, both to the formation of a coherent and effective personal style -\-> -->
<!--     <\!--   and to a decline in flexibility that may be wrongly attributed to -\-> -->
<!--     <\!--   aging. See Exception Principle.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Isonome (22.1) A signal or pathway in the brain that has similar effects -\-> -->
<!--     <\!--   on several different agencies.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   K-Line (8.1) The theory that certain kinds of memories are based on -\-> -->
<!--     <\!--   turning on sets of agents that reactivate one&#39;s previous partial -\-> -->
<!--     <\!--   mental states. This idea was first described in my essay <em>K-lines: A -\-> -->
<!--     <\!-- 	Theory of Memory,</em> Cognitive Science, 4 (2), April 1980.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Learning (7. 5) An omnibus word for all the processes that lead to -\-> -->
<!--     <\!--   long-term changes in our minds.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Level-Band (8. 5) The idea that a typical mental process tends to -\-> -->
<!--     <\!--   operate, at each moment, only within a certain range or portion of the -\-> -->
<!--     <\!--   structure of each agency. This makes it possible for one process to work -\-> -->
<!--     <\!--   on small details without disrupting other processes that are concerned -\-> -->
<!--     <\!--   with large-scale plans.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Logical Thinking (18.1) The popular but unsound theory that much of -\-> -->
<!--     <\!--   human reasoning proceeds in accord with clear-cut rules that lead to -\-> -->
<!--     <\!--   foolproof conclusions. In my view, we employ logical reasoning only in -\-> -->
<!--     <\!--   special forms of adult thought, which are used mainly to summarize what -\-> -->
<!--     <\!--   has already been discovered. Most of our ordinary mental work &mdash; -\-> -->
<!--     <\!--   that is, our commonsense reasoning &mdash; is based more on <em>thinking -\-> -->
<!--     <\!-- 	by analogy</em> &mdash; that is, applying to our present circumstances -\-> -->
<!--     <\!--   our representations of seemingly similar previous experiences.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Memorizer (19.5) An agent that can reset an agency into some previously -\-> -->
<!--     <\!--   useful state. See Recognizer and Distributed Memory. -\-> -->
      
<!--     <\!--   Memory (15.3) An omnibus term for a great many structures and processes -\-> -->
<!--     <\!--   that have ill-defined boundaries in both everyday and technical -\-> -->
<!--     <\!--   psychology; these include what we call -\-> -->
<!--     <\!--   <em>re-membering,</em> <em>re-collecting,</em> <em>re-minding,</em> and -\-> -->
<!--     <\!--   <em>recognizing.</em> This book suggests that what these share in common -\-> -->
<!--     <\!--   is their involvement with how we reproduce our former partial mental -\-> -->
<!--     <\!--   states. -\-> -->
      
<!--     <\!--   Mental State (8.4) The condition of activity of a group of agents at a -\-> -->
<!--     <\!--   certain moment. In this book we have assumed that every agent, at any -\-> -->
<!--     <\!--   moment, is either completely aroused or completely quiescent; in other -\-> -->
<!--     <\!--   words, we ignore the possibility of different degrees of arousal. This -\-> -->
<!--     <\!--   kind of <em>two-state</em> or <em>digital</em> assumption is -\-> -->
<!--     <\!--   characteristic of computer science and, at first, may seem too -\-> -->
<!--     <\!--   simplistic. However, experience has shown that the so-called analog -\-> -->
<!--     <\!--   theories that are alleged to be more realistic quickly become so -\-> -->
<!--     <\!--   complicated that, in the end, the</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   simpler two-state models actually lead to deeper understandings &mdash; -\-> -->
<!--     <\!--   at least about basic principles. See Partial Mental State.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Metaphor (29.8) The myth that there is a clear distinction between -\-> -->
<!--     <\!--   representations that are <em>realistic</em> and those that are merely -\-> -->
<!--     <\!--   suggestive. In their book Metaphors We Live By, University of Chicago -\-> -->
<!--     <\!--   Press, 1980, Mark Johnson and George Lakoff demonstrate that metaphor is -\-> -->
<!--     <\!--   no mere special device of literary expression but permeates virtually -\-> -->
<!--     <\!--   every aspect of human thought.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Micromemory (15.8) The smallest components of our short-term -\-> -->
<!--     <\!--   memory-systems. -\-> -->
      
<!--     <\!--   Microneme (20. S) A neme involved with agents at a relatively low -\-> -->
<!--     <\!--   level. See Neme.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Model (30.3) Any structure that a person can use to simulate or -\-> -->
<!--     <\!--   anticipate the behavior of something else.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Neme (25.6) An agent whose output represents a fragment of an idea or -\-> -->
<!--     <\!--   state of mind. The <em>context</em> within which a typical agent works -\-> -->
<!--     <\!--   is largely determined by the activity of the nemes that reach it. I -\-> -->
<!--     <\!--   called nemes <em>C-lines</em> in <em>Plain Talk About Neuro- -\-> -->
<!--     <\!-- 	developmental Epistemology,</em> in Proceedings of the Fifth -\-> -->
<!--     <\!--   International Joint Conference on Artificial Intelligence, Cambridge, -\-> -->
<!--     <\!--   Mass., 1977; the description in section 20. 5 is also based on the idea -\-> -->
<!--     <\!--   of <em>microfeature</em> developed by David L.Waltz and Jordan Pollack -\-> -->
<!--     <\!--   in <em>Massively Parallel Parsing,</em> Cognitive Science, 9 (1).</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Nome (25.6) An agent whose outputs affect an agency in some -\-> -->
<!--     <\!--   predetermined manner, such as a pronome, isonome, or paranome; an agent -\-> -->
<!--     <\!--   whose effect depends more on genetic architecture than on learning from -\-> -->
<!--     <\!--   experience. The suffix -nome was chosen to suggest an atom-like, -\-> -->
<!--     <\!--   unchanging quality.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Noncompromise Principle (3.2) The idea that when two agencies conflict -\-> -->
<!--     <\!--   it may be better to ignore them both and yield control to yet another, -\-> -->
<!--     <\!--   independent agency.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Papert&#39;s Principle (10.4) The hypothesis that many steps in mental -\-> -->
<!--     <\!--   growth are based less on the acquisition of new skills than on building -\-> -->
<!--     <\!--   new administrative systems for managing already established abilities.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Paranome (29.3) An agent that operates on agencies of several different -\-> -->
<!--     <\!--   mental realms at once, with similar effects on all of them.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Partial Mental State (8.4) A description of the state of activity of -\-> -->
<!--     <\!--   some particular group of mental agents. This technical but simple idea -\-> -->
<!--     <\!--   makes it easy to understand how one can entertain and combine several -\-> -->
<!--     <\!--   ideas at the same time. See Mental State.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Perceptron (19.7) A type of recognition machine that learns to weigh -\-> -->
<!--     <\!--   evidence. Invented by Frank Rosenblatt in the late 1950s, Perceptrons -\-> -->
<!--     <\!--   use singularly simple procedures for learning which weights to assign to -\-> -->
<!--     <\!--   various fragments of evidence. Seymour Papert and I analyzed this type -\-> -->
<!--     <\!--   of machine in the book Perceptrons, MIT Press, 1969, and showed that the -\-> -->
<!--     <\!--   simplest kinds</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   of Perceptrons cannot do very much by themselves. However, they can do -\-> -->
<!--     <\!--   much more when arranged into societies so that some of them can then -\-> -->
<!--     <\!--   learn to recognize relations among the patterns recognized by the -\-> -->
<!--     <\!--   others. It seems quite likely that some types of brain cells use similar -\-> -->
<!--     <\!--   principles.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Picture-Frames (24.7) A type of frame whose terminals are controlled by -\-> -->
<!--     <\!--   direction-nemes. Picture-frames are particularly suited to representing -\-> -->
<!--     <\!--   certain kinds of spatial information.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Polyneme (19.5) An agent that arouses different activities, at the same -\-> -->
<!--     <\!--   time, in different agencies &mdash; as a result of learning from -\-> -->
<!--     <\!--   experience. Contrast with Isonome.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Pronome (21.1 ) A type of agent associated with a -\-> -->
<!--     <\!--   particular <em>role</em> or aspect of a representation &mdash; -\-> -->
<!--     <\!--   corresponding, for example, to the Actor, Trajectory, or Cause of some -\-> -->
<!--     <\!--   action. Pronome agents frequently control the attachments of terminals -\-> -->
<!--     <\!--   of frames to other frames; to do this, a pronome must possess some -\-> -->
<!--     <\!--   temporary memory.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Proto-specialist (16.3) One of the genetically constructed subsystems -\-> -->
<!--     <\!--   responsible for some of an animal&#39;s <em>instinctive</em> behavior. -\-> -->
<!--     <\!--   Large portions of our minds start out as almost separate -\-> -->
<!--     <\!--   proto-specialists, and we interpret their activity as manifesting -\-> -->
<!--     <\!--   different, primitive emotions. Later, as agencies become more -\-> -->
<!--     <\!--   interconnected and learn to exploit one another, these differences grow -\-> -->
<!--     <\!--   less distinct. This conception is based on the societylike theory -\-> -->
<!--     <\!--   proposed by Niko Tinbergen in The Study of Instinct, Oxford University -\-> -->
<!--     <\!--   Press, 1951.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Puzzle Principle (7. 3) The idea that any problem can be solved by trial -\-> -->
<!--     <\!--   and error &mdash; provided one already has some way to recognize a -\-> -->
<!--     <\!--   solution when one is found. See Generate and Test.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Realm, Mental (29.1) A division of the mind that deals with some -\-> -->
<!--     <\!--   distinct variety of concern by using distinct mechanisms and -\-> -->
<!--     <\!--   representations.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Recognizer (19.6) An agent that becomes active in response to a -\-> -->
<!--     <\!--   particular pattern of input signals.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Recursion Principle ( 15.11 ) The idea that no society, however large, -\-> -->
<!--     <\!--   can overcome every limitation &mdash; unless it has some way to reuse -\-> -->
<!--     <\!--   the same agents, over and over again, for different purposes. See -\-> -->
<!--     <\!--   Interruption.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Reformulation (13.1) Replacing one representation of something by -\-> -->
<!--     <\!--   another, different type of representation.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Representation (21.6) A structure that can be used as a substitute for -\-> -->
<!--     <\!--   something else, for a certain purpose, as one can use a map as a -\-> -->
<!--     <\!--   substitute for an actual city. See Functional Definition and Model.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Re-duplication Theory of Speech (22.10) My conjecture about what happens -\-> -->
<!--     <\!--   when a speaker explains an idea to a listener. A difference-enginelike -\-> -->
<!--     <\!--   process tries to construct a second copy of the idea&#39;s -\-> -->
<!--     <\!--   representation inside the speaker&#39;s mind. Each mental operation used -\-> -->
<!--     <\!--   in the course of that duplication process activates a corresponding -\-> -->
<!--     <\!--   grammar-tactic in the language- agency, and these lead to a stream of -\-> -->
<!--     <\!--   speech. This will</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   result in communication to the extent that suitably matched -\-> -->
<!--     <\!--   <em>inverse grammar-tactics</em> construct, inside the listener&#39;s -\-> -->
<!--     <\!--   mind, an equivalent representation.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Script (13.5) A sequence of actions produced so automatically that it -\-> -->
<!--     <\!--   can be performed without disturbing the activities of many other -\-> -->
<!--     <\!--   agencies. The action script in section 21.7 accomplishes this by -\-> -->
<!--     <\!--   eliminating all the higher-level managers like Put and Get. A -\-> -->
<!--     <\!--   script-based skill tends to be inflexible because it lacks bureaucracy; -\-> -->
<!--     <\!--   one gains speed by removing higher-level anchor points but loses access -\-> -->
<!--     <\!--   to alternatives when things go wrong; script-based experts run the risk -\-> -->
<!--     <\!--   of becoming inarticulate. The book by Roger Schank and Robert Abelson, -\-> -->
<!--     <\!--   Scripts, Goals, Plans and Understanding, Erlbaum Associates, 1977, -\-> -->
<!--     <\!--   speculates about the human use of scripts.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Self (4.1) In this book, when written <em>Self,</em> the myth that each -\-> -->
<!--     <\!--   of us contains some special part that embodies the essence of the -\-> -->
<!--     <\!--   mind. When written as <em>self,</em> the word has the ordinary sense of -\-> -->
<!--     <\!--   a person&#39;s individuality. See Single-Agent Fallacy.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Single-Agent Fallacy (4.1) The idea that a person&#39;s thought, will, -\-> -->
<!--     <\!--   decisions, and actions originate in some single center of control, -\-> -->
<!--     <\!--   instead of emerging from the activity of complex societies of processes.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Simulation (2.4) A situation in which one system mimics the behavior of -\-> -->
<!--     <\!--   another. ln principle, a modern computer can be used to simulate any -\-> -->
<!--     <\!--   other kind of machine. This is important for psychology, because in the -\-> -->
<!--     <\!--   past, there was usually no way for scientists to confirm their -\-> -->
<!--     <\!--   expectations about the consequences of a complicated theory or -\-> -->
<!--     <\!--   mechanism. The theories in this book have not yet been simulated, partly -\-> -->
<!--     <\!--   because they are not specified clearly enough and partly because the -\-> -->
<!--     <\!--   older computers lacked enough capacity and speed to simulate enough -\-> -->
<!--     <\!--   agents.  Such machines have recently become available; for an example, -\-> -->
<!--     <\!--   see W. Daniel Hillis&#39;s doctoral thesis, <em>The Connection -\-> -->
<!--     <\!-- 	Machine,</em> MIT Press, Cambridge, Mass., 1985.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Simulus (16.8) An illusion that a certain thing is present, caused by a -\-> -->
<!--     <\!--   process that evokes, at higher levels of the mind, a state resembling -\-> -->
<!--     <\!--   the state of mind that would be caused by that thing&#39;s actual -\-> -->
<!--     <\!--   presence. (A new word. )</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Society (1.1) In this book, an organization of parts of a mind. I -\-> -->
<!--     <\!--   reserved the term <em>community</em> for referring to organizations of -\-> -->
<!--     <\!--   people because I did not want to suggest that a human mind resembles a -\-> -->
<!--     <\!--   human community in any particular way.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Society of More (10.2) The agents used by a mind to make comparisons of -\-> -->
<!--     <\!--   quantities.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Stage of Development (16.2) An episode in the growth of a mind.  Chapter -\-> -->
<!--     <\!--   17 offers several reasons why complicated systems tend to grow in -\-> -->
<!--     <\!--   sequences of episodes, rather than through processes of steady change.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   State of Mind (8.4) See Mental State.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Structural Definition (12.4) Describing something in terms of the -\-> -->
<!--     <\!--   relationships among its parts. Contrast with Functional Definition. -\-> -->
      
<!--     <\!--   Suppressor (27.2) A censorlike agent that works by disrupting a mental -\-> -->
<!--     <\!--   state that has already occurred. Suppressors are easier to construct -\-> -->
<!--     <\!--   than censors, and require less memory, but are much less efficient.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Time Blinking (23.3) Finding differences between two mental states by -\-> -->
<!--     <\!--   activating them in rapid succession and noticing which agents change -\-> -->
<!--     <\!--   their states. I suspect it is by using this method that our brains avoid -\-> -->
<!--     <\!--   the duplication problem mentioned in section 23.2.  Time blinking might -\-> -->
<!--     <\!--   be one of the synchronized activities of brain cells that gives rise -\-> -->
<!--     <\!--   to <em>brain waves.</em></p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Trajectory (21.6) Literally, the path or route of an action or activity. -\-> -->
<!--     <\!--   However, we use this word not only for a path in space, but, by analogy, -\-> -->
<!--     <\!--   for other realms of thought. See Pronome.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Trans-Frame (21. 3) A particular type of frame that is centered around -\-> -->
<!--     <\!--   the trajectory between two situations, one for <em>before</em> and the -\-> -->
<!--     <\!--   other for <em>after.</em> The theories in this book about Trans-frames -\-> -->
<!--     <\!--   owe much to Roger Schank. See his book, Conceptual Information -\-> -->
<!--     <\!--   Processing, North-Holland, 1975.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Unconscious (17.10) A term often used, in common-sense psychology, to -\-> -->
<!--     <\!--   refer to areas of thought that are actively barred or censored against -\-> -->
<!--     <\!--   introspection. In this book we take <em>conscious</em> to mean aspects -\-> -->
<!--     <\!--   of our mental activity of which we are aware.  But since there are very -\-> -->
<!--     <\!--   few such processes, we must consider virtually everything done by the -\-> -->
<!--     <\!--   mind to be unconscious.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Uniframe (12.3) A description designed to represent whichever common -\-> -->
<!--     <\!--   aspects of a group of things can be used to distinguish them from other -\-> -->
<!--     <\!--   things.</p> -\-> -->

<!--     <\!-- <p> -\-> -->
<!--     <\!--   Will, Freedom of (30.6) The myth that human volition is based upon some -\-> -->
<!--     <\!--   third alternative to either causality or chance.</p> -\-> -->

<!--     <h2 class="endmatter" id="references">Additional references</h2> -->

<!--     <p> -->
<!--       Several sections of this book were adapted from my earlier -->
<!--       publications. The discussion of mathematics in section 18.08 is based -->
<!--       partly on <em>Form and Content in Computer Science,</em> [Assoc. -->
<!--       Computing Machinery, January 1972], and partly on my introduction to -->
<!--       LogoWorks by Cynthia Solomon, Margaret Minsky, Brian Harvey (eds.), -->
<!--       McGraw-Hill, 1985.  Section 2.06 is based on <em>Why People Think -->
<!-- 	Computers Can&#39;t,</em> in AI Magazine, Fall 1982. Some of chapter 30 -->
<!--       was adapted from my essay <em>Matter, Mind and Models</em> in my book -->
<!--       Semantic Information Processing, MIT Press, 1968. Some of the ideas -->
<!--       about definitions came from my book Computation: Finite and Infinite -->
<!--       Machines, Prentice-Hall, 1967. The Hogarth quotations are from The -->
<!--       Analysis of Beauty, 1753. The Lavoisier quotation is from Elements of -->
<!--       Chemistry, 1783.</p> -->

<!--     <p> -->
<!--       MATTER, MIND, AND MODELS Published in Proc. International Federation of -->
<!--       Information Processing Congress 1965, vol. 1, pp. 45-49.</p> -->

<!--     <p> -->
<!--       Marvin L. Minsky</p> -->

<!--     <p> -->
<!--       9.1 Introduction This chapter attempts to explain why people become -->
<!--       confused by questions about the relation between mental and physical -->
<!--       events.  When a question leads to confused, inconsistent answers, this -->
<!--       may be because the question is ultimately meaningless or at least -->
<!--       unanswerable, but it may also be because an adequate answer requires a -->
<!--       powerful analytical apparatus. It is the author&#39;s view that many -->
<!--       important questions about the relation between mind and brain are of -->
<!--       this latter kind, and that some of the necessary technical and -->
<!--       conceptual tools are becoming available as a result of work on the -->
<!--       problems of making computer programs behave intelligently. We shall -->
<!--       suggest a theory to explain why introspection does not give clear -->
<!--       answers to these questions. Technical solutions to the questions will -->
<!--       not be attempted, but there is probably some value in finding at least a -->
<!--       clear explanation of why we are confused.</p> -->

<!--     <p> -->
<!--       9.2 Knowledge and Models If a creature can answer a question about a -->
<!--       hypothetical experiment without actually performing it, then it has -->
<!--       demonstrated some knowledge about the world. For, his answer to the -->
<!--       question must be an encoded description of the behavior (inside the -->
<!--       creature) of some sub-machine or <em>model</em> responding to an encoded -->
<!--       description of the world situation described by the question.  We use -->
<!--       the term <em>model</em> in the following sense: To an observer B, an -->
<!--       object A* is a model of an object A to the extent that B can use A* to -->
<!--       answer questions that interest him about A.  The model relation is -->
<!--       inherently ternary. Any attempt to suppress the role of the intentions -->
<!--       of the investigator B leads to circular definitions or to ambiguities -->
<!--       about <em>essential features</em> and the like.  It is understood that -->
<!--       B&#39;s use of a model entails the use of encodings for input and -->
<!--       output, both for A and for A*. If A is the world, questions for A are -->
<!--       experiments. A* is a good model of A, in B&#39;s view, to the extent -->
<!--       that A*&#39;s answers agree with those of A&#39;s, on the whole, with -->
<!--       respect to the questions important to B.  When a man M answers questions -->
<!--       about the world, then (taking on ourselves the role of B) we attribute -->
<!--       this ability to some internal mechanism W* inside of M. It would be most -->
<!--       convenient if we could discern physically within M two separate regions, -->
<!--       W* and M-W*, such that W* <em>really contains the knowledge</em> and -->
<!--       M-W* contains only general-purpose machinery for coding questions, -->
<!--       decoding answers, and general administrative work. However, one cannot -->
<!--       really expect to find, in an intelligent machine, a clear separation -->
<!--       between coding and knowledge structures, either anatomically or -->
<!--       functionally, because (for example) some -->
<!--       <em>knowledge</em> is likely to be used in the encoding and interpreting -->
<!--       processes. What is important for our purposes is the intuitive notion of -->
<!--       a model, not the technical ability to delineate a model&#39;s -->
<!--       boundaries.</p> -->

<!--     <p> -->
<!--       Indeed, part of our argument hinges on the inherent difficulty of -->
<!--       discerning such boundaries. -->
      
<!--       9.3 Models of Models Questions about things in the world are answered by -->
<!--       making statements about the behavior of corresponding structures in -->
<!--       one&#39;s model W* of the world. For simple mechanical, physical, or -->
<!--       geometric matters one can imagine, as did Craik (1), some machinery that -->
<!--       does symbolic calculation but when read through proper codings has an -->
<!--       apparently analogue character. But what about broader questions about -->
<!--       the nature of the world? These have to be treated (by M) not as -->
<!--       questions to be answered by W*, but as questions to be answered by -->
<!--       making general statements about W*. If W* contains a model M* of M, then -->
<!--       M* can contain a model W** of W*; and, going one step further, W** may -->
<!--       contain a model M** of M*. Indeed, this must be the case if M is to -->
<!--       answer general questions about himself. Ordinary questions about -->
<!--       himself, e.g., how tall he is, are answered by M*, but very broad -->
<!--       questions about his nature, e.g., what kind of a thing he is, etc., are -->
<!--       answered, if at all, by descriptive statements made by M** about M*. -->
<!--       The reader may be anxious, at this point, for more details about the -->
<!--       relation between W* and W**. How can he tell, for example, when a -->
<!--       question is of the kind that requires reference to W** rather than to -->
<!--       W*. Is W** a part of W*? (Certainly W*, like everything else, is part of -->
<!--       W.) Unfortunately, I cannot supply these details yet, and I expect -->
<!--       serious problems in eventually clarifying them. We must envision W* as -->
<!--       including an interpretative mechanism that can make reference to W*, -->
<!--       using it as a sort of computer-program subroutine, to a certain depth of -->
<!--       recursion. In this sense W** must contain W*, but in another, more -->
<!--       straightforward, sense W* can contain W**. This suggests first that the -->
<!--       notion <em>contained in</em> is not sufficiently sophisticated to -->
<!--       describe the kinds of relations between parts of programlike processes -->
<!--       and second that the intuitive notion of <em>model</em> used herein is -->
<!--       likewise too unsophisticated to support developing the theory in -->
<!--       technical detail. It is clear that in this area one cannot describe -->
<!--       intermodel relationships in terms of models as simply physical -->
<!--       substructures. An adequate analysis will need much more advanced ideas -->
<!--       about symbolic representation of information-processing structures.</p> -->

<!--     <p> -->
<!--       9.4 Dimorphism of our World Models A man&#39;s model of the world has a -->
<!--       distinctly bipartite structure: One part is concerned with matters of -->
<!--       mechanical, geometrical, physical character, while the other is -->
<!--       associated with things like goals, meanings, social matters, and the -->
<!--       like. This division of W* carries through the representations of many -->
<!--       things in W*, especially to M itself.  Hence, a man&#39;s model of -->
<!--       himself is bipartite, one part concerning his body as a physical object -->
<!--       and the other accounting for his social and psychological -->
<!--       experience. When we see an object, we account for its mechanical support -->
<!--       and coherence (we are amazed at levitations) and we also account, in -->
<!--       different terms, for its teleology (who put it there and for what -->
<!--       purpose). When something moves we find either a simple force or a -->
<!--       purpose &mdash; rarely both &mdash; in the kind of ordinary common-sense -->
<!--       explanation that concerns us here.  Why is this division so richly -->
<!--       represented in language and thought?  We recognize that a person&#39;s -->
<!--       W* is not really two clearly disjoint parts but must have many -->
<!--       overlapping, indistinctly bounded models.  The bipartite structure -->
<!--       proposed here is only an approximation, and we do not really want to -->
<!--       suggest that the argument depends at all on a clear division into any -->
<!--       particular number of parts.  The distinction between energetic and -->
<!--       informational (or symbolic) explanations is another aspect of the same -->
<!--       general dimorphism. In one sphere, mechanical-geometric constraints are -->
<!--       powerful, e.g., impenetrability in the arrangement of physical objects, -->
<!--       conservation in their transformation. In the other sphere one finds -->
<!--       symbolic restraints of (substantially) equal power. The two domains -->
<!--       overlap in many complicated ways: a child discovers mechanical obstacles -->
<!--       (in the form, e.g., of limitation of reach, mobility, strength, and -->
<!--       precision) to its psychological goals; it discovers emotional symbols in -->
<!--       the geometric arrangements of facial expressions, and intentions in -->
<!--       postural attitudes. In explanations of complicated things the two models -->
<!--       become inextricably involved &mdash; viz. the imagery of the preceding -->
<!--       sentences. But this involvement reflects not so much any synthesis of -->
<!--       the two kinds of explanation as it reflects the poverty of either model -->
<!--       for description of complicated situations.  As for the genesis of such -->
<!--       partitions, I suppose that they grow apart rather than together, on the -->
<!--       whole. That is not to say that infantile, primitive models are more -->
<!--       unitary, but rather that they are simply too indistinct to admit -->
<!--       approximate boundaries. An infant is not a monist: It simply hasn&#39;t -->
<!--       enough structure in M* to be a dualist yet; it can hardly be said to -->
<!--       have a position on the mind-body problem. -->
      
<!--       9.5 The Central Argument: Belief in Dualism When a man is asked a -->
<!--       general question about his own nature, he will try to give a general -->
<!--       description of his model of himself. That is, the question will be -->
<!--       answered by M**. To the extent that M* is divided as we have supposed -->
<!--       and that the man has discovered this (that is, this fact is now -->
<!--       represented in M**), his reply will show this.  His statement (his -->
<!--       belief) that he has a mind as well as a body is the conventional way to -->
<!--       express the roughly bipartite appearance of his model of himself. -->
<!--       Because the separation of the two parts of M* is so indistinct and their -->
<!--       interconnections are so complicated and difficult to describe, the -->
<!--       man&#39;s further attempts to elaborate on the nature of -->
<!--       this <em>mind-body</em> distinction are bound to be confused and -->
<!--       unsatisfactory.</p> -->

<!--     <p> -->
<!--       9.6 Heuristic Vale of Quasi-Separate Models From a scientific point of -->
<!--       view, it is desirable to obtain a unitary model of the world comprising -->
<!--       both mechanical and psychological phenomena. Such a theory would become -->
<!--       available, for example, if the workers in artificial intelligence, -->
<!--       cybernetics, and neurophysiology would all reach their goals. Still, -->
<!--       such a success might have little effect on the over-all form of our -->
<!--       personal world models. I maintain that for practical, heuristic reasons, -->
<!--       these would still retain their form of quasi-separate parts. Even when a -->
<!--       disciple is grossly transformed in techniques, bases, and concepts, it -->
<!--       can maintain its identity if its problems and concerns remain grouped -->
<!--       together for practical reasons.  For example, Chemistry survives today -->
<!--       as a science because the primitives of the quantum theory are a little -->
<!--       too remote for direct application to practical problems; a hierarchy of -->
<!--       intermediate concepts is necessary to apply the theory to everyday -->
<!--       problems. The primitive notions of physics, or even of neurophysiology, -->
<!--       will be far too remote to be useful in accounting directly for the -->
<!--       mental events of everyday life.</p> -->

<!--     <p> -->
<!--       Thus synthesis by direct theoretical reduction is unlikely to have a -->
<!--       large effect on the over-all form of W*. The heuristic need for -->
<!--       approximately self-contained subtheories is too strong to resist in -->
<!--       practical life and thought. Now one might hope for another kind of unity -->
<!--       &mdash; parallel rather than hierarchical &mdash; in which the -->
<!--       quasi-separate models are converted to basically similar structures and -->
<!--       then merged by removal of redundancy, with coding for those differences -->
<!--       that remain significant. It is doubtful that much can be done in this -->
<!--       direction.  The use of psychological explanations for physical processes -->
<!--       runs exactly counter to the directions that have led to scientific -->
<!--       progress.  Similarly, there have long been available plenty -->
<!--       of <em>reductions</em> of psychological explanations to analogies with -->
<!--       simple physical systems, but these are recognized as inadequate and are -->
<!--       giving way to information-processing models of more abstract character. -->
<!--       In everyday practical thought, physical analogy metaphors play a large -->
<!--       role, presumably because one gets a large payoff for a model of -->
<!--       apparently small complexity. (Actually, only the incremental complexity -->
<!--       is small because most of the model is already there as part of -->
<!--       the <em>physical</em> part of W*.) It would be hard to give up such -->
<!--       metaphors, even though they probably interfere with our further -->
<!--       development, just because of this apparent high value-to-cost ratio.  We -->
<!--       cannot expect to get much more by extending the mechanical analogies, -->
<!--       because they are so inflexible in character. Mental processes resemble -->
<!--       more the kinds of processes found in computer programs: arbitrary -->
<!--       symbol-associations, treelike storage schemes, conditioned transfers, -->
<!--       and the like. In short, we can expect the simpler useful mechanical -->
<!--       analogies to survive, but it seems doubtful that they can grow to bring -->
<!--       us usable ideas for the parallel unification of W*.  Finally, we should -->
<!--       note that in a creature with high intelligence one can expect to find a -->
<!--       well-developed special model concerned with the creature&#39;s own -->
<!--       problem-solving activity. In my view the key to any really advanced -->
<!--       problem-solving technique must exploit some mechanism for planning -->
<!--       &mdash; for breaking the problem into parts and shrewdly allocating the -->
<!--       machine&#39;s effort and resources for the work ahead. This means the -->
<!--       machine must have facilities for representing and analyzing its own -->
<!--       goals and resources. One could hardly expect to find a useful way to -->
<!--       merge this structure with that used for analyzing uncomplicated -->
<!--       structures in the outer world, nor could one expect that anything much -->
<!--       simpler would be of much power in analyzing the behavior of other -->
<!--       creatures of the same character. -->
      
<!--       9.7 Interpreters The notion of <em>part</em> is more complicated for -->
<!--       things like computer programs than for ordinary physical objects. A -->
<!--       single conditional branch makes it possible for a program to behave, -->
<!--       functionally, like two very different machines in different -->
<!--       circumstances, yet using almost (or exactly) the same sets of -->
<!--       instructions.  The notion of a machine containing a model of itself is -->
<!--       also complicated, and one might suspect potential logical paradoxes. -->
<!--       There is no logical problem about the basic idea, for the internal model -->
<!--       could be very much simplified, and its internal model could be -->
<!--       vacuous. But, in fact, there is no paradox even in a machine&#39;s -->
<!--       having a model of itself complete in all detail. For example, it is -->
<!--       possible to construct a Turing machine that can print out an entire -->
<!--       description of itself and also execute an arbitrarily complicated -->
<!--       computation, so that the machine is not expending all its structure on -->
<!--       its description.  In particular, the machine can contain -->
<!--       an <em>interpretative</em> program that can use the internal description -->
<!--       to calculate what it itself would do under some hypothetical -->
<!--       circumstance. Similarly, while it is impossible for a machine or mind to -->
<!--       analyze from moment to moment precisely what it is doing at each step -->
<!--       (for it would never get past the first step), there seems to be no -->
<!--       logical limitation to the possibility of a machine understanding its own -->
<!--       basic principles of operation or, given enough memory, examining all the -->
<!--       details of its operation in some previously recorded state.  With -->
<!--       interpretative operation ability, a program can use itself as its own -->
<!--       model, and this can be repeated recursively to as many levels as -->
<!--       desired, until the memory records of the state of the process get out of -->
<!--       hand. With the possibility of this sort of -->
<!--       <em>introspection,</em> the boundaries between parts, things, and models -->
<!--       become very hard to understand.  Does interpreted operation play an -->
<!--       important role in our mental function? It is clear that one interprets -->
<!--       memorized instructions in certain circumstances. One could memorize, for -->
<!--       example, the rules for reading musical notation and then actually -->
<!--       perform a piece of music, at a very slow tempo, by referring to these -->
<!--       rules in executing each note. Eventually, with practice, one plays -->
<!--       faster, and it seems clear that one is no longer interpreting the rules -->
<!--       for each note, but that one has assembled special mechanisms for the -->
<!--       task. This certainly suggests an analogy with the notion of -->
<!--       <em>compiling</em> a previously interpreted program. Perhaps our level -->
<!--       of consciousness is closely related to the extent to which the machine -->
<!--       is functioning interpretatively rather than executing compiled programs. -->
<!--       While interpreting, one has the opportunity of examining the next step -->
<!--       in the task before doing it. -->
      
<!--       9.8 Free Will If one thoroughly understands a machine or a program, he -->
<!--       finds no urge to attribute <em>volition</em> to it. If one does not -->
<!--       understand it so well, he must supply an incomplete model for -->
<!--       explanation. Our everyday intuitive models of higher human activity are -->
<!--       quite incomplete, and many notions in our informal explanations do not -->
<!--       tolerate close examination. Free will or volition is one such notion: -->
<!--       people are incapable of explaining how it differs from stochastic -->
<!--       caprice but feel strongly that it does. I conjecture that this idea has -->
<!--       its genesis in a strong primitive defense mechanism. Briefly, in -->
<!--       childhood we learn to recognize various forms of aggression and -->
<!--       compulsion and to dislike them, whether we submit or resist. Older, when -->
<!--       told that our behavior is <em>controlled</em> by such and such a set of -->
<!--       laws, we insert this fact in our model (inappropriately) along with -->
<!--       other recognizers of compulsion. We resist <em>compulsion,</em> no -->
<!--       matter from -->
<!--       <em>whom.</em> Although resistance is logically futile, the resentment -->
<!--       persists and is rationalized by defective explanations, since the -->
<!--       alternative is emotionally unacceptable.  How is this reflected in M*? -->
<!--       If one asks how one&#39;s mind works, he notices areas where it is -->
<!--       (perhaps incorrectly) understood &mdash; that is, where one recognizes -->
<!--       rules. One sees other areas where he lacks rules. One could fill this in -->
<!--       by postulating chance or random activity.  But this too, by another -->
<!--       route, exposes the self to the same indignity of remote control. We -->
<!--       resolve this unpleasant form of M* by postulating a third part, -->
<!--       embodying a will or spirit or conscious agent. But there is no structure -->
<!--       in this part; one can say nothing meaningful about it, because whenever -->
<!--       a regularity is observed, its representation is transferred to the -->
<!--       deterministic rule region. The will model is thus not formed from a -->
<!--       legitimate need for a place to store definite information about -->
<!--       one&#39;s self; it has the singular character of being forced into the -->
<!--       model, willy-nilly, by formal but essentially content-free ideas of what -->
<!--       the model must contain. -->
      
<!--       9.9 Conclusion When intelligent machines are constructed, we should not -->
<!--       be surprised to find them as confused and as stubborn as men in their -->
<!--       convictions about mind-matter, consciousness, free will, and the like. -->
<!--       For all such questions are pointed at explaining the complicated -->
<!--       interactions between parts of the self-model. A man&#39;s or a -->
<!--       machine&#39;s strength of conviction about such things tells us nothing -->
<!--       about the man or about the machine except what it tells us about his -->
<!--       model of himself.  The gross divisions of our models probably have as -->
<!--       much heuristic value to us. Indeed we identify (in children) some stages -->
<!--       in delineating the distinctions between these models as associated with -->
<!--       the growth of intelligence. The distinctions could be abandoned only at -->
<!--       great cost in everyday practice. That is why, even if one accepts the -->
<!--       conclusions of this essay, he is unlikely to note any serious effect on -->
<!--       his way of thinking about most things.</p> -->

<!--     <p> -->
<!--       Bibliography</p> -->

<!--     <p> -->
<!--       1. Craik, K. J. W., The Nature of Explanation, Cambridge University -->
<!--       Press, Cambridge, England, 1952.</p> -->

<!--     <p> -->
<!--       ARTIFICAL INTELLIGENCE: A FRAMEWORK FOR REPRESENTING KNOWLEDGE -->
<!--       Artificial Intelligence Memo no. 306</p> -->

<!--     <p> -->
<!--       Marvin Minsky June 1974</p> -->

<!--     <p> -->
<!--       Abstract This is a partial theory of thinking combining a number of -->
<!--       classical and modern concepts from psychology, linguistics, and -->
<!--       AI. Whenever one encounters a new situation (or makes a substantial -->
<!--       change in one&#39;s viewpoint) he selects from memory a structure called -->
<!--       a frame: a remembered network to be adapted to its reality by changing -->
<!--       details as necessary.  A frame is a data-structure for representing a -->
<!--       stereotyped situation, like being in a certain kind of living room, or -->
<!--       going to a child&#39;s birthday party. Attached to each frame are -->
<!--       several different kinds of information. Some of this information is -->
<!--       about how to use the frame. Some is about what one can expect to happen -->
<!--       next. Some is about what to do if these expectations are not confirmed. -->
<!--       The <em>top levels</em> of a frame are fixed, and represent things that -->
<!--       are always true about the supposed situation. The lower levels have -->
<!--       many <em>slots</em> that must be filled by specific instances or data. -->
<!--       Collections of related frames are linked together into frame-systems. -->
<!--       The effects of important actions are mirrored by transformations between -->
<!--       the frames of system. These are used to make certain kinds of -->
<!--       calculations economical, to represent changes of emphasis and attention, -->
<!--       and to account for the effectiveness of <em>imagery.</em>  In Vision, -->
<!--       the different frames of a system describe the scene from different -->
<!--       viewpoints, and the transformations between one frame and another -->
<!--       represent the effects of moving from place to place.  Other kinds of -->
<!--       frame-systems can represent actions, cause-effect relations, or changes -->
<!--       in conceptual viewpoint. The paper applies the frame-system idea also to -->
<!--       problems or linguistic understanding: memory, acquisition and retrieval -->
<!--       of knowledge, and a variety of ways to reason by analogy and jump to -->
<!--       conclusions based on partial similarity matching.</p> -->

<!--     <p> -->
<!--       1. FRAMES</p> -->

<!--     <p> -->
<!--       It seems to me that the ingredients of most theories both in Artificial -->
<!--       Intelligence and in Psychology have been on the whole too minute, local, -->
<!--       and unstructured to account &mdash; either practically or -->
<!--       phenomenologically &mdash; for the effectiveness of common-sense -->
<!--       thought.  The <em>chunks</em> of reasoning, language, memory, -->
<!--       and <em>perception</em> ought to be larger and more structured; their -->
<!--       factual and procedural contents must be more intimately connected in -->
<!--       order to explain the apparent power and speed of mental activities. -->
<!--       Similar feelings seem to be emerging in several centers working on -->
<!--       theories of intelligence. They take one form in the proposal of Papert -->
<!--       and myself (1972) to sub-structure knowledge into <em>micro-worlds</em>; -->
<!--       another form in the <em>Problem-spaces</em> of Newell and Simon (1972); -->
<!--       and yet another in new, large structures that theorists like Schank -->
<!--       (1974), Abelson (1974), and Norman (1972) assign to linguistic -->
<!--       objects. I see all these as moving away from the traditional attempts -->
<!--       both by behavioristic psychologists and by logic-oriented students of -->
<!--       Artificial Intelligence in trying to represent knowledge as collections -->
<!--       of separate, simple fragments.  I try here to bring together several of -->
<!--       these issues by pretending to have a unified, coherent theory. The paper -->
<!--       raises more questions than it answers, and I have tried to note the -->
<!--       theory&#39;s deficiencies.  Here is the essence of the theory: When one -->
<!--       encounters a new situation (or makes a substantial change in one&#39;s -->
<!--       view of the present problem) one selects from memory a structure called -->
<!--       a Frame. This is a remembered framework to be adapted to fit reality by -->
<!--       changing details as necessary.  A frame is a data-structure for -->
<!--       representing a stereotyped situation, like being in a certain kind of -->
<!--       living room, or going to a child&#39;s birthday party. Attached to each -->
<!--       frame are several kinds of information. Some of this information is -->
<!--       about how to use the frame.  Some is about what one can expect to happen -->
<!--       next. Some is about what to do if these expectations are not confirmed. -->
<!--       We can think of a frame as a network of nodes and relations. The -->
<!--       <em>top levels</em> of a frame are fixed, and represent things that are -->
<!--       always true about the supposed situation. The lower levels have many -->
<!--       terminals &mdash; <em>slots</em> that must be filled by specific -->
<!--       instances or data. Each terminal can specify conditions its assignments -->
<!--       must meet. (The assignments themselves are usually smaller -->
<!--       <em>sub-frames.</em>) Simple conditions are specified by markers that -->
<!--       might require a terminal assignment to be a person, an object of -->
<!--       sufficient value, or a pointer to a sub-frame of a certain type. More -->
<!--       complex conditions can specify relations among the things assigned to -->
<!--       several terminals.  Collections of related frames are linked together -->
<!--       into frame-systems. The effects of important actions are mirrored by -->
<!--       transformations between the frames of a system. These are used to make -->
<!--       certain kinds of calculations economical, to represent changes of -->
<!--       emphasis and attention, and to account for the effectiveness -->
<!--       of <em>imagery.</em>  For visual scene analysis, the different frames of -->
<!--       a system describe the scene from different viewpoints, and the -->
<!--       transformations between one frame and another represent the effects of -->
<!--       moving from place to place. For non-visual kinds of frames, the -->
<!--       differences between the frames of a system can represent actions,</p> -->

<!--     <p> -->
<!--       cause-effect relations, or changes in conceptual viewpoint. Different -->
<!--       frames of a system share the same terminals; this is the critical point -->
<!--       that makes it possible to coordinate information gathered from different -->
<!--       viewpoints.  Much of the phenomenological power of the theory hinges on -->
<!--       the inclusion of expectations and other kinds of presumptions. A -->
<!--       frame&#39;s terminals are normally already filled with <em>default</em> -->
<!--       assignments.  Thus, a frame may contain a great many details whose -->
<!--       supposition is not specifically warranted by the situation. These have -->
<!--       many uses in representing general information, most likely cases, -->
<!--       techniques for bypassing <em>logic,</em> and ways to make useful -->
<!--       generalizations.  The default assignments are attached loosely to their -->
<!--       terminals, so that they can be easily displaced by new items that fit -->
<!--       better the current situation. They thus can serve also -->
<!--       as <em>variables</em> or as special cases for <em>reasoning by -->
<!-- 	example,</em> or as <em>textbook cases,</em> and often make the use of -->
<!--       logical quantifiers unnecessary.  The frame-systems are linked, in turn, -->
<!--       by an information retrieval network. When a proposed frame cannot be -->
<!--       made to fit reality &mdash; when we cannot find terminal assignments -->
<!--       that suitably match its terminal marker conditions &mdash; this network -->
<!--       provides a replacement frame. These inter-frame structures make possible -->
<!--       other ways to represent knowledge about facts, analogies, and other -->
<!--       information useful in understanding.  Once a frame is proposed to -->
<!--       represent a situation, a matching process tries to assign values to each -->
<!--       frame&#39;s terminals, consistent with the markers at each place. The -->
<!--       matching process is partly controlled by information associated with the -->
<!--       frame (which includes information about how to deal with surprises) and -->
<!--       partly by knowledge about the system&#39;s current goals. There are -->
<!--       important uses for the information, obtained when a matching process -->
<!--       fails. I will discuss how it can be used to select an alternative frame -->
<!--       that better suits the situation.  Apology! The schemes proposed herein -->
<!--       are incomplete in many respects. First, I often propose representations -->
<!--       without specifying the processes that will use them. Sometimes I only -->
<!--       describe properties the structures should exhibit. I talk about markers -->
<!--       and assignments as though it were obvious how they are attached and -->
<!--       linked; it is not.  Besides the technical gaps, I will talk as though -->
<!--       unaware of many problems related to <em>understanding</em> that really -->
<!--       need much deeper analysis. I do not claim that the ideas proposed here -->
<!--       are enough for a complete theory, but only that the frame-system scheme -->
<!--       may help explain a number of phenomena of human intelligence. The basic -->
<!--       frame idea itself is not particularly original &mdash; it is in the -->
<!--       tradition of the <em>schema</em> of Bartlett and the <em>paradigms</em> -->
<!--       of Kuhn (1970); the idea of a frame-system is probably more novel. -->
<!--       Winograd (1974) discusses the recent trend, in theories of Artificial -->
<!--       Intelligence, toward frame-like ideas.  The rest of 1 applies the -->
<!--       frame-system idea to vision and imagery.  In 2 we turn to linguistic and -->
<!--       other kinds of understanding. 3 discusses memory, acquisition, and -->
<!--       retrieval of knowledge; 4 is about control, and 5 takes up other -->
<!--       problems of vision and spatial imagery.  In the body of the paper I -->
<!--       discuss a variety of kinds of reasoning by analogy, and ways to impose -->
<!--       stereotypes on reality and jump to conclusions based on partial -->
<!--       similarity matching. These are basically uncertain methods. Why not use -->
<!--       methods that are more <em>logical</em> and certain? Section 6 is a sort -->
<!--       of Appendix which argues that traditional logic cannot deal very well -->
<!--       with realistic, complicated problems because it is poorly suited to -->
<!--       represent approximations to solutions &mdash; and these are absolutely -->
<!--       vital.</p> -->

<!--     <p> -->
<!--       <em>Thinking always begins with suggestive but imperfect plans and -->
<!-- 	images; these are progressively replaced by better &mdash; but usually -->
<!-- 	still imperfect &mdash; ideas.</em> -->
      
      
<!--       1.1 LOCAL AND GLOBAL THEORIES FOR VISION</p> -->

<!--     <p> -->
<!--       <em>For there exists a great chasm between those, on the one side, who -->
<!-- 	relate everything to a single central vision, one system more or less -->
<!-- 	coherent or articulate, in terms of which they understand, think and -->
<!-- 	feel &mdash; a single, universal, organizing principle in terms of -->
<!-- 	which alone all that they are and say has significance &mdash; and, on -->
<!-- 	the other side, those who pursue many ends, often unrelated and even -->
<!-- 	contradictory, connected, if at all, only in some de facto way, for -->
<!-- 	some psychological or physiological cause, related by no moral or -->
<!-- 	esthetic principle. . . .</em> -->
      
<!--       I. Berlin, The Hedgehog and the Fox</p> -->

<!--     <p> -->
<!--       When we enter a room we seem to see the entire scene at a glance.  But -->
<!--       seeing is really an extended process. It takes time to fill in details, -->
<!--       collect evidence, make conjectures, test, deduce, and interpret in ways -->
<!--       that depend on our knowledge, expectations and goals. Wrong first -->
<!--       impressions have to be revised. Nevertheless, all this proceeds so -->
<!--       quickly and smoothly that it seems to demand a special explanation. -->
<!--       Some people dislike theories of vision that explain scene-analysis -->
<!--       largely in terms of discrete, serial, symbolic processes. They feel that -->
<!--       although programs built on such theories may indeed seem -->
<!--       to <em>see,</em> they must be too slow and clumsy for a nervous system -->
<!--       to use. But the alternative usually proposed is some extreme position -->
<!--       of <em>holism</em> that never materializes into a technical proposal. I -->
<!--       will argue that serial symbolic mechanisms could indeed explain much of -->
<!--       the apparent instantaneity and completeness of visual experience.  Some -->
<!--       early Gestalt theorists tried to explain a variety of visual phenomena -->
<!--       in terms of global properties of electrical fields in the brain. This -->
<!--       idea did not come to much (Koffka, 1935). Its modern counterpart, a -->
<!--       scattered collection of attempts to use ideas about integral transforms, -->
<!--       holograms, and interference phenomena, has done no better. In spite of -->
<!--       this, most thinkers outside (and some inside) the symbolic processing -->
<!--       community still believe that only through some sort of field-like global -->
<!--       parallel process could the required speed be attained.  While my theory -->
<!--       is thus addressed to basic problems of Gestalt psychology, the method is -->
<!--       fundamentally different. In both approaches, one wants to explain the -->
<!--       structuring of sensory data into wholes and parts. Gestalt theorists -->
<!--       hoped this could be based primarily on the operation of a few general -->
<!--       and powerful principles; but these never crystallized effectively and -->
<!--       the proposal lost popularity. In my theory the analysis is based on many -->
<!--       interactions between sensations and a huge network of learned symbolic -->
<!--       information. While ultimately those interactions must themselves be -->
<!--       based also on a reasonable set of powerful principles, the performance -->
<!--       theory is separate from the theory of how the system might originate and -->
<!--       develop. -->
      
      
<!--       1.2 PARALLELISM</p> -->

<!--     <p> -->
<!--       Would parallel processing help? This is a more technical question than -->
<!--       it might seem. At the level of detecting elementary visual features, -->
<!--       texture elements, stereoscopic and motion-parallax cues, it is obvious -->
<!--       that parallel processing might be useful. At the level of grouping -->
<!--       features into objects, it is harder to see exactly how to use -->
<!--       parallelism, but one can at least conceive of the aggregation of -->
<!--       connected <em>nuclei</em> (Guzman, 1968), or the application of boundary -->
<!--       line constraint semantics (Waltz, 1972), performed in a special parallel -->
<!--       network.  At <em>higher</em> levels of cognitive processing, however, I -->
<!--       suspect fundamental limitations in the usefulness of parallelism. Many -->
<!--       <em>integral</em> schemes were proposed in the literature on <em>pattern -->
<!-- 	recognition</em> for parallel operations on pictorial material &mdash; -->
<!--       perceptrons, integral transforms, skeletonizers, and so forth. These -->
<!--       mathematically and computationally interesting schemes might quite -->
<!--       possibly serve as ingredients of perceptual processing theories.  But -->
<!--       as ingredients only! Basically, <em>integral</em> methods work only on -->
<!--       isolated figures in two dimensions. They fail disastrously to cope -->
<!--       with complicated, three-dimensional scenery. Why?  In complex scenes, -->
<!--       the features belonging to different objects have to be correctly -->
<!--       segregated to be meaningful; but solving this problem &mdash; which is -->
<!--       equivalent to the traditional Gestalt -->
<!--       <em>figure-ground</em> problem &mdash; presupposes solutions for so many -->
<!--       visual problems that the possibility and perhaps even the desirability -->
<!--       of a separate recognition technique falls into question, as noted by -->
<!--       Minsky and Papert (1969). In three dimensions the problem is further -->
<!--       confounded by the distortion of perspective and by the occlusions of -->
<!--       parts of each figure by its own surfaces and those of other figures. -->
<!--       The new, more successful symbolic theories use hypothesis formation and -->
<!--       confirmation methods that seem, on the surface at least, more inherently -->
<!--       serial. It is hard to solve any very complicated problem without giving -->
<!--       essentially full attention, at different times, to different -->
<!--       sub-problems. Fortunately, however, beyond the brute idea of doing many -->
<!--       things in parallel, one can imagine a more serial process that deals -->
<!--       with large, complex, symbolic structures as units!  This opens a new -->
<!--       theoretical <em>niche</em> for performing a rapid selection of large -->
<!--       substructures; in this niche our theory hopes to find the secret of -->
<!--       speed, both in vision and in ordinary thinking.</p> -->

<!--     <p> -->
<!--       1.3 ARTIFICIAL INTELLIGENCE AND HUMAN PROBLEM SOLVING -->
      
<!--       In this essay I draw no boundary between a theory of human thinking and -->
<!--       a scheme for making an intelligent machine; no purpose would be served -->
<!--       by separating these today since neither domain has theories good enough -->
<!--       to explain &mdash; or to produce &mdash; enough mental capacity. There -->
<!--       is, however, a difference in professional attitudes. Workers from -->
<!--       psychology inherit stronger desires to minimize the variety of assumed -->
<!--       mechanisms. I believe this leads to attempts to extract more performance -->
<!--       from fewer <em>basic mechanisms</em> than is reasonable. Such theories -->
<!--       especially neglect mechanisms of procedure control and explicit -->
<!--       representations of processes. On the other side, workers in Artificial -->
<!--       Intelligence have perhaps focused too sharply on just such -->
<!--       questions. Neither have given enough attention to the structure of -->
<!--       knowledge, especially procedural knowledge.  It is understandable why -->
<!--       psychologists are uncomfortable with complex proposals not based on well -->
<!--       established mechanisms. But I believe that parsimony is still -->
<!--       inappropriate at this stage, valuable as it may be in later phases of -->
<!--       every science. There is room in the anatomy and genetics of the brain -->
<!--       for much more mechanism than anyone today is prepared to propose, and we -->
<!--       should concentrate for a while more on sufficiency and efficiency rather -->
<!--       than on necessity.  Up to a few years ago, the primary goal of AI work -->
<!--       on vision had to be sufficiency: to find any way at all to make a -->
<!--       machine analyze scenes. Only recently have we seen the first signs of -->
<!--       adequate capacity to aggregate features and cues correctly into parts -->
<!--       and wholes. I cite especially the sequence of work of Roberts (1965), -->
<!--       Guzman (1968), Winston (1970), Huffman (1971), Clowes (1971), Shirai -->
<!--       (1972), Waltz (1972), Binford (1971), Nevatia (1973) and Agin (1973) to -->
<!--       indicate some steps toward adequate analyses of figure-ground, -->
<!--       whole-part, and group-structuring issues.  Although this line of -->
<!--       development is still primitive, I feel it is sound enough that we can -->
<!--       ask it to explain not only the brute performance of vision but also some -->
<!--       of its speed and smoothness. Some new issues confront our theory when we -->
<!--       turn from sufficiency to efficiency: How can different kinds -->
<!--       of <em>cues</em> lead so quickly to identifying and describing complex -->
<!--       situations? How can one make changes in case of error or if new evidence -->
<!--       is found? How does one resolve inconsistencies? How can position change -->
<!--       without recomputing everything? What about moving objects? How does the -->
<!--       vision process exploit knowledge associated with general, non-visual -->
<!--       activities? How does one synthesize the information obtained from -->
<!--       different viewpoints? How can the system exploit generally correct -->
<!--       expectations about effects of contemplated actions? Can the theory -->
<!--       account for the phenomenological effects of imagery, the self-directed -->
<!--       construction and manipulation of imaginary scenes?  Very little was -->
<!--       learned about such matters in the main traditions of behavioral or of -->
<!--       perceptual psychology; but the speculations of some earlier -->
<!--       psychologists, particularly of Bartlett (1932), have surely found their -->
<!--       way into this essay. In the more recent tradition of symbolic -->
<!--       information processing theories, papers like those of Newell (1973) and -->
<!--       Pylyshyn (1973) take larger technical steps to formulate these issues.</p> -->

<!--     <p> -->
<!--       1.4 TRACKING THE IMAGE OF A CUBE</p> -->

<!--     <p> -->
<!--       <em>But in the common way of taking the view of any opake object, that -->
<!-- 	part of its surface, which fronts the eye, is apt to occupy the mind -->
<!-- 	alone, and the opposite, nay even every other part of it whatever, is -->
<!-- 	left unthought of at that time: and the least motion we make to -->
<!-- 	reconnoitre any other side of the object, confounds our first idea, -->
<!-- 	for want of the connexion of the two ideas, which the complete -->
<!-- 	knowledge of the whole world would naturally have given us, if we had -->
<!-- 	considered it the other way before.</em> -->
      
<!--       W. Hogarth, The Analysis of Beauty -->
      
<!--       I begin by developing a simplified frame-system to represent the -->
<!--       perspective appearances of a cube. Later I will adapt it to represent -->
<!--       the insides of rooms and to acquiring, using, and revising the kinds of -->
<!--       information one needs to move around within a house.  In the tradition -->
<!--       of Guzman and Winston, we assume that the result of looking at a cube is -->
<!--       a structure something like that in figure 1.1.</p> -->

<!--     <p> -->
<!--       The substructures <em>A</em> and <em>B</em> represent details or -->
<!--       decorations on two faces of the cube. When we move to the right, -->
<!--       face <em>A</em> disappears from view, while the new face decorated -->
<!--       with <em>C</em> is now seen. If we had to reanalyse the scene from the -->
<!--       start, we would have to (1) lose the knowledge about <em>A,</em> (2) -->
<!--       recompute <em>B,</em> and</p> -->

<!--     <p> -->
<!--       (3) compute the description of <em>C.</em> -->
      
<!--       But since we know we moved to the right, we can save <em>B</em> by -->
<!--       assigning it also to the <em>left face</em> terminal of a second -->
<!--       cube-frame. To save <em>A</em> (just in case!) we connect it also to an -->
<!--       extra, invisible face-terminal of the new cube-schema as in figure 1.2. -->
<!--     </p> -->

<!--     <p> -->
<!--     </p> -->

<!--     <p> -->
<!--       If later we move back to the left, we can reconstruct the first scene -->
<!--       without any perceptual computation at all: just restore the top-level -->
<!--       pointers to the first cube-frame. We now need a place to -->
<!--       store <em>C</em>; we can add yet another invisible face to the right in -->
<!--       the first cube-frame! See figure 1.3.</p> -->

<!--     <p> -->
<!--     </p> -->

<!--     <p> -->
<!--       We could extend this to represent further excursions around the object. -->
<!--       This would lead to a more comprehensive frame system, in which each -->
<!--       frame represents a different <em>perspective</em> of a cube. In figure -->
<!--       1.4 there are three frames corresponding to 45-degree MOVE-RIGHT and -->
<!--       MOVE-LEFT actions. If we pursue this analysis, the resulting system can -->
<!--       become very large; more complex objects need even more different -->
<!--       projections. It is not obvious either that all of them are normally -->
<!--       necessary or that just one of each variety is adequate. It all depends. -->
<!--       I am not proposing that this kind of complicated structure is recreated -->
<!--       every time one examines an object. I imagine instead that a great -->
<!--       collection of frame systems is stored in permanent memory, and one of -->
<!--       them is evoked when evidence and expectation make it plausible that the -->
<!--       scene in view will fit it. How are they acquired? I will propose that if -->
<!--       a chosen frame does not fit well enough, and if no better one is easily -->
<!--       found, and if the matter is important enough, then an adaptation of the -->
<!--       best one so far discovered will be constructed and remembered for future -->
<!--       use.</p> -->

<!--     <p> -->
<!--     </p> -->

<!--     <p> -->
<!--       Do we build such a system for every object we know? That would seem -->
<!--       extravagant. More likely, I would think, one has special systems for -->
<!--       important objects but also a variety of frames for generally -->
<!--       useful <em>basic shapes</em>; these are composed to form frames for new -->
<!--       cases.  The different frames of a system resemble the -->
<!--       multiple <em>models</em> described in Guzman (1967) and Winston -->
<!--       (1970). Different frames correspond to different views, and the names of -->
<!--       pointers between frames correspond to the motions or actions that change -->
<!--       the viewpoint. Later I discuss whether these views should be considered -->
<!--       as two- or as three-dimensional.  Each frame has terminals for attaching -->
<!--       pointers to substructures. Different frames can share the same terminal, -->
<!--       which can thus correspond to the same physical feature as seen in -->
<!--       different views. This permits us to represent, in a single place, view -->
<!--       independent information gathered at different times and places. This is -->
<!--       important also in non-visual applications.  The matching process which -->
<!--       decides whether a proposed frame is suitable is controlled partly by -->
<!--       one&#39;s current goals and partly by information attached to the frame; -->
<!--       the frames carry terminal markers and other constraints, while the goals -->
<!--       are used to decide which of these constraints are currently -->
<!--       relevant. Generally, the matching process could have these components: -->
<!--       (1) A frame, once evoked on the basis of partial evidence or -->
<!--       expectation, would first direct a test to confirm its own -->
<!--       appropriateness, using knowledge about recently noticed features, loci, -->
<!--       relations, and plausible subframes. The current goal list is used to -->
<!--       decide which terminals and conditions must be made to match reality. -->
      
<!--       (2) Next it would request information needed to assign values to those -->
<!--       terminals that cannot retain their default assignments. For example, it -->
<!--       might request a description of face <em>C,</em> if this terminal is -->
<!--       currently unassigned, but only if it is not marked <em>invisible.</em> -->
<!--       Such assignments must agree with the current markers at the terminal. -->
<!--       Thus, face <em>C</em> might already have markers for such constraints or -->
<!--       expectations as:</p> -->

<!--     <p> -->
<!--       * Right-middle visual field.  * Must be assigned.</p> -->

<!--     <p> -->
<!--       * Should be visible; if not, consider moving right.  * Should be a -->
<!--       cube-face subframe.  * Share left vertical boundary terminal with -->
<!--       face <em>B.</em>  * If failure, consider box-lying-on-side frame.  * -->
<!--       Same background color as face <em>B.</em>  (3) Finally, if informed -->
<!--       about a transformation (e.g., an impending motion) it would transfer -->
<!--       control to the appropriate other frame of that system. -->
      
<!--       Within the details of the control scheme are opportunities to embed many -->
<!--       kinds of knowledge. When a terminal-assigning attempt fails, the -->
<!--       resulting error message can be used to propose a second-guess -->
<!--       alternative. Later I will suggest using these to organize memory into a -->
<!--       Similarity Network as proposed in Winston (1970). -->
      
      
<!--       1.5 IS VISION SYMBOLIC?</p> -->

<!--     <p> -->
<!--       Can one really believe that a person&#39;s appreciation of -->
<!--       three-dimensional structure can be so fragmentary and atomic as to be -->
<!--       representable in terms of the relations between parts of two-dimensional -->
<!--       views? Let us separate, at once, the two issues: is imagery symbolic and -->
<!--       is it based on two-dimensional fragments? The first problem is one of -->
<!--       degree; surely everyone would agree that at some level vision is -->
<!--       essentially symbolic. The quarrel would be between certain naive -->
<!--       conceptions on one side &mdash; in which one accepts seeing either as -->
<!--       picture-like or as evoking imaginary solids &mdash; against the -->
<!--       confrontation of such experimental results of Piaget (1956) and others -->
<!--       in which many limitations that one might fear would result from symbolic -->
<!--       representations are shown actually to exist!  Thus we know that in the -->
<!--       art of children (and, in fact, in that of most adult cultures) graphic -->
<!--       representations are indeed composed from very limited, highly symbolic -->
<!--       ingredients. See, for example, chapter 2 of Gombrich -->
<!--       (1969). Perspectives and occlusions are usually not -->
<!--       represented <em>realistically</em> but by conventions. Metrical -->
<!--       relations are grossly distorted; complex forms are replaced by signs for -->
<!--       a few of their important features. Naive observers do not usually -->
<!--       recognize these devices and maintain that they do <em>see and manipulate -->
<!-- 	pictorial images</em> in ways that, to them, could not conceivably be -->
<!--       accounted for by discrete descriptions.</p> -->

<!--     <p> -->
<!--       As for our second question: the issue of two- vs.  three-dimensions -->
<!--       evaporates at the symbolic level. The very concept of dimension becomes -->
<!--       inappropriate. Each type of symbolic representation of an object serves -->
<!--       some goals well and others poorly.  If we attach the relation labels -->
<!--       left-of, right-of, and above between parts of the structure, say, as -->
<!--       markers on pairs of terminals, certain manipulations will work out -->
<!--       smoothly; for example, some properties of these relations -->
<!--       are <em>invariant</em> if we rotate the cube while keeping the same face -->
<!--       on the table. Most objects have <em>permanent</em> tops and bottoms. But -->
<!--       if we turn the cube on its side such predictions become harder to make; -->
<!--       people have great difficulty keeping track of the faces of a six-colored -->
<!--       cube if one makes them roll it around in their mind.  If one uses -->
<!--       instead more <em>intrinsic</em> relations like next-to and opposite-to, -->
<!--       then turning the object on its side disturbs the <em>image</em> much -->
<!--       less. In Winston we see how systematic replacements (e.g., of -->
<!--       <em>left</em> for <em>behind,</em> and <em>right</em> -->
<!--       for <em>in-front-of</em>) can simulate the effect of spatial rotation. -->
<!--       Hogarth (1753) did not take a position on the symbolic issue, but he did -->
<!--       consider good imagery to be an acquired skill and scolds artists who -->
<!--       give too little time to perfecting the ideas they ought to have in their -->
<!--       minds of the objects in nature. He recommends that -->
      
<!--       <em>[he who will undertake the acquisition of] perfect ideas of the -->
<!-- 	distances, bearings, and oppositions of several material points and -->
<!-- 	lines in even the most irregular figures, will gradually arrive at the -->
<!-- 	knack of recalling them into his mind when the objects themselves are -->
<!-- 	not before him &mdash; and will be of infinite service to those who -->
<!-- 	invent and draw from fancy, as well as to enable those to be more -->
<!-- 	correct who draw from the life.</em></p> -->

<!--     <p> -->
<!--       Thus, deliberate self-discipline in cataloguing relations between points -->
<!--       on opposing surfaces is, he thinks, a key to understanding the invariant -->
<!--       relations between the visible and invisible parts; they supply the -->
<!--       information needed to imagine oneself within the interior of the object, -->
<!--       or at other unexperienced locations; he thus rejects the naive image -->
<!--       idea.  Some people believe that we solve spatial problems by maintaining -->
<!--       in one&#39;s head, somehow, the analog of a three-dimensional structure. -->
<!--       But even if one somehow could assemble such a model there would remain, -->
<!--       for the <em>mind&#39;s eye,</em> most of the old problems we had for the -->
<!--       real eye as well as the new and very hard problem of assembling &mdash; -->
<!--       from two-dimensional data &mdash; the hypothetical imaginary solid. -->
<!--       Although these arguments may seem to favor interconnected -->
<!--       two-dimensional views for aggregation and recognition, I do not consider -->
<!--       these satisfactory for planning or for manipulative activities. Another -->
<!--       representation, still symbolic but in terms of basic solid forms, would -->
<!--       seem more natural. Thus a telephone handset could be described in terms -->
<!--       of two modified spherical forms connected by a curved, rectangular -->
<!--       bar. The problem of connecting two or more qualitatively different ways -->
<!--       to represent the same thing is discussed, but not solved, in a later -->
<!--       section. -->
      
<!--       1.6 SEEING A ROOM</p> -->

<!--     <p> -->
<!--       Visual experience seems continuous. One reason is that we move -->
<!--       continuously. A deeper explanation is that our <em>expectations</em> -->
<!--       usually interact smoothly with our perceptions. Suppose you were to -->
<!--       leave a room, close the door, turn to reopen it, and find an entirely -->
<!--       different room. You would be shocked. The sense of change would be -->
<!--       hardly less striking if the world suddenly changed before your eyes.</p> -->

<!--     <p> -->
<!--       A naive theory of phenomenological continuity is that we see so quickly -->
<!--       that our image changes as fast as does the scene. Below I press an -->
<!--       alternative theory: the changes in one&#39;s frame-structure -->
<!--       representation proceed at their own pace; the system prefers to make -->
<!--       small changes whenever possible; and the illusion of continuity is due -->
<!--       to the persistence of assignments to terminals common to the different -->
<!--       view-frames. Thus, continuity depends on the confirmation of -->
<!--       expectations which in turn depends on rapid access to remembered -->
<!--       knowledge about the visual world.  Just before you enter a room, you -->
<!--       usually know enough to -->
<!--       <em>expect</em> a room rather than, say, a landscape. You can usually -->
<!--       tell just by the character of the door. And you can often select in -->
<!--       advance a frame for the new room. Very often, one expects a certain -->
<!--       particular room. Then many assignments are already filled in.  The -->
<!--       simplest sort of room-frame candidate is like the inside of a -->
<!--       box. Following our cube-model, the room-frame might have the top-level -->
<!--       structure shown in figure 1.5. One has to assign to the frame&#39;s -->
<!--       terminals the things that are seen. If the room is familiar, some are -->
<!--       already assigned. If no expectations are recorded already, the first -->
<!--       priority might be locating the principal geometric landmarks.</p> -->

<!--     <p> -->
<!--       To fill in LEFT WALL one might first try to find edges <em>a</em> -->
<!--       and <em>d</em> and then the associated corners <em>ag</em> -->
<!--       and <em>gd.</em> Edge <em>g,</em> for example, is usually easy to find -->
<!--       because it should intersect any eye-level horizontal scan from left to -->
<!--       right. Eventually, <em>ag,</em> <em>gb,</em> and <em>ba</em> must not be -->
<!--       too inconsistent with one another &mdash; because they are the same -->
<!--       physical vertex.</p> -->

<!--     <p> -->
<!--       However the process is directed, there are some generally useful -->
<!--       knowledge-based tactics. It is probably easier to find edge <em>e</em> -->
<!--       than any other edge, because if we have just entered a normal -->
<!--       rectangular room, then we may expect that -->
      
<!--       *Edge <em>e</em> is a horizontal line.  *It is below eye level.  *It -->
<!--       defines a floor-wall texture boundary. -->
      
<!--       Given an expectation about the size of a room, we can estimate the -->
<!--       elevation of <em>e,</em> and vice versa. In outdoor scenes, <em>e</em> -->
<!--       is the horizon and on flat ground we can expect to see it at -->
<!--       eye-level. If we fail quickly to locate and assign this horizon, we must -->
<!--       consider rejecting the proposed frame: either the room is not normal or -->
<!--       there is a large obstruction.  The room-analysis strategy might try next -->
<!--       to establish some other landmarks. Given <em>e,</em> we next look for -->
<!--       its left and right corners, and then for the verticals rising from -->
<!--       them. Once such gross geometrical landmarks are located, we can guess -->
<!--       the room&#39;s general shape and size. This might lead to selecting a -->
<!--       new frame better matched to that shape and size, with additional markers -->
<!--       confirming the choice and completing the structure with further details. -->
<!--       Of course a competent vision system has to analyze the scene not merely -->
<!--       as a picture, but also in relation to some sort of external -->
<!--       space-frame. For vision to proceed smoothly when one is moving around, -->
<!--       one has to know where each feature <em>is,</em> in the external world of -->
<!--       mobility, to compensate for transformations induced by eye, head, and -->
<!--       body motions, as well as for gross locomotion.</p> -->

<!--     <p> -->
<!--       1.7 SCENE ANALYSIS AND SUBFRAMES</p> -->

<!--     <p> -->
<!--       If the new room is unfamiliar, no pre-assembled frame can supply fine -->
<!--       details; more scene-analysis is needed. Even so, the complexity of the -->
<!--       work can be reduced, given suitable subframes for constructing -->
<!--       hypotheses about substructures in the scene. How useful these will be -->
<!--       depends both on their inherent adequacy and on the quality of the -->
<!--       expectation process that selects which one to use next. One can say a -->
<!--       lot even about an unfamiliar room. Most rooms are like boxes, and they -->
<!--       can be categorized into types: kitchen, hall, living room, theater, and -->
<!--       so on. One knows dozens of kinds of rooms and hundreds of particular -->
<!--       rooms; one no doubt has them structured into some sort of similarity -->
<!--       network for effective access. This will be discussed later.  A typical -->
<!--       room-frame has three or four visible walls, each perhaps of a -->
<!--       different <em>kind.</em> One knows many kinds of walls: walls with -->
<!--       windows, shelves, pictures, and fireplaces. Each kind of room has its -->
<!--       own kinds of walls. A typical wall might have a 3 x 3 array of -->
<!--       region-terminals (left-center-right) x (top-middle-bottom) so that -->
<!--       wall-objects can be assigned qualitative locations. One would further -->
<!--       want to locate objects relative to geometric inter-relations in order to -->
<!--       represent such facts as <em>Y is a little above the center of the line -->
<!-- 	between X and Z.</em>  In three dimensions, the location of a visual -->
<!--       feature of a subframe is ambiguous, given only eye-direction. A feature -->
<!--       in the middle of the visual field could belong either to a Center Front -->
<!--       Wall object or to a High Middle Floor object; these attach to different -->
<!--       subframes. The decision could depend on reasoned evidence for support, -->
<!--       on more directly visual distance information derived from stereo -->
<!--       disparity or motion-parallax, or on plausibility information derived -->
<!--       from other frames: a clock would be plausible only on the wall-frame -->
<!--       while a person is almost certainly standing on the floor.  I do not -->
<!--       imagine the boundaries of spatial frame-cells to be constrained by -->
<!--       accurate metrical dimensions. Each cell terminal would specify the -->
<!--       (approximate) location of a typically central place in that cell, and -->
<!--       some comparative size range. We expect correct topological constraints; -->
<!--       a left-wall-edge must agree to stay to the left of any object assigned -->
<!--       to lie flat against that wall. The process of <em>matching</em> a scene -->
<!--       against all such constraints may result in a degree of <em>strain,</em> -->
<!--       as a cell expands (against its size-range specification) to include -->
<!--       objects proposed for its interior. Tolerance of such strains should -->
<!--       depend on one&#39;s current purpose and past experience. While this -->
<!--       might seem complicated, I do not think that the richness of visual -->
<!--       experience supports a drive for much simpler theories.</p> -->

<!--     <p> -->
<!--       1.8 PERSPECTIVE AND VIEWPOINT TRANSFORMATIONS</p> -->

<!--     <p> -->
<!--       <em>In sum, at Substage IIIB (age 8 or 9, typically) the operations -->
<!-- 	required to coordinate perspectives are complete, and in the following -->
<!-- 	quite independent forms. First, to each position of the observer there -->
<!-- 	corresponds a particular set of left-right, before-behind relations -->
<!-- 	between the objects. . . . These are governed by the projections and -->
<!-- 	sections appropriate to the visual plane of the observer -->
<!-- 	(perspective). During this final substage the point to point nature of -->
<!-- 	the correspondence between position and perspective is -->
<!-- 	discovered. Second, between each perspective viewpoint valid for a -->
<!-- 	given position of the observer and each of the others, there is also a -->
<!-- 	correspondence expressed by specific changes of left-right, -->
<!-- 	before-behind relations, and consequently by changes of the -->
<!-- 	appropriate projections and sections. It is this correspondence -->
<!-- 	between all possible points of view which constitutes co-ordination of -->
<!-- 	perspectives . . . though as yet only in a rudimentary form.</em></p> -->

<!--     <p> -->
<!--       Piaget and Inhelder, The Child&#39;s Conception of Space</p> -->

<!--     <p> -->
<!--       When we move about a room, the shapes of things change. How can these -->
<!--       changes be anticipated, or compensated, without complete reprocessing? -->
<!--       The results of eye and head rotation are simple: things move in the -->
<!--       visual field but keep their shapes; but changing place causes large -->
<!--       shape changes that depend both on angle and on distance relations -->
<!--       between the object and observer. The problem is particularly important -->
<!--       for fast-moving animals because a model of the scene must be built up -->
<!--       from different, partially analyzed views.  Perhaps the need to do this, -->
<!--       even in a relatively primitive fashion, was a major evolutionary -->
<!--       stimulus to develop frame-systems, and later, other symbolic mechanisms. -->
<!--       Given a box-shaped room, lateral motions induce orderly changes in the -->
<!--       quadrilateral shapes of the walls as in figure 1.6.</p> -->

<!--     <p> -->
<!--       Four wall-frames, one invisible, each with four perspective sub-views -->
<!--       (one invisible) in a subsystem showing one move right transformation -->
<!--       rotating each subsystem.</p> -->

<!--     <p> -->
<!--       A picture-frame rectangle, lying flat against a wall, should transform -->
<!--       in the same way as does its wall. If a <em>center-rectangle</em> is -->
<!--       drawn on a left wall it will appear to project out because one makes the -->
<!--       default assumption that any such quadrilateral is actually a rectangle -->
<!--       and hence must lie in a plane that would so project. In figure 1.7A, -->
<!--       both quadrilaterals could <em>look like</em> rectangles, but the one to -->
<!--       the right does not match the markers for a <em>left rectangle</em> -->
<!--       subframe (these require, e.g., that the left side be longer than the -->
<!--       right side). That rectangle is therefore represented by a -->
<!--       center-rectangle frame, and seems to project out as though parallel to -->
<!--       the center wall.  Thus we must not simply assign the -->
<!--       label <em>rectangle</em> to a quadrilateral but to a particular frame of -->
<!--       a rectangle-system. When we move, we expect whatever -->
<!--       space-transformation is applied to the top-level system will be applied -->
<!--       also to its subsystems as suggested in figure 1.7B.</p> -->

<!--     <p> -->
<!--       Similarly, the sequence of elliptical projections of a circle contains -->
<!--       congruent pairs that are visually ambiguous as shown in figure 1.8.  But -->
<!--       because wall objects usually lie flat, we assume that an ellipse on a -->
<!--       left wall is a left-ellipse, expect it to transform the same way as the -->
<!--       left wall, and are surprised if the prediction is not confirmed.</p> -->

<!--     <p> -->
<!--       Is it plausible that a finite, qualitative symbolic system can represent -->
<!--       perspective transformations adequately? People in our culture are -->
<!--       chronically unrealistic about their visualization abilities, e.g., to -->
<!--       visualize how spatial relations will appear from other viewpoints. We -->
<!--       noted that people who claim to have clear images of such configurations -->
<!--       often make qualitative errors in describing the rotations of a simple -->
<!--       multicolored cube. And even where we are actually able to make accurate -->
<!--       metrical judgements we do not always make them; few people are disturbed -->
<!--       by Huffman&#39;s (1970) -->
<!--       <em>impossible</em> pyramid, shown in figure 1.9.</p> -->

<!--     <p> -->
<!--       This is not a perspective of any actual truncated pyramid; if it were -->
<!--       the three edges, when extended, would all meet at one point. In -->
<!--       well-developed skills, no doubt, people can routinely make more precise -->
<!--       judgements, but this need not require a different mechanism.  Where a -->
<!--       layman uses 10 frames for some job, an expert might use 1000 and thus -->
<!--       get the appearance of a different order of performance.  In any case, to -->
<!--       correctly anticipate perspective changes in our systems, the top-level -->
<!--       transformation must induce appropriate transforms in the subframe -->
<!--       systems. To a first approximation, this can be done simply by using the -->
<!--       same transformation names. Then a -->
<!--       <em>move-right</em> action on a room frame would induce -->
<!--       a <em>move-right</em> action on objects attached to the wall subframes -->
<!--       (and to their subframes).  I said <em>first approximation</em> because -->
<!--       this scheme has a serious bug.  If you stand near a left wall and walk -->
<!--       forward, the nearby left-wall objects suffer a large <em>move-right</em> -->
<!--       transform, the front wall experiences a <em>move closer</em> transform, -->
<!--       and the right wall experiences a small <em>move left</em> transform. So -->
<!--       matters are not so simple that it is always sufficient merely to -->
<!--       transmit the motion name down to lower levels.</p> -->

<!--     <p> -->
<!--       1.9 OCCLUSIONS</p> -->

<!--     <p> -->
<!--       When we move to the right, a large object in the center foreground will -->
<!--       probably occlude any further-away object to its visual left. When motion -->
<!--       is planned, one should be able to anticipate some of these changes. Some -->
<!--       objects should become invisible and other objects should appear. Our -->
<!--       prototype cube-system has no occlusion problem because the scene is -->
<!--       completely convex; the disappearance of an entire side and its contents -->
<!--       is easily handled at the top level. But in a room, which is basically -->
<!--       concave, the sub-objects of different terminals can occlude one -->
<!--       another. We consider two extreme strategies:</p> -->

<!--     <p> -->
<!--       LOCAL ASSEMBLIES: Just as for the different views of a single object, -->
<!--       occlusions of a familiar assembly could be handled by a special frame -->
<!--       system for that configuration; for example, a chair and table as in -->
<!--       figure 1.10. If we apply the same perspective transformations to such -->
<!--       a <em>niche-frame</em> that we apply to its superiors, then to a first -->
<!--       approximation, occlusions between the objects are handled automatically.</p> -->

<!--     <p> -->
<!--       This works for compact, familiar subgroups of objects but cannot handle -->
<!--       the details of occlusions between elements of the niche and other things -->
<!--       in the room. For engineering applications the scheme&#39;s simplicity -->
<!--       would not outweigh its frequent errors. As a theory of human -->
<!--       performance, it might be good enough. A trained artist or draftsman can -->
<!--       answer such questions better, but such activities proceed slowly and -->
<!--       need not be explained by a first-order theory concerned mainly with -->
<!--       speed. -->
      
<!--       GLOBAL OCCLUSION SYSTEM: A more radical scheme would make all -->
<!--       perspective frames subsidiary to a central, common, space-frame -->
<!--       system. The terminals of that system would correspond to cells of a -->
<!--       gross subjective space, whose transformations represent, -->
<!--       once-and-for-all, facts about which cells occlude others from different -->
<!--       viewpoints. -->
      
<!--       If there were such a supersystem, would it be learned or innate? The -->
<!--       context of the Piaget-Inhelder quotation presents evidence that complete -->
<!--       coordination structures of this sort are not available to children in -->
<!--       their first decade.</p> -->

<!--     <p> -->
<!--       1.10 IMAGERY AND FRAME SYSTEMS</p> -->

<!--     <p> -->
<!--       <em>Everyone will readily allow that there is a considerable difference -->
<!-- 	between the perceptions of the mind, when a man feels the pain of -->
<!-- 	excessive heat, or the pleasure of moderate warmth, and when he -->
<!-- 	afterwards recalls to his memory this sensation, or anticipates it by -->
<!-- 	his imagination. These faculties may mimic or copy the perceptions of -->
<!-- 	the senses; but they never can entirely reach the force and vivacity -->
<!-- 	of the original sentiment. . . . The most lively thought is still -->
<!-- 	inferior to the dullest sensation.</em> -->
      
<!--       D. Hume, Enquiry into Human Understanding -->
      
<!--       A theory of seeing should also be a theory of imagining. For in our view -->
<!--       both have the same end results: assignments to terminals of -->
<!--       frames. Everyone will agree with Hume that there are differences between -->
<!--       vision and imagery. Hume theorizes that this is because vision is -->
<!--       immediate and direct, whereas imagery is derived from recombinations of -->
<!--       memories of direct <em>impressions</em> and that some of the force is -->
<!--       lost, somehow, in the storage, retrieval, and computation.  I propose -->
<!--       instead that Seeing seems more vivid than Imagining because its -->
<!--       assignments are less flexible; they more firmly resist the attempts of -->
<!--       other processes to modify them. If you try to change the description of -->
<!--       a scene actually projected on your retinae, your vision system is likely -->
<!--       simply to change it right back. There is no correspondingly rigid -->
<!--       constraint on fantasies.  However, even <em>seen</em> assignments are -->
<!--       not completely inflexible; anyone can learn to mentally reverse the -->
<!--       interpretation of a skeleton- cube drawing. So-called <em>ambiguous</em> -->
<!--       figures are those that are easy to describe in different ways. Changing -->
<!--       a frame for such a purpose amounts to a change in <em>descriptive -->
<!-- 	viewpoint,</em> one in which the action or transformation is symbolic -->
<!--       rather than physical; in any case, we are told that there are mental -->
<!--       states in which fantasies are more inflexible than <em>direct -->
<!-- 	impressions</em> and even, sometimes, more -->
<!--       <em>vivid.</em></p> -->

<!--     <p> -->
<!--       1.11 DEFAULT ASSIGNMENT</p> -->

<!--     <p> -->
<!--       While both Seeing and Imagining result in assignments to frame -->
<!--       terminals, Imagination leaves us wider choices of detail and variety of -->
<!--       such assignments. I conjecture that frames are never stored in long-term -->
<!--       memory with unassigned terminal values. Instead, what really happens is -->
<!--       that frames are stored with weakly-bound default assignments at every -->
<!--       terminal! These manifest themselves as often-useful but sometimes -->
<!--       counter-productive stereotypes.  Thus if I say, <em>John kicked the -->
<!-- 	ball,</em> you probably cannot think of a purely abstract ball, but must -->
<!--       imagine characteristics of a vaguely particular ball; it probably has a -->
<!--       certain default size, default color, default weight. Perhaps it is a -->
<!--       descendant of one you first owned or were injured by. Perhaps it -->
<!--       resembles your latest one. In any case your image lacks the sharpness of -->
<!--       presence because the processes that inspect and operate upon the -->
<!--       weakly-bound default features are very likely to change, adapt, or -->
<!--       detach them.  Such default assignments would have subtle, idiosyncratic -->
<!--       influences on the paths an individual would tend to follow in making -->
<!--       analogies, generalizations, and judgements, especially when the exterior -->
<!--       influences on such choices are weak. Properly chosen, such stereotypes -->
<!--       could serve as a storehouse of valuable heuristic plan-skeletons; badly -->
<!--       selected, they could form paralyzing collections of irrational -->
<!--       biases. Because of them one might expect, as reported by Freud, to -->
<!--       detect evidences of early cognitive structures in <em>free -->
<!-- 	association</em> thinking.</p> -->

<!--     <p> -->
<!--       1.12 FRAME-SYSTEMS AND PIAGET&#39;S CONCRETE OPERATIONS</p> -->

<!--     <p> -->
<!--       <em>What, in effect, are the conditions for the construction of formal -->
<!-- 	thought?  The child must not only apply operations to objects &mdash; -->
<!-- 	in other words, mentally execute possible actions on them &mdash; he -->
<!-- 	must also &lsquo;reflect&rsquo; those operations in the absence of the -->
<!-- 	objects which are replaced by pure propositions. This -->
<!-- 	&lsquo;reflection&rsquo; is thought raised to the second power. -->
<!-- 	Concrete thinking is the representation of a possible action, and -->
<!-- 	formal thinking is the representation of a representation of possible -->
<!-- 	action.  It is not surprising, therefore, that the system of concrete -->
<!-- 	operations must be completed during the last years of childhood before -->
<!-- 	it can be &lsquo;reflected&rsquo; by formal operations. In terms of -->
<!-- 	their function, formal operations do not differ from concrete -->
<!-- 	operations except that they are applied to hypotheses or propositions -->
<!-- 	[whose logic is] an abstract translation of the system of -->
<!-- 	&lsquo;inference&rsquo; that governs concrete operations.</em> -->
      
<!--       J. Piaget, 1968, The Mental Development of the Child</p> -->

<!--     <p> -->
<!--       I think there is a similarity between Piaget&#39;s idea of a concrete -->
<!--       operation and the idea of applying a transformation between frames of a -->
<!--       system. But other, more <em>abstract</em> kinds of reasoning should be -->
<!--       much harder to do in such concrete ways. Similarly, some kinds of -->
<!--       <em>logical</em> operations should be easy to perform with frames by -->
<!--       substituting into loosely attached default assignments. It should be -->
<!--       easy, for example, to approximate logical transitivities; thus surface -->
<!--       syllogisms of the form -->
      
<!--       All A&#39;s are B&#39;s and All B&#39;s are C&#39;s ==> All A&#39;s are -->
<!--       C&#39;s would occur in the natural course of substituting acceptable -->
<!--       subframes into marked terminals of a frame. I do not mean that the -->
<!--       generalization itself is asserted, but only that its content is applied -->
<!--       to particular cases, because of the transitivity of instantiation of -->
<!--       subframes. One would expect, then, also to find the same belief in Most -->
<!--       A&#39;s are B&#39;s and Most B&#39;s are C&#39;s ==> Most A&#39;s are -->
<!--       C&#39;s even though this is sometimes false, as some adults have -->
<!--       learned.  It would be valuable better to understand what can be done by -->
<!--       simple processes working on frames. One could surely invent some -->
<!--       <em>inference-frame technique</em> that could be used to rearrange -->
<!--       terminals of other frames so as to simulate deductive logic. A major step -->
<!--       in that direction, I think, is the <em>flat and cover</em> procedure -->
<!--       proposed for Moore and Newell&#39;s MERLIN (1973). This is a procedure, -->
<!--       related to logical <em>unification,</em> whose output, given two frames A -->
<!--       and B, is interpreted to mean (roughly): A can be viewed as a kind of B -->
<!--       given a <em>mapping</em> or frame-transformation C that expresses (perhaps -->
<!--       in terms of other mappings) how A&#39;s terminals can be viewed in terms -->
<!--       of B&#39;s terminals. The same essay uses the view-changing concept to -->
<!--       suggest a variety of new interpretations of such basic concepts as -->
<!--       goal-direction, induction, and assimilation of new knowledge, and it makes -->
<!--       substantial proposals about how the general frame idea might be realized -->
<!--       in a computer program.  It appears that only with the emergence of -->
<!--       Piaget&#39;s <em>formal</em> stage (for perspective, not usually until the -->
<!--       second decade) are children reliably able to reason about, rather than -->
<!--       with transformations. Nor do such capacities appear at once, or -->
<!--       synchronously in all mental activities. To get greater reasoning power -->
<!--       &mdash; and to be released from the useful but unreliable pseudologic of -->
<!--       manipulating default assignments &mdash; one must learn the equivalent of -->
<!--       operating on the transformations themselves. (One needs to get at the -->
<!--       transformations because they contain knowledge needed for more -->
<!--       sophisticated reasoning.) In a computational model constructed for -->
<!--       Artificial Intelligence, one might try to make the system read its own -->
<!--       programs. An alternative is to represent (redundantly) information about -->
<!--       processes some other way. Workers on recent -->
<!--       <em>program-understanding</em> programs in our laboratory have usually -->
<!--       decided, for one reason or another, that programs should carry -->
<!--       <em>commentaries</em> that express more directly their intentions,</p> -->

<!--     <p> -->
<!--       prerequisites, and effects; these commentaries are (at present) usually -->
<!--       written in specialized sub-languages.  This raises an important point -->
<!--       about the purpose of our theory. -->
<!--       <em>Schematic</em> thinking, based on matching complicated situations -->
<!--       against stereotyped frame structures, must be inadequate for some -->
<!--       aspects of mental activity. Obviously mature people can to some extent -->
<!--       think about, as well as use their own representations. Let us -->
<!--       speculatively interpret <em>formal operations</em> as processes that can -->
<!--       examine and criticize our earlier representations (be they frame-like or -->
<!--       whatever). With these we can begin to build up new structures to -->
<!--       correspond to <em>representations of representations.</em> I have no -->
<!--       idea what role frame systems might play in these more complex -->
<!--       activities.  The same strategy suggests that we identify (schematically, -->
<!--       at least) the direct use of frames with Piaget&#39;s <em>concrete -->
<!-- 	operations.</em> If we do this then I find Piaget&#39;s explanation of -->
<!--       the late occurrence of -->
<!--       <em>formal thinking</em> paradoxically reassuring. In first trying to -->
<!--       apply the frame-system paradigm to various problems, I was disturbed by -->
<!--       how well it explained some things and how poorly others. But it was -->
<!--       foolish to expect any single scheme to explain very much about -->
<!--       thinking. Certainly one cannot expect to solve all the problems of -->
<!--       sophisticated reasoning within a system confined to concrete operations -->
<!--       &mdash; if that indeed amounts to the manipulation of stereotypes.</p> -->

<!--     <p> -->
<!--       2. LANGUAGE, UNDERSTANDING, AND SCENARIOS</p> -->

<!--     <p> -->
<!--       2.1 WORDS, SENTENCES AND MEANINGS</p> -->

<!--     <p> -->
<!--       <em>The device of images has several defects that are the price of its -->
<!-- 	peculiar excellences. Two of these are perhaps the most important: the -->
<!-- 	image, and particularly the visual image, is apt to go farther in the -->
<!-- 	direction of the individualisation of situations than is biologically -->
<!-- 	useful; and the principles of the combination of images have their own -->
<!-- 	peculiarities and result in constructions which are relatively wild, -->
<!-- 	jerky and irregular, compared with the straightforward unwinding of a -->
<!-- 	habit, or with the somewhat orderly march of thought.</em> -->
      
<!--       F. C. Bartlett, Remembering</p> -->

<!--     <p> -->
<!--       The concepts of frame and default assignment seem helpful in discussing -->
<!--       the phenomenology of <em>meaning.</em> Chomsky (1957) points out that -->
<!--       such a sentence as</p> -->

<!--     <p> -->
<!--       (A) <em>colorless green ideas sleep furiously</em></p> -->

<!--     <p> -->
<!--       is treated very differently than the non-sentence</p> -->

<!--     <p> -->
<!--       (B) <em>furiously sleep ideas green colorless</em></p> -->

<!--     <p> -->
<!--       and suggests that because both are <em>equally nonsensical,</em> what is -->
<!--       involved in the recognition of sentences must be quite different from -->
<!--       what is involved in the appreciation of meanings.  There is no doubt -->
<!--       that there are processes especially concerned with grammar. Since the -->
<!--       meaning of an utterance is <em>encoded</em> as much in the positional -->
<!--       and structural relations between the words as in the word choices -->
<!--       themselves, there must be processes concerned with analyzing those -->
<!--       relations in the course of building the structures that will more -->
<!--       directly represent the meaning. What makes the words of (A) more -->
<!--       effective and predictable than (B) in producing such a structure &mdash; -->
<!--       putting aside the question of whether that structure should be called -->
<!--       semantic or syntactic &mdash; is that the word-order relations in (A) -->
<!--       exploit the (grammatical) convention and rules people usually use to -->
<!--       induce others to make assignments to terminals of structures. This is -->
<!--       entirely consistent with grammar theories. A generative grammar would be -->
<!--       a summary description of the exterior appearance of those frame rules -->
<!--       &mdash; or their associated processes &mdash; while the operators of -->
<!--       transformational grammars seem similar enough to some of our frame -->
<!--       transformations.  But one must also ask: to what degree does grammar -->
<!--       have a separate identity in the actual working of a human mind? Perhaps -->
<!--       the rejection of an utterance (either as non-grammatical, as -->
<!--       nonsensical, or most important, as not understood) indicates a more -->
<!--       complex failure of the semantic process to arrive at any usable -->
<!--       representation; I will argue now that the grammar-meaning distinction -->
<!--       may illuminate two extremes of a continuum, but obscures its -->
<!--       all-important interior.  We certainly cannot assume -->
<!--       that <em>logical</em> meaninglessness has a precise psychological -->
<!--       counterpart. Sentence (A) can certainly generate an image! The dominant -->
<!--       frame (in my case) is that of someone sleeping; the default system -->
<!--       assigns a particular bed, and in it lies a mummy-like shape-frame with a -->
<!--       translucent green color property. In this frame there is a terminal for -->
<!--       the character of the sleep &mdash; restless, perhaps &mdash; -->
<!--       and <em>furiously</em> seems somewhat inappropriate at that terminal, -->
<!--       perhaps because the terminal does not like to accept anything -->
<!--       so <em>intentional</em> for a sleeper. <em>Idea</em> is even more -->
<!--       disturbing, because a person is expected, or at least something -->
<!--       animate. I sense frustrated procedures trying to resolve these tensions -->
<!--       and conflicts more properly, here or there, into the sleeping framework -->
<!--       that has been evoked.  Utterance (B) does not get nearly so far because -->
<!--       no subframe accepts any substantial fragment. As a result no larger -->
<!--       frame finds anything to match its terminals, hence finally, no top -->
<!--       level <em>meaning</em> or <em>sentence</em> frame can organize the -->
<!--       utterance as either meaningful or grammatical. By combining -->
<!--       this <em>soft</em> theory with gradations of assignment tolerances, I -->
<!--       imagine one could develop systems that degrade properly for sentences -->
<!--       with <em>poor</em> grammar rather than none; if the smaller fragments -->
<!--       &mdash; phrases and sub-clauses &mdash; satisfy subframes well enough, -->
<!--       an image adequate for certain kinds of comprehension could be -->
<!--       constructed anyway, even though some parts of the top level structure -->
<!--       are not entirely satisfied. Thus, we arrive at a qualitative theory -->
<!--       of <em>grammatical</em>: if the top levels are satisfied but some lower -->
<!--       terminals are not, we have a meaningless sentence; if the top is weak -->
<!--       but the bottom solid, we can have an ungrammatical but meaningful -->
<!--       utterance.  I do not mean to suggest that sentences must evoke visual -->
<!--       images.  Some people do not admit to assigning a color to the ball -->
<!--       in <em>he kicked the ball.</em> But everyone admits (eventually) to -->
<!--       having assumed, if not a size or color, at least some purpose, attitude, -->
<!--       or other elements of an assumed scenario. When we go beyond vision, -->
<!--       terminals and their default assignments can represent purposes and -->
<!--       functions, not just colors, sizes and shapes.</p> -->

<!--     <p> -->
<!--       2.2 DISCOURSE</p> -->

<!--     <p> -->
<!--       Linguistic activity involves larger structures than can be described in -->
<!--       terms of sentential grammar, and these larger structures further blur -->
<!--       the distinctness of the syntax-semantic dichotomy. Consider the -->
<!--       following fable, as told by W. Chafe (Chafe 1972).</p> -->

<!--     <p> -->
<!--       There was once a Wolf who saw a Lamb drinking at a river and wanted an -->
<!--       excuse to eat it. For that purpose, even though he himself was upstream, -->
<!--       he accused the Lamb of stirring up the water and keeping him from -->
<!--       drinking . . . -->
      
<!--       To understand this, one must realize that the Wolf is lying! To -->
<!--       understand the key conjunctive <em>even though</em> one must realize -->
<!--       that contamination never flows upstream. This in turn requires us to -->
<!--       understand (among other things) the word <em>upstream</em> -->
<!--       itself. Within a declarative, predicate-based <em>logical</em> system, -->
<!--       one might try to axiomatize <em>upstream</em> by some formula like: -->
      
<!--       [A upstream B] AND [Event T, Stream muddy at A] = => [Exists [Event U, -->
<!--       Stream muddy at B]] AND [Later U, T] -->
      
<!--       But an adequate definition would need a good deal more. What about the -->
<!--       fact that the order of things being transported by water currents is not -->
<!--       ordinarily changed? A logician might try to deduce this from a suitably -->
<!--       intricate set of <em>local</em> axioms, together with appropriate -->
<!--       <em>induction</em> axioms. I propose instead to represent this knowledge -->
<!--       in a structure that automatically translocates spatial descriptions from -->
<!--       the terminals of one frame to those of another frame of the same -->
<!--       system. While this might be considered to be a form of logic, it uses -->
<!--       some of the same mechanisms designed for spatial thinking.  In many -->
<!--       instances we would handle a change over time, or a cause- effect -->
<!--       relation, in the same way as we deal with a change in position.  Thus, -->
<!--       the concept river-flow could evoke a frame-system structure something -->
<!--       like the following, where S1, S2, and S3 are abstract slices of the -->
<!--       flowing river shown in figure 2.1. In my default system the Wolf is at -->
<!--       the left, the Lamb at the right, and S1, S2, and S3 flow past them. In -->
<!--       the diagram, presume that the S&#39;s cannot be seen unless they are -->
<!--       directly next to either the wolf or the lamb. On reflection, my -->
<!--       imaginary currents usually flow from left to right, and I find it some -->
<!--       effort to use reversed versions. Perhaps they all descend from copies of -->
<!--       the same proto-system.  The time (and not coincidentally, current) -->
<!--       transformation represents part of our understanding of the effects of -->
<!--       the flow of the river. If the terminal S3 is the mud effect produced by -->
<!--       the Lamb, the frame system causes the mud-effect to become invisible and -->
<!--       not-near the Wolf. Thus, he has no valid reason to complain. A more -->
<!--       detailed system could have intermediate frames; in none of them is the -->
<!--       Wolf contaminated.</p> -->

<!--     <p> -->
<!--       There are many more nuances to fill in. What is <em>stirring up</em> and -->
<!--       why would it keep the wolf from drinking? One might normally assign -->
<!--       default floating objects to the S&#39;s, but here S3 interacts -->
<!--       with <em>stirring up</em> to yield something that <em>drink</em> does -->
<!--       not find acceptable. Was it -->
<!--       <em>deduced</em> that stirring river-water means that S3 in the first -->
<!--       frame should have <em>mud</em> assigned to it; or is this simply the -->
<!--       default assignment for stirred water?</p> -->

<!--     <p> -->
<!--       Almost any event, action, change, flow of material, or even flow of -->
<!--       information can be represented to a first approximation by a two-frame -->
<!--       generalized event. The frame-system can have slots for agents, tools, -->
<!--       side-effects, preconditions, generalized trajectories, just as in -->
<!--       the <em>trans</em> verbs of <em>case grammar</em> theories, but we have -->
<!--       the additional flexibility of representing changes explicitly. To see if -->
<!--       one has understood an event or action, one can try to build an -->
<!--       appropriate instantiated frame-pair.  However, in representing changes -->
<!--       by simple <em>before-after</em> frame-pairs, we can expect to pay a -->
<!--       price. Pointing to a pair is not the same as describing their -->
<!--       differences. This makes it less convenient to do planning or abstract -->
<!--       reasoning; there is no explicit place to attach information about the -->
<!--       transformation. As a second approximation, we could label pairs of nodes -->
<!--       that point to corresponding terminals, obtaining structure like -->
<!--       the <em>comparison-notes</em> in Winston (1970), or we might place at -->
<!--       the top of the frame-system information describing the differences more -->
<!--       abstractly. Something of this sort will be needed eventually.  In his -->
<!--       work on <em>conceptual dependency,</em> R. Schank (1972) attempts to -->
<!--       represent meanings of complex assertions like <em>Sam believes that John -->
<!-- 	is a fool,</em> in which the thing that Sam believes is not an object -->
<!--       but requires a <em>conceptualization</em> and even situations like that -->
<!--       in <em>Q: Do you want a piece of chocolate? A: No, I just had an ice -->
<!-- 	cream cone</em> in which understanding requires representing details of -->
<!--       a complex notion of satiation. He proposes a small collection -->
<!--       of <em>basic conceptualizations</em> and relations between them from -->
<!--       which to build representations for any meaning. I find it hard to decide -->
<!--       how adequate these are; how well, for example, could they describe -->
<!--       flows?  Schank&#39;s schemes include an idea of <em>conceptual -->
<!-- 	cases</em> which resemble some of our frame-terminals, but he attempts -->
<!--       to represent the effects of actions as explicit abstractions rather than -->
<!--       as relations between frame-like pairs. There are problems in this as -->
<!--       well; one wonders how well a single abstract concept of cause (or even -->
<!--       several) would suffice in a functioning <em>belief system.</em> It -->
<!--       certainly would not be enough to characterize causality only in terms of -->
<!--       one condition or action being necessary for another to happen. Putting -->
<!--       details aside, I think Schank has made a strong start and, once this -->
<!--       area develops some performance tests, it should yield good -->
<!--       knowledge-representation methods.  The work of Y. Wilks (1973) -->
<!--       on <em>preference semantics</em> also seems rich in ideas about ways to -->
<!--       build frame-like structures out of simpler ones, and his preference -->
<!--       proposals embody specific ways one might represent default assignments -->
<!--       and procedures for making them depend on larger aspects of a discourse -->
<!--       than mere sentences. Wilks&#39; system is interesting also in -->
<!--       demonstrating, I think, ways in which one can get some useful informal -->
<!--       reasoning, or pseudo-deduction as a product of the template building and -->
<!--       instantiation processes without an elaborate formal logical system or -->
<!--       undue concern with consistency.  R. P. Abelson (Abelson 1973) has worked -->
<!--       toward representing even more extended activities. Beginning with -->
<!--       elements like Schank&#39;s, he works out schemes in which the different -->
<!--       concepts interact, arriving at intricate scripts; skeletonized scenarios -->
<!--       of elaborate belief systems,</p> -->

<!--     <p> -->
<!--       attempting even to portray such interactions as one&#39;s image of the -->
<!--       role he plays in another person&#39;s plans.  D. McDermott (1973) -->
<!--       discusses in his M.S. thesis many issues related to knowledge -->
<!--       representations. In his scheme for plausible inference, statements are -->
<!--       not simply accepted, but are subjected to a process of <em>doubting</em> -->
<!--       and <em>believing</em>; in effect, things assumed by default (or -->
<!--       plausibility) are retained with mechanisms for revising those beliefs -->
<!--       when later, dependent assumptions run into problems.  McDermott (1974) -->
<!--       is particularly attentive to the problems involved in recovery from the -->
<!--       errors any such system is forced to make in the course of informal, -->
<!--       common sense inference. (See also Wilks, 1973)</p> -->

<!--     <p> -->
<!--       2.3 MEANING-STRUCTURE OF A DISCOURSE</p> -->

<!--     <p> -->
<!--       <em>Words . . . can indicate the qualitative and relational features of -->
<!-- 	a situation in their general aspect just as directly as, and perhaps -->
<!-- 	even more satisfactorily than, they can describe its particular -->
<!-- 	individuality.  This is, in fact, what gives to language its intimate -->
<!-- 	relation to thought processes. For thinking, in the proper -->
<!-- 	psychological sense, is never the mere reinstatement of some suitable -->
<!-- 	past situation produced by a crossing of interests, but is the -->
<!-- 	utilisation of the past in solution of difficulties set by the -->
<!-- 	present. . . . Equally, nobody ever thinks who, being challenged, -->
<!-- 	merely sets up an image from some more or less relevant situation, and -->
<!-- 	then finds for himself a solution, without in any way formulating the -->
<!-- 	relational principle involved.</em></p> -->

<!--     <p> -->
<!--       F. C. Bartlett, Remembering</p> -->

<!--     <p> -->
<!--       <em>Case grammar</em> sentence-analysis theories such as those of -->
<!--       Fillmore (1968) and Celce-Murcia (1972) involve structures somewhat like -->
<!--       frames. Centered mainly around the verb, parts of a sentence are used to -->
<!--       instantiate a sort of verb-frame in accord with various uses of -->
<!--       prepositions. I agree that this surely is a real phenomenon; sentences -->
<!--       are built around verbs, so it makes sense to use verb-centered -->
<!--       frame-like structures for analyzing sentences.  In more extended -->
<!--       discourse, however, I think that verb-centered structures often become -->
<!--       subordinate or even disappear. The topic or -->
<!--       <em>theme</em> of a paragraph is as likely to be a scene as to be an -->
<!--       action, as likely to be a characterization of a person as to be -->
<!--       something he is doing. Thus in understanding a discourse, the synthesis -->
<!--       of a verb-structure with its case-assignments may be a necessary but -->
<!--       transient phase. As sentences are understood, the resulting -->
<!--       substructures must be transferred to a growing <em>scene-frame</em> to -->
<!--       build up the larger picture. An action that is the chief concern of one -->
<!--       sentence might, for example, become subsidiary to a characterization of -->
<!--       one of the actors, in a larger story-frame.  I am not proposing anything -->
<!--       like <em>verbs describe local (sentential) structures and nouns describe -->
<!-- 	global (paragraphic) structures</em> &mdash; although that might be a -->
<!--       conceptually useful first approximation. Any concept can be invoked by -->
<!--       all sorts of linguistic representations. It is not a matter of nouns or -->
<!--       verbs. The important point is that we must not assume that the transient -->
<!--       semantic structure built during the syntactic analysis (what language -->
<!--       theorists today call the <em>deep structure</em> of a sentence) is -->
<!--       identical with the larger (and <em>deeper</em>) structure built up -->
<!--       incrementally as each fragment of a coherent linguistic communication -->
<!--       operates upon it!  I do not want this emphasis on topical or thematic -->
<!--       superframes to suggest a radical confrontation between linguistic -->
<!--       vs. non-linguistic representations. Introspectively, a substantial -->
<!--       portion of common-sense thinking and reasoning seem to resemble -->
<!--       linguistic transformations and other manipulations. The frames -->
<!--       associated with word senses, be they noun, verb or whatever, are surely -->
<!--       centers for the concentrated representation of vital knowledge about how -->
<!--       different things are related, how they are used, and how they transform -->
<!--       one another. Practically, there would be large advantages in having -->
<!--       mechanisms that could use these same structures both for thinking and -->
<!--       for communicating.  Let us imagine a frame-oriented scenario for how -->
<!--       coherent discourse might be represented. At the start of a story, we -->
<!--       know little other than that it will be a story, but even this gives us a -->
<!--       start. A conventional frame for <em>story</em> (in general) would arrive -->
<!--       with slots for setting, protagonists, main event, moral, etc. Indeed, -->
<!--       the first line of a properly told story usually helps with the setting; -->
<!--       the wolf and lamb story immediately introduces two antagonists, places -->
<!--       them by the river (setting), and provides the wolf with a motive. The -->
<!--       word -->
<!--       <em>excuse</em> somehow prepares us for the likelihood of the wolf -->
<!--       making false statements.  Each sentential analysis need be maintained -->
<!--       only until its contents can be used to instantiate a larger -->
<!--       structure. The terminals of the growing meaning-structure thus -->
<!--       accumulate indicators and descriptors, which expect and key further -->
<!--       assignments. A terminal that has acquired a <em>female person</em> -->
<!--       marker will reject <em>male</em> pronominal assignments using, I -->
<!--       suppose, the same sorts of considerations that resist assignment of -->
<!--       tables and chairs to terminals of wall frames. As the story proceeds, -->
<!--       information is transferred to superframes whenever possible, -->
<!--       instantiating or elaborating the scenario. In some cases we will be -->
<!--       lucky enough to attach a whole subframe, for example, a description of -->
<!--       the hero, to a single terminal in the superframe. This could happen if a -->
<!--       terminal of the <em>story</em> superframe matches a top level indicator -->
<!--       on the current sentence-frame. Other sentences might produce relations -->
<!--       constraining pairs of already existing terminals. But what if no such -->
<!--       transfer can be made because the listener expected a wrong kind of story -->
<!--       and has no terminals to receive the new structure?  We go on to suppose -->
<!--       that the listener actually has many story frames, linked by the kinds of -->
<!--       retrieval structures discussed later on.  First we try to fit the new -->
<!--       information into the current story-frame. If we fail, we construct an -->
<!--       error comment like <em>there is no place here for an animal.</em> This -->
<!--       causes us to replace the current story-frame by, say,</p> -->

<!--     <p> -->
<!--       an animal-story frame. The previous assignments to terminals may all -->
<!--       survive, if the new story frame has the same kinds of terminals.  But if -->
<!--       many previous assignments do not so transfer, we must get another new -->
<!--       story-frame. If we fail, we must either construct a basically new -->
<!--       story-frame &mdash; a major intellectual event, perhaps &mdash; or just -->
<!--       give up and forget the assignments. (Presumably that is the usual -->
<!--       reaction to radically new narrative forms! One does not learn well if -->
<!--       the required jumps are too large: one cannot really understand animal -->
<!--       stories until one posesses the conventional personality frames for the -->
<!--       wolf, pig, fox, etc.)  Thus a discourse assembles a network of -->
<!--       instantiated frames and subframes. Attributive or descriptive -->
<!--       information can often be represented by simple sub-structures, but -->
<!--       actions, temporal successions, explanations and other complicated things -->
<!--       surely need more elaborate attachments. We must recognize that -->
<!--       profoundly hard questions, central to epistemology as well as to -->
<!--       linguistics, are entrained in this problem of how to merge information -->
<!--       from different sources and subframes. The next few sections raise more -->
<!--       questions about these than they begin to answer.</p> -->

<!--     <p> -->
<!--       2.4 LANGUAGE TRANSLATION</p> -->

<!--     <p> -->
<!--       Translation affords an opportunity to observe defaults at work. In -->
<!--       translating the story about the wolf and the lamb from English to -->
<!--       Japanese, according to Chafe, it is required to mention the place on the -->
<!--       river where the actors stand, although it is not required in English. In -->
<!--       English one must cite the time &mdash; if only by saying -->
<!--       <em>Once. . . .</em> In Japanese, it is customary to characterize the -->
<!--       place, as well as the time, even if only by a nonspecific <em>In a -->
<!-- 	certain place. . . .</em>  I think both place and time are required, in -->
<!--       the deeper meaning-frames of people who think much as we do whatever -->
<!--       natural language they speak! Hence, default assignmments for both would -->
<!--       be immediately available to the translator if he understood the sentence -->
<!--       at all. Good simultaneous translators proceed so rapidly that one -->
<!--       wonders how much they can really understand before speaking; our theory -->
<!--       makes this less of an issue because, if the proper frame is retrieved in -->
<!--       the course of partial understanding, its default assignments are -->
<!--       available instantly, before the more complex assignment negotiations are -->
<!--       completed.</p> -->

<!--     <p> -->
<!--       A translation of <em>The Wolf and Lamb</em> into Japanese with -->
<!--       acceptable surface structure might be, according to Chafe, -->
      
<!--       Once certain place in river at water drinking be child-sheep saw one -->
<!--       animal wolf was and that wolf that child-sheep eat for excuse -->
<!--       make-want-seeming was. . . . -->
      
<!--       It is more natural, in Japanese, to say what the Lamb was drinking than -->
<!--       just to say he was drinking. Here is one way that language affects -->
<!--       thinking: each such linguistic convention focuses special attention on -->
<!--       filling certain terminals. If water is the usual thing to drink in -->
<!--       one&#39;s culture, then water is the default assignment for what is -->
<!--       being drunk. When speech production requires such an assignment in a -->
<!--       sentence-output frame, that default will normally be assumed. Of course, -->
<!--       one should be even more certain of water if the drinking is done beside -->
<!--       a river; this needs some machinery for relating drinking and river -->
<!--       stereotypes. It seems clear that if there is a weakly-bound -->
<!--       drinkable-fluid slot in one frame, and a strongly-bound drinkable fluid -->
<!--       in the subframe to be attached, the latter should dislodge the -->
<!--       former. Thus, even if our listener usually drinks wine, he should -->
<!--       correctly imagine the lamb drinking water.</p> -->

<!--     <p> -->
<!--       2.5 ACTIVE VS. PASSIVE In our traditional <em>folk phenomenology,</em> -->
<!--       Seeing and Imagining are usually seen as <em>passive</em> -->
<!--       and <em>active.</em> It is tempting to exploit this viewpoint for -->
<!--       vision:</p> -->

<!--     <p> -->
<!--       In seeing, one analyses a scene by assembling and instantiating frames, -->
<!--       generally without much choice because of the domination of the need to -->
<!--       resolve <em>objective</em> visual evidence against the need for a -->
<!--       consistent and plausible spatial scene-description.</p> -->

<!--     <p> -->
<!--       In imagining, we have much more choice, for we are trying to assemble -->
<!--       and instantiate frames to represent a <em>scene</em> that satisfies -->
<!--       internally chosen &mdash; hence changeable &mdash; goals.</p> -->

<!--     <p> -->
<!--       In language, a similar contrast is tempting:</p> -->

<!--     <p> -->
<!--       In listening, which includes parsing, one has little choice because of -->
<!--       the need to resolve the objective word string into a structure -->
<!--       consistent with grammar, context, and the assumed intention.</p> -->

<!--     <p> -->
<!--       In speaking, we have much more choice, because there are so many ways to -->
<!--       assemble sentence-making frames for our chosen purpose, be it to inform, -->
<!--       convince, or mislead.</p> -->

<!--     <p> -->
<!--       However, these are dangerous oversimplifications; things are often quite -->
<!--       the other way around! Speaking is often a straightforward encoding from -->
<!--       a semantic structure into a word sequence, while listening often -->
<!--       involves extensive and difficult constructions &mdash; which involve the -->
<!--       totality of complexities we call understanding.  Consider the analogy -->
<!--       between a frame for a room in a visual scene and a frame for a -->
<!--       noun-phrase in a discourse.  In each case, some assignments to terminals -->
<!--       are mandatory, while others are optional. A wall need not be decorated, -->
<!--       but every moveable object must be supported. A noun phrase need not -->
<!--       contain a numerical determiner, but it must contain a noun or pronoun -->
<!--       equivalent. One generally has little choice so far as surface structure -->
<!--       is concerned: one must account for all the words in a sentence and for -->
<!--       all the major features of a scene.  But surface structure is not -->
<!--       everything in vision or in language.  One has unlimited options about -->
<!--       incorporating consequences of context and knowledge into semantic -->
<!--       structure. An object has not only a visual form, but a history. Its -->
<!--       presence has usually a cause and often some other significance &mdash; -->
<!--       perhaps as a clue in a puzzle, or as a symbol of a changing -->
<!--       relationship.  Any sentence can be understood in many ways. I emphasize -->
<!--       that I am not talking of the accidental (and relatively unimportant) -->
<!--       ambiguities of parsing, but of the purposeful variations of -->
<!--       interpretation. Just as any room can be seen from different physical -->
<!--       viewpoints, so any assertion can be <em>viewed</em> from different -->
<!--       representational viewpoints as in the following, each of which suggests -->
<!--       a different structure: He kicked the ball.  The ball was kicked.  There -->
<!--       was some kicking today.</p> -->

<!--     <p> -->
<!--       Because such variations formally resemble the results of the syntactic, -->
<!--       active-passive operations of transformational grammars, one might -->
<!--       overlook their semantic significance. We select one or the other in -->
<!--       accord with thematic issues &mdash; on whether one is concerned with -->
<!--       what <em>he</em> did, with finding a lost ball, with who damaged it, or -->
<!--       whatever. One answers such questions most easily by bringing the -->
<!--       appropriate entity or action into the focus of attention, by evoking a -->
<!--       frame primarily concerned with that topic.  In the traditional view of -->
<!--       transformational linguistics, these alternate frames have no separate -->
<!--       existence but are only potential derivatives from a single deep -->
<!--       structure. There is an advantage to supposing their separate existence -->
<!--       in long term memory: we could attach specific knowledge to each about -->
<!--       how it should be used.  However, as language theorists rightly point -->
<!--       out, there are systematic regularities which suggest that -->
<!--       such <em>transformations</em> are nearly as readily applied to -->
<!--       unfamiliar verbs with the same redirections of concern; this makes -->
<!--       separate existence less plausible. I have the impression that -->
<!--       transformational theorists tend to believe in some special central -->
<!--       mechanisms for management of such changes of -->
<!--       <em>semantic perspective,</em> even though, I should think, the variety -->
<!--       of idiosyncracies attached to individual words makes this technically -->
<!--       difficult. A theory more in the spirit of this essay would suggest that -->
<!--       whenever one encounters an unfamiliar usage (or an unfamiliar word) he -->
<!--       applies some matching process to guess &mdash; rightly or wrongly -->
<!--       &mdash; which familiar usage it resembles, and then adapts the existing -->
<!--       attention-transformation system for that word. I cannot see what kind of -->
<!--       experiment might distinguish between these conjectures, but I still feel -->
<!--       that the distinction is important.  Some readers might object that -->
<!--       things should not be so complicated &mdash; that we need a simpler -->
<!--       theory &mdash; if only to explain how people understand sentences so -->
<!--       quickly. One must not forget that it often takes minutes, hours, or -->
<!--       forever, to understand something. -->
      
<!--       2.6 SCENARIOS</p> -->

<!--     <p> -->
<!--       <em>Thinking . . . is biologically subsequent to the image-forming -->
<!-- 	process. It is possible only when a way has been found of breaking up -->
<!-- 	the &lsquo;massed&rsquo; influence of past stimuli and situations, -->
<!-- 	only when a device has already been discovered for conquering the -->
<!-- 	sequential tyranny of past reactions.  But though it is a later and a -->
<!-- 	higher development, it does not supercede the method of images. It has -->
<!-- 	its own drawbacks. Contrasted with imaging it loses something of -->
<!-- 	vivacity, of vividness, of variety. Its prevailing instruments are -->
<!-- 	words, and, not only because these are social, but also because in use -->
<!-- 	they are necessarily strung out in sequence, they drop into habit -->
<!-- 	reactions even more readily than images do. [With thinking] we run -->
<!-- 	greater and greater risk of being caught up in generalities that may -->
<!-- 	have little to do with actual concrete experience. If we fail to -->
<!-- 	maintain the methods of thinking, we run the risks of becoming tied to -->
<!-- 	individual instances and of being made sport of by the accidental -->
<!-- 	circumstances belonging to these.</em>  F. C. Bartlett, Remembering -->
      
<!--       We condense and conventionalize, in language and thought, complex -->
<!--       situations and sequences into compact words and symbols.  Some words can -->
<!--       perhaps be <em>defined</em> in elegant, simple structures, but only a -->
<!--       small part of the meaning of <em>trade</em> is captured by first frame = -->
<!--       => second frame A has X B has Y B has X A has Y Trading normally occurs -->
<!--       in a social context of law, trust and convention. Unless we also -->
<!--       represent these other facts, most trade transactions will be almost -->
<!--       meaningless. It is usually essential to know that each party usually -->
<!--       wants both things but has to compromise. It is a happy but unusual -->
<!--       circumstance in which each trader is glad to get rid of what he has. To -->
<!--       represent trading strategies, one could insert the basic maneuvers right -->
<!--       into the above frame-pair scenario: in order for A to make B want X more -->
<!--       (or want Y less) we expect him to select one of the familiar tactics: -->
      
<!--       Offer more for Y.  Explain why X is so good.  Create favorable -->
<!--       side-effect of B having X.  Disparage the competition.  Make B think C -->
<!--       wants X. -->
      
<!--       These only scratch the surface. Trades usually occur within a scenario -->
<!--       tied together by more than a simple chain of events each linked to the -->
<!--       next. No single such scenario will do; when a clue about trading appears -->
<!--       it is essential to guess which of the different available scenarios is -->
<!--       most likely to be useful.</p> -->

<!--     <p> -->
<!--       Charniak&#39;s thesis (1972) studies questions about transactions that -->
<!--       seem easy for people to comprehend yet obviously need rich default -->
<!--       structures. We find in elementary school reading books such stories as: -->
      
<!--       She wondered if he would like a kite.  She went to her room and shook -->
<!--       her piggy bank.  It made no sound. -->
      
<!--       Most young readers understand that Jane wants money to buy Jack a kite -->
<!--       for a present but that there is no money to pay for it in her piggy -->
<!--       bank. Charniak proposes a variety of ways to facilitate such inferences -->
<!--       &mdash; a <em>demon</em> for present that looks for things concerned -->
<!--       with money, a demon for <em>piggy bank</em> which knows that shaking -->
<!--       without sound means the bank is empty, etc. But although present now -->
<!--       activates money, the reader may be surprised to find that neither of -->
<!--       those words (nor any of their synonyms) occurs in the -->
<!--       story. <em>Present</em> is certainly associated with <em>party</em> -->
<!--       and <em>money</em> with <em>bank,</em> but how are the longer chains -->
<!--       built up? Here is another problem raised in Charniak. A friend tells -->
<!--       Jane:</p> -->

<!--     <p> -->
<!--       He already has a Kite.  He will make you take it back. -->
      
<!--       Take which kite back? We do not want Jane to return Jack&#39;s old kite. -->
<!--       To determine the referent of the pronoun <em>it</em> requires -->
<!--       understanding a lot about an assumed scenario. Clearly, <em>it</em> -->
<!--       refers to the proposed new kite. How does one know this? (Note that we -->
<!--       need not agree on any single explanation.) Generally, pronouns refer to -->
<!--       recently mentioned things, but as this example shows, the referent -->
<!--       depends on more than the local syntax.  Suppose for the moment we are -->
<!--       already trying to instantiate a -->
<!--       <em>buying a present</em> default subframe. Now, the word <em>it</em> -->
<!--       alone is too small a fragment to deal with, but <em>take it back</em> -->
<!--       could be a plausible unit to match a terminal of an appropriately -->
<!--       elaborate buying scenario. Since that terminal would be constrained to -->
<!--       agree with the assignment of <em>present</em> itself, we are assured of -->
<!--       the correct meaning of it in <em>take X back.</em> Automatically, the -->
<!--       correct kite is selected. Of course, that terminal will have its own -->
<!--       constraints as well; a subframe for the <em>take it back</em> idiom -->
<!--       should know that <em>take X back</em> requires that:</p> -->

<!--     <p> -->
<!--       X was recently purchased.  The return is to the place of purchase.  You -->
<!--       must have your sales slip.  Etc.  If the current scenario does not -->
<!--       contain a <em>take it back</em> terminal, then we have to find one that -->
<!--       does and substitute it, maintaining as many prior assignments as -->
<!--       possible. Notice that if things go well the question of it being the old -->
<!--       kite never even arises. The sense of ambiguity arises only when -->
<!--       a <em>near miss</em> mismatch is tried and rejected.  Charniak&#39;s -->
<!--       proposed solution to this problem is in the same spirit but emphasizes -->
<!--       understanding that because Jack already has a kite, he may not want -->
<!--       another one. He proposes a mechanism associated with <em>present</em>: -->
      
<!--       (A) If we see that a person P might not like a present X, then look for -->
<!--       X being returned to the store where it was bought.</p> -->

<!--     <p> -->
<!--       (B) If we see this happening, or even being suggested, assert that the -->
<!--       reason why is that P does not like X.</p> -->

<!--     <p> -->
<!--       This statement of <em>advice</em> is intended by Charniak to be realized -->
<!--       as a production-like entity to be added to the currently active -->
<!--       data-base whenever a certain kind of context is encountered. Later, if -->
<!--       its antecedent condition is satisfied, its action adds enough -->
<!--       information about Jack and about the new kite to lead to a correct -->
<!--       decision about the pronoun.  Charniak in effect proposes that the system -->
<!--       should watch for certain kinds of events or situations and inject -->
<!--       proposed reasons, motives, and explanations for them. The additional -->
<!--       interconnections between the story elements are expected to help bridge -->
<!--       the gaps that logic might find it hard to cross, because the additions -->
<!--       are only -->
<!--       <em>plausible</em> default explanations, assumed without corroborative -->
<!--       assertions. By assuming (tentatively) <em>does not like X</em> when X is -->
<!--       taken back, Charniak hopes to simulate much of ordinary -->
<!--       <em>comprehension</em> of what is happening. We do not yet know how -->
<!--       complex and various such plausible inferences must be to get a given -->
<!--       level of performance, and the thesis does not answer this because it did -->
<!--       not include a large simulation. Usually he proposes terminating the -->
<!--       process by asserting the allegedly plausible motive without further -->
<!--       analysis unless necessary. To understand why Jack might return the -->
<!--       additional kite it should usually be enough to assert that he does not -->
<!--       like it. A deeper analysis might reveal that Jack would not really mind -->
<!--       having two kites but he probably realizes that he will get only one -->
<!--       present; his utility for two different presents is probably higher.</p> -->

<!--     <p> -->
<!--       2.7 SCENARIOS AND <em>QUESTIONS</em></p> -->

<!--     <p> -->
<!--       The meaning of a child&#39;s birthday party is very poorly approximated -->
<!--       by any dictionary definition like <em>a party assembled to celebrate a -->
<!-- 	birthday,</em> where a party would be defined, in turn, as -->
<!--       <em>people assembled for a celebration.</em> This lacks all the flavor -->
<!--       of the culturally required activities. Children know that -->
<!--       the <em>definition</em> should include more specifications, the -->
<!--       particulars of which can normally be assumed by way of default -->
<!--       assignments:</p> -->

<!--     <p> -->
<!--       Dress &mdash; Sunday best.  Present &mdash; Must please host. Must be -->
<!--       bought and gift-wrapped.  Games &mdash; Hide and seek. Pin tail on -->
<!--       donkey.</p> -->

<!--     <p> -->
<!--       Decor &mdash; Balloons. Favors. Crepe-paper.  Party-meal &mdash; -->
<!--       Cake. Ice-cream. Soda. Hot dogs.  Cake &mdash; -->
<!--       Candles. Blow-out. Wish. Sing birthday song.  Ice-cream &mdash; Standard -->
<!--       three-flavor.</p> -->

<!--     <p> -->
<!--       These ingredients for a typical American birthday party must be set into -->
<!--       a larger structure. Extended events take place in one or more days. A -->
<!--       Party takes place in a Day, of course, and occupies a substantial part -->
<!--       of it, so we locate it in an appropriate day frame. A typical day has -->
<!--       main events such as Get-up Dress Eat-1 Go-to-Work Eat-2. . .</p> -->

<!--     <p> -->
<!--       but a School-Day has more fixed detail:</p> -->

<!--     <p> -->
<!--       Get-up Dress Eat-1 Go-to-School Be-in-School Home-Room Assembly English -->
<!--       Math (arrgh) Eat-2 Science Recess Sport Go-Home Play Eat-3 Homework -->
<!--       Go-To-Bed</p> -->

<!--     <p> -->
<!--       Birthday parties obviously do not fit well into school-day frames.  Any -->
<!--       parent knows that the Party-Meal is bound to Eat-2 of its Day. I -->
<!--       remember a child who did not seem to realize this. Absolutely stuffed -->
<!--       after the Party-Meal, he asked when he would get Lunch.  Returning to -->
<!--       Jane&#39;s problem with the kite, we first hear that she is invited to -->
<!--       Jack&#39;s Birthday Party. Without the party scenario, or at least an -->
<!--       invitation scenario, the second line seems rather mysterious: -->
      
<!--       She wondered if he would like a kite.</p> -->

<!--     <p> -->
<!--       To explain one&#39;s rapid comprehension of this, I will make a somewhat -->
<!--       radical proposal: to represent explicitly, in the frame for a scenario -->
<!--       structure, pointers to a collection of the most serious problems and -->
<!--       questions commonly associated with it.  In fact we shall consider the -->
<!--       idea that the frame terminals are exactly those questions. -->
      
<!--       Thus, for the birthday party: -->
      
<!--       Y must get P for X &mdash; Choose P!</p> -->

<!--     <p> -->
<!--       X must like P &mdash; Will X like P?  Buy P &mdash; Where to buy P?  Get -->
<!--       money to buy P &mdash; Where to get money?  (Sub-questions of -->
<!--       the <em>present</em> frame?)  Y must dress up &mdash; What should Y -->
<!--       wear? -->
      
<!--       Certainly these are one&#39;s first concerns, when one is invited to a -->
<!--       party.  The reader is free to wonder, with the author, whether this -->
<!--       solution is acceptable. The question, <em>Will X like P?</em> certainly -->
<!--       matches -->
<!--       <em>She wondered if he would like a kite?</em> and correctly assigns the -->
<!--       kite to P. But is our world regular enough that such question sets could -->
<!--       be pre-compiled to make this mechanism often work smoothly? I think the -->
<!--       answer is mixed. We do indeed expect many such questions; we surely do -->
<!--       not expect all of them. But surely <em>expertise</em> consists partly in -->
<!--       not having to realize, ab initio what are the outstanding problems and -->
<!--       interactions in situations. Notice, for example, that there is no -->
<!--       default assignment for the Present in our party-scenario frame. This -->
<!--       mandates attention to that assignment problem and prepares us for a -->
<!--       possible thematic concern. In any case, we probably need a more active -->
<!--       mechanism for understanding <em>wondered</em> which can apply the -->
<!--       information currently in the frame to produce an expectation of what -->
<!--       Jane will think about.  The third line of our story, about shaking the -->
<!--       bank, should also eventually match one of the present-frame questions, -->
<!--       but the unstated connection between Money and Piggy-Bank is presumably -->
<!--       represented in the piggy-bank frame, not the party frame, although once -->
<!--       it is found it will match our Get-Money question terminal. The primary -->
<!--       functions and actions associated with piggy banks are Saving and -->
<!--       Getting-Money-Out, and the latter has three principal methods: -->
      
<!--       1. Using a key. Most piggy banks don&#39;t offer this option. -->
<!--       2. Breaking it. Children hate this.  3. Shaking the money out, or using -->
<!--       a thin slider. -->
      
<!--       In the fourth line does one know specifically that a silent Bank is -->
<!--       empty, and hence out of money (I think, yes) or does one use general -->
<!--       knowledge that a hard container which makes no noise when shaken is -->
<!--       empty? I have found quite a number of people to prefer the latter. -->
<!--       Logically the <em>general principle</em> would indeed suffice, but I -->
<!--       feel that this misses the important point that a specific scenario of -->
<!--       this character is engraved in every child&#39;s memory. The story is -->
<!--       instantly intelligible to most readers. If more complex reasoning from -->
<!--       general principles were required this would not be so, and more readers -->
<!--       would surely go astray. It is easy to find more complex problems: -->
      
<!--       A goat wandered into the yard where Jack was painting. The goat got the -->
<!--       paint all over himself. When Mother saw the goat she asked, <em>Jack, -->
<!-- 	did you do that?</em> -->
      
<!--       There is no one word or line, which is the referent of <em>that.</em> It -->
<!--       seems to refer, as Charniak notes, to <em>cause the goat to be covered -->
<!-- 	with paint.</em> Charniak does not permit himself to make a specific -->
<!--       proposal to handle this kind of problem, remarking only that -->
<!--       his <em>demon</em> model would need a substantial extension to deal with -->
<!--       such a poorly localized <em>thematic subject.</em> Consider how much one -->
<!--       has to know about our culture, to realize that that is not the -->
<!--       goat-in-the-yard but the goat-covered-with-paint. Charniak&#39;s thesis -->
<!--       &mdash; basically a study rather than a debugged system &mdash; -->
<!--       discusses issues about the activation, operation, and dismissal of -->
<!--       expectation and default-knowledge demons. Many of his ideas have been -->
<!--       absorbed into this essay.  In spite of its tentative character, I will -->
<!--       try to summarize this image of language understanding as somewhat -->
<!--       parallel to seeing. The key words and ideas of a discourse evoke -->
<!--       substantial thematic or scenario structures, drawn from memory with rich -->
<!--       default assumptions. The individual statements of a discourse lead to -->
<!--       temporary representations &mdash; which seem to correspond to what -->
<!--       contemporary linguists call <em>deep structures</em> &mdash; which are -->
<!--       then quickly rearranged or consumed in elaborating the growing scenario -->
<!--       representation. In order of <em>scale,</em> among the ingredients of -->
<!--       such a structure there might be these kinds of levels: -->
      
<!--       Surface Syntactic Frames: Mainly verb and noun structures. -->
<!--       Prepositional and word-order indicator conventions. -->
      
<!--       Surface Semantic Frames: Action-centered meanings of words.  Qualifiers -->
<!--       and relations concerning participants, instruments, trajectories and -->
<!--       strategies, goals, consequences and side-effects. -->
      
<!--       Thematic Frames: Scenarios concerned with topics, activities,</p> -->

<!--     <p> -->
<!--       portraits, setting. Outstanding problems and strategies commonly -->
<!--       connected with topic. -->
      
<!--       Narrative Frames: Skeleton forms for typical stories, explanations, and -->
<!--       arguments. Conventions about foci, protagonists, plot forms, -->
<!--       development, etc., designed to help a listener construct a new, -->
<!--       instantiated Thematic Frame in his own mind. -->
      
<!--       A single sentence can assign terminals, attach subframes, apply a -->
<!--       transformation, or cause a gross replacement of a high level frame when -->
<!--       a proposed assignment no longer fits well enough. A pronoun is -->
<!--       comprehensible only when general linguistic conventions, interacting -->
<!--       with defaults and specific indicators, determine a terminal or subframe -->
<!--       of the current scenario.  In vision the transformations usually have a -->
<!--       simple group-like structure. In language we expect more complex, less -->
<!--       regular systems of frames. Nevertheless, because time, cause, and action -->
<!--       are so important to us, we often use sequential transformation pairs -->
<!--       that replace situations by their temporal or causal successors.  Because -->
<!--       syntactic structural rules direct the selection and assembly of the -->
<!--       transient sentence frames, research on linguistic structures should help -->
<!--       us understand how our frame systems are constructed.  One might look for -->
<!--       such structures specifically associated with assigning terminals, -->
<!--       selecting emphasis or attention viewpoints (transformations), inserting -->
<!--       sentential structures into thematic structures, and changing gross -->
<!--       thematic representations.  Finally, just as there are familiar <em>basic -->
<!-- 	plots</em> for stories, there must be basic superframes for discourses, -->
<!--       arguments, narratives, and so forth. As with sentences, we should expect -->
<!--       to find special linguistic indicators for operations concerning these -->
<!--       larger structures; we should move beyond the grammar of sentences to try -->
<!--       to find and systematize the linguistic conventions that, operating -->
<!--       across wider spans, must be involved with assembling and transforming -->
<!--       scenarios and plans. -->
      
      
<!--       2.8 QUESTIONS, SYSTEMS, AND CASES -->
      
<!--       <em>Questions arise from a point of view &mdash; from something that -->
<!-- 	helps to structure what is problematical, what is worth asking, and -->
<!-- 	what constitutes an answer (or progress). It is not that the view -->
<!-- 	determines reality, only what we accept from reality and how we -->
<!-- 	structure it. I am realist enough to believe that in the long run -->
<!-- 	reality gets its own chance to accept or reject our various views. -->

<!-- 	<p> -->
<!-- 	  A. Newell, Artificial Intelligence and the Concept of Mind -->
	  
<!-- 	  Examination of linguistic discourse leads thus to a view of the -->
<!-- 	  frame concept in which the <em>terminals</em> serve to represent the -->
<!-- 	  questions most likely to arise in a situation. To make this -->
<!-- 	  important viewpoint more explicit, we will spell out this -->
<!-- 	  reinterpretation. -->
	  
<!-- 	  A Frame is a collection of questions to be asked about a -->
<!-- 	  hypothetical situation; it specifies issues to be raised and methods -->
<!-- 	  to be used in dealing with them. -->
	  
<!-- 	  The terminals of a frame correspond perhaps to what Schank (Schank -->
<!-- 	  1973) calls <em>conceptual cases,</em> although I do not think we -->
<!-- 	  should restrict them to so few types as Schank suggests. To -->
<!-- 	  understand a narrated or perceived action, one often feels compelled -->
<!-- 	  to ask such questions as: -->
	  
<!-- 	  What caused it (agent)?  What was the purpose (intention)?  What are -->
<!-- 	  the consequences (side-effects)?  Who does it affect (recipient)? -->
<!-- 	  How is it done (instrument)? -->
	  
<!-- 	  The number of such <em>cases</em> or questions is -->
<!-- 	  problematical. While we would like to reduce meaning to a very -->
<!-- 	  few <em>primitive</em> concepts, perhaps in analogy to the situation -->
<!-- 	  in traditional linguistic analysis, I know of no reason to suppose -->
<!-- 	  that that goal can be achieved. My own inclination is to side with -->
<!-- 	  such workers as W. Martin (1974), who look toward very large -->
<!-- 	  collections of <em>primitives,</em> annotated with comments about -->
<!-- 	  how they are related. Only time will tell which is better.  For -->
<!-- 	  entities other than actions one asks different questions; for -->
<!-- 	  thematic topics the questions may be much less localized, e.g., -->
	  
<!-- 	  Why are they telling this to me? -->

<!-- 	<p> -->
<!-- 	  How can I find out more about it?  How will it help with -->
<!-- 	  the <em>real problem</em>? -->
	  
<!-- 	  and so forth. In a <em>story</em> one asks what is the topic, what -->
<!-- 	  is the author&#39;s attitude, what is the main event, who are the -->
<!-- 	  protagonists and so on. As each question is given a tentative answer -->
<!-- 	  the corresponding subframes are attached and the questions they ask -->
<!-- 	  become active in turn.  The <em>markers</em> we proposed for -->
<!-- 	  vision-frames become more complex in this view. If we adopt for the -->
<!-- 	  moment Newell&#39;s larger sense of <em>view,</em> it is not enough -->
<!-- 	  simply to ask a question; one must indicate how it is to be -->
<!-- 	  answered. Thus a terminal should also contain (or point to) -->
<!-- 	  suggestions and recommendations about how to find an -->
<!-- 	  assignment. Our <em>default</em> assignments then become the -->
<!-- 	  simplest special cases of such recommendations, and one certainly -->
<!-- 	  could have a hierarchy in which such proposals depend on features of -->
<!-- 	  the situation, perhaps along the lines of Wilks&#39; (Wilks -->
<!-- 	  1973) <em>preference</em> structures.  For syntactic frames, the -->
<!-- 	  drive toward ritualistic completion of assignments is strong, but we -->
<!-- 	  are more flexible at the conceptual level. As Schank (1973) says, -->
	  
<!-- 	  <em>People do not usually state all the parts of a given thought -->
<!--             that they are trying to communicate because the speaker tries to -->
<!--             be brief and leaves out assumed or unessential information [ -->
<!--             . . . ].  The conceptual processor makes use of the unfilled slots -->
<!--             to search for a given type of information in a sentence or a -->
<!--             larger unit of discourse that will fill the needed slot.</em> -->
	  
<!-- 	  Even in physical perception we have the same situation. A box will -->
<!-- 	  not present all of its sides at once to an observer, and while this -->
<!-- 	  is certainly not because it wants to be brief, the effect is the -->
<!-- 	  same; the processor is prepared to find out what the missing sides -->
<!-- 	  look like and (if the matter is urgent enough) to move around to -->
<!-- 	  find answers to such questions.  Frame-Systems, in this view, become -->
<!-- 	  choice-points corresponding (on the conceptual level) to the -->
<!-- 	  mutually exclusive choice <em>Systems</em> exploited by Winograd -->
<!-- 	  (1970). The different frames of a system represent different ways of -->
<!-- 	  using the same information, located at the common terminals. As in -->
<!-- 	  the grammatical situation, one has to choose one of them at a -->
<!-- 	  time. On the conceptual level this choice becomes: what questions -->
<!-- 	  shall I ask about this situation?  View-changing, as we shall argue, -->
<!-- 	  is a problem-solving technique important in representing, -->
<!-- 	  explaining, and predicting. In the rearrangements inherent in the -->
<!-- 	  frame-system representation (for example, of an action) we have a -->
<!-- 	  first approximation to Simmons&#39; (1973) idea of <em>procedures -->
<!--             which in some cases will change the contextual definitional -->
<!--             structure to reflect the action of a verb.</em>  Where do -->
<!-- 	  the <em>questions</em> come from? This is not in the scope of this -->
<!-- 	  paper, really, but we can be sure that the frame-makers (however -->
<!-- 	  they operate) must use some principles. The methods used to generate -->
<!-- 	  the questions ultimately shape each person&#39;s general -->
<!-- 	  intellectual style.  People surely differ in details of preferences -->
<!-- 	  for asking <em>Why?</em>, <em>How can I find out -->
<!--             more?</em>, <em>What&#39;s in it for me?</em>, <em>How will this -->
<!--             help with the current higher goals?</em>, and so forth.  Similar -->
<!-- 	  issues about the style of answering must arise. In its simplest form -->
<!-- 	  the drive toward instantiating empty terminals would appear as a -->
<!-- 	  variety of hunger or discomfort, satisfied by any default or other -->
<!-- 	  assignment that does not conflict with a prohibition. In more -->
<!-- 	  complex cases we should perceive less animalistic strategies for -->
<!-- 	  acquiring deeper understandings.  It is tempting, then, to imagine -->
<!-- 	  varieties of frame-systems that span from simple template-filling -->
<!-- 	  structures to implementations of the <em>views</em> of Newell -->
<!-- 	  &mdash; with all their implications about coherent generators of -->
<!-- 	  issues with which to be concerned, ways to investigate them, and -->
<!-- 	  procedures for evaluating proposed solutions. But as I noted in -->
<!-- 	  1.12, I feel uncomfortable about any superficially coherent -->
<!-- 	  synthesis in which one expects the same kind of theoretical -->
<!-- 	  framework to function well on many different levels of scale or -->
<!-- 	  concept. We should expect very different question-processing -->
<!-- 	  mechanisms to operate our low-level stereotypes and our most -->
<!-- 	  comprehensive strategic overviews. -->
	  
	  

<!-- 	<p> -->
<!-- 	  3. LEARNING, MEMORY, AND PARADIGMS -->

<!-- 	<p> -->
<!-- 	  <em>To the child, Nature gives various means of rectifying any -->
<!--             mistakes he may commit respecting the salutary or hurtful -->
<!--             qualities of the objects which surround him. On every occasion his -->
<!--             judgements are corrected by experience; want and pain are the -->
<!--             necessary consequences arising from false judgement; gratification -->
<!--             and pleasure are produced by judging aright. Under such masters, -->
<!--             we cannot fail but to become well informed; and we soon learn to -->
<!--             reason justly, when want and pain are the necessary consequences -->
<!--             of a contrary conduct.  In the study and practice of the sciences -->
<!--             it is quite different; the false judgements we form neither affect -->
<!--             our existence nor our welfare; and we are not forced by any -->
<!--             physical necessity to correct them. Imagination, on the contrary, -->
<!--             which is ever wandering beyond the bounds of truth, joined to -->
<!--             self-love and that self-confidence we are so apt to indulge, -->
<!--             prompt us to draw conclusions that are not immediately derived -->
<!--             from facts. . . .</em> -->
	  
<!-- 	  A. Lavoisier, Elements of Chemistry -->
	  
<!-- 	  How does one locate a frame to represent a new situation? -->
<!-- 	  Obviously, we cannot begin any complete theory outside the context -->
<!-- 	  of some proposed global scheme for the organization of knowledge in -->
<!-- 	  general. But if we imagine working within some bounded domain we can -->
<!-- 	  discuss some important issues: -->

<!-- 	<p> -->
<!-- 	  EXPECTATION: How to select an initial frame to meet some given -->
<!-- 	  conditions. -->
	  
<!-- 	  ELABORATION: How to select and assign subframes to represent -->
<!-- 	  additional details. -->
	  
<!-- 	  ALTERATION: How to find a frame to replace one that does not fit -->
<!-- 	  well enough. -->
	  
<!-- 	  NOVELTY: What to do if no acceptable frame can be found. Can we -->
<!-- 	  modify an old frame or must we build a new one? -->
	  
<!-- 	  LEARNING: What frames should be stored, or modified, as a result of -->
<!-- 	  the experience? -->
	  
<!-- 	  In popular culture, memory is seen as separate from the rest of -->
<!-- 	  thinking; but finding the right memory &mdash; it would be better to -->
<!-- 	  say: finding a useful memory &mdash; needs the same sorts of -->
<!-- 	  strategies used in other kinds of thinking!  We say someone -->
<!-- 	  is <em>clever</em> who is unusually good at quickly locating highly -->
<!-- 	  appropriate frames. His information retrieval systems are better at -->
<!-- 	  making good hypotheses, formulating the conditions the new frame -->
<!-- 	  should meet, and exploiting knowledge gained in -->
<!-- 	  the <em>unsuccessful</em> part of the search. Finding the right -->
<!-- 	  memory is no less a problem than solving any other kind of puzzle! -->
<!-- 	  Because of this, a good retrieval mechanism can be based only in -->
<!-- 	  part upon basic <em>innate</em> mechanisms. It must also depend -->
<!-- 	  largely on (learned) knowledge about the structure of one&#39;s own -->
<!-- 	  knowledge! Our proposal will combine several elements &mdash; a -->
<!-- 	  Pattern Matching Process, a Clustering Theory, and a Similarity -->
<!-- 	  Network.  In seeing a room, or understanding a story, one assembles -->
<!-- 	  a network of frames and subframes. Everything noticed or guessed, -->
<!-- 	  rightly or wrongly, is represented in this network. We have already -->
<!-- 	  suggested that an active frame cannot be maintained unless its -->
<!-- 	  terminal conditions are satisfied.  We now add the postulate that -->
<!-- 	  all satisfied frames must be assigned to terminals of superior -->
<!-- 	  frames. This applies, as a special case, to any substantial -->
<!-- 	  fragments of <em>data</em> that have been observed and represented. -->
<!-- 	  Of course, there must be an exception! We must allow a certain -->
<!-- 	  number of items to be attached to something like a set of <em>short -->
<!--             term memory</em> registers. But the intention is that very little -->
<!-- 	  can be remembered unless embedded in a suitable frame. This, at any -->
<!-- 	  rate, is the conceptual scheme; in particular domains we would of -->
<!-- 	  course admit other kinds of memory <em>hooks</em> and special -->
<!-- 	  sensory buffers. -->
	  

<!-- 	<p> -->
<!-- 	  3.1 REQUESTS TO MEMORY -->

<!-- 	<p> -->
<!-- 	  We can now imagine the memory system as driven by two complementary -->
<!-- 	  needs. On one side are items demanding to be properly represented by -->
<!-- 	  being embedded into larger frames; on the other side are -->
<!-- 	  incompletely-filled frames demanding terminal assignments. The rest -->
<!-- 	  of the system will try to placate these lobbyists, but not so much -->
<!-- 	  in accord with <em>general principles</em> as in accord with special -->
<!-- 	  knowledge and conditions imposed by the currently active goals. -->
<!-- 	  When a frame encounters trouble &mdash; when an important condition -->
<!-- 	  cannot be satisfied &mdash; something must be done. We envision the -->
<!-- 	  following major kinds of accomodation to trouble. -->
	  
<!-- 	  MATCHING: When nothing more specific is found, we can attempt to use -->
<!-- 	  some <em>basic</em> associative memory mechanism. This will -->

<!-- 	<p> -->
<!-- 	  succeed by itself only in relatively simple situations, but should -->
<!-- 	  play a supporting role in the other tactics. -->
	  
<!-- 	  EXCUSE: An apparent misfit can often be excused or explained. A -->
<!-- 	  <em>chair</em> that meets all other conditions but is much too small -->
<!-- 	  could be a <em>toy.</em> -->
	  
<!-- 	  ADVICE: The frame contains explicit knowledge about what to do about -->
<!-- 	  the trouble. Below, we describe an extensive, learned, -->
<!-- 	  <em>Similarity Network</em> in which to embed such knowledge. -->
	  
<!-- 	  SUMMARY: If a frame cannot be completed or replaced, one must give -->
<!-- 	  it up. But first one must construct a well-formulated complaint or -->
<!-- 	  summary to help whatever process next becomes responsible for -->
<!-- 	  reassigning the subframes left in limbo. -->
	  
<!-- 	  In my view, all four of these are vitally important. I discuss them -->
<!-- 	  in the following sections. -->

<!-- 	<p> -->
<!-- 	  3.2 MATCHING -->

<!-- 	<p> -->
<!-- 	  When replacing a frame, we do not want to start all over again.  How -->
<!-- 	  can we remember what was already <em>seen?</em> We consider here -->
<!-- 	  only the case in which the system has no specific knowledge about -->
<!-- 	  what to do and must resort to some <em>general</em> strategy. No -->
<!-- 	  completely general method can be very good, but if we could find a -->
<!-- 	  new frame that shares enough terminals with the old frame, then some -->
<!-- 	  of the common assignments can be retained, and we will probably do -->
<!-- 	  better than chance.  The problem can be formulated as follows: let E -->
<!-- 	  be the cost of losing a certain already assigned terminal and let F -->
<!-- 	  be the cost of being unable to assign some other terminal. If E is -->
<!-- 	  worse than F, then any new frame should retain the old -->
<!-- 	  subframe. Thus, given any sort of priority ordering on the -->
<!-- 	  terminals, a typical request for a new frame should include: (1) -->
<!-- 	  Find a frame with as many terminals in common with (a,b, . . .  z) -->
<!-- 	  as possible, where we list high priority terminals already assigned -->
<!-- 	  in the old frame. -->

<!-- 	<p> -->
<!-- 	  But the frame being replaced is usually already a subframe of some -->
<!-- 	  other frame and must satisfy the markers of its attachment terminal, -->
<!-- 	  lest the entire structure be lost. This suggests another form of -->
<!-- 	  memory request, looking upward rather than downward: -->
	  
<!-- 	  (2) Find or build a frame that has properties [a,b,. . . , z] -->
	  
<!-- 	  If we emphasize differences rather than absolute specifications, we -->
<!-- 	  can merge (2) and (1): -->
	  
<!-- 	  (3) Find a frame that is like the old frame except for certain -->
<!-- 	  differences [a,b,. . . , z] between them. -->
	  
<!-- 	  One can imagine a parallel-search or hash-coded memory to handle (1) -->
<!-- 	  and (2) if the terminals or properties are simple atomic symbols. -->
<!-- 	  (There must be some such mechanism, in any case, to support a -->
<!-- 	  production-based program or some sort of pattern matcher.) -->
<!-- 	  Unfortunately, there are so many ways to do this that it implies no -->
<!-- 	  specific design requirements.  Although (1) and (2) are formally -->
<!-- 	  special cases of (3), they are different in practice because -->
<!-- 	  complicated cases of (3) require knowledge about differences. In -->
<!-- 	  fact (3) is too general to be useful as stated, and I will later -->
<!-- 	  propose to depend on specific, learned, knowledge about differences -->
<!-- 	  between pairs of frames rather than on broad, general principles. -->
<!-- 	  It should be emphasized again that we must not expect magic. For -->
<!-- 	  difficult, novel problems a new representation structure will have -->
<!-- 	  to be constructed, and this will require application of both general -->
<!-- 	  and special knowledge. The paper of Freeman and Newell (1971) -->
<!-- 	  discusses the problem of design of structures. That paper -->
<!-- 	  complements this one in an important dimension, for it discusses how -->
<!-- 	  to make a structure that satisfies a collection of functional -->
<!-- 	  requirements &mdash; conditions related to satisfying goals &mdash; -->
<!-- 	  in addition to conditions on containment of specified substructures -->
<!-- 	  and symbols. -->

<!-- 	<p> -->
<!-- 	  3.3 EXCUSES We can think of a frame as describing an <em>ideal.</em> -->
<!-- 	  If an ideal does not match reality because it is <em>basically</em> -->
<!-- 	  wrong, it must be replaced. But it is in the nature of ideals that -->
<!-- 	  they are really elegant simplifications; -->

<!-- 	<p> -->
<!-- 	  their attractiveness derives from their simplicity, but their real -->
<!-- 	  power depends upon additional knowledge about interactions between -->
<!-- 	  them!  Accordingly we need not abandon an ideal because of a failure -->
<!-- 	  to instantiate it, provided one can explain the discrepancy in terms -->
<!-- 	  of such an interaction. Here are some examples in which such an -->
<!-- 	  <em>excuse</em> can save a failing match: -->
	  
<!-- 	  OCCLUSION: A table, in a certain view, should have four legs, but a -->
<!-- 	  chair might occlude one of them. One can look for things like -->
<!-- 	  T-joints and shadows to support such an excuse. -->

<!-- 	<p> -->
<!-- 	  FUNCTIONAL VARIANT: A chair-leg is usually a stick, geometrically; -->
<!-- 	  but more important, it is functionally a support.  Therefore, a -->
<!-- 	  strong center post, with an adequate base plate, should be an -->
<!-- 	  acceptable replacement for all the legs. Many objects are multiple -->
<!-- 	  purpose and need functional rather than physical descriptions. -->

<!-- 	<p> -->
<!-- 	  BROKEN: A visually missing component could be explained as in fact -->
<!-- 	  physically missing, or it could be broken. Reality has a -->

<!-- 	<p> -->
<!-- 	  variety of ways to frustrate ideals. -->

<!-- 	<p> -->
<!-- 	  PARASITIC CONTEXTS: An object that is just like a chair, except in -->
<!-- 	  size, could be (and probably is) a toy chair. The complaint <em>too -->
<!--             small</em> could often be so interpreted in contexts with other -->
<!-- 	  things too small, children playing, peculiarly large -->
<!-- 	  <em>grain,</em> and so forth. -->
	  
<!-- 	  In most of those examples, the kinds of knowledge to make the repair -->
<!-- 	  &mdash; and thus salvage the current frame &mdash; -->
<!-- 	  are <em>general</em> enough usually to be attached to the thematic -->
<!-- 	  context of a superior frame. In the remainder of this essay, I will -->
<!-- 	  concentrate on types of more sharply localized knowledge that would -->
<!-- 	  naturally be attached to a frame itself, for recommending its own -->
<!-- 	  replacement. -->
	  
<!-- 	  3.4 ADVICE AND SIMILARITY NETWORKS -->

<!-- 	<p> -->
<!-- 	  <em>The justification of Napoleon&#39;s statement &mdash; if, -->
<!--             indeed, he ever made it &mdash; that those who form a picture of -->
<!--             everything are unfit to command, is to be found in the first of -->
<!--             these defects. A commander who approaches a battle with a picture -->
<!--             before him of how such and such a fight went on such and such an -->
<!--             occasion, will find, two minutes after the forces have joined, -->
<!--             that something has gone awry. Then his picture is destroyed. He -->
<!--             has nothing in reserve except another individual picture and this -->
<!--             also will not serve him for long. Or it may be that when his first -->
<!--             pictured forecast is found to be inapplicable, he has so -->
<!--             multifarious and pressing a collection of pictures that equally he -->
<!--             is at a loss what practical adjustment to make. Too great -->
<!--             individuality of past reference may be very nearly as embarassing -->
<!--             as no individuality of past reference at all. To serve adequately -->
<!--             the demands of a constantly changing environment, we have not only -->
<!--             to pick items out of their general setting, but we must know what -->
<!--             parts of them may flow and alter without disturbing their general -->
<!--             significance and functions.</em> -->
	  
<!-- 	  F. C. Bartlett, Remembering -->

<!-- 	<p> -->
<!-- 	  In moving about a familiar house, we already know a dependable -->
<!-- 	  structure for <em>information retrieval</em> of room frames. When we -->
<!-- 	  move through Door D, in Room X, we expect to enter Room Y (assuming -->
<!-- 	  D is not the Exit). We could represent this as an action -->
<!-- 	  transformation of the simplest kind, consisting of pointers between -->
<!-- 	  pairs of room frames of a particular house system.  When the house -->
<!-- 	  is not familiar, a <em>logical</em> strategy might be to move up a -->
<!-- 	  level of classification: when you leave one room, you may not know -->
<!-- 	  which room you are entering, but you usually know that it is some -->
<!-- 	  room. Thus, one can partially evade lack of specific information by -->
<!-- 	  dealing with classes &mdash; and one has to use some form of -->
<!-- 	  abstraction or generalization to escape the dilemma of -->
<!-- 	  Bartlett&#39;s commander.  In some sense the use of classes is -->
<!-- 	  inescapable; when specific information is unavailable, one turns to -->
<!-- 	  classes as a <em>first-order</em> theory underlying any more -->
<!-- 	  sophisticated model. Fortunately, it is not necessary to use classes -->
<!-- 	  explicitly; indeed, that leads to trouble! While -->
<!-- 	  <em>class,</em> taken literally or mathematically, forces one into -->
<!-- 	  an inclusion- based hierarchy, <em>concepts</em> are interrelated in -->
<!-- 	  different ways when in different contexts, and no single -->
<!-- 	  hierarchical ordering is generally satisfactory for all goals. This -->
<!-- 	  observation holds also for procedures and for frames. We do not want -->
<!-- 	  to be committed to an inflexible, inclusion-oriented classification -->
<!-- 	  of knowledge.  Winston&#39;s thesis (1970) proposes a way to -->
<!-- 	  construct a retrieval system that can represent classes but has -->
<!-- 	  additional flexibility. His retrieval pointers can be made to -->
<!-- 	  represent goal requirements and action effects as well as class -->
<!-- 	  memberships. Because the idea is not well-known, I will explain it -->
<!-- 	  by elaborating an example sketched in his thesis: -->
	  
<!-- 	  What does it mean to expect a chair? Typically, four legs, some -->
<!-- 	  assortment of rungs, a level seat, an upper back. One expects also -->
<!-- 	  certain relations between these <em>parts.</em> The legs must be -->
<!-- 	  below the seat, the back above. The legs must be supported by the -->
<!-- 	  floor. The seat must be horizontal, the back vertical, and so -->
<!-- 	  forth. Now suppose that this description does not match; the vision -->
<!-- 	  system finds four legs, a level plane, but no back. The -->
<!-- 	  <em>difference</em> between what we expect and what we see -->
<!-- 	  is <em>too few backs.</em> This suggests not a chair, but a table -->
<!-- 	  or a bench. -->
	  
<!-- 	  Winston proposes pointers from each description in memory to other -->
<!-- 	  descriptions, with each pointer labelled by a difference marker. -->
<!-- 	  Complaints about mismatch are matched to the difference pointers -->
<!-- 	  leaving the frame and thus may propose a better candidate frame. -->
<!-- 	  Winston calls the resulting structure a Similarity Network. -->

<!-- 	<p> -->
<!-- 	  Winston proposes, incidentally, that a machine might spend idle time -->
<!-- 	  in an orderly comparison of various models in memory with one -->
<!-- 	  another. Whenever it finds few important differences between a pair, -->
<!-- 	  it inserts difference pointers for them.  But difference information -->
<!-- 	  becomes available also in any attempt to match a situation with -->
<!-- 	  memory, as successive attempts yield models that are generally -->
<!-- 	  similar but have specific, describable differences. Thus, instead of -->
<!-- 	  wasting this information one can use it to make the Similarity -->
<!-- 	  Network structure grow in the course of normal use of memory. If -->
<!-- 	  this pointer-building procedure is sensible about recording -->
<!-- 	  differences <em>relevant</em> to achieving goals, the result will be -->
<!-- 	  so much the more useful, and we have a mechanism for learning from -->
<!-- 	  experience.  Is a Similarity Network practical? At first sight, -->
<!-- 	  there might seem to be a danger of unconstrained growth of -->
<!-- 	  memory. If there are N frames, and K kinds of differences, then -->
<!-- 	  there could be as many as K*N*N interframe pointers. One might fear -->
<!-- 	  the following consequences: -->

<!-- 	<p> -->
<!-- 	  (1) If N is large, say 10**7, then N*N is very large &mdash; of the -->
<!-- 	  order of 10**14 &mdash; which might be impractical, at least for -->
<!-- 	  human memory. -->

<!-- 	<p> -->
<!-- 	  (2) There might be so many pointers for a given difference and a -->
<!-- 	  given frame that the system will not be selective enough to be -->
<!-- 	  useful. -->
	  
<!-- 	  (3) K itself might be very large if the system is sensitive to many -->
<!-- 	  different kinds of issues. -->
	  
<!-- 	  Actually, none of these problems seem really serious in connection -->
<!-- 	  with human memory. According to contemporary opinions (admittedly, -->
<!-- 	  not very conclusive) about the rate of storage into human long-term -->
<!-- 	  memory there are probably not enough seconds in a lifetime to cause -->
<!-- 	  a saturation problem.  In regard to (2), most pairs of frames that -->
<!-- 	  make up the N*N term should be so different that no plausible -->
<!-- 	  comparison mechanism should consider inserting any pointers at all -->
<!-- 	  between them. As Winston notes, only a <em>near miss</em> is likely -->
<!-- 	  to be of much value. Certainly, excessive reliance on -->
<!-- 	  undiscriminating differences will lead to confusion.  So the real -->
<!-- 	  problem, paradoxically, is that there will be too few connections! -->
<!-- 	  One cannot expect to have enough time to fill out the network to -->
<!-- 	  saturation. Given two frames that should be linked by a difference, -->
<!-- 	  we cannot count on that pointer being there; the problem may not -->
<!-- 	  have occurred before. However, in the next section we see how to -->
<!-- 	  partially escape this problem. -->

<!-- 	<p> -->
<!-- 	  3.5 CLUSTERS, CLASSES, AND A GEOGRAPHIC ANALOGY -->

<!-- 	<p> -->
<!-- 	  <em>Though a discussion of some of the attributes shared by a number -->
<!--             of games or chairs or leaves often helps us to learn how to employ -->
<!--             the corresponding term, there is no set of characteristics that is -->
<!--             simultaneously applicable to all members of the class and to them -->
<!--             alone.  Instead, confronted with a previously unobserved activity, -->
<!--             we apply the term &lsquo;game&rsquo; because what we are seeing -->
<!--             bears a close &lsquo;family resemblance&rsquo; to a number of the -->
<!--             activities we have previously learned to call by that name. For -->
<!--             Wittgenstein, in short, games, chairs, and leaves are natural -->
<!--             families, each constituted by a network of overlapping and -->
<!--             crisscross resemblances. The existence of such a network -->
<!--             sufficiently accounts for our success in identifying the -->
<!--             corresponding object or activity.</em> -->

<!-- 	<p> -->
<!-- 	  T. Kuhn, The Structure of Scientific Revolutions -->

<!-- 	<p> -->
<!-- 	  To make the Similarity Network act more <em>complete,</em> consider -->
<!-- 	  the following analogy. In a city, any person should be able to visit -->
<!-- 	  any other; but we do not build a special road between each pair of -->
<!-- 	  houses; we place a group of houses on a <em>block.</em> We do not -->
<!-- 	  connect roads between each pair of blocks; but have them share -->
<!-- 	  streets. We do not connect each town to every other; but construct -->
<!-- 	  main routes, connecting the centers of larger groups. Within such an -->
<!-- 	  organization, each member has direct links to some other individuals -->
<!-- 	  at his own -->
<!-- 	  <em>level,</em> mainly to nearby, highly similar ones; but each -->
<!-- 	  individual has also at least a few links to <em>distinguished</em> -->
<!-- 	  members of higher level groups. The result is that there is usually -->
<!-- 	  a rather short sequence between any two individuals, if one can but -->
<!-- 	  find it.  To locate something in such a structure, one uses a -->
<!-- 	  hierarchy like the one implicit in a mail address. Everyone knows -->
<!-- 	  something about the largest categories, in that he knows where the -->
<!-- 	  major cities are. An inhabitant of a city knows the nearby towns, -->
<!-- 	  and people in the towns know the nearby villages. No person knows -->
<!-- 	  all the individual routes between pairs of houses; but, for a -->
<!-- 	  particular friend, one may know a special route to his home in a -->
<!-- 	  nearby town that is better than going to the city and -->
<!-- 	  back. Directories factor the problem, basing paths on standard -->
<!-- 	  routes between major nodes in the network. Personal shortcuts can -->
<!-- 	  bypass major nodes and go straight between familiar -->
<!-- 	  locations. Although the standard routes are usually not quite the -->
<!-- 	  very best possible, our stratified transport and communication -->
<!-- 	  services connect everything together reasonably well, with -->
<!-- 	  comparatively few connections.  At each level, the aggregates -->
<!-- 	  usually have distinguished foci or capitols. These serve as elements -->
<!-- 	  for clustering at the next level of aggregation. There is no -->
<!-- 	  non-stop airplane service between New Haven and San Jose because it -->
<!-- 	  is more efficient overall to share the -->
<!-- 	  <em>trunk</em> route between New York and San Francisco, which are -->
<!-- 	  the capitols at that level of aggregation.  As our memory networks -->
<!-- 	  grow, we can expect similar aggregations of the destinations of our -->
<!-- 	  similarity pointers. Our decisions about what we consider to be -->
<!-- 	  primary or <em>trunk</em> difference features and which are -->
<!-- 	  considered subsidiary will have large effects on our abilities. -->
<!-- 	  Such decisions eventually accumulate to become epistemological -->
<!-- 	  committments about the <em>conceptual</em> cities of our mental -->
<!-- 	  universe.  The non-random convergences and divergences of the -->
<!-- 	  similarity pointers, for each difference d, thus tend to structure -->
<!-- 	  our conceptual world around (1) the aggregation into d-clusters (2) -->
<!-- 	  the selection of d-capitols -->
	  
<!-- 	  Note that it is perfectly all right to have several capitols in a -->
<!-- 	  cluster, so that there need be no one attribute common to them -->
<!-- 	  all. The -->
<!-- 	  <em>crisscross resemblances</em> of Wittgenstein are then -->
<!-- 	  consequences of the local connections in our similarity network, -->
<!-- 	  which are surely adequate to explain how we can feel as though we -->
<!-- 	  know what is a chair or a game &mdash; yet cannot always define it -->
<!-- 	  in a <em>logical</em> way as an element in some class-hierarchy or -->
<!-- 	  by any other kind of compact, formal, declarative rule. The apparent -->
<!-- 	  coherence of the conceptual aggregates need not reflect explicit -->
<!-- 	  definitions, but can emerge from the success-directed sharpening of -->
<!-- 	  the difference-describing processes.  The selection of capitols -->
<!-- 	  corresponds to selecting stereotypes or typical elements whose -->
<!-- 	  default assignments are unusually useful.  There are many forms of -->
<!-- 	  chairs, for example, and one should choose carefully the -->
<!-- 	  chair-description frames that are to be the major capitols of -->
<!-- 	  chair-land. These are used for rapid matching and assigning -->
<!-- 	  priorities to the various differences. The lower priority features -->
<!-- 	  of the cluster center then serve either as default properties of the -->
<!-- 	  chair types or, if more realism is required, as dispatch pointers to -->
<!-- 	  the local chair villages and towns. Difference pointers could -->
<!-- 	  be <em>functional</em> as well as geometric. Thus, after rejecting a -->
<!-- 	  first try at <em>chair</em> one might try the functional idea -->
<!-- 	  of <em>something one can sit on</em> to explain an unconventional -->
<!-- 	  form. This requires a deeper analysis in terms of forces and -->
<!-- 	  strengths. Of course, that analysis would fail to capture toy -->
<!-- 	  chairs, or chairs of such ornamental delicacy that their actual use -->
<!-- 	  would be unthinkable. These would be better handled by the method of -->
<!-- 	  excuses, in which one would bypass the usual geometrical or -->
<!-- 	  functional explanations in favor of responding to contexts involving -->
<!-- 	  art or play.  It is important to re-emphasize that there is no -->
<!-- 	  reason to restrict the memory structure to a single hierarchy; the -->
<!-- 	  notions of <em>level</em> of aggregation need not coincide for -->
<!-- 	  different kinds of differences. The d-capitols can exist, not only -->
<!-- 	  by explicit declarations, but also implicitly by their focal -->
<!-- 	  locations in the structure defined by convergent d-pointers. (In the -->
<!-- 	  Newell-Simon GPS framework, the <em>differences</em> are ordered -->
<!-- 	  into a fixed hierarchy. By making the priorities depend on the goal, -->
<!-- 	  the same memories could be made to serve more purposes; the -->
<!-- 	  resulting problem-solver would lose the elegance of a single, -->
<!-- 	  simply-ordered measure of <em>progress,</em> but that is the price -->
<!-- 	  of moving from a first-order theory.)  Finally, we should point out -->
<!-- 	  that we do not need to invoke any mysterious additional mechanism -->
<!-- 	  for creating the clustering structure.  Developmentally, one would -->
<!-- 	  assume, the earliest frames would tend to become the capitols of -->
<!-- 	  their later relatives, unless this is firmly prevented by -->
<!-- 	  experience, because each time the use of one stereotype is -->
<!-- 	  reasonably successful, its centrality is reinforced by another -->
<!-- 	  pointer from somewhere else. Otherwise, the acquisition of new -->
<!-- 	  centers is in large measure forced upon us from the outside: by the -->
<!-- 	  words available in one&#39;s language; by the behavior of objects in -->
<!-- 	  one&#39;s environment; by what one is told by one&#39;s teachers, -->
<!-- 	  family, and general culture. Of course, at each step the structure -->
<!-- 	  of the previous structure dominates the acquisition of the -->
<!-- 	  later. But in any case such forms and clusters should emerge from -->
<!-- 	  the interactions between the world and almost any memory-using -->
<!-- 	  mechanism; it would require more explanation were they not found! -->

<!-- 	<p> -->
<!-- 	  3.6 ANALOGIES AND ALTERNATIVE DESCRIPTIONS -->
	  
<!-- 	  We have discussed the use of different frames of the same system to -->
<!-- 	  describe the same situation in different ways: for change of -->
<!-- 	  position in vision and for change of emphasis in language. In the -->
<!-- 	  wolf and lamb episode, for example, two frames are used in a -->
<!-- 	  before-after situation pair. Sometimes, in <em>problem-solving</em> -->
<!-- 	  we use two or more descrip- tions in a more complex way to construct -->
<!-- 	  an analogy or to apply two radically different kinds of analysis to -->
<!-- 	  the same situation. For hard problems, one <em>problem space</em> is -->
<!-- 	  usually not enough!  Suppose your car battery runs down. You believe -->
<!-- 	  that there is an electricity shortage and blame the generator.  The -->
<!-- 	  generator can be represented as a mechanical system: the rotor has a -->
<!-- 	  pulley wheel driven by a belt from the engine. Is the belt tight -->
<!-- 	  enough? Is it even there? The output, seen mechanically, is a cable -->
<!-- 	  to the battery or whatever. Is it intact? Are the bolts tight? Are -->
<!-- 	  the brushes pressing on the commutator?  Seen electrically, the -->
<!-- 	  generator is described differently. The rotor is seen as a -->
<!-- 	  flux-linking coil, rather than as a rotating device. The brushes and -->
<!-- 	  commutator are seen as electrical switches. The output is current -->
<!-- 	  along a pair of conductors leading from the brushes through control -->
<!-- 	  circuits to the battery.  We thus represent the situation in two -->
<!-- 	  quite different frame-systems.  In one, the armature is a mechanical -->
<!-- 	  rotor with pulley, in the other it is a conductor in a changing -->
<!-- 	  magnetic field. The same &mdash; or analogous &mdash; elements share -->
<!-- 	  terminals of different frames, and the frame- transformations apply -->
<!-- 	  only to some of them.  The differences between the two frames are -->
<!-- 	  substantial. The entire mechanical chassis of the car plays the -->
<!-- 	  simple role, in the electrical frame, of one of the battery -->
<!-- 	  connections. The diagnostician has to use both representations. A -->
<!-- 	  failure of current to flow often means that an intended conductor is -->
<!-- 	  not acting like one. For this case, the basic transformation between -->
<!-- 	  the frames depends on the fact that electrical continuity is in -->
<!-- 	  general equivalent to firm mechanical attachment.  Therefore, any -->
<!-- 	  conduction disparity revealed by electrical measurements should make -->
<!-- 	  us look for a corresponding disparity in the mechanical frame. In -->
<!-- 	  fact, since <em>repair</em> in this universe is synonymous -->
<!-- 	  with <em>mechanical repair,</em> the diagnosis must end in the -->
<!-- 	  mechanical frame. Eventually, we might locate a defective mechanical -->
<!-- 	  junction and discover a loose connection, corrosion, wear, or -->
<!-- 	  whatever. -->

<!-- 	<p> -->
<!-- 	  Why have two separate frames, rather than one integrated structure -->
<!-- 	  to represent the generator? I believe that in such a complex problem -->
<!-- 	  one can never cope with many details at once. At each moment one -->
<!-- 	  must work within a reasonably simple framework. I contend that any -->
<!-- 	  problem that a person can solve at all is worked out at each moment -->
<!-- 	  in a small context and that the key operations in problem solving -->
<!-- 	  are concerned with finding or constructing these working -->
<!-- 	  environments.  Indeed, finding an electrical fault requires moving -->
<!-- 	  between at least three frames: a visual one along with the -->
<!-- 	  electrical and mechanical frames. If electrical evidence suggests a -->
<!-- 	  loose mechanical connection, one needs a visual frame to guide -->
<!-- 	  one&#39;s self to the mechanical fault.  Are there general methods -->
<!-- 	  for constructing adequate frames? The answer is both yes and no! -->
<!-- 	  There are some often-useful strategies for adapting old frames to -->
<!-- 	  new purposes; but I should emphasize that humans certainly have no -->
<!-- 	  magical way to solve all hard problems!  One must not fall into what -->
<!-- 	  Papert calls the Superhuman-Human Fallacy and require a theory of -->
<!-- 	  human behavior to explain even things that people cannot really do! -->

<!-- 	<p> -->
<!-- 	  One cannot expect to have a frame exactly right for any problem or -->
<!-- 	  expect always to be able to invent one. But we do have a good deal -->
<!-- 	  to work with, and it is important to remember the contribution of -->
<!-- 	  one&#39;s culture in assessing the complexity of problems people -->
<!-- 	  seem to solve.  The experienced mechanic need not routinely invent; -->
<!-- 	  he already has engine representations in terms of ignition, -->
<!-- 	  lubrication, cooling, timing, fuel mixing, transmission, -->
<!-- 	  compression, and so forth. Cooling, for example, is already -->
<!-- 	  subdivided into fluid circulation, air flow, thermostasis, -->
<!-- 	  etc. Most <em>ordinary</em> problems are presumably solved by -->
<!-- 	  systematic use of the analogies provided by the transformations -->
<!-- 	  between pairs of these structures. The huge network of knowledge, -->
<!-- 	  acquired from school, books, apprenticeship, or whatever is -->
<!-- 	  interlinked by difference and relevancy pointers. No doubt the -->
<!-- 	  culture imparts a good deal of this structure by its conventional -->
<!-- 	  use of the same words in explanations of different views of a -->
<!-- 	  subject.  What about interactions that cross many of these -->
<!-- 	  boundaries? A Gestalt philosopher might demand some kind of -->
<!-- 	  synthesis in which one sees the engine as a whole. But before we -->
<!-- 	  demand a general solution, we should remind ourselves that for -->
<!-- 	  faults that stem from three-or-more interacting elements, a human -->
<!-- 	  auto mechanic will diagnose them, if at all, only after expensive, -->
<!-- 	  exhaustive replacement of many innocent components. Thus, the desire -->
<!-- 	  for complete synthesis should not be a theoretical requirement. To -->
<!-- 	  be sure, there must indeed be some structure linking together the -->
<!-- 	  different conceptual engine frames. But this, too, may be relatively -->
<!-- 	  simple. Perhaps one must add a fourth engine-superframe whose -->
<!-- 	  terminals point to the various electrical, mechanical, and visual -->
<!-- 	  representation frames, and are themselves interconnected by pointers -->
<!-- 	  describing when and how the different subframes are to be -->
<!-- 	  used. Presumably every complicated system that -->
<!-- 	  is <em>understood</em> contains some superframe structures that -->
<!-- 	  direct the utilization of subframes.  Incidentally, it is tempting -->
<!-- 	  in our culture to believe that a larger view is taken in our -->
<!-- 	  subconscious minds. As Poincare observes, one often comes upon a -->
<!-- 	  sudden illumination after a period of conscious formulation, -->
<!-- 	  followed by a much longer period of non-conscious activity. I read -->
<!-- 	  his further discussion as proposing that the unconscious activity is -->
<!-- 	  a combinatorial heuristic search in which the chance of success -->
<!-- 	  depends mainly of the quality of the ingredients introduced by the -->
<!-- 	  preliminary conscious analysis; these elements are combined in -->
<!-- 	  different ways until a configuration is reached that passes some -->
<!-- 	  sort of test. -->
	  
<!-- 	  <em>I have spoken of the feeling of absolute certitude accompanying -->
<!--             the inspiration . . . ; often this feeling deceives us without -->
<!--             being any the less vivid, and we only find it out when we seek to -->
<!--             put on foot the demonstrations. I have especially noticed this -->
<!--             fact in regard to ideas coming to me in the morning or evening in -->
<!--             bed while in a self-hypnagogic state.</em> -->

<!-- 	<p> -->
<!-- 	  H. Poincare, Foundations of Science -->
	  
<!-- 	  The product of inspiration is thus not a fully detailed solution but -->
<!-- 	  a -->
<!-- 	  <em>point of departure</em> or plan, brought to consciousness -->
<!-- 	  because it has passed some sort of threshold of <em>esthetic -->
<!--             sensibility.</em>  On this last point Poincare does indeed seem to -->
<!-- 	  subscribe to a holistic conception for he -->
<!-- 	  characterizes <em>elegant</em> mathematical entities as -->
<!-- 	  those <em>whose elements are so harmoniously disposed that the mind -->
<!--             can embrace their totality while realizing the details.</em> It -->
<!-- 	  remains to be seen whether the filters that admit new descriptive -->
<!-- 	  combinations to the status of fully conscious attention require a -->
<!-- 	  complex, active analysis or can be explained by simpler matching and -->
<!-- 	  retrieval operations. (It is an unhappy fact that mathematicians -->
<!-- 	  have not contributed much to understanding the mechanisms of -->
<!-- 	  problem- solving &mdash; with the exception of Poincare, Polya, and -->
<!-- 	  a few others. I wonder if this is not largely due to their -->
<!-- 	  attachment to the concept of -->
<!-- 	  <em>elegance</em> &mdash; passed from one generation to the next as -->
<!-- 	  an intangible quality, worshipped but not explained or analyzed.) In -->
<!-- 	  any case, I see no reason to suppose that the unconscious is -->
<!-- 	  distinguished either along the dimension of massive parallel -->
<!-- 	  computation or by extraordinary holistic synthesis. A more plausible -->
<!-- 	  function would seem to be rapid, shallow exploration using material -->
<!-- 	  prepared by earlier analysis. The unconscious aspect might only -->
<!-- 	  reflect the lack of <em>annotation</em> and record-keeping that -->
<!-- 	  would make the process otherwise accessible to review and -->
<!-- 	  analysis. But the question about the complexity of the acceptance -->
<!-- 	  filter certainly still stands. -->
	  
<!-- 	  3.7 SUMMARIES: USING FRAMES IN HEURISTIC SEARCH -->

<!-- 	<p> -->
<!-- 	  Over the past decade, it has become widely recognized how important -->
<!-- 	  are the details of the representation of a <em>problem space</em>; -->

<!-- 	<p> -->
<!-- 	  but it was not so well recognized that descriptions can be useful to -->
<!-- 	  a program, as well as to the person writing the program. Perhaps -->
<!-- 	  progress was actually retarded by ingenious schemes to avoid -->
<!-- 	  explicit manipulation of descriptions. Especially -->
<!-- 	  in <em>theorem-proving</em> and in -->
<!-- 	  <em>game-playing</em> the dominant paradigm of the past might be -->
<!-- 	  schematized so: -->
	  
<!-- 	  The central goal of a Theory of Problem Solving is to find -->
<!-- 	  systematic ways to reduce the extent of the Search through the -->
<!-- 	  Problem Space. -->
	  
<!-- 	  Sometimes a simple problem is indeed solved by trying a sequence of -->
<!-- 	  <em>methods</em> until one is found to work. Some harder problems -->
<!-- 	  are solved by a sequence of local improvements, -->
<!-- 	  by <em>hill-climbing</em> within the problem space. But even when -->
<!-- 	  this solves a particular problem, it tells us little about the -->
<!-- 	  problem-space; hence yielding no improved future competence. The -->
<!-- 	  best-developed technology of Heuristic Search is that of -->
<!-- 	  game-playing using tree-pruning, plausible-move generation, and -->
<!-- 	  terminal-evaluation methods. But even those systems that use -->
<!-- 	  hierarchies of symbolic goals do not improve their understanding or -->
<!-- 	  refine their representations. I now propose a more mature and -->
<!-- 	  powerful paradigm: -->
	  
<!-- 	  The primary purpose in problem solving should be better to -->
<!-- 	  understand the problem space, to find representations within which -->
<!-- 	  the problems are easier to solve. The purpose of search is to get -->
<!-- 	  information for this reformulation, not &mdash; as is usually -->
<!-- 	  assumed &mdash; to find solutions; once the space is adequately -->
<!-- 	  understood, solutions to problems will more easily be found. -->
	  
<!-- 	  In particular, I reject the idea that the value of an intellectual -->
<!-- 	  experiment should be assessed along the dimension of success &mdash; -->
<!-- 	  partial success &mdash; failure, or in terms of <em>improving the -->
<!--             situation</em> or -->
<!-- 	  <em>reducing a difference.</em> An application of a <em>method,</em> -->
<!-- 	  or a reconfiguration of a representation can be valuable if it leads -->
<!-- 	  to a way to improve the strategy of subsequent trials. Earlier -->
<!-- 	  formulations of the role of heuristic search strategies did not -->
<!-- 	  emphasize these possibilities, although they are implicit in -->
<!-- 	  discussions of <em>planning.</em>  How can the new paradigm be -->
<!-- 	  combined with the classical minimax strategy? In a typical episode, -->
<!-- 	  one is located at a certain node A in the search tree, and examines -->
<!-- 	  two or more possible moves, say, B and C. Each of these is somehow -->
<!-- 	  evaluated to yield values V(B) and V(C). Then these are somehow -->
<!-- 	  combined to yield a score -->
	  
<!-- 	  S(A) = M(V(B), V(C)) -->
	  
<!-- 	  where M is some function that takes two numbers and yields one. In -->
<!-- 	  effect, M has to summarize the results of all the search below A and -->
<!-- 	  compress them into a single numerical quantity to represent the -->
<!-- 	  value of being at node A.  Now, what is the purpose of this? If one -->
<!-- 	  were able to search the entire game-tree, we could use S at each -->
<!-- 	  node to decide which move is best to make. Since we cannot search -->
<!-- 	  the whole tree, we need information about what next to explore; we -->
<!-- 	  want S to tell the move generator what kinds of moves to -->
<!-- 	  consider. But if S is a mere number, this is unsuitable for much -->
<!-- 	  reasoning or analysis.  If S(B) has a low value, we can assume that -->
<!-- 	  B is a bad position. But if we want the move generator not to make -->
<!-- 	  the <em>same kind of mistake</em> again, the message must contain -->
<!-- 	  some additional clue about why B is weak &mdash; or better, what to -->
<!-- 	  do about it. So we really need a summary explanation of what was -->
<!-- 	  found in the search; and since we are in a tree we need further to -->
<!-- 	  summarize such summaries recursively.  There is a problem here we -->
<!-- 	  might call <em>summary-divergence.</em> If the summary of the -->
<!-- 	  situation at A contains (in general) any explicit mention of B and -->
<!-- 	  C, then any recursive description scheme is in danger of containing -->
<!-- 	  an explicit copy of the entire move-tree; then to answer a question -->
<!-- 	  one might have nearly as bad a time searching the summary as the -->
<!-- 	  game-tree itself. One way to prevent this is simply to limit the -->
<!-- 	  size of the summary. However, we can avoid such drastic -->
<!-- 	  knowledge-destruction; in a frame-description, the important -->
<!-- 	  features and relations at the top levels can serve as summaries -->
<!-- 	  while the lower-level subsidiary descriptions can be accessed only -->
<!-- 	  if necessary. How much of the whole analysis tree remains in long -->
<!-- 	  term memory, and how much is left as garbage after the move is made -->
<!-- 	  would depend on other aspects of how the game-player uses his -->
<!-- 	  general experience.  How are the summaries to be made? Again, the -->
<!-- 	  frame idea suggests a flexible approach. Instead of demanding a -->
<!-- 	  rigid format, we could build up a collection of ad -->
<!-- 	  hoc <em>summary</em> frames, each evoked when their terminals fit -->
<!-- 	  subordinate descriptions and its frame-markers match the current -->
<!-- 	  goals. Thus each does its job when appropriate. For example, one -->
<!-- 	  might have a variety of <em>fork</em> frames.  If a Knight lands on -->
<!-- 	  a square that threatens both check and rook capture, a fork frame is -->
<!-- 	  activated by its condition that in each of only two plausible moves, -->
<!-- 	  the unmoved piece is lost. Once this frame is activated it can make -->
<!-- 	  a specific recommendation, perhaps that the generator for the forked -->
<!-- 	  player see if a previously available move can apply additional -->
<!-- 	  defense to the forking square. -->

<!-- 	<p> -->
<!-- 	  3.8 FRAMES AS PARADIGMS -->

<!-- 	<p> -->
<!-- 	  <em>Until that scholastic paradigm [the medieval -->
<!--             &lsquo;impetus&rsquo; theory] was invented, there were no -->
<!--             pendulums, but only swinging stones, for scientists to -->
<!--             see. Pendulums were brought into the world by something very like -->
<!--             a paradigm-induced gestalt switch.  Do we, however, really need to -->
<!--             describe what separates Galileo from Aristotle, or Lavoisier from -->
<!--             Priestly, as a transformation of vision? Did these men really see -->
<!--             different things when looking at the same sorts of objects? Is -->
<!--             there any legitimate sense in which we can say they pursued their -->
<!--             research in different worlds? -->

<!--             <p> -->
<!--               [I am] acutely aware of the difficulties created by saying that -->
<!--               when Aristotle and Galileo looked at swinging stones, the first -->
<!--               saw constrained fall, the second a pendulum. Nevertheless, I am -->
<!--               convinced that we must learn to make sense of sentences that at -->
<!--               least resemble these.</em> -->

<!-- 	<p> -->
<!-- 	  T. Kuhn, The Structure of Scientific Revolutions -->
	  
<!-- 	  According to Kuhn&#39;s model of scientific -->
<!-- 	  evolution <em>normal</em> science proceeds by using established -->
<!-- 	  descriptive schemes. Major changes result from -->
<!-- 	  new <em>paradigms,</em> new ways of describing things that lead to -->
<!-- 	  new methods and techniques. Eventually there is a redefining -->
<!-- 	  of <em>normal.</em>  Now while Kuhn prefers to apply his own very -->
<!-- 	  effective redescription paradigm at the level of major scientific -->
<!-- 	  revolutions, it seems to me that the same idea applies as well to -->
<!-- 	  the microcosm of everyday thinking. Indeed, in that last sentence -->
<!-- 	  quoted, we see that Kuhn is seriously considering the paradigms to -->
<!-- 	  play a substantive rather than metaphorical role in visual -->
<!-- 	  perception, just as we have proposed for frames. -->

<!-- 	<p> -->
<!-- 	  Whenever our customary viewpoints do not work well, whenever we fail -->
<!-- 	  to find effective frame systems in memory, we must construct new -->
<!-- 	  ones that bring out the right features. Presumably, the most usual -->
<!-- 	  way to do this is to build some sort of pair-system from two or more -->
<!-- 	  old ones and then edit or debug it to suit the circumstances. How -->
<!-- 	  might this be done? It is tempting to formulate it in terms of -->
<!-- 	  constructing a frame-system with certain properties.  This appears -->
<!-- 	  to simplify the problem by dividing it into two stages: first -->
<!-- 	  formulate the requirements, and then solve the construction problem. -->
<!-- 	  But that is certainly not the usual course of ordinary thinking! -->
<!-- 	  Neither are requirements formulated all at once, nor is the new -->
<!-- 	  system constructed entirely by deliberate pre-planning. Instead we -->
<!-- 	  recognize unsatisfied requirements, one by one, as deficiencies or -->
<!-- 	  <em>bugs,</em> in the course of a sequence of modifications made to -->
<!-- 	  an unsatisfactory representation.  I think Papert (1972, see also -->
<!-- 	  Minsky, 1972) is correct in believing that the ability to diagnose -->
<!-- 	  and modify one&#39;s own procedures is a collection of specific and -->
<!-- 	  important <em>skills.</em> Debugging, a fundamentally important -->
<!-- 	  component of intelligence, has its own special techniques and -->
<!-- 	  procedures. Every normal person is pretty good at them; or otherwise -->
<!-- 	  he would not have learned to see and talk!  Although this essay is -->
<!-- 	  already speculative, I would like to point here to the theses of -->
<!-- 	  Goldstein (1974) and Sussman (1973) about the explicit use of -->
<!-- 	  knowledge about debugging in learning symbolic representations. -->
<!-- 	  They build new procedures to satisfy multiple requirements by such -->
<!-- 	  elementary but powerful techniques as: -->
	  
<!-- 	  1) Make a crude first attempt by the first order method of simply -->
<!-- 	  putting together procedures that separately achieve the individual -->
<!-- 	  goals. -->

<!-- 	<p> -->
<!-- 	  2) If something goes wrong, try to characterize one of the defects -->
<!-- 	  as a specific (and undesirable) kind of interaction between two -->
<!-- 	  procedures. -->

<!-- 	<p> -->
<!-- 	  3) Apply a <em>debugging technique</em> that, according to a record -->
<!-- 	  in memory, is good at repairing that specific kind of interaction. -->

<!-- 	<p> -->
<!-- 	  4) Summarize the experience, to add to the <em>debugging -->

<!--             <p> -->
<!--               techniques library</em> in memory. -->
	  
<!-- 	  These might seem simple-minded, but if the new problem is not too -->
<!-- 	  radically different from the old ones, then they have a good chance -->
<!-- 	  to work, especially if one picks out the right first-order -->
<!-- 	  approximations.  If the new problem is radically different, one -->
<!-- 	  should not expect any learning theory to work well. Without a -->
<!-- 	  structured cognitive map &mdash; without the <em>near misses</em> of -->
<!-- 	  Winston, or a cultural supply of good training sequences of problems -->
<!-- 	  &mdash; we should not expect radically new paradigms to appear -->
<!-- 	  magically whenever we need them.  What are <em>kinds of -->
<!--             interactions,</em> and what are <em>debugging techniques?</em> The -->
<!-- 	  simplest, perhaps, are those in which the result of achieving a -->
<!-- 	  first goal interferes with some condition prerequisite for achieving -->
<!-- 	  a second goal. The simplest repair is to reinsert that prerequisite -->
<!-- 	  as a new condition. There are examples in which this technique alone -->
<!-- 	  cannot succeed because a prerequisite for the second goal is -->
<!-- 	  incompatible with the first. Sussman presents a more sophisticated -->
<!-- 	  diagnosis and repair method that recognizes this and exchanges the -->
<!-- 	  order of the goals. Goldstein considers related problems in a -->
<!-- 	  multiple description context. -->

<!-- 	<p> -->
<!-- 	  If asked about important future lines of research on Artificial or -->
<!-- 	  Natural Intelligence, I would point to the interactions between -->
<!-- 	  these ideas and the problems of using multiple representations to -->
<!-- 	  deal with the same situation from several viewpoints. To carry out -->
<!-- 	  such a study, we need better ideas about interactions among the -->
<!-- 	  transformed relationships. Here the frame-system idea by itself -->
<!-- 	  begins to show limitations. Fitting together new representations -->
<!-- 	  from parts of old ones is clearly a complex process itself, and one -->
<!-- 	  that could be solved within the framework of our theory (if at all) -->
<!-- 	  only by an intricate bootstrapping. This, too, is surely a special -->
<!-- 	  skill with its own techniques.  I consider it a crucial component of -->
<!-- 	  a theory of intelligence.  We must not expect complete success in -->
<!-- 	  the above enterprise; there is a difficulty, as Newell (1973) notes -->
<!-- 	  in a larger context: -->
	  
<!-- 	  <em> &lsquo;Elsewhere&rsquo; is another view &mdash; possibly from -->
<!--             philosophy &mdash; or other &lsquo;elsewheres&rsquo; as well, -->
<!--             since the views of man are multiple. Each view has its own -->
<!--             questions. Separate views speak mostly past each -->
<!--             other. Occasionally, of course, they speak to the same issue and -->
<!--             then comparison is possible, but not often and not on demand.</em> -->

<!-- 	<p> -->
<!-- 	  4. CONTROL -->

<!-- 	<p> -->
<!-- 	  I have said little about the processes that manipulate -->
<!-- 	  frame-systems. This is not the place to discuss long-duration -->
<!-- 	  management of thought involving such problems as controlling a large -->
<!-- 	  variety of types of goals, sharing time between chronic and acute -->
<!-- 	  concerns, or regulating allocation of energy, storage, and other -->
<!-- 	  resources.  Over much smaller time spans &mdash; call them episodes -->
<!-- 	  &mdash; I imagine that thinking and understanding, be it perceptual -->
<!-- 	  or problem-solving, is usually concerned with finding and -->
<!-- 	  instantiating a frame. This breaks large problems down into many -->
<!-- 	  small jobs to be done and raises all the usual issues about -->
<!-- 	  heuristic programming, the following for example: -->
	  
<!-- 	  TOP-DOWN OR LATERAL: Should one make a pass over all the terminals -->
<!-- 	  first, or should one attempt a complete, detailed instantiation of -->
<!-- 	  some supposedly most critical one? In fact, neither policy is -->
<!-- 	  uniformly good. One should usually <em>look before leaping,</em> but -->
<!-- 	  there must be pathways through which -->

<!-- 	<p> -->
<!-- 	  an interesting or unexpected event can invoke a subframe to be -->
<!-- 	  processed immediately. -->

<!-- 	<p> -->
<!-- 	  CENTRAL CONTROL: Should a frame, once activated, -->
<!-- 	  <em>take over</em> and control its instantiation, or should a -->
<!-- 	  central process organize the operation. Again, no uniform strategy -->
<!-- 	  is entirely adequate. No <em>demon</em> or other local process can -->
<!-- 	  know enough about the overall situation to make good decisions; but -->
<!-- 	  no top-level manager can know enough details either. -->
	  
<!-- 	  Perhaps both issues can be resolved by something involving the idea -->
<!-- 	  of <em>back-off</em> proposed to me by William Martin in contrast to -->
<!-- 	  <em>back-up</em> as a strategy for dealing with errors and -->
<!-- 	  failures. One cannot either release control to subsidiaries or keep -->
<!-- 	  it at the top, so we need some sort of interpreter that has access -->
<!-- 	  both to the top level goals and to the operation of the -->
<!-- 	  separate <em>demons.</em> In any case, one cannot ask for a uniform -->
<!-- 	  strategy; different kinds of terminals require different kinds of -->
<!-- 	  processes. Instantiating a wall terminal of a room-frame invites -->
<!-- 	  finding and filling a lower level wall subframe, while instantiating -->
<!-- 	  a door terminal invites attaching another room frame to the house -->
<!-- 	  frame. To embed in each frame expectations about such matters, each -->
<!-- 	  terminal could point to instructions for the interpreter about how -->
<!-- 	  to collect the information it needs and how to complain about -->
<!-- 	  difficulties or surprises.  In any case, the frame-filling process -->
<!-- 	  ought to combine at least the components of decision-tree and -->
<!-- 	  demon-activation processes: in a decision tree, control depends on -->
<!-- 	  results of tests. A particular room frame, once accepted, might test -->
<!-- 	  for a major feature of a wall. Such tests would work through a tree -->
<!-- 	  of possible wall frames, the tree structure providing a convenient -->
<!-- 	  non-linear ordering for deciding which default assignments can -->
<!-- 	  remain and which need attention.  In a demon model, several -->
<!-- 	  terminals of an evoked frame activate -->
<!-- 	  <em>demons</em> for noticing things. A round object high on a center -->
<!-- 	  wall (or elliptical on a side wall) suggests a clock, to be -->
<!-- 	  confirmed by finding an appropriate number, mark, or radial line. If -->
<!-- 	  not so confirmed, the viewer would have <em>seen</em> the clock but -->
<!-- 	  would be unable to describe it in detail. An eye-level trapezoid -->
<!-- 	  could indicate a picture or a window; here further analysis is -->
<!-- 	  usually mandatory.  The goal of Seeing is not a fixed requirement to -->
<!-- 	  find what is out there in the world; it is subordinate to answering -->
<!-- 	  questions by combining exterior visual evidence with expectations -->
<!-- 	  generated by internal processes. Nevertheless, most questions -->
<!-- 	  require us in any case to know our orientation with respect to our -->
<!-- 	  immediate surroundings. Therefore a certain amount -->
<!-- 	  of <em>default</em> processing can proceed without any special -->
<!-- 	  question or goal. We clearly need a compromise in which a weak -->
<!-- 	  default ordering of terminals to be filled is easily superseded when -->
<!-- 	  any demon encounters a surprise.  In the <em>productions</em> of -->
<!-- 	  Newell and Simon (1972), the control structure is implicit in the -->
<!-- 	  sequential arrangement (in some memory) of the local behavior -->
<!-- 	  statements. In systems like the CONNIVER language, 1972, there are -->
<!-- 	  explicit higher-level control structures, but a lot still depends on -->
<!-- 	  which production-like assertions are currently in active memory and -->
<!-- 	  this control is not explicit. Both systems feature a high degree of -->
<!-- 	  local procedural control. Anything <em>noticed</em> is matched to -->
<!-- 	  an <em>antecedent pattern</em> which evokes another subframe, -->
<!-- 	  attaches it, and executes some of its processes.  There remains a -->
<!-- 	  problem. Processes common to many systems ought to be centralized, -->
<!-- 	  both for economy and for sharing improvements that result from -->
<!-- 	  debugging. Too much autonomy makes it hard for the whole system to -->
<!-- 	  be properly responsive to central, high level goals.  The next -->
<!-- 	  section proposes one way such conflicts might possibly be -->
<!-- 	  resolved. A frame is envisioned as a <em>packet</em> of data and -->
<!-- 	  processes and so are the high level goals. When a frame is proposed, -->
<!-- 	  its packet is added to the current program <em>environment</em> so -->
<!-- 	  that its processes have direct access to what they need to know, -->
<!-- 	  without being choked by access to the entire knowledge of the whole -->
<!-- 	  system. It remains to be seen how to fill in the details of this -->
<!-- 	  scheme and how well it will work.  I should explain at this point -->
<!-- 	  that this manuscript took shape, between 1972 and 1974, in the form -->
<!-- 	  of a file in the experimental ARPA computer network. The manuscript -->
<!-- 	  resided at various times in two different MIT computers and one at -->
<!-- 	  Stanford, freely accessible to students and colleagues. A graduate -->
<!-- 	  student, Scott Fahlman, now a professor at Carnegie-Mellon -->
<!-- 	  University, read an early draft before it contained a control -->
<!-- 	  scheme. Later, as part of his thesis proposal, Fahlman presented a -->
<!-- 	  control plan that seemed substantially better than my own, which he -->
<!-- 	  had not seen, and the next section is taken from his -->
<!-- 	  proposal. Several terms are used differently, but this should cause -->
<!-- 	  no problem. Fahlman&#39;s essay (written, I think, in 1973), is -->
<!-- 	  still one of the clearest images of how a society of mind might -->
<!-- 	  operate. I have changed only a few terms. A frame is a packet of -->
<!-- 	  related facts and processes that can include (or otherwise activate) -->
<!-- 	  other frames.  Any number of frames can be aroused at once, -->
<!-- 	  whereupon all the information involved can become available unless -->
<!-- 	  specifically canceled. The essay is about deciding when to allow -->
<!-- 	  such fragments of information to become active enough to initiate -->
<!-- 	  yet other processes. Fahlman&#39;s ideas, as further developed in -->
<!-- 	  his doctoral thesis, were later to be a major influence on the -->
<!-- 	  modern theories of non-monotonic and default logics. -->
	  
<!-- 	  Frame Verification by Scott Fahlman -->

<!-- 	<p> -->
	  
<!-- 	  I envision a data base in which related sets of facts and demons are -->
<!-- 	  grouped into packets, any number of which can be activated or made -->
<!-- 	  available for access at once. A packet can contain any number of -->
<!-- 	  other packets (recursively), in the sense that if the containing -->
<!-- 	  packet is activated, the contained packets are activated as well, -->
<!-- 	  and any data items in them become available unless they are -->
<!-- 	  specifically modified or canceled. Thus, by activating a few -->
<!-- 	  appropriate packets, the system can create a tailor-made execution -->
<!-- 	  environment containing only the relevant portion of its global -->
<!-- 	  knowledge and an appropriate set of demons. Sometimes, of course, it -->
<!-- 	  will have to add specific new packets to the active set in order to -->
<!-- 	  deal with some special situation, but this inconvenience will be far -->
<!-- 	  less than the burden of constantly tripping over unwanted knowledge -->
<!-- 	  or triggering spurious demons. -->
	  
<!-- 	  The frame begins the verification process by checking any sample -->
<!-- 	  features that it already has on hand &mdash; features that arrived -->
<!-- 	  in the first wave or were obtained while testing previous -->
<!-- 	  hypotheses. Then, if the hypothesis has not already been accepted or -->
<!-- 	  rejected, the frame begins asking questions to get more information -->
<!-- 	  about features of the sample. The nature of these questions will -->
<!-- 	  vary according to the problem domain: A doctor program might order -->
<!-- 	  some lab tests, a vision program might direct its low-level -->
<!-- 	  components to look at some area more closely. Sometimes a question -->
<!-- 	  will recursively start another recognition process: &lsquo;This -->
<!-- 	  might be a cow &mdash; see if that part is an udder.&rsquo; -->
	  
<!-- 	  The order in which the questions are asked is determined by -->
<!-- 	  auxiliary information in the frame. This information indicates which -->
<!-- 	  features are the most critical in the verification at hand, how -->
<!-- 	  these priorities might be affected by information already present, -->
<!-- 	  and how much each question will cost to answer. As each new feature -->
<!-- 	  of the sample is established, its description is added to a special -->
<!-- 	  packet of information about the sample, along with some indication -->
<!-- 	  of where the information came from and how reliable it is. This -->
<!-- 	  packet can be taken along if the system moves to another -->
<!-- 	  hypothesis. Sometimes unsolicited information will be noticed along -->
<!-- 	  the way; it, too, is tested and thrown into the pot. -->
	  
<!-- 	  Of course, the system will practically never get a perfect match to -->
<!-- 	  any of its ideal exemplars. Auxiliary frame information will -->
<!-- 	  indicate for each expected type of violation whether it should be -->
<!-- 	  considered trivial, serious, or fatal (in the sense that it -->
<!-- 	  decisively rules out the current frame). Continuously variable -->
<!-- 	  features such as size, body proportions, or blood pressure will have -->
<!-- 	  a range of normal variation indicated, along with a mapping from -->
<!-- 	  other ranges into seriousness values. Sometimes a feature will -->
<!-- 	  provide no real evidence for or against a hypothesis, but can be -->
<!-- 	  explained by it; this, too, is noted in the frame. If there are -->
<!-- 	  striking or conspicuous features in the sample (antlers, perhaps) -->
<!-- 	  that are not mentioned in the current frame, the system will usually -->
<!-- 	  consider these to be serious violations; such features are evaluated -->
<!-- 	  according to information stored in a packet associated with the -->
<!-- 	  feature, since the hypothesis frame clearly cannot mention every -->
<!-- 	  feature not present in the exemplar. -->
	  
<!-- 	  Occasionally a feature will have a strong confirming effect: If you -->
<!-- 	  see it, you can stop worrying about whether you are in the right -->
<!-- 	  place.  Usually, though, we will not be so lucky as to have a -->
<!-- 	  decisive test. The normal procedure, then, is to gather in sample -->
<!-- 	  features until either some satisfaction level is reached and the -->
<!-- 	  hypothesis is accepted, or until a clear violation or the weight of -->
<!-- 	  several minor violations sends the system off in search of something -->
<!-- 	  better. (My current image of the satisfaction level is as some sort -->
<!-- 	  of numerical score, with each matched feature adding a few points -->
<!-- 	  and each trivial mismatch removing a few. Perhaps some more complex -->
<!-- 	  symbolic scheme will be needed for this, but right now I do not see -->
<!-- 	  why.) The satisfaction level can vary considerably, according to the -->
<!-- 	  situation: The most cursory glance will convince me that my desk is -->
<!-- 	  still in my office, while a unicorn or a thousand dollar bill will -->
<!-- 	  rate a very close inspection before being accepted. -->
	  
<!-- 	  Sometimes the sample will appear to fit quite well into some -->
<!-- 	  category, but there will be one or two serious violations. In such a -->
<!-- 	  case the system will consider possible excuses for the -->
<!-- 	  discrepancies: Perhaps the cow is purple because someone has painted -->
<!-- 	  it. Perhaps the patient doesn&#39;t have the expected high blood -->
<!-- 	  pressure because he is taking some drug to suppress it. If a -->
<!-- 	  discrepancy can be satisfactorily explained away, the system can -->
<!-- 	  accept the hypothesis after all. Of course, if the discrepancies -->
<!-- 	  suggest some other hypothesis, the system will try that first and -->
<!-- 	  resort to excuses only if the new hypothesis is no better. Sometimes -->
<!-- 	  two categories will be so close together that they can only be told -->
<!-- 	  apart by some special test or by paying particular attention to some -->
<!-- 	  otherwise insignificant detail.  It is a simple enough matter for -->
<!-- 	  both of the frames to include a warning of the similarity and a set -->
<!-- 	  of instructions for making the discrimination. In medicine, such -->
<!-- 	  testing is called differential diagnosis. -->
	  
<!-- 	  Note that this use of exemplars gives the system an immense -->
<!-- 	  flexibility in dealing with noisy, confused, and unanticipated -->
<!-- 	  situations. A cow may formally be a large quadruped, but our system -->
<!-- 	  would have little trouble dealing with a three-legged cow amputee, -->
<!-- 	  as long as it is a reasonably good cow in most other respects. (A -->
<!-- 	  missing leg is easy to explain; an extra one is somewhat more -->
<!-- 	  difficult.) If the system is shown something that fits none of its -->
<!-- 	  present categories, it can at least indicate what the sample is -->
<!-- 	  close to, along with some indication of the major deviations from -->
<!-- 	  that category. A visual system organized along these lines might -->
<!-- 	  easily come up with &lsquo;like a person, only 80 feet tall and -->
<!-- 	  green&rsquo; or &lsquo;a woman from the waist up and a tuna fish -->
<!-- 	  from the waist down.&rsquo; Under certain circumstances, such -->
<!-- 	  descriptions might serve as the nuclei of new recognition frames -->
<!-- 	  representing legitimate, though unnamed, conceptual categories. -->
	  
<!-- 	  An important feature of recognition frames (and of the recognition -->
<!-- 	  categories they represent) is that they can be organized into -->
<!-- 	  hierarchies. The system can thus hypothesize at many levels, from -->
<!-- 	  the very general to the very specific: An animal of some sort, a -->
<!-- 	  medium-sized quadruped, a dog, a collie, Lassie. Each level has its -->
<!-- 	  own recognition frame, but the frames of the more specific -->
<!-- 	  hypotheses include the information packets of the more general -->
<!-- 	  frames above them; thus, if the system is working under the -->
<!-- 	  &lsquo;dog&rsquo; frame, the information in the &lsquo;animal&rsquo; -->
<!-- 	  frame is available as well. A specific frame may, of course, -->
<!-- 	  indicate exceptions to the more general information: The -->
<!-- 	  &lsquo;platypus&rsquo; frame would include the information in -->

<!-- 	<p> -->
<!-- 	  &lsquo;mammal&rsquo;, but it would have to cancel the parts about -->
<!-- 	  live birth of young. Often a general frame will use one of the -->
<!-- 	  specific cases below it as its exemplar; &lsquo;mammal&rsquo; might -->
<!-- 	  simply use &lsquo;dog&rsquo; or &lsquo;cow&rsquo; as its exemplar, -->
<!-- 	  rather than trying to come up with some schematic model of an ideal -->
<!-- 	  non-specific mammal. In such a case, the only difference between -->
<!-- 	  hypothesizing &lsquo;mammal&rsquo; and &lsquo;cow&rsquo; would be a -->
<!-- 	  somewhat greater reluctance to move to another mammal in the latter -->
<!-- 	  case; the system would test the same things in either case. -->
	  
<!-- 	  Note that there can be many different hierarchical networks, and -->
<!-- 	  that these can overlap and tangle together in interesting ways: A -->
<!-- 	  komodo dragon is taxonomically a reptile, but its four-legged shape -->
<!-- 	  and its habits are closer to a dog&#39;s than to a snake&#39;s. How -->
<!-- 	  to represent these entanglements and what to do about them are -->
<!-- 	  problems that will require some further thought. Some frames are -->
<!-- 	  parasitic: Their sole purpose is to attach themselves to other -->
<!-- 	  frames and alter the effects of those frames. (Perhaps -->
<!-- 	  &lsquo;viral&rsquo; would be a better term.) -->
<!-- 	  &lsquo;Statue-of&rsquo; might attach to a frame like -->
<!-- 	  &lsquo;cow&rsquo; to wipe out its animal properties of motion and -->
<!-- 	  material (beef), while leaving its shape properties -->
<!-- 	  intact. &lsquo;Mythical&rsquo; could be added to animal to make -->
<!-- 	  flying, disappearance, and the speaking of riddles in Latin more -->
<!-- 	  plausible, -->

<!-- 	<p> -->
<!-- 	  but actual physical presence less so. Complications could be grafted -->
<!-- 	  onto a disease using this mechanism. There is nothing to prevent -->
<!-- 	  more than one parasite at a time from attaching to a frame, as long -->
<!-- 	  as the parasites are not hopelessly contradictory; one could, for -->
<!-- 	  instance, have a statue of a mythical animal. -->
	  

<!-- 	<p> -->
<!-- 	  5: SPATIAL IMAGERY -->

<!-- 	<p> -->
<!-- 	  5.1 PLACES AND HEADINGS -->
	  
<!-- 	  We normally imagine ourselves moving within a stationary spatial -->
<!-- 	  setting. The world does not recede when we advance; it does not spin -->
<!-- 	  when we turn! At my desk I am aware of a nearby river whose -->
<!-- 	  direction I think of as north although I know that this is off by -->
<!-- 	  many degrees, assimilated years ago from a truer north at another -->
<!-- 	  location on the same river. This sense of direction permeates the -->
<!-- 	  setting; the same <em>north</em> is constant through one&#39;s house -->
<!-- 	  and neighborhood, and every fixed object has a definite heading. -->
<!-- 	  Besides a heading, every object has a place. We are less positive -->
<!-- 	  about the relations between places from one room to another. This is -->
<!-- 	  partly because heading is computationally simpler but also because -->
<!-- 	  (in rectangular rooms) headings transfer directly -->
<!-- 	  whereas <em>place</em> requires metric calculations.  In unfamiliar -->
<!-- 	  surroundings, some persons deal much less capriciously than others -->
<!-- 	  with headings. One person I know regularly and accurately relates -->
<!-- 	  himself to true compass direction. He is never lost in a new -->
<!-- 	  city. Only a small part of this is based on better quantitative -->
<!-- 	  integration of rotations. He uses a variety of cues &mdash; maps, -->
<!-- 	  shadows, time-of-day, major landmarks (even glimpsed from windows), -->
<!-- 	  and so forth. It seems at first uncanny, but it doesn&#39;t really -->
<!-- 	  require much information. The trick is to acquire effective habits -->
<!-- 	  of noticing and representing such things.  Once acquired, headings -->
<!-- 	  are quite persistent and are difficult to revise when one tries to -->
<!-- 	  make <em>basic</em> changes. When I finally understood the bend in -->
<!-- 	  the river, it did not seem worth the effort to rebuild my wrong, -->
<!-- 	  large-scale spatial model. Similarly, I spent years in Boston before -->
<!-- 	  noticing that its <em>Central Park</em> has five sides. A native of -->
<!-- 	  rectangular Manhattan, I never repaired the thoroughly non-Euclidean -->
<!-- 	  nonsense this mistake created; there is simply no angular sector -->
<!-- 	  space in it to represent Boston&#39;s North End.  Such difficulties -->
<!-- 	  suggest that we use gross, global frames of reference as well as -->
<!-- 	  smaller, local structures. The difficulty of rearrangement suggests -->
<!-- 	  that the local frames are not complete, transformable, structures -->
<!-- 	  but depend on their attachment to <em>global frames</em> to deduce -->
<!-- 	  inter-object relationships. Below I discuss some implications of -->
<!-- 	  using global reference systems; in principle this suggests more -->
<!-- 	  powerful and general processes for rearranging parts of complicated -->
<!-- 	  images, but in practice people seem quite limited at this, -->
<!-- 	  especially when operating under time constraints. -->
	  
	  
<!-- 	  5.2 A GLOBAL SPACE FRAME SYSTEM? -->
	  
<!-- 	  I do not like the following model very much, but something of its -->
<!-- 	  sort seems needed. A Global Space Frame (GSF for short) is a fixed -->
<!-- 	  collection of <em>typical locations</em> in an abstract three -->
<!-- 	  dimensional space, and copies of it are used as frameworks for -->
<!-- 	  assembling components of complex scenes. One might imagine such a -->
<!-- 	  skeleton as a five-by-five horizontal array of <em>places,</em> each -->
<!-- 	  with three vertical levels. The central cells represent zones near -->
<!-- 	  the center of interest, while the peripheral cells have to represent -->
<!-- 	  everything else.  (In effect, one always imagines himself within -->
<!-- 	  this universal ghost- room in which one&#39;s current real -->
<!-- 	  environment is also embedded.)  Actually, people probably use -->
<!-- 	  skeletons more complicated and less mathematically regular than -->
<!-- 	  this, emphasizing easily-accessible volumes near the hands and face -->
<!-- 	  to represent space in ways more directly related to manipulative -->
<!-- 	  access than to a uniform physical geometry.  The GSF is associated -->
<!-- 	  with a system of view-frames; each view- frame describes the visual -->
<!-- 	  appearance of the GSF from a different observer viewpoint. The -->
<!-- 	  system is thus both Copernican and Ptolemaic; the embedding of the -->
<!-- 	  current scene in the GSF skeleton does not change when the observer -->
<!-- 	  moves, but each viewpoint gives the scene a distinctive appearance -->
<!-- 	  because the observer&#39;s location (or, rather, his belief about -->
<!-- 	  his location) activates an appropriate view-frame.  The view-frame -->
<!-- 	  corresponding to any particular place is derived by projecting the -->
<!-- 	  GSF cells toward that place; this yields an array of view-lists -->
<!-- 	  &mdash; each of which is an ordered list of those cells of the GSF -->
<!-- 	  that would intersect some certain ray emitted from the -->
<!-- 	  observer&#39;s eye. -->

<!-- 	<p> -->
<!-- 	  Thus a view-frame is like an ordinary scene frame except that its -->
<!-- 	  elements are derived from the GSF skeleton rather than from specific -->
<!-- 	  visual features and relations of any particular scene. While -->
<!-- 	  view-lists correspond to retinal regions, we think of them as -->
<!-- 	  three-dimensional zones extending in some general direction out to -->
<!-- 	  distant space.  Occlusions are explained or imagined in terms of -->
<!-- 	  view-list orderings; one expects not to see all of an object that -->
<!-- 	  comes later on a view-list than does another object. (Similarly, -->
<!-- 	  earlier objects are obstacles to manipulating later ones.) In memory -->
<!-- 	  matching, occluded view-list cells should relax the matching -->
<!-- 	  constraints on corresponding terminals.  To absorb visual -->
<!-- 	  information from multiple viewpoints, we need some sort -->
<!-- 	  of <em>indirect-address</em> scheme in which visual features are -->
<!-- 	  assigned to view-frames through the GSF skeleton; here is a -->
<!-- 	  first-order sketch of such a scheme: SEEING: A variety of types of -->
<!-- 	  visual <em>features</em> are detected by retinal or -->
<!-- 	  post-retinal <em>feature-demons.</em> Each detected feature is -->
<!-- 	  automatically associated with the view-direction of the current -->
<!-- 	  view-list corresponding to its location in the visual field. -->

<!-- 	<p> -->
<!-- 	  FRAME-ACTIVATION: At the same moment, some object-frame or -->
<!-- 	  expectation is tentatively assigned to some of the GSF cells in the -->
<!-- 	  current view-list for that direction. This means that each terminal -->
<!-- 	  of that frame is associated with the view-direction of some active -->
<!-- 	  view-list. (In other words, scene frame terminals contain -->
<!-- 	  spatial-location information by pointing to GSF places. See below.) -->
<!-- 	  Different scene frames of the same system are selected according to -->
<!-- 	  the current view-frame. The headings of objects must be -->
<!-- 	  appropriately transformed. -->

<!-- 	<p> -->
<!-- 	  INSTANTIATION: When looking in a certain direction we (a) expect to -->
<!-- 	  see certain visual features in certain cells, as suggested by the -->
<!-- 	  active scene frame and (b) we actually see certain features in -->
<!-- 	  certain visual regions. So it is natural to propose a first-order -->
<!-- 	  vision theory in which each marker of each terminal actually -->
<!-- 	  specifies the signature &mdash; and also the proposed GSF -->
<!-- 	  location-cell &mdash; of some class of visual feature-demon. The -->
<!-- 	  observer can also be represented within -->

<!-- 	<p> -->
<!-- 	  the system as an object, allowing one to imagine himself within a -->
<!-- 	  scene but viewed from another location. -->
	  
<!-- 	  Given all this it is easy to obtain the information needed to assign -->
<!-- 	  terminals and instantiate frames. All the system has to do is match -->
<!-- 	  the -->
<!-- 	  <em>perceptual</em> (feature-demon, view-list) pairs to -->
<!-- 	  the <em>schematic</em> (marker, GSF-cell) pairs. If object-frame -->
<!-- 	  terminals could be attached directly to GSF locations and if these -->
<!-- 	  were automatically projected into view-lists, this would eliminate -->
<!-- 	  almost all need to recompute representations of things that have -->
<!-- 	  already been seen from other viewpoints. -->

<!-- 	<p> -->
<!-- 	  5.3 EMBEDDING COMPLICATIONS -->

<!-- 	<p> -->
<!-- 	  In our first formulation, the terminals of a vision frame were -->
<!-- 	  understood to be in some way associated with cells of the GSF -->
<!-- 	  skeleton. The idea is tempting: why not abandon the whole visual -->
<!-- 	  frame-system idea and build <em>3-D</em> object-frames that map -->
<!-- 	  directly into space locations? Then an object-frame could represent -->
<!-- 	  almost directly a symbolic three-dimensional structure and the GSF -->
<!-- 	  system could automatically generate different view-frames for the -->
<!-- 	  object.  For a computer system, this might work very well. For a -->
<!-- 	  psychological model, it leaves too many serious problems: how can we -->
<!-- 	  deal with translations, rotations and scale-changes; how do we -->
<!-- 	  reorient substructures? A crude solution, for rotations, is to have -->
<!-- 	  for each object a few standard views &mdash; embeddings of different -->
<!-- 	  sizes and orientations. Before rejecting this outright, note that it -->
<!-- 	  might be entirely adequate for some kinds of performance and for -->
<!-- 	  early stages of development of others.  But in <em>adult</em> -->
<!-- 	  imagery, any object type can be embedded in so many different ways -->
<!-- 	  that some more general kind of transformation-based operation seems -->
<!-- 	  needed. The obvious mathematical solution, for purposes of -->
<!-- 	  relocation and scaling, is to provide some kind of intermediate -->
<!-- 	  structure: each object-frame could be embedded in a -->
<!-- 	  relocatable, <em>portable</em> mini-GSF that can be rotated and -->
<!-- 	  attached to any global GSF cell, with an -->
<!-- 	  appropriate <em>view-note</em> specifying how the prototype figure -->
<!-- 	  was transformed.  Providing such a structure entails more than -->
<!-- 	  merely complicating the embedding operation. It also requires -->
<!-- 	  building a <em>uniform structure</em> into the GSF, straightening -->
<!-- 	  out the early, useful, but idiosyncratic exaggerations of the more -->
<!-- 	  familiar parts of near-body space. Attractive as such a model might -->
<!-- 	  be, I simply do not believe one is ever actually realized in -->
<!-- 	  people. People are not very good at imagining transformed scenes; I -->
<!-- 	  quoted Hogarth&#39;s account of the very special training required, -->
<!-- 	  and I noted Piaget&#39;s observation that even moderate competence -->
<!-- 	  in such matters seems not to mature before the second decade.  We -->
<!-- 	  thus have a continuum of spatial mechanism theories to consider. I -->
<!-- 	  will not pick any particular point in this spectrum to designate -->
<!-- 	  as <em>the theory.</em> This is not entirely because of laziness; it -->
<!-- 	  is important to recognize that each individual probably has to -->
<!-- 	  develop through some sequence of more-and-more sophisticated -->
<!-- 	  mechanisms.  Before we can expect to build a theory consistent with -->
<!-- 	  developmental phenomena, we will have to understand better which -->
<!-- 	  mechanisms can suffice for different levels of image-manipulation -->
<!-- 	  performance.  And we certainly need to see a much more complete -->
<!-- 	  psychological portrait of what people really do with spatial-visual -->
<!-- 	  imagery.  Some readers may ask: since we have come so close to -->
<!-- 	  building a three-dimensional analogue mechanism, why not simply do -->
<!-- 	  that in some more elegant and systematic way? Although this is a -->
<!-- 	  popular proposal, no one has moved past the early, inadequate -->
<!-- 	  Gestalt models to suggest how a practical scheme of this sort might -->
<!-- 	  function.  The neuronal construction of a non-symbolic -->
<!-- 	  three-dimensional representation system is imaginable, but the -->
<!-- 	  problems of constructing hypothetical solids and surfaces within it -->
<!-- 	  bring us right back to the same computationally non-trivial &mdash; -->
<!-- 	  and basically symbolic &mdash; issues.  And the equivalent of the -->
<!-- 	  instantiated view-list has to be constructed in any case, so far as -->
<!-- 	  I can see, so that the function of an intermediate, analogue -->
<!-- 	  space-model remains somewhat questionable. -->
	  

<!-- 	<p> -->
<!-- 	  5.4 EVOLUTION -->

<!-- 	<p> -->
<!-- 	  Our frame theory assumes a variety of special mechanisms for vision -->
<!-- 	  and symbolic manipulation. I doubt that much of this arises -->
<!-- 	  from <em>self-organizing</em> processes; most of it probably depends -->
<!-- 	  on innately provided <em>hardware.</em> What evolutionary steps -->
<!-- 	  could have produced this equipment? The arguments below suggest that -->
<!-- 	  the requirements of three-dimensional vision may have helped the -->
<!-- 	  evolution of frame-like representations in general. -->

<!-- 	<p> -->
<!-- 	  In the early steps of visual evolution, the most critical steps must -->
<!-- 	  have concerned the refinement of specific feature-detectors for use -->
<!-- 	  in nutrition, reproduction, and defense. As both vision and mobility -->
<!-- 	  grew more sophisticated, it became more important to better relate -->
<!-- 	  the things that are seen to their places in the outer world &mdash; -->
<!-- 	  to locations that one can reach or leap at. Especially, one needs -->
<!-- 	  the transformations that compensate for postural changes. These -->
<!-- 	  problems become acute in competitive, motion-rich situations. In -->
<!-- 	  predation or flight, there is an advantage in being able to -->
<!-- 	  coordinate information obtained during motion; even if vision is -->
<!-- 	  still based on the simplest feature-list recognition scheme, there -->
<!-- 	  is an advantage in correct aggregation of different features seen at -->
<!-- 	  different times.  Many useful <em>recognition</em> schemes can be -->
<!-- 	  based on simple, linear, horizontal ordering of visual features. One -->
<!-- 	  can get even more by using similar data from two motion-related -->
<!-- 	  views, or by using changes (motion parallax) in a moving view. Since -->
<!-- 	  so much can be done with such lists, we should look (1) for -->
<!-- 	  recognition schemes based on matching linear memory frames to parts -->
<!-- 	  of such ordered sets and (2) for aggregation schemes that might -->
<!-- 	  serve as early stages in developing a coarse ground-plan -->
<!-- 	  representation. One would not expect anything like a ground plan at -->
<!-- 	  first; initially one would expect an egocentric polar -->
<!-- 	  representation, relating pairs of objects, or relating an object to -->
<!-- 	  some reference direction such as the sun. We would not expect -->
<!-- 	  relational descriptions, sophisticated figure-ground mechanisms, or -->
<!-- 	  three-dimensional schemata at early stages. (I know of no good -->
<!-- 	  evidence that animals other than men ever develop realistic ground -->
<!-- 	  plans; although other animals&#39; behavior can appear to use them, -->
<!-- 	  there may be simpler explanations.)  The construction and use of a -->
<!-- 	  ground plan requires evolution of the very same motion -->
<!-- 	  transformations needed to assign multiple view data to appropriate -->
<!-- 	  cells. For a theory of how these in turn might develop we need to -->
<!-- 	  imagine possible developmental sequences, beginning in egocentric -->
<!-- 	  angular space, that at every stage offer advantages in visual-motor -->
<!-- 	  performance. Among such schemata, I would expect to find some -->
<!-- 	  structures that would also help to realize multiple memory frames -->
<!-- 	  with common terminals &mdash; since this is a similar (and simpler) -->
<!-- 	  problem. Other visual memory needs demand ways to file assignment -->
<!-- 	  sets in long term memory; one wants representations of one&#39;s -->
<!-- 	  home, nesting area, predation regions, mate, enemies, and <em>bad -->
<!--             places.</em> It would be of value to develop a reliable global -->
<!-- 	  orientation within one&#39;s territory, if one is that kind of -->
<!-- 	  animal.  While the needs of vision point toward frame-like symbol -->
<!-- 	  manipulation, they do not so clearly point toward processes in which -->
<!-- 	  one makes hypothetical internal substitutions, i.e., -->
<!-- 	  imagination. But those operations would be useful in any -->
<!-- 	  problem-solving activity that requires planning.  We should consider -->
<!-- 	  individual as well as evolutionary development.  In -->
<!-- 	  an <em>adult</em> system one&#39;s current view-frame depends on -->
<!-- 	  where one thinks his feet are; and this requires accumulating -->
<!-- 	  rotations due to body posture, head rotation, and eye-direction. It -->
<!-- 	  would be no surprise to find <em>innate</em> hardware, perhaps in -->
<!-- 	  the frontal visual cortex, through which such postural parameters -->
<!-- 	  operate to re-address the signatures of visual feature-demons; the -->
<!-- 	  innateness hypothesis is supported by the good visual-motor -->
<!-- 	  coordination seen in the early infancy of many vertebrates. On the -->
<!-- 	  other hand, men could do with less pre-programming, given enough -->
<!-- 	  other mechanism to make this evolution within the individual -->
<!-- 	  reasonably certain.  Although the <em>adult</em> system is -->
<!-- 	  Copernican we would expect to find, in babies, more self-centered -->
<!-- 	  schemata. Perhaps the infant begins with a system centered around -->
<!-- 	  the face (rather than the feet), -->

<!-- 	<p> -->
<!-- 	  whose primary function is to relate vision to arm-motions; next one -->
<!-- 	  would expect a crude locomotor body image; only much later emerges -->
<!-- 	  the global system with a <em>permanent</em> sense of heading and -->
<!-- 	  within which the <em>observer</em> can freely move. This evolution -->
<!-- 	  from head through body to space-centered imagery would certainly be -->
<!-- 	  very laborious, but the infant has plenty of time. Perhaps one could -->
<!-- 	  study such a process, in microcosm, by seeing how people acquire the -->
<!-- 	  skill required for map-navigation. At first, one has to align the -->
<!-- 	  map with the scene; later this seems less necessary. The trick seems -->
<!-- 	  to involve representing both the scene and the map, alike, with -->
<!-- 	  respect to an internally defined reference direction for (say) -->
<!-- 	  North. Of course, part of this new skill involves improving -->
<!-- 	  one&#39;s collection of perspective transforms for irregular shapes -->
<!-- 	  of landmarks as one&#39;s viewpoint moves through extremes of -->
<!-- 	  obliquity.  In any case, the question is not to decide -->
<!-- 	  between <em>innate</em> and -->
<!-- 	  <em>developmental</em> models but to construct better scenarios of -->
<!-- 	  how intermediate systems would operate. the relative helplessness of -->
<!-- 	  the infant human does not mean he lacks the innate spatiomotor -->
<!-- 	  machinery of the infant horse, but perhaps only that its -->
<!-- 	  availability is -->
<!-- 	  <em>purposefully</em> delayed until the imagery prerequisites are -->
<!-- 	  also available for building the more complex system. -->
	  
	  
<!-- 	  5.5 METRIC AND QUANTITATIVE ISSUES -->

<!-- 	<p> -->
<!-- 	  Most people in our culture feel a conflict between (a) explaining -->
<!-- 	  thinking in terms of discrete symbolic descriptions and (b) the -->
<!-- 	  popular phenomenology in which the inner world seems continuously -->
<!-- 	  colored by magnitudes, intensities, strengths and weaknesses &mdash; -->
<!-- 	  entities with the properties of continua. Introspection or intuition -->
<!-- 	  is not very helpful in this area. I am convinced that the symbolic -->
<!-- 	  models are the more profound ones and that, perhaps paradoxically to -->
<!-- 	  some readers, continuous structures are restrictive and -->
<!-- 	  confining. We already illustrated this point in the discussion of -->
<!-- 	  evaluation functions in chess. To be sure, continuous variables -->
<!-- 	  (and <em>analogue machinery</em>) could be helpful in many -->
<!-- 	  applications. There would be no basic problem in adding magnitudes, -->
<!-- 	  probabilities, utility theories, or comparable mathematical -->
<!-- 	  gadgets. On the other side, naive analysts underrate the power of -->
<!-- 	  symbolic systems. Perhaps we tend to reject the idea of symbolic -->
<!-- 	  descriptions because of our sense of <em>continuous awareness</em> -->
<!-- 	  &mdash; would we not notice any hypothetical processes in which one -->
<!-- 	  symbolic description is abruptly dissolved and replaced by another? -->
<!-- 	  There would be no actual power in such a continuous awareness; for -->
<!-- 	  only a process that can reflect on what it has done &mdash; that can -->
<!-- 	  examine a record of what has happened &mdash; can have any -->
<!-- 	  consequences.  Just as our ability to debug a computer program -->
<!-- 	  depends on the character and quality of traces and records, -->
<!-- 	  self-consciousness itself must depend on the quality and character -->
<!-- 	  of one&#39;s summaries of his own recent -->
<!-- 	  states. The <em>phenomenological</em> smoothness or roughness of a -->
<!-- 	  sequence of mental states would then reflect only the style of -->
<!-- 	  description used in the representation of that sequence.  In a -->
<!-- 	  computer-based robot, one certainly could use metric parameters to -->
<!-- 	  make exact perspective calculations. But in a theory of human -->
<!-- 	  vision, I think we should try to find out how well our image -->
<!-- 	  abilities can be simulated by <em>qualitative,</em> symbolic -->
<!-- 	  methods. People are very poor at handling magnitudes or intensities -->
<!-- 	  on any absolute scale; they cannot reliably classify size, loudness, -->
<!-- 	  pitch, weight, into even so many as ten reliably distinct -->
<!-- 	  categories. In comparative judgements, too, many conclusions that -->
<!-- 	  might seem to require numerical information are already implied by -->
<!-- 	  simple order, or gross order of magnitude. Consider three objects A -->
<!-- 	  B C tentatively assigned, in that order, to a center wall of a -->
<!-- 	  room. If we move right and now find B to the left of A, we can -->
<!-- 	  reassign B to the foreground.  There is even more information in -->
<!-- 	  crude judgements of apparent movement, which can be interpreted as -->
<!-- 	  (inverse) order of distance from the observer&#39;s line of motion. -->
<!-- 	  One thus hardly ever needs quantitative precision; differential -->
<!-- 	  measurements are fine for nearby objects while correspondingly gross -->
<!-- 	  judgements suffice for objects at grossly different ranges. For most -->
<!-- 	  practical purposes it is enough to notice just a few relations -->
<!-- 	  between an object and its neighbors. The number of noticed relations -->
<!-- 	  need not even grow faster than the number of objects: if two objects -->
<!-- 	  are near opposite walls, then this fact is directly represented in -->
<!-- 	  the top-level room frame, and one rarely needs to know more; if two -->
<!-- 	  objects are close together, there is usually a smaller frame -->
<!-- 	  including both, which gives more information about their -->
<!-- 	  relation. So we would (correctly) expect people to find it hard to -->
<!-- 	  recall spatial relations between objects in distinct frames because -->
<!-- 	  reconstruction through chaining of several frames needs information -->
<!-- 	  that is not usually stored &mdash; and would be tedious and -->
<!-- 	  inaccurate in any case.  There are some substantial objections to -->
<!-- 	  the GSF scheme. It is in the nature of perspective that each nearby -->
<!-- 	  cell will occlude a number of far away cells, and the cell-boundary -->
<!-- 	  occlusions are so irregular that one would not be able to tell just -->
<!-- 	  which parts of a far away object will be occluded. (So the view-list -->
<!-- 	  idea does not work very well, but so far as human imagery is -->
<!-- 	  concerned, people have similar problems.) To improve the predictive -->
<!-- 	  quality of the system, the view-lists could be elaborated to -->
<!-- 	  view-structures for representing spatial relations more complex than -->
<!-- 	  simple <em>nearer-further.</em> The metrical quality of the system -->
<!-- 	  could be dramatically improved, I think, by using <em>symbolic -->
<!--             interpolation</em>: consider together or sequentially two or more -->
<!-- 	  view- lists from nearby locations, and compromise between -->
<!-- 	  predictions that do not agree. One can thus better estimate the -->
<!-- 	  exact boundary of an occlusion by finding out which motions would -->
<!-- 	  make it certainly occur.  This idea of interpolation &mdash; or, in -->
<!-- 	  its simplest form, superposition &mdash; may often offer a way to -->
<!-- 	  improve the accuracy of an otherwise adequate strategy. If one -->
<!-- 	  averages &mdash; or otherwise summarizes &mdash; the predictions of -->
<!-- 	  two or more standard views, one obtains predictions of intermediate -->
<!-- 	  views that are better than one might imagine. Thus the calculations -->
<!-- 	  for body-image management (which one might suppose require complex -->
<!-- 	  vector and matrix transformations) might very well be handled by -->
<!-- 	  summing the expectations or predictions from the -->
<!-- 	  nearest <em>stereotype postures</em> &mdash; provided that the -->
<!-- 	  latter are reasonably adequate by themselves. It is tempting to -->
<!-- 	  generalize this to abstract activities, e.g., processes that can -->
<!-- 	  make symbolic use of multiple representations.  Another area in -->
<!-- 	  which quantitative methods seem important, at least on the surface, -->
<!-- 	  is in memory retrieval. One needs mechanisms for controlling the -->
<!-- 	  allowed range-of-variation of assignments. Does one demand <em>best -->
<!--             match,</em> does one require a threshold of fit, or what? No one -->
<!-- 	  policy will work well. Consider a request of the form -->
	  
<!-- 	  <em>Pick up the big red block.</em> -->
	  
<!-- 	  To decide what is <em>biggest,</em> one has to compare different -->
<!-- 	  dimensions.  Rather than assign a fixed procedure &mdash; which -->
<!-- 	  might work in simple problems &mdash; one should refer to the -->
<!-- 	  current problem-goal. If one is concerned with weight, then biggest -->
<!-- 	  = heaviest should work. If one is propping up a window, then biggest -->
<!-- 	  = largest dimension &mdash; that is, -->

<!-- 	<p> -->
<!-- 	  longest &mdash; is appropriate. The situation is more complex with -->
<!-- 	  unspecified selection, as in -->
	  
<!-- 	  <em>Pick up a big red block.</em> -->
	  
<!-- 	  but the same principles apply: divide the world into classes -->
<!-- 	  appropriate to the micro-world we are in and then pick one from that -->
<!-- 	  class that best fits <em>big.</em> Normally <em>big</em> means -->
<!-- 	  biggest, but not in a context that refers also to <em>enormous</em> -->
<!-- 	  blocks. Again, one must choose from one&#39;s collection of -->
<!-- 	  clustering methods by using the goal - microworld context. But here, -->
<!-- 	  again, the quantitative aspects should be on tap, not on top, or -->
<!-- 	  else the outstandingly important aspects of each domain will not be -->
<!-- 	  captured. McDermott (1973) discusses many issues about discrete -->
<!-- 	  representation of spatial structures in his thesis.  This essay -->
<!-- 	  contains quite a few different arguments against quantitative -->
<!-- 	  models. Perhaps I should explain the general principle upon which -->
<!-- 	  they are based, since I see that separately they are not very -->
<!-- 	  compelling. Thesis: the output of a quantitative mechanism, be it -->
<!-- 	  numerical, statistical, analogue, or physical (non-symbolic), is too -->
<!-- 	  structureless and uninformative to permit further analysis. -->

<!-- 	<p> -->
<!-- 	  Number-like magnitudes can form the basis of decisions for immediate -->
<!-- 	  action, for muscular superpositions, for filtering and summing of -->
<!-- 	  stimulus features, and so forth. But each is a <em>dead end</em> so -->
<!-- 	  far as further understanding and planning is concerned, for each is -->
<!-- 	  an evaluation &mdash; and not a summary. A Number cannot reflect the -->
<!-- 	  considerations that formed it. Thus, although quantitative results -->
<!-- 	  are useful for immediate purposes, they impose a large cost on -->
<!-- 	  further and deeper development.  This does not mean that people do -->
<!-- 	  not, or even that they should not, use such methods. But because of -->
<!-- 	  the block they present to further contemplation, we can predict that -->
<!-- 	  they will tend to be focused in what we might call terminal -->
<!-- 	  activities. In large measure, these may be just the activities most -->
<!-- 	  easily seen behavioristically and this might account in part for the -->
<!-- 	  traditional attraction of such models to workers in the -->
<!-- 	  behavioristic tradition. The danger is that theories based upon them -->
<!-- 	  &mdash; response probabilities, subjective probabilities, -->
<!-- 	  reinforcement schedule parameters &mdash; are not likely to be able -->
<!-- 	  to account for sophisticated cognitive activities. As psychological -->
<!-- 	  theories they are very likely to be wrong.  At times I may have -->
<!-- 	  overemphasized ways in which other kinds of first-order models can -->
<!-- 	  be satisfactory. This may be an over-reaction to some -->
<!-- 	  holism-oriented critics who showed (but did not notice) that if you -->
<!-- 	  can always notice one more feature of a situation, then you can make -->
<!-- 	  yourself believe that you have already noticed an infinite number of -->
<!-- 	  them. On the other side I may have overreacted against colleagues -->
<!-- 	  who ignore introspective phenomenology too thoroughly, or try to -->
<!-- 	  explain behavior in terms of unstructured elementary -->
<!-- 	  fragments. While any theory must <em>reduce</em> things to simpler -->
<!-- 	  elements, these need not be identifiable with behaviorally -->
<!-- 	  observable units of learning or doing.  I especially want to -->
<!-- 	  acknowledge the influence of S. A. Papert and of my former students -->
<!-- 	  Daniel Bobrow, Eugene Charniak, Bertram Raphael, William Martin, -->
<!-- 	  Joel Moses, and Patrick Winston, as well as the more specific -->
<!-- 	  contributions of Ira Goldstein, Gerald Sussman, Scott Fahlman, Andee -->
<!-- 	  Rubin, Stephen Smoliar, Marvin Denicoff, Ben Kuipers, Michael -->
<!-- 	  Freiling and others who have commented on early versions of the -->
<!-- 	  manuscript. -->

<!-- 	<p> -->
<!-- 	  6. Appendix: Criticism of the Logistic Approach -->

<!-- 	<p> -->
<!-- 	  <em>If one tries to describe processes of genuine thinking in terms -->
<!--             of formal traditional logic, the result is often unsatisfactory; -->
<!--             one has, then, a series of correct operations, but the sense of -->
<!--             the process and what was vital, forceful, creative in it seems -->
<!--             somehow to have evaporated in the formulations.</em> -->

<!-- 	<p> -->
<!-- 	  M. Wertheimer, Productive Thinking -->
	  
<!-- 	  I here explain why I think more <em>logical</em> approaches will not -->
<!-- 	  work.  There have been serious attempts, from as far back as -->
<!-- 	  Aristotle, to represent common sense reasoning by -->
<!-- 	  a <em>logistic</em> system &mdash; that is, one that makes a -->
<!-- 	  complete separation between -->
	  
<!-- 	  (1) <em>propositions</em> that embody specific information, and -->
<!-- 	  (2) <em>syllogisms</em> or general laws of proper inference. -->
	  
<!-- 	  No one has been able successfully to confront such a system with a -->
<!-- 	  realistically large set of propositions. I think such attempts will -->
<!-- 	  continue to fail, because of the character of logistic in general -->
<!-- 	  rather than from defects of particular formalisms. (Most recent -->
<!-- 	  attempts have used variants of <em>first order predicate logic,</em> -->
<!-- 	  but I do not think that is the problem.)  A typical attempt to -->
<!-- 	  simulate common-sense-thinking by logistic systems begins in -->
<!-- 	  a <em>microworld</em> of limited complication. At one end are -->
<!-- 	  high-level goals such as <em>I want to get from my house to the -->
<!--             Airport.</em> At the other end we start with many small items -->
<!-- 	  &mdash; the axioms &mdash; like <em>the car is in the -->
<!--             garage,</em> <em>one does not go outside undressed,</em> <em>to get -->
<!--             to a place one should (on the whole) move in its direction,</em> -->
<!-- 	  etc. To make the system work one designs heuristic search procedures -->
<!-- 	  to <em>prove</em> the desired goal, or to produce a list of actions -->
<!-- 	  that will achieve it.  I will not recount the history of attempts to -->
<!-- 	  make both ends meet &mdash; but merely summarize my impression: in -->
<!-- 	  simple cases one can get such systems to <em>perform,</em> but as we -->
<!-- 	  approaches reality the obstacles become overwhelming. The problem of -->
<!-- 	  finding suitable axioms &mdash; the problem of <em>stating the -->
<!--             facts</em> in terms of always-correct, logical, assumptions is very -->
<!-- 	  much harder than is generally believed. -->

<!-- 	<p> -->
<!-- 	  FORMALIZING THE REQUIRED KNOWLEDGE Just constructing a knowledge -->
<!-- 	  base is a major intellectual research problem. Whether one&#39;s -->
<!-- 	  goal is logistic or not, we still know far too little about the -->
<!-- 	  contents and structure of common-sense knowledge. A -->
<!-- 	  <em>minimal</em> common-sense system must <em>know</em> something -->
<!-- 	  about cause-and-effect, time, purpose, locality, process, and types -->
<!-- 	  of knowledge. It also needs ways to acquire, represent, and use such -->
<!-- 	  knowledge. We need a serious epistemological research effort in this -->
<!-- 	  area. The essays of McCarthy and Sandewall are steps in that -->
<!-- 	  direction.  I have no easy plan for this large enterprise; but the -->
<!-- 	  magnitude of the task will certainly depend strongly on the -->
<!-- 	  representations chosen, and I think that Logistic is already making -->
<!-- 	  trouble. -->

<!-- 	<p> -->
<!-- 	  RELEVANCY The problem of selecting relevance from excessive variety -->
<!-- 	  is a key issue! A modern epistemology will not resemble the old -->
<!-- 	  ones!  Computational concepts are necessary and novel. Perhaps the -->
<!-- 	  better part of knowledge is not <em>propositional</em> in character, -->
<!-- 	  but inter- propositional. For each <em>fact</em> one needs -->
<!-- 	  meta-facts about how it is to be used, and when it should not be -->
<!-- 	  used. In McCarthy&#39;s <em>Airport</em> -->

<!-- 	<p> -->
<!-- 	  paradigm we see ways to deal with some interactions between -->
<!-- 	  <em>situations, actions, and causal laws</em> within a restricted -->
<!-- 	  microworld of things and actions. But while the system can make -->
<!-- 	  deductions implied by its axioms, it cannot be told when it should -->
<!-- 	  or should not make such deductions.  For example, one might want to -->
<!-- 	  tell the system to <em>not cross the road if a car is coming.</em> -->
<!-- 	  But one cannot demand that the system -->
<!-- 	  <em>prove</em> no car is coming, for there will not usually be any -->
<!-- 	  such proof.  In PLANNER, one can direct an attempt to prove that a -->
<!-- 	  car is coming, and if the (limited) deduction attempt ends -->
<!-- 	  with <em>failure,</em> one can act.  This cannot be done in a pure -->
<!-- 	  logistic system. <em>Look right, look left</em> is a first -->
<!-- 	  approximation. But if one tells the system the real truth about -->
<!-- 	  speeds, blind driveways, probabilities of racing cars whipping -->
<!-- 	  around the corner, proof becomes impractical. If it reads in a -->
<!-- 	  physics book that intense fields perturb light rays, should it fear -->
<!-- 	  that a mad scientist has built an invisible car? We need to -->
<!-- 	  represent <em>usually</em>!  Eventually it must understand the -->
<!-- 	  trade-off between mortality and accomplishment, for one can do -->
<!-- 	  nothing if paralyzed by fear. -->

<!-- 	<p> -->
<!-- 	  MONOTONICITY -->
	  
<!-- 	  Even if we formulate relevancy restrictions, logistic systems have a -->
<!-- 	  problem in using them. In any logistic system, all the axioms are -->
<!-- 	  necessarily <em>permissive</em> &mdash; they all help to permit new -->
<!-- 	  inferences to be drawn. Each added axiom means more theorems, none -->
<!-- 	  can disappear. There simply is no direct way to add information to -->
<!-- 	  tell such the system about kinds of conclusions that should not be -->
<!-- 	  drawn!  To put it simply: if we adopt enough axioms to deduce what -->
<!-- 	  we need, we deduce far too many other things. But if we try to -->
<!-- 	  change this by adding axioms about relevancy, we still produce all -->
<!-- 	  the unwanted theorems, plus annoying statements about their -->
<!-- 	  irrelevancy.  Because Logicians are not concerned with systems that -->
<!-- 	  will later be enlarged, they can design axioms that permit only the -->
<!-- 	  conclusions they want. In the development of Intelligence the -->
<!-- 	  situation is different.  One has to learn which features of -->
<!-- 	  situations are important, and which kinds of deductions are not to -->
<!-- 	  be regarded seriously. The usual reaction to the <em>liar&#39;s -->
<!--             paradox</em> is, after a while, to laugh. The conclusion is not to -->
<!-- 	  reject an axiom, but to reject the deduction itself!  This raises -->
<!-- 	  another issue: -->

<!-- 	<p> -->
<!-- 	  PROCEDURE-CONTROLLING KNOWLEDGE -->

<!-- 	<p> -->
<!-- 	  The separation between axioms and deduction makes it impractical to -->
<!-- 	  include classificational knowledge about propositions. Nor can we -->
<!-- 	  include knowledge about management of deduction. A paradigm problem -->
<!-- 	  is that of axiomatizing everyday concepts of approximation or -->
<!-- 	  nearness. One would like nearness to be transitive: -->
	  
<!-- 	  (A near B) AND (B near C) = => (A near C) -->

<!-- 	<p> -->
<!-- 	  but unrestricted application of this rule would make everything near -->
<!-- 	  everything else. One can try technical tricks like -->

<!-- 	<p> -->
<!-- 	  (A near*1 B) AND (B near*1 C) = => (A near*2 C) -->
	  
<!-- 	  and admit only (say) five grades of near*1, near*2, near*3, etc. One -->
<!-- 	  might invent analog quantities or parameters. But one cannot (in a -->
<!-- 	  Logistic system) decide to make a new kind of <em>axiom</em> to -->
<!-- 	  prevent applying transitivity after (say) three chained uses, -->
<!-- 	  conditionally, unless there is a <em>good excuse.</em> I do not mean -->
<!-- 	  to propose a particular solution to the transitivity of -->
<!-- 	  nearness. (To my knowledge, no one has made a creditable proposal -->
<!-- 	  about it.) My complaint is that because of acceptance of Logistic, -->
<!-- 	  no one has freely explored this kind of procedural restriction. -->
	  
<!-- 	  COMBINATORIAL PROBLEMS -->

<!-- 	<p> -->
<!-- 	  I see no reason to expect these systems to escape combinatorial -->
<!-- 	  explosions when given richer knowledge-bases. Although we see -->
<!-- 	  encouraging demonstrations in microworlds, from time to time, it is -->
<!-- 	  common in AI research to encounter high-grade performance on hard -->
<!-- 	  puzzles &mdash; given just enough information to solve the problem -->
<!-- 	  &mdash; but this does not often lead to good performance in larger -->
<!-- 	  domains. -->
	  
<!-- 	  CONSISTENCY and COMPLETENESS -->

<!-- 	<p> -->
<!-- 	  A human thinker reviews plans and goal-lists as he works, revising -->
<!-- 	  his knowledge and policies about using it. One can program some of -->
<!-- 	  this into the theorem-proving program itself &mdash; but one really -->
<!-- 	  wants also to represent it directly, in a natural way, in the -->
<!-- 	  declarative corpus &mdash; -->

<!-- 	<p> -->
<!-- 	  for use in further introspection. Why then do workers try to make -->
<!-- 	  Logistic systems do the job? A valid reason is that the systems have -->
<!-- 	  an attractive simple elegance; if they worked this would be fine. An -->
<!-- 	  invalid reason is more often offered: that such systems have a -->
<!-- 	  mathematical virtue because they are (1) Complete &mdash; <em>All -->
<!--             true statements can be proven</em>; and (2) Consistent -->
<!-- 	  &mdash; <em>No false statements can be proven.</em>  It seems not -->
<!-- 	  often realized that Completeness is no rare prize. It is a trivial -->
<!-- 	  consequence of any exhaustive search procedure, and any system can -->
<!-- 	  be <em>completed</em> by adjoining to it any other complete system -->
<!-- 	  and interlacing the computational steps. Consistency is more -->
<!-- 	  refined; it requires one&#39;s axioms to imply no -->
<!-- 	  contradictions. But I do not believe that consistency is necessary -->
<!-- 	  or even desirable in a developing intelligent system. No one is ever -->
<!-- 	  completely consistent.  What is important is how one handles paradox -->
<!-- 	  or conflict, how one learns from mistakes, how one turns aside from -->
<!-- 	  suspected inconsistencies.  Because of this kind of misconception, -->
<!-- 	  Godel&#39;s Incompleteness Theorem has stimulated much foolishness -->
<!-- 	  about alleged differences between machines and men. No one seems to -->
<!-- 	  have noted its more -->

<!-- 	<p> -->
<!-- 	  <em>logical</em> interpretation: that enforcing consistency produces -->
<!-- 	  limitations.  Of course there will be differences between humans -->
<!-- 	  (who are demonstrably inconsistent) and machines whose designers -->
<!-- 	  have imposed consistency. But it is not inherent in machines that -->
<!-- 	  they be programmed only with consistent logical systems. Those -->
<!-- 	  <em>philosophical</em> discussions all make this quite unnecessary -->
<!-- 	  assumption! (I regard the recent demonstration of the consistency of -->
<!-- 	  modern set theory, thus, as indicating that set-theory is probably -->
<!-- 	  inadequate for our purposes &mdash; not as reassuring evidence that -->
<!-- 	  set-theory is safe to use!)  A famous mathematician, warned that his -->
<!-- 	  proof would lead to a paradox if he took one more logical step, -->
<!-- 	  replied <em>Ah, but I shall not take that step.</em> He was -->
<!-- 	  completely serious. A large part of ordinary (or even mathematical) -->
<!-- 	  knowledge resembles that in dangerous professions: when are certain -->
<!-- 	  actions unwise? When are certain approximations safe to use? When do -->
<!-- 	  various measures yield sensible estimates? Which self-referent -->
<!-- 	  statements are permissible if not carried too far? Concepts -->
<!-- 	  like <em>nearness</em> are to valuable to give up just because no -->
<!-- 	  one can exhibit satisfactory axioms for them. To summarize: -->

<!-- 	<p> -->
<!-- 	  1. <em>Logical</em> reasoning is not flexible enough to serve as a -->
<!-- 	  basis for thinking; I prefer to think of it as a collection of -->
<!-- 	  heuristic methods, effective only when applied to starkly simplified -->
<!-- 	  schematic plans.  The Consistency that Logic absolutely demands is -->
<!-- 	  not otherwise usually available &mdash; and probably not even -->
<!-- 	  desirable!  &mdash; because consistent systems are likely to be -->
<!-- 	  too <em>weak.</em>  2. I doubt the feasibility of representing -->
<!-- 	  ordinary knowledge effectively in the form of many small, -->
<!-- 	  independently <em>true</em> propositions.  3. The strategy of -->
<!-- 	  complete separation of specific knowledge from general rules of -->
<!-- 	  inference is much too radical. We need more direct ways for linking -->
<!-- 	  fragments of knowledge to advice about how they are to be used. -->
<!-- 	  4. It was long believed that it was crucial to make all knowledge -->
<!-- 	  accessible to deduction in the form of declarative statements; but -->
<!-- 	  this seems less urgent as we learn ways to manipulate structural and -->
<!-- 	  procedural descriptions. -->

<!-- 	<p> -->
<!-- 	  I do not mean to suggest that <em>thinking</em> can proceed very far -->
<!-- 	  without something like <em>reasoning.</em> We certainly need (and -->
<!-- 	  use) something like syllogistic deduction; but I expect mechanisms -->
<!-- 	  for doing such things to emerge in any case from processes -->
<!-- 	  for <em>matching</em> and -->
<!-- 	  <em>instantiation</em> required for other functions. Traditional -->
<!-- 	  formal logic is a technical tool for discussing either everything -->
<!-- 	  that can be deduced from some data or whether a certain consequence -->
<!-- 	  can be so deduced; it cannot discuss at all what ought to be deduced -->
<!-- 	  under ordinary circumstances. Like the abstract theory of Syntax, -->
<!-- 	  formal Logic without a powerful procedural semantics cannot deal -->
<!-- 	  with meaningful situations.  I cannot state strongly enough my -->
<!-- 	  conviction that the preoccupation with Consistency, so valuable for -->
<!-- 	  Mathematical Logic, has been incredibly destructive to those working -->
<!-- 	  on models of mind.  At the popular level it has produced a weird -->
<!-- 	  conception of the potential capabilities of machines in general. At -->
<!-- 	  the <em>logical</em> level it has blocked efforts to represent -->
<!-- 	  ordinary knowledge, by presenting an unreachable image of a corpus -->
<!-- 	  of context-free <em>truths</em> that can stand almost by -->
<!-- 	  themselves. And at the intellect-modeling level it has blocked the -->
<!-- 	  fundamental realization that thinking begins first with suggestive -->
<!-- 	  but defective plans and images, that are slowly (if ever) refined -->
<!-- 	  and replaced by better ones. -->

<!-- 	<p> -->
<!-- 	  Bibliography Abelson, R. P.  The Structure of Belief Systems, Schank -->
<!-- 	  and Colby, 1973 -->

<!-- 	<p> -->
<!-- 	  Bartlett , F. C.  Remembering, Cambridge Univ. Press, 1967 -->

<!-- 	<p> -->
<!-- 	  Berlin, I.  The Hedgehog and the Fox, New American Library, N.Y., -->
<!-- 	  1957 -->

<!-- 	<p> -->
<!-- 	  Celce-Murcia, M.  Paradigms for Sentence Recognition, UCLA Dept. of -->
<!-- 	  Linguistics, 1972 -->

<!-- 	<p> -->
<!-- 	  Chafe, W.  First Tech. Report, Contrastive Semantics Project, -->
<!-- 	  Dept. of Linguistics, Berkeley, 1972 -->

<!-- 	<p> -->
<!-- 	  Chomsky, N.  Syntactic Structure, Mouton, 1957 -->

<!-- 	<p> -->
<!-- 	  Fillmore, C. J.  The Case for Case, Universals in Linguistic Theory, -->
<!-- 	  Bach and Harms, Ed., Chicago, Holt Rinehart and Winston, 1968 -->

<!-- 	<p> -->
<!-- 	  Freeman, P. and Newell, A.  A Model for Functional Reasoning in -->
<!-- 	  Design, Proc. Second Intl. Conf. on Artificial Intelligence, London, -->
<!-- 	  Sept. 1971 -->

<!-- 	<p> -->
<!-- 	  Goldstein, I. P.  Understanding Fixed-Instruction Turtle Programs, -->
<!-- 	  MIT Artificial Intelligence Laboratory Tech. Rept TR-294 -->

<!-- 	<p> -->
<!-- 	  Gombrich, E.H.  Art and Illusion, Princeton 1969 -->

<!-- 	<p> -->
<!-- 	  Guzman, A.  Some Aspects of Pattern Recognition by Computer, M.S. -->
<!-- 	  Thesis, MIT, Feb. 1967 -->

<!-- 	<p> -->
<!-- 	  Guzman, A.  Computer Recognition of Three Dimensional Objects in a -->
<!-- 	  Visual Scene, Thesis, MIT, Dec. 1969 -->

<!-- 	<p> -->
<!-- 	  Hogarth, W.  The Analysis of Beauty, Oxford 1955 -->

<!-- 	<p> -->
<!-- 	  Huffman, D. A.  <em>Impossible Objects as Nonsense Sentences,</em> -->
<!-- 	  Machine Intelligence 6, Edinburgh Univ. Press, 1970 -->

<!-- 	<p> -->
<!-- 	  Koffka, K. Principles of Gestalt Psychology, Harcourt, Brace and -->
<!-- 	  World, New York, 1963 -->

<!-- 	<p> -->
<!-- 	  Kuhn, T.  The Structure of Scientific Revolutions, Univ. of Chicago -->
<!-- 	  Press, (2nd Ed.) 1970 -->

<!-- 	<p> -->
<!-- 	  Lavoisier, A.  Elements of Chemistry, Regnery, Chicago, 1949 -->

<!-- 	<p> -->
<!-- 	  Levin, J. A.  Network Representation and Rotation of Letters, -->
<!-- 	  Dept. of Psychology, UCSD, La Jolla, Calif 92037, Sept. l973 -->

<!-- 	<p> -->
<!-- 	  Martin, W.  Memos on the OWL System, MIT, l974 -->

<!-- 	<p> -->
<!-- 	  McDermott, D.  Assimilation of New Information by a Natural Language -->
<!-- 	  Understanding System, MIT Artificial Intelligence Laboratory -->
<!-- 	  Tech. rept. AI TR-298, March 1974. -->

<!-- 	<p> -->
<!-- 	  McDermott, D. and Sussman, G. J.  The CONNIVER Reference Manual, AI -->
<!-- 	  Memo 259, May 1972. -->

<!-- 	<p> -->
<!-- 	  Minsky, M.  Form and Content in Computer Science, J.A.C.M., Jan. -->
<!-- 	  1972 -->

<!-- 	<p> -->
<!-- 	  Minsky, M. and Papert, S.  Perceptrons, MIT Press, 1969 Minsky, -->
<!-- 	  M. and Papert, S.  <em>Progress Report on Artificial -->
<!--             Intelligence,</em> AI Memo 252, MIT Artificial Intelligence -->
<!-- 	  Laboratory, Cambridge, Mass., Jan. 1972 -->

<!-- 	<p> -->
<!-- 	  Moore, J. and Newell, A.  <em>How can MERLIN Understand?</em>, -->
<!-- 	  Knowledge and Cognition, J. Gregg, Ed., Lawrence Erlbaum Associates, -->
<!-- 	  Potomac Md. 1973 -->

<!-- 	<p> -->
<!-- 	  Newell, A.  Productions Systems: Models of Control Structures, -->
<!-- 	  Visual Information Processing, Academic Press, 1973 -->

<!-- 	<p> -->
<!-- 	  Newell, A.  Artificial Intelligence and the Concept of Mind, Schank -->
<!-- 	  and Colby, 1973. -->

<!-- 	<p> -->
<!-- 	  Newell, A. and Simon, H.A. Human Problem Solving, Prentice-Hall 1972 -->

<!-- 	<p> -->
<!-- 	  Norman, D.  Memory, Knowledge and the Answering of Questions, Loyola -->
<!-- 	  Symposium on Cognitive Psychology, Chicago 1972. -->

<!-- 	<p> -->
<!-- 	  Papert, S.  Teaching Children to be Mathematicians Versus Teaching -->
<!-- 	  About Mathematics, Int. J. Math. Educ. Sci. Technol., vol. 3, -->
<!-- 	  249-262, 1972 -->

<!-- 	<p> -->
<!-- 	  Piaget, J.  Six Psychological Studies, (D. Elkind, Ed), Vintage, N. -->
<!-- 	  Y.,1968 -->

<!-- 	<p> -->
<!-- 	  Piaget, J. and Inhelder, B.  The Child&#39;s Conception of Space, -->
<!-- 	  The Humanities Press, N.Y., 1956 -->

<!-- 	<p> -->
<!-- 	  Pylyshyn, Z.W.  <em>What the Mind&#39;s Eye tells the Mind&#39;s -->
<!--             Brain,</em> Psychological Bulletin, vol. 80, pp1-24, 1973 -->

<!-- 	<p> -->
<!-- 	  Roberts, L. G.  <em>Machine Perception of Three Dimensional -->
<!--             Solids,</em> Optical and Optoelectric Information Processing, MIT -->
<!-- 	  Press, 1965 -->

<!-- 	<p> -->
<!-- 	  Sandewall, E.  Representing Natural Language Information in -->
<!-- 	  Predicate Calculus, Machine Intelligence, Vol. 6, Edinburgh, 1970 -->

<!-- 	<p> -->
<!-- 	  Schank, R.  <em>Conceptual Dependency: A Theory of Natural Language -->
<!--             Understanding,</em> Cognitive Psychology, pp. 552-631, 1972 -->

<!-- 	<p> -->
<!-- 	  Schank, R.  and Colby, K.  Computer Models of Thought and Language, -->
<!-- 	  Freeman, San Francisco, 1973 -->

<!-- 	<p> -->
<!-- 	  Simmons, R. F.  Semantic Networks: Their Computation and Use for -->
<!-- 	  Understanding English Sentences, Schank and Colby, 1973 -->

<!-- 	<p> -->
<!-- 	  Sussman, G. J. A Computational Model of Skill Acquisition, MIT -->
<!-- 	  Artificial Intelligence Laboratory Tech. Rept AI TR-297 1973 -->

<!-- 	<p> -->
<!-- 	  Underwood, S.A. and Gates, C.L.  Visual Learning and Recognition by -->
<!-- 	  Computer, TR-123, Elect. Res. Center, University of Texas, April -->
<!-- 	  1972 -->

<!-- 	<p> -->
<!-- 	  Waltz, D. L.  Generating Semantic Descriptions from Drawings of -->
<!-- 	  Scenes with Shadows, MIT Thesis, Nov. 1972 -->

<!-- 	<p> -->
<!-- 	  Wertheimer, M.  Productive Thinking, Harper and Row, 1959 -->

<!-- 	<p> -->
<!-- 	  Wilks, Y.  Preference Semantics, Stanford Artificial Intelligence -->
<!-- 	  Laboratory Memo AIM-206, Stanford University, July 1973 -->

<!-- 	<p> -->
<!-- 	  Wilks, Y.  An Artificial Intelligence Approach to Machine -->
<!-- 	  Translation, Schank and Colby, 1973 -->

<!-- 	<p> -->
<!-- 	  APPLYING ARTIFICIAL INTELLIGENCE TO EDUCATION Reprinted from -->
<!-- 	  Computers and Communications: Implications for Education, 1977 -->
<!-- 	  Academic Press, Inc. -->

<!-- 	<p> -->
<!-- 	  The following is an edited transcript of remarks made by Dr. Minsky -->
<!-- 	  during the conference. -->

<!-- 	<p> -->
<!-- 	  Marvin Minsky Massachusetts Institute of Technology Cambridge, -->
<!-- 	  Massachusetts -->

<!-- 	<p> -->
<!-- 	  Most of the people at this meeting are concerned both with Education -->
<!-- 	  and with Computer Science. But it seems to me that these interests -->
<!-- 	  have been deflected from the richest possibilities by seeing -->
<!-- 	  Computer Science only as a source of new machine technology. This -->
<!-- 	  technology certainly brings us fabulous new capabilities and it is -->
<!-- 	  important to ask how these resources could improve the educational -->
<!-- 	  situation in schools.  But computer science is more than computers! -->
<!-- 	  It has given us a wholly new collection of concepts for thinking -->
<!-- 	  about Thinking itself.  For the first time, perhaps, we may be able -->
<!-- 	  to compose theories of Learning, and of Education, based on adequate -->
<!-- 	  descriptions of mental processes. In particular, recent ideas from -->
<!-- 	  the fields of artificial Intelligence and Computational Linguistics -->
<!-- 	  are giving us new tools for discussing the representation of -->
<!-- 	  Knowledge.  Let me give a highly oversimplified example of how these -->
<!-- 	  ideas might impinge on Educational theory. Most of us grew up in a -->
<!-- 	  mixture of <em>behavioristic</em> and <em>dynamic</em> psychological -->
<!-- 	  theories, neither of which really suited our needs. The -->
<!-- 	  behavioristic, reinforcement- oriented schema modeled a variety of -->
<!-- 	  slowly-modified behaviors, but did not attempt to capture insightful -->
<!-- 	  and knowledge-based thinking. The dynamic theories drew attention to -->
<!-- 	  such issues but were unable to make scientific progress because they -->
<!-- 	  lacked suitably powerful technical tools.  What -->
<!-- 	  is <em>understanding?</em> one person takes only a moment to learn a -->
<!-- 	  certain kind of thing, another may not be able to learn it at -->
<!-- 	  all. We want to study this phenomenon. It is common sense to propose -->
<!-- 	  that if the Learner possesses a suitable Representation scheme for -->
<!-- 	  the knowledge &mdash; and if he thinks of applying it to the -->
<!-- 	  situation &mdash; then he has a much simpler task. For many years, -->
<!-- 	  workers in AI have been developing different kinds of such -->
<!-- 	  Representations, in their attempts to make computer programs -->
<!-- 	  smarter. It did not seem to make much difference (in my opinion) -->
<!-- 	  whether or not these workers were overtly concerned with making -->
<!-- 	  psychological theories.  In the earlier years of AI, in the 50s and -->
<!-- 	  60s, it was painfully discovered that <em>common-sense</em> was very -->
<!-- 	  hard to understand! Many computer programs were constructed that -->
<!-- 	  were remarkably <em>expert</em> at particular specialized jobs. But -->
<!-- 	  if one tried to extend them to other areas, either by more -->
<!-- 	  programming, or by introducing various attempts -->
<!-- 	  at <em>learning,</em> the results were discouraging. The programs -->
<!-- 	  that did <em>learn</em> never became very expert at anything, while -->
<!-- 	  the -->

<!-- 	<p> -->
<!-- 	  <em>expert</em> programs so modified usually became worse at their -->
<!-- 	  job, if any thing. The reason, I think, is now fairly -->
<!-- 	  clear: <em>general</em> cybernetic ideas about learning were simply -->
<!-- 	  too weak. A successful person doesn&#39;t simply <em>learn -->
<!--             things</em> by absorbing knowledge in a smooth, uniform way. The -->
<!-- 	  process is more intricate: in each novel situation he works out a -->
<!-- 	  way to <em>learn to learn</em> &mdash; he constructs new -->
<!-- 	  representational schemes for new problems, and makes new procedures -->
<!-- 	  for exploiting the new representational structures. Any dynamic -->
<!-- 	  psychologist would agree with this, I should think.  In our new -->
<!-- 	  picture, it is easier to see how such things might happen, for in -->
<!-- 	  recent work in AI we see a form of knowledge that really was never -->
<!-- 	  considered in older theories &mdash; either in Psychology or in -->
<!-- 	  Computer Science &mdash; which has here an absolutely critical role. -->
<!-- 	  Older <em>epistemological</em> views distinguished between two -->
<!-- 	  principle varieties of Knowledge &mdash; Declarative, -->
<!-- 	  e.q., <em>facts,</em> <em>propositions,</em> etc., and Procedural, -->
<!-- 	  e.g. habits, <em>tacit</em> non-symbolic processes, etc..  In other -->
<!-- 	  words, to be good at something, in the traditional scheme, one needs -->
<!-- 	  (1) ordinary knowledge about the subject, and (2) knowledge-using -->
<!-- 	  processes to exploit the first-level knowledge. -->

<!-- 	<p> -->
<!-- 	  The new view emphasizes a third kind of knowledge; what does one do -->
<!-- 	  if the current system doesn&#39;t work, if the processes applied to -->
<!-- 	  the data do not solve the problem? All people &mdash; and smart ones -->
<!-- 	  more than others &mdash; have also an enormously important body of -->
<!-- 	  knowledge about How to Debug one&#39;s failures.  Knowledge about -->
<!-- 	  Debugging! -->

<!-- 	<p> -->
<!-- 	  What to do if you don&#39;t know something?  What if what the -->
<!-- 	  Teacher told you doesn&#39;t work?  If the CAI machine says -->
<!-- 	  something stupid?  If you get into a fight with your friend and -->
<!-- 	  didn&#39;t want to? -->
	  
<!-- 	  Is this program-knowledge or data-knowledge? The distinction is -->
<!-- 	  fuzzy. Ability to debug is knowing ways to debug and having -->
<!-- 	  processes for debugging. Since 1970 we have seen a number of -->
<!-- 	  experiments in AI in which programs are provided with specific -->
<!-- 	  facilities for analyzing and debugging their own failures. They -->
<!-- 	  rewrite their own programs to a certain extent, still limited but, -->
<!-- 	  in my view, of revolutionary significance. -->

<!-- 	<p> -->
<!-- 	  FEUERZEIG: Is that all there is to it? -->
	  
<!-- 	  MINSKY: Yes and no. Once one sees knowledge as based on these three -->
<!-- 	  instead of two components, one can start building pyramids that -->
<!-- 	  don&#39;t fall over so fast. Let me suggest two references: The -->
<!-- 	  Ph. D.  theses of G. Sussman and I. P. Goldstein discuss early forms -->
<!-- 	  of ideas about implementing these concepts of knowledge about -->
<!-- 	  debugging.  In any case, to return to my main theme, we expect the -->
<!-- 	  new descriptive tools of Computer Science to become fundamental in -->
<!-- 	  Educational Science. The concepts embodied in Programming Languages -->
<!-- 	  are intellectual contributions of very broad importance.  The reason -->
<!-- 	  they have not been so recognized is probably because their uses have -->
<!-- 	  been so obvious and practical that <em>familiarity</em> has bred a -->
<!-- 	  very substantial amount of contempt. They are important in ordinary -->
<!-- 	  life because (for the first time) they supply words for describing -->
<!-- 	  processes. I suppose most people think Mathematics fills that need -->
<!-- 	  but I view Mathematics (as we usually think of it) to be a weaker -->
<!-- 	  earlier stage in our development of ways to describe things! -->
<!-- 	  Mathematics had an uneven history; early success with Geometric and -->
<!-- 	  Arithmetic problems was followed by a long Dark Age -->

<!-- 	<p> -->
<!-- 	  (recapitulated with remarkable authenticity in our own schools -->
<!-- 	  between 3rd and 10th grades!) and at last had a Renaissance in which -->
<!-- 	  Newton and others found first a way to represent moving and changing -->
<!-- 	  structures.  But the invention of Calculus as a way to describe and -->
<!-- 	  explain Processes, was not very successful! It freezes certain kinds -->
<!-- 	  of change into static equations, but the classical ensemble of such -->
<!-- 	  descriptions can capture precious few of the kinds of processes -->
<!-- 	  people need to understand. They do well for the smooth, regular and -->
<!-- 	  continuous phenomena of Physics and perhaps for some of -->
<!-- 	  macro-economics, but serve poorly for problems of real life. -->
<!-- 	  Example: there is currently really no good theory -->
<!-- 	  of <em>posture</em>: how does a man keep from falling over? How are -->
<!-- 	  the hundreds of muscular subsystems kept functioning together? The -->
<!-- 	  classical mathematical control theories do not deal adequately with -->
<!-- 	  such models, and so such areas of natural interest and real-life -->
<!-- 	  concern are avoided in school subjects. Is there nothing we can say -->
<!-- 	  about other complex systems, ecologies, economies, political -->
<!-- 	  structures? By constructing simulations, kids can themselves come to -->
<!-- 	  see the various phenomena that emerge when one interconnects a lot -->
<!-- 	  of little systems, and become less naive about imaginary panaceas -->
<!-- 	  for well-intentioned correction of disturbances, ills, and -->
<!-- 	  imbalances. I expect in the next few years to see -->
<!-- 	  procedural-description models that do give suitable accounts of -->
<!-- 	  conditions that might be sufficient or necessary to stabilize -->
<!-- 	  postures or economics. Such insights might begin to prepare them -->
<!-- 	  better to serve as models of their own bodies and other complicated -->
<!-- 	  systems.  Programming languages already provide a great many new -->
<!-- 	  ways to describe complex systems and processes: they can handle -->
<!-- 	  decisions and discontinuities. Today children, in even the best -->
<!-- 	  schools, live in a conceptually deprived environment. How many of -->
<!-- 	  them have clear names and notions for such basic decision-making -->
<!-- 	  ideas as <em>subgoal,</em> or derived structures -->
<!-- 	  like <em>goal-tree?</em> Can they distinguish stacks from trees from -->
<!-- 	  strings? These distinctions are not mere technical specialization; -->
<!-- 	  they help to describe important features of the different kinds of -->
<!-- 	  problems people really get into.  Each social, technical, -->
<!-- 	  administrative, or learning problem has its own representational -->
<!-- 	  problems. We don&#39;t supply the kids with names for these -->
<!-- 	  things. Instead we emphasize nonexistent differences between -->
<!-- 	  Rationals, Fractions, and Quotients. We tell them that there are -->
<!-- 	  differences between numbers and numerals, that they must distinguish -->
<!-- 	  Cardinals from Ordinals. (How many teachers really understand that -->
<!-- 	  the latter are isomorphic!) Some readers might at first feel that -->
<!-- 	  there is something shallow or callous about the suggestion that -->
<!-- 	  computational representations could be helpful in real life -->
<!-- 	  problems. Many <em>humanists</em> react by saying things -->
<!-- 	  like <em>I&#39;d rather keep those problems than solve them in -->
<!--             mechanical ways.</em> I think that this is a shallow reaction. No -->
<!-- 	  matter how powerful our analytic culture becomes, there will always -->
<!-- 	  be problems too deep and too hard for us. It is childish, I feel, to -->
<!-- 	  make our older problems into symbols of security!  Let me dwell on -->
<!-- 	  this issue of providing children with words. In Baseball, everyone -->
<!-- 	  learns a hundred technical terms. In Geography, perhaps a -->
<!-- 	  thousand. In mathematics, only a few dozen. For real-life -->
<!-- 	  problem-analysis, we provide hardly any <em>technical</em> words at -->
<!-- 	  all.  For example, we all know what it means for a model or theory -->
<!-- 	  to be -->
<!-- 	  <em>robust.</em> Why don&#39;t we let children use words -->
<!-- 	  like <em>robust</em> and -->
<!-- 	  <em>sensitive?</em>  Children are not innately afraid of <em>big -->
<!--             words,</em> but they are very good at reading the mind of teachers -->
<!-- 	  who are! Our culture says that there&#39;s something dirty about -->
<!-- 	  precision; don&#39;t talk (think) so clearly, don&#39;t use so much -->
<!-- 	  detail, at least wait till you&#39;re older! There really seems to -->
<!-- 	  be some sort of taboo here; we don&#39;t give children our best -->
<!-- 	  words &mdash; or even use them when the kids are around.  When we -->
<!-- 	  allow kids to use our computer, with an easy but rich language like -->
<!-- 	  LOGO, we find that they soon begin to use <em>technical words</em> -->
<!-- 	  naturally and comfortably. They talk about <em>error-message,</em> -->
<!-- 	  <em>Boolean,</em> <em>Recursion,</em> <em>control-structure,</em> -->
<!-- 	  and so forth. You don&#39;t have to force or <em>teach</em> the -->
<!-- 	  language; the internal coherence of the subject makes their needs -->
<!-- 	  apparent. After a while, every user will want to know how to use two -->
<!-- 	  conditionals at a time, and you tell him the word &mdash; or -->
<!-- 	  concept-name, <em>Boolean,</em> for that. He already has built for -->
<!-- 	  himself the data-structure for understanding the concept.  The most -->
<!-- 	  important knowledge is knowledge about how to debug, and we -->
<!-- 	  encourage using words to express the kinds of problems in that. One -->
<!-- 	  kind of bug is the simple clerical error; typing a wrong -->
<!-- 	  letter. This kind of <em>bug</em> is not very important in the long -->
<!-- 	  run, and anyone can invent ways to make them less frequent if -->
<!-- 	  necessary. One learns about other kinds of bugs from -->
<!-- 	  programming: <em>wrong format</em> is like bad grammar, again not -->
<!-- 	  profound, but different from -->

<!-- 	<p> -->
<!-- 	  <em>mistake.</em> <em>Side effect</em> bugs are very important; one -->
<!-- 	  part of a process changes a <em>state</em> so that another process -->
<!-- 	  goes wrong. The concept or STATE is superbly important, yet -->
<!-- 	  there&#39;s no <em>ordinary</em> English word for it. Other bugs -->
<!-- 	  stem from -->
	  
<!-- 	  Common resource conflicts Conflicting brother goals Wrong data type -->
<!-- 	  Unrecognized interaction Initialization failure Wrong context -->
<!-- 	  assignment Children (and adults) in the programming environment soon -->
<!-- 	  came easily to make distinctions between local and global meanings -->
<!-- 	  of symbols; they really understand the nuances of contexts.  Are -->
<!-- 	  such things important in real life? One soon learns that it is very -->
<!-- 	  hard to build a complicated system if one has a <em>bad -->
<!--             representation</em> &mdash; one in which it is hard to describe the -->
<!-- 	  important features of the situation. Indeed, one might put it the -->
<!-- 	  other way around; if one finds oneself trying to build -->
<!-- 	  a <em>complicated</em> system, -->

<!-- 	<p> -->
<!-- 	  very likely the complication itself is an elaborate side-effect of -->
<!-- 	  having a bad representation. This carries over to life; if I am -->
<!-- 	  having trouble learning or understanding something, perhaps it is -->
<!-- 	  because I have a bad representation!  A longer-range <em>bug</em> -->
<!-- 	  is <em>inadequate comment structure.</em> If I have a large project -->
<!-- 	  &mdash; simulating a whole baseball game or something like that, -->
<!-- 	  then I find I have trouble each day remembering what I did the -->
<!-- 	  last. I have to develop a way of representing what I have done -->
<!-- 	  &mdash; a way that is more perspicuous than the program itself; -->
<!-- 	  otherwise I&#39;ll get a <em>bad representation</em> bug in my -->
<!-- 	  comment-structure! I have to learn how to make up really good names -->
<!-- 	  for things, symbols for the important things, relations, -->
<!-- 	  interactions. It&#39;s fun to understand the thing once or twice, -->
<!-- 	  but I don&#39;t want to start from scratch again and again.  Does -->
<!-- 	  the particular programming language matter? There is more to this -->
<!-- 	  issue than the usual comparison of the <em>features</em> and syntax -->
<!-- 	  of competing languages. In a certain mathematical sense all -->
<!-- 	  languages are more or less equivalent, for any computation can be -->
<!-- 	  expressed in any computer language. Of course, it is easier to say -->
<!-- 	  certain things in certain languages, and on occasion one can even -->
<!-- 	  say that language X is in all respects better than language Y.  But -->
<!-- 	  there is another dimension not so often discussed, and this is the -->
<!-- 	  cultural development of computer languages. A computer language, -->
<!-- 	  just like a Natural language, can come to have a characteristic -->
<!-- 	  literature. It acquires a lexicon as well as a syntax. When one -->
<!-- 	  talks of knowing English, one does not usually mean just the mastery -->
<!-- 	  of syntactic intricacies as in <em>She is used to. . .</em> One -->
<!-- 	  assumes also that the user knows the use and meanings of a few -->
<!-- 	  thousand words. Words are not arbitrary symbols. The collection that -->
<!-- 	  every child knows embodies (through the cultural mechanisms that -->
<!-- 	  teach him their meanings) a million years &mdash; well, who knows; -->
<!-- 	  let us say a billion man-years &mdash; of experiment and evolution, -->
<!-- 	  sorting, inventing, and weeding out of vast areas of -->
<!-- 	  conceptualization.  When one learns, for example, BASIC, one usually -->
<!-- 	  &mdash; not necessarily always &mdash; learns a grammar and not much -->
<!-- 	  more. When one learns LISP or LOGO &mdash; not a substantially -->
<!-- 	  different investment, initially, in effort &mdash; one is more -->
<!-- 	  likely to gain entrance to a whole culture with a collection of -->
<!-- 	  concepts larger than the language&#39;s <em>basic</em> grammar, -->
<!-- 	  because the handbooks and the users of such languages present not -->
<!-- 	  only the syntax but a collection of <em>functions</em> &mdash; -->
<!-- 	  numbering in the hundreds, each captures an important computational -->
<!-- 	  concept in a <em>word,</em> and this lexicon is the product of many -->
<!-- 	  years of evolution among interacting users with much common -->
<!-- 	  experience. Thus, the basic definitions of LISP tell one how to make -->
<!-- 	  lists and trees &mdash; data-structures &mdash; by building them up -->
<!-- 	  from just three or four -->
<!-- 	  <em>primitives</em> &mdash; processes that attach one more element -->
<!-- 	  to the structure in simple ways. But the <em>language</em> in the -->
<!-- 	  extended sense, does not stop there. The extended lexicon goes on to -->
<!-- 	  suggest to the user many ways to manipulate those structures, to -->
<!-- 	  apply functions that combine whole lists and trees, to search -->
<!-- 	  through them for specified patters, to apply functions to nodes so -->
<!-- 	  found, and so forth.  In principle a beginner could re-invest all -->
<!-- 	  those computational concepts, but he would have to recapitulate a -->
<!-- 	  generation of experience and would almost surely do it in such a way -->
<!-- 	  as to build into his system serious strategic errors that would -->
<!-- 	  haunt him later.  The extended lexicon includes schemas that have -->
<!-- 	  been discovered to be very useful in displaying and printing out -->
<!-- 	  results, organizing them for easy reading, and even -->
<!-- 	  painfully-discovered techniques for Editing and revising large -->
<!-- 	  programs. The conventional concept of Computer Language is terribly -->
<!-- 	  narrow. The extended concept includes not only the grammar but also -->
<!-- 	  suggestions for tracing, debugging, comparing old files, etc., and -->
<!-- 	  &mdash; on a less tangible level &mdash; a literature in which are -->
<!-- 	  embodied the current culture&#39;s canons of good taste and -->
<!-- 	  style. In the <em>Social Studies</em> everyone understands the -->
<!-- 	  uselessness of presenting fragments of other cultures without -->
<!-- 	  context, but in presenting kids with such a circumscribed fragment -->
<!-- 	  &mdash; like BASIC &mdash; of the culture of computer science -->
<!-- 	  &mdash; we seem not to have built up any such awareness.  Thus, -->
<!-- 	  besides the visible syntactical aspects of the languages, one should -->
<!-- 	  be aware of the less viable collection of extensions that -->
<!-- 	  distinguish between the <em>natural</em> communally evolved -->
<!-- 	  languages and the austere and elegant, but sharply unexpressive -->
<!-- 	  formal systems. The natural languages grow over a period of years in -->
<!-- 	  a culture of dedicated people with intense personal reasons for -->
<!-- 	  wanting to do things well. When one introduces a structure into the -->
<!-- 	  school environment, it is crucial that we choose one that has many -->
<!-- 	  avenues for smooth and comfortable growth. -->
	  
<!-- 	  Editor&#39;s note: Upon completion of Dr. Minsky&#39;s presentation, -->
<!-- 	  the following discussion ensued. -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: I despair that I am too late to save you the effort of -->
<!-- 	  rediscovering the Gestalt psychology but I wanted to point out that -->
<!-- 	  Skinner and company were well aware of Gestalt psychology and what -->
<!-- 	  it has done; it has done some things very brilliantly as you have -->
<!-- 	  done brilliantly in an analysis of learning situations and learning -->
<!-- 	  tasks.The problem with Gestalt psychology and the point of view of -->
<!-- 	  theory of instruction is that it was the economy of prescriptives -->
<!-- 	  that were effective and this is a point that Bruner has touched on -->
<!-- 	  in his book. A theory of instruction has to have a prescriptive -->
<!-- 	  aspect and this is what the Gestalt psychology could do. -->

<!-- 	<p> -->
<!-- 	  MINSKY: Certainly, the Gestalt psychologists were our predecessors, -->
<!-- 	  but I feel that neither them nor the possibility, or rather the -->
<!-- 	  substantial realizability, of knowledge about -->
<!-- 	  debugging. . . Debugging knowledge can be highly prescriptive, but I -->
<!-- 	  do not think that the Gestaltists really envisioned Gestalts as -->
<!-- 	  emerging from knowledge-based computational processes. They tended -->
<!-- 	  to look for more elementary, uniform principles. -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: I don&#39;t see in the work on debugging the prescriptive -->
<!-- 	  aspect of instruction. -->

<!-- 	<p> -->
<!-- 	  MINSKY: The prescription seems very clear. Find out the nature and -->
<!-- 	  character of debugging knowledge and tell the kids and let them find -->
<!-- 	  out about it. -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: Give them the results of the analysis and they will find -->
<!-- 	  their own prescription. -->
	  
<!-- 	  PAPERT: Absolutely not. We will expect one of our kids who has been -->
<!-- 	  through this, faced with juggling, to say <em>I want to learn to -->
<!--             juggle.</em>  This is a design problem for a learning situation. The -->
<!-- 	  kid is going to design the learning process. What this kid has -->
<!-- 	  learned, by rote, however, is some powerful principles of design of -->
<!-- 	  learning processes.  Some of them are too simple to talk about but -->
<!-- 	  if you have a complex process, try to break it up into simpler -->
<!-- 	  ones. Here is a simpler one. -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: An analytical tool. -->
	  
<!-- 	  PAPERT: An analytical tool which he uses to design the learning -->
<!-- 	  process. -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: To analyze what is to be learned rather than to describe -->
<!-- 	  the first step to be taken. -->
	  
<!-- 	  PAPERT: This is an analysis that leads into an automatic -->
<!-- 	  prescription, the first step to be taken in the learning process is -->
<!-- 	  to design it. The first step in design is to see if we can break it -->
<!-- 	  down. -->
	  
<!-- 	  MINSKY: Maybe there&#39;s a misunderstanding. You analyze something -->
<!-- 	  for a purpose. He has the goal; I want to learn it. I will analyze -->
<!-- 	  what has to be done to learn it. The result of the analysis is the -->
<!-- 	  prescription. Analysis leads to a result &mdash; it doesn&#39;t just -->
<!-- 	  sit there and then you have to get a prescription. The child -->
<!-- 	  says, <em>What should I prescribe for myself? To decide what to -->
<!--             prescribe for myself, I should make a model of the situation and -->
<!--             apply learning theory to it and then I will realize that it will not -->
<!--             do to practice juggling one at a time because there is a serious -->
<!--             bug.</em> -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: In a theory of instruction, we ask the instructor to -->
<!-- 	  prescribe a course of action for the student and what you are saying -->
<!-- 	  is to help with that, teach the kid to do the same analysis that you -->
<!-- 	  expect the instructor to do. -->

<!-- 	<p> -->
<!-- 	  PAPERT: What instructor? -->

<!-- 	<p> -->
<!-- 	  MINSKY: Why is there a theory of instruction in which there is an -->
<!-- 	  instructor and a kid? Do you have an instructor, is anyone telling -->
<!-- 	  you what to ask me? -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: I have a number of mentors, to whom I am grateful, who -->
<!-- 	  have taught me things that they have learned and I don&#39;t have to -->
<!-- 	  learn them. -->
	  
<!-- 	  MINSKY: I don&#39;t see them instructing you. -->
	  
<!-- 	  SCHNEIDER: The human postural system is a second order serve -->
<!-- 	  mechanism. Residence is at one cycle and 15 cycles and a damping -->
<!-- 	  coefficient of .4. Don&#39;t reinvent that, too. -->
	  
<!-- 	  MINSKY: We teach the kids to find out those things. Did you know -->
<!-- 	  that when you were a fifth grader? Why didn&#39;t you? -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: I&#39;m just telling you, don&#39;t go reinvent the -->
<!-- 	  posture system because that has already been discovered. -->
	  
<!-- 	  MINSKY: Do you think you could make a machine with 30 degrees of -->
<!-- 	  freedom that could stand up? -->

<!-- 	<p> -->
<!-- 	  SCHNEIDER: I gave you the damping coefficient and complete -->
<!-- 	  specifications. -->

<!-- 	<p> -->
<!-- 	  PAPERT: With complete specifications, you could translate it into -->
<!-- 	  making a machine. The facts you said may be true but it is a very -->
<!-- 	  incomplete specification as everyone who has tried to make robotic -->
<!-- 	  devices knows. -->

<!-- 	<p> -->
<!-- 	  MINSKY: Linear servo theory turned out not to work for large -->
<!-- 	  systems. Cybernetics of 1950 have not stood up and are not being -->
<!-- 	  used very much. -->

<!-- 	<p> -->
<!-- 	  FEURZEIG: I think I will ask you to defer further questions to -->
<!-- 	  later. -->

<!-- 	<p> -->
<!-- 	  JOKES and the LOGIC of the Cognitive Unconscious A.I. Memo No.603 -->
<!-- 	  November, 1980 Marvin Minsky, MIT Abstract -->

<!-- 	<p> -->
<!-- 	  Freud&#39;s theory of jokes explains how they overcome the mental -->
<!-- 	  <em>censors</em> that make it hard for us to -->
<!-- 	  think <em>forbidden</em> thoughts. But his theory did not work so -->
<!-- 	  well for humorous nonsense as for other comical subjects.  In this -->
<!-- 	  essay I argue that the different forms of humor can be seen as much -->
<!-- 	  more similar, once we recognize the importance of knowledge about -->
<!-- 	  knowledge and, particularly, aspects of thinking concerned with -->
<!-- 	  recognizing and suppressing bugs &mdash; ineffective or destructive -->
<!-- 	  thought processes. When seen in this light, much humor that at first -->
<!-- 	  seems pointless, or mysterious, becomes more understandable. -->

<!-- 	<p> -->
<!-- 	  INTRODUCTION A gentleman entered a pastry-cook&#39;s shop and -->
<!-- 	  ordered a cake; but he soon brought it back and asked for a glass of -->
<!-- 	  liqueur instead. He drank it and began to leave without having -->
<!-- 	  payed. The proprietor detained him. <em>You&#39;ve not paid for the -->
<!--             liqueur.</em> <em>But I gave you the cake in exchange for -->
<!--             it.</em> <em>You didn&#39;t pay for that either.</em> <em>But I -->
<!--             hadn&#39;t eaten it.</em> -->

<!-- 	<p> -->
<!-- 	  &mdash; Freud (1905) {0}. -->

<!-- 	<p> -->
<!-- 	  In trying to classify humorous phenomena, Sigmund Freud asks whether -->
<!-- 	  this should be called a joke, <em>for the fact is we do not yet know -->
<!--             in what the characteristic of being a joke resides.</em> Let us -->
<!-- 	  agree that some of the cake-joke&#39;s humor is related to a logical -->
<!-- 	  absurdity &mdash; leaving aside whether it is in the logic itself, -->
<!-- 	  or in keeping track of it.  Later Freud goes on to ask what is the -->
<!-- 	  status of a <em>knife without a blade which has no handle?</em> This -->
<!-- 	  absurdity has a different quality; some representation is being -->
<!-- 	  misused &mdash; like a frame without a picture.  Freud, who never -->
<!-- 	  returned to the subject after writing his 1905 book on the theory of -->
<!-- 	  jokes 0 , suggested that <em>censors</em> in the mind form powerful, -->
<!-- 	  unconscious barriers that make it difficult to think -->
<!-- 	  <em>forbidden</em> thoughts. But jokes can elude these censors -->
<!-- 	  &mdash; to create the pleasure of unearned release of psychic -->
<!-- 	  energy, which is discharged in the form of laughter. He explains why -->
<!-- 	  jokes tend to be compact and condensed, with double meanings: this -->
<!-- 	  is to fool the childishly simple-minded censors, who see only -->
<!-- 	  innocent surface meanings and fail to penetrate the disguise of the -->
<!-- 	  forbidden wishes. -->

<!-- 	<p> -->
<!-- 	  But Freud&#39;s theories do not work as well for humorous nonsense -->
<!-- 	  as for humorous aggression and sexuality {0}. In this essay I try to -->
<!-- 	  show how these different forms of humor can be seen as much more -->
<!-- 	  similar, once we make certain observations about the nature of -->
<!-- 	  commonsense reasoning. Here is our thesis: -->

<!-- 	<p> -->
<!-- 	  1. Common sense logic is too unreliable for practical use.  It -->
<!-- 	  cannot be repaired, so we must learn to avoid its most common -->
<!-- 	  malfunctions. -->

<!-- 	<p> -->
<!-- 	  Humor plays a special role in learning and communicating about such -->
<!-- 	  matters. -->

<!-- 	<p> -->
<!-- 	  2. It is not enough to detect errors in reasoning; one must -->
<!-- 	  anticipate and prevent them.  We embody much of our knowledge about -->
<!-- 	  how to do this in the form of <em>censors</em> that suppress -->
<!-- 	  unproductive mental states. This is why humor is so concerned with -->
<!-- 	  the prohibited. -->
	  
<!-- 	  3. Productive thinking depends on knowing how to use Analogy and -->
<!-- 	  Metaphor.  But analogies are often false, and metaphors -->
<!-- 	  misleading. So the <em>cognitive unconscious</em> must suppress -->
<!-- 	  inappropriate comparisons. This is why humor is so concerned with -->
<!-- 	  the nonsensical. -->
	  
<!-- 	  4. The consequences of intellectual failure are manifest in -->
<!-- 	  one&#39;s own head, while social failures involve other people. -->
<!-- 	  Intellect and Affect seem less different once we theorize that -->
<!-- 	  the <em>cognitive unconscious</em> considers faulty reasoning to be -->
<!-- 	  just as <em>naughty</em> as the usual <em>Freudian</em> wishes. -->
	  
<!-- 	  5. Humor evolved in a social context.  Its forms include graciously -->
<!-- 	  disarming ways to instruct others about inappropriate behavior -->

<!-- 	<p> -->
<!-- 	  and faulty reasoning. This deviousness makes the subject more -->
<!-- 	  confusing. -->

<!-- 	<p> -->
<!-- 	  Our theory emphasizes the importance of knowledge about knowledge -->
<!-- 	  and, particularly, aspects of thinking concerned with recognizing -->
<!-- 	  and suppressing bugs &mdash; ineffective or destructive thought -->
<!-- 	  processes. When seen in this light, much humor that at first seems -->
<!-- 	  pointless, or mysterious, becomes more understandable. {1} -->

<!-- 	<p> -->
<!-- 	  I. PROBLEMS OF COMMON SENSE REASONING When you tell a young -->
<!-- 	  child <em>I am telling a lie</em> then, if he is old enough to -->
<!-- 	  reason so, he will think: <em>If that is false, then he&#39;s not -->
<!--             telling a lie. But, then it must be true. But then, it must be a -->
<!--             lie, for it says so.  But then &mdash; .</em> And so on, back and -->
<!-- 	  forth. -->

<!-- 	<p> -->
<!-- 	  A child might find this situation disagreeable for several reasons. -->
<!-- 	  It challenges the belief that propositions are always either true or -->
<!-- 	  false. It threatens to propagate through his knowledge-structure, -->

<!-- 	<p> -->
<!-- 	  creating other inconsistencies. And he can make no progress when his -->
<!-- 	  mind returns again and again to the same state. {2} Common sense can -->
<!-- 	  go awry in endless ways. Beliefs can be wrong from the start, one -->
<!-- 	  can make mistakes from each step to the next, and one can wander -->
<!-- 	  aimlessly, getting nowhere. But before we discuss these, we should -->
<!-- 	  observe what actually happens when you say things like <em>this -->
<!--             statement is false.</em> Often the listener first seems puzzled, -->
<!-- 	  then troubled, and finally laughs. <em>That&#39;s funny,</em> he -->
<!-- 	  says. <em>Tell me another liar joke.</em> -->

<!-- 	<p> -->
<!-- 	  THE PROBLEM OF TRUTH: How do we know where to begin? The conclusions -->
<!-- 	  of even the best reasoning can be no better than its premises. In -->
<!-- 	  mathematics, this is of little concern (because one cares more where -->
<!-- 	  premises lead than where they come from). But in real life, few -->
<!-- 	  propositions are perfectly trustworthy. What does one do when an -->
<!-- 	  accepted <em>fact</em> turns out false? One of my children was once -->
<!-- 	  entranced by an ornamental fish-shaped bowl with four short -->
<!-- 	  legs. After a while she announced, somewhat uncertainly: <em>Some -->
<!--             fish don&#39;t have legs.</em> -->

<!-- 	<p> -->
<!-- 	  We never know anything for certain. What should one do upon reaching -->
<!-- 	  a conclusion that appears false &mdash; erase all the assumptions? -->
<!-- 	  When a long held belief turns false, should one erase all that has -->
<!-- 	  been deduced from it? When an acquaintance once tells a lie, should -->
<!-- 	  one reject everything else he ever said? There is no simple, single -->
<!-- 	  rule: each person must find his own ways to maintain his knowledge -->
<!-- 	  about his knowledge. (1) -->

<!-- 	<p> -->
<!-- 	  WHENCE THE RULES OF INFERENCE? How do we know how to infer? Most -->
<!-- 	  people believe that if most A&#39;s are B&#39;s, and if most B&#39;s -->
<!-- 	  are C&#39;s, then most A&#39;s are C&#39;s. Though false, this has -->
<!-- 	  great heuristic value, especially for children who encounter few -->
<!-- 	  exceptions.  Psychologically, I see no great difference between -->
<!-- 	  heuristic and logical reasoning; deduction is <em>just another</em> -->
<!-- 	  kind of evidence. We firmly believe a deduced conclusion only when -->
<!-- 	  it seems plausible on other grounds as well. At one time, many -->
<!-- 	  philosophers held that faultless <em>laws of thought</em> were -->
<!-- 	  somehow inherent, a priori, in the very nature of mind. This belief -->
<!-- 	  was twice shaken in the past century; first when Russell and his -->
<!-- 	  successors showed how the logic men employ can be defective, and -->
<!-- 	  later when Freud and Piaget started to reveal the tortuous ways in -->
<!-- 	  which our minds actually develop. -->

<!-- 	<p> -->
<!-- 	  After Russell observed that the seemingly frivolous <em>Who shaves -->
<!--             the Barber, who shaves everyone who does not shave himself?</em> -->
<!-- 	  was a truly serious obstacle to formalizing common sense logic, he -->
<!-- 	  and others tried to develop new formalisms that avoided such -->
<!-- 	  problems &mdash; by preventing the fatal self-references. But the -->
<!-- 	  proposed substitutes were much too complicated to serve for -->
<!-- 	  everyday use. -->

<!-- 	<p> -->
<!-- 	  I am inclined to doubt that anything very resembling formal logic -->
<!-- 	  could be a good model for human reasoning. (The paper by Hewitt and -->
<!-- 	  Kornfeld might suggest a possible avenue of compromise (2).) In -->
<!-- 	  particular, I doubt that any logic that prohibits self-reference can -->
<!-- 	  be adequate for psychology: no mind can have enough power &mdash; -->
<!-- 	  without the power to think about Thinking itself. Without -->
<!-- 	  Self-Reference it would seem immeasurably harder to achieve -->
<!-- 	  Self-Consciousness &mdash; which, so far as I can see, requires at -->
<!-- 	  least some capacity to reflect on what it does. (3) -->

<!-- 	<p> -->
<!-- 	  If Russell shattered our hopes for making a completely reliable -->
<!-- 	  version of commonsense reasoning, still we we can try to find the -->
<!-- 	  islands of <em>local consistency,</em> in which naive reasoning -->
<!-- 	  remains correct. It seems that only certain kinds of expressions -->
<!-- 	  lead to paradoxes and inconsistencies, and it seems worth taking -->
<!-- 	  some risks, gambling for greater power &mdash; provided we can -->
<!-- 	  learn, over time, to avoid the most common disasters. We all know -->
<!-- 	  the legend of the great mathematician who warned that his proof -->
<!-- 	  would lead to a paradox if he took one more step. He replied <em>Ah, -->
<!--             but I shall not take that step.</em> (4) One would miss the point to -->
<!-- 	  treat this as a <em>mere</em> joke.  What it means, really, is that -->
<!-- 	  we build into our minds two complementary functions: -->

<!-- 	<p> -->
<!-- 	  We work to discover <em>islands of power</em> within which -->
<!-- 	  commonsense reasoning seems safe. -->
	  
<!-- 	  We work also to find and mark the unsafe boundaries of those -->
<!-- 	  islands. -->

<!-- 	<p> -->
<!-- 	  In civilized communities, guardians display warnings to tell drivers -->
<!-- 	  about sharp turns, skaters about thin ice. Similarly, our -->
<!-- 	  philosophers and mathematicians display paradigms &mdash; like the -->
<!-- 	  Barber, the Tortoise, and the Liar &mdash; to tell us where to stop -->
<!-- 	  &mdash; and laugh. I suggest that when such paradigms are -->
<!-- 	  incorporated into the mind, they form intellectual counterparts to -->
<!-- 	  Freud&#39;s emotional censors. This would help explain why purely -->
<!-- 	  logical nonsense so often has the same humorous quality as do jokes -->
<!-- 	  about injury and discomfort &mdash; the problem that bothered -->
<!-- 	  Freud. The cake-joke reminds us, somewhat obscurely, to avoid a -->
<!-- 	  certain kind of logical absurdity &mdash; lest we do ourselves some -->
<!-- 	  vaguely understood cognitive harm. Hence our thesis: since we have -->
<!-- 	  no systematic way to avoid all the inconsistencies of commonsense -->
<!-- 	  logic, each person must find his own way by building a private -->
<!-- 	  collection of <em>cognitive censors</em> to suppress the kinds of -->
<!-- 	  mistakes he has discovered in the past. -->

<!-- 	<p> -->
<!-- 	  HEURISTIC CONTROL OF LOGIC: How do we know what next to do? I once -->
<!-- 	  tutored a student having trouble with middle-school geometry. I -->
<!-- 	  began to explain the axioms, and how proofs were structured. <em>I -->
<!--             understand all that,</em> he said, <em>only I was sick the day the -->
<!--             teacher explained how to find the proofs.</em> -->

<!-- 	<p> -->
<!-- 	  It is not enough just to know the principles of reasoning; one must -->
<!-- 	  know also when to apply them. We each know millions of facts, and -->
<!-- 	  perhaps millions of rules of inference. Which to apply to what, and -->
<!-- 	  when? There is a basic problem of direction, of not meandering, lest -->
<!-- 	  one aimlessly derive billions of inferences, all perfectly logical -->
<!-- 	  but none relevant to any goal. First, some <em>plan</em> is -->
<!-- 	  required. Next, one must avoid circling &mdash; returning to the -->
<!-- 	  same place again and again.  Finally, to avoid confusion, one needs -->
<!-- 	  an administrative structure to keep track of what one is doing, and -->
<!-- 	  why. -->

<!-- 	<p> -->
<!-- 	  The new science called Artificial Intelligence is concerned with -->
<!-- 	  just such issues of the efficiency and effectiveness of Reason -->
<!-- 	  &mdash; matters rarely discussed in Logic or Philosophy, which focus -->
<!-- 	  on verifying that proofs are valid, or that arguments are sound, -->
<!-- 	  rather than on how proofs are discovered. Much has been learned, -->
<!-- 	  in <em>AI,</em> about how to avoid excessive meandering and -->
<!-- 	  confusion, by using goal-structures and plans &mdash; techniques for -->
<!-- 	  insuring progress. Using such methods, some modern computer programs -->
<!-- 	  can thread their ways through some quite complicated situations. -->

<!-- 	<p> -->
<!-- 	  Nevertheless, the problem of meandering is certain to re-emerge once -->
<!-- 	  we learn how to make machines that examine themselves to formulate -->
<!-- 	  their own new problems. Questioning one&#39;s own -->
<!-- 	  <em>top-level</em> goals always reveals the paradox-oscillation of -->
<!-- 	  ultimate purpose. How could one decide that a goal is worthwhile -->
<!-- 	  &mdash; unless one already knew what it is that is worthwhile? How -->
<!-- 	  could one decide when a question is properly answered &mdash; unless -->
<!-- 	  one knows how to answer that question itself? Parents dread such -->
<!-- 	  problems and enjoin kids to not take them seriously. We learn to -->
<!-- 	  suppress those lines of thoughts, to <em>not even think about -->
<!--             them</em> and to dismiss the most important of all as nonsensical, -->
<!-- 	  viz. the joke <em>Life is like a bridge.</em> <em>In what -->
<!--             way?</em> <em>How should I know?</em> Such questions lie beyond the -->
<!-- 	  shores of sense and in the end it is Evolution, not Reason, that -->
<!-- 	  decides who remains to ask them. -->

<!-- 	<p> -->
<!-- 	  II. CENSORSHIP Just like taboos in human societies, certain things -->
<!-- 	  must not be thought inside the Mind. The best way for a child to -->
<!-- 	  learn not to do a certain bad thing would be to learn not to even to -->
<!-- 	  think of it. But isn&#39;t that like trying <em>not to think of a -->
<!--             monkey</em>? Contrast two ways: (i) suppress an idea already in the -->
<!-- 	  mind or (ii) prevent it from being thought in the first place: -->

<!-- 	<p> -->
<!-- 	  (i) Stop thinking that!  (ii) Don&#39;t even (or ever) think that! -->

<!-- 	<p> -->
<!-- 	  It is easy to begin to make a type (i) censor: wait for the -->
<!-- 	  specified -->
<!-- 	  <em>bad</em> event to happen, and then suppress it. But how does one -->
<!-- 	  prevent it from recurring? It seems harder to begin to make a type -->
<!-- 	  (ii) censor because it must be able to recognize the repressed -->
<!-- 	  thought&#39;s Precursors &mdash; but it is easier to see what to do -->
<!-- 	  next, since each Precursor usually leads to several options, and -->
<!-- 	  suppressing one still leaves the others. So we shall discuss only -->
<!-- 	  the second censor-type.  So, our censor-builder has to learn to -->
<!-- 	  recognize Precursors &mdash; mind-brain states that precede a -->
<!-- 	  recognizable (and, here, to be prohibited) activity. To do this, it -->
<!-- 	  will need a short-term memory (to remember what just happened) and a -->
<!-- 	  long-term memory (to store the result of learning). The latter may -->
<!-- 	  eventually become quite large, -->

<!-- 	<p> -->
<!-- 	  because a prohibited event may have many different precursors. In -->
<!-- 	  any case, an experienced type (ii) censor can recognize its joke by -->
<!-- 	  the situation and need not wait for the punch line. A type (i) -->
<!-- 	  censor makes you wait till the comedian finishes: only then can you -->
<!-- 	  complain <em>Oh, I&#39;ve heard that one before!</em> -->

<!-- 	<p> -->
<!-- 	  To place these in a larger framework, let&#39;s consider a simple -->
<!-- 	  <em>two-brain</em> theory. An <em>A-brain</em> has sensory inputs -->
<!-- 	  from the world, and motor outputs to the world. The B-brain&#39;s -->
<!-- 	  inputs come from the interior of A &mdash; so B can -->
<!-- 	  perceive <em>A-states</em> &mdash; and its outputs go into A, so B -->
<!-- 	  can affect activities in A. Thus, B can <em>see</em> what is -->
<!-- 	  happening inside A, and act to influence it, just as A -->
<!-- 	  can <em>see</em> and affect what happens in the world. B need not -->
<!-- 	  &mdash; and probably can not &mdash; know what -->
<!-- 	  A-events <em>mean,</em> vis-a-vis the world, but B is in a position -->
<!-- 	  to recognize such metapsychological conditions such as A being -->
<!-- 	  <em>meandering, circling, or confused.</em> (5) -->

<!-- 	<p> -->
<!-- 	  When a B-censor acts, it must disturb the A-brain so as to suppress -->
<!-- 	  the undesired activity. (It would be even better for B to remember, -->
<!-- 	  from past events, which is a good way to go, but that is outside -->
<!-- 	  this essay&#39;s concern.) In any case, the point is that -->
<!-- 	  precursor-sensitive censors can do their work before the problems -->
<!-- 	  that they evade actually arise. Probably, also, they can do this so -->
<!-- 	  quickly and gently as to produce no noticeable mental -->
<!-- 	  phenomenology. This would explain why censors are (in the) -->
<!-- 	  unconscious. -->

<!-- 	<p> -->
<!-- 	  The censorship theory explains why a joke is not so funny if -->
<!-- 	  you&#39;ve heard it before; this is because a new censor has been -->
<!-- 	  constructed, or an old one extended. Freud touches -->
<!-- 	  on <em>novelty</em> as a component of humor, but never dwells on why -->
<!-- 	  old jokes get few laughs. I presume that he simply considered it too -->
<!-- 	  obvious to mention, that censors are learners. -->

<!-- 	<p> -->
<!-- 	  How big must the censor memory be, to protect us from naive -->
<!-- 	  reasoning mistakes? Probably not so large for formal logic, -->
<!-- 	  considering how rarely we discover a new paradox. But for avoiding -->
<!-- 	  nonsense in general, we might accumulate millions of censors. For -->
<!-- 	  all we know, this <em>negative meta-knowledge</em> &mdash; about -->
<!-- 	  patterns of thought and inference that have been found defective or -->
<!-- 	  harmful &mdash; may be a large portion of all we know. -->

<!-- 	<p> -->
<!-- 	  Consider the activities called play and practice. The insensitive -->
<!-- 	  learning theories of behavioristic psychology regard play not at -->
<!-- 	  all, and see practice as reinforcing something repetitive. But -->
<!-- 	  practice (I conjecture) is often far from mere repetition and -->
<!-- 	  refinement of the same thing; often it is exploratory, testing out a -->
<!-- 	  skill&#39;s minute variations and perturbations &mdash; and learning -->
<!-- 	  which of them to enhance or suppress. Similarly play, (commonly seen -->
<!-- 	  as <em>mere</em>) is often also an exploration of variations on a -->
<!-- 	  larger scale. Many other everyday activities can so be seen as ways -->
<!-- 	  to learn to avoid bugs and mistakes. -->

<!-- 	<p> -->
<!-- 	  I know a young child whose sense of humor tends toward jokes like -->
<!-- 	  <em>what if the spoon were rubber,</em> apparently observing that a -->
<!-- 	  flexible spoon would be absurd because the food would fall out of -->
<!-- 	  it.  Is he enforcing a <em>must-be-rigid</em> property of some -->
<!-- 	  spoon-frame, or is he censoring the use of some spoon-frame that -->
<!-- 	  lacks the property?  The humor-behavior of children also needs more -->
<!-- 	  study. -->

<!-- 	<p> -->
<!-- 	  III. MEANING AND METAPHOR Two villagers decided to go -->
<!-- 	  bird-hunting. They packed their guns and set out, with their dog, -->
<!-- 	  into the fields. Near evening, with no success at all, one said to -->
<!-- 	  the other, <em>We must be doing something wrong.</em> <em>Yes,</em> -->
<!-- 	  agreed his friend. <em>Perhaps we&#39;re not throwing the dog high -->
<!--             enough.</em> -->

<!-- 	<p> -->
<!-- 	  When you want to fasten a screw and therefore reach for a certain -->
<!-- 	  screwdriver, your mind has chosen to see that screwdriver as a -->
<!-- 	  screw-driver; you could have seen it as a kind of dull knife, or as -->
<!-- 	  a hammer without a head. When we see something only in its -->
<!-- 	  <em>intended</em> aspect, we are <em>confusing the thing with -->
<!--             itself.</em> As Korzybski (3) intoned, <em>whatever a thing is, it -->
<!--             is not.</em>{6} {7} -->

<!-- 	<p> -->
<!-- 	  FRAMES: I have suggested in (4) that perceptions are ordinarily -->
<!-- 	  interpreted by the mind in terms of previously acquired description- -->
<!-- 	  structures called Frames. A frame is a way to represent a -->
<!-- 	  stereotyped situation, like being in a certain kind of room, or -->
<!-- 	  going to a certain kind of party. Attached to each frame are several -->
<!-- 	  kinds of information; some about how to use the frame, some about -->
<!-- 	  what one might expect to happen next, some about what to do if those -->
<!-- 	  expectations are not confirmed, and so forth. This theory was -->
<!-- 	  proposed to explain the speed and virtual absence of noticeable -->
<!-- 	  phenomenology in perceiving and thinking, and here I propose to -->
<!-- 	  sketch just enough of it to explain some features, and -->
<!-- 	  some <em>bugs,</em> of reasoning. Then we can return to unconscious -->
<!-- 	  censorship and error-correction. -->

<!-- 	<p> -->
<!-- 	  Each frame includes, among other things, a variety of terminals to -->
<!-- 	  which other frames are attached. Thus a chair-frame specifies that a -->
<!-- 	  (certain kind of) chair has a seat, a back, and four legs. The -->
<!-- 	  details of these would be described, not in the chair-frame itself, -->
<!-- 	  but in other frames attached to its terminals. Each frame includes -->
<!-- 	  also a set of features which, if enough of them are present, may -->
<!-- 	  activate the Frame. So, when you see enough parts of a chair, these -->
<!-- 	  will activate one of your chair-frames which, in turn, will activate -->
<!-- 	  the sub-frames attached to its terminals. These, then, will <em>look -->
<!--             for</em> other chair- parts that were not recognized at first -->
<!-- 	  &mdash; because of being unusual, or partially hidden from view, or -->
<!-- 	  whatever. Finally, if some elements required by the frame are not -->
<!-- 	  seen at all &mdash; one rarely sees all the legs of a chair, and -->
<!-- 	  never all the sides of a box &mdash; the missing elements are -->
<!-- 	  supplied by default. This is easy because most terminals of most -->
<!-- 	  frames have certain sub-frames already attached as default -->
<!-- 	  assignments. When one reads in a story about some shoe or some -->
<!-- 	  chair, these cause one, <em>by default</em> to assume a certain kind -->
<!-- 	  of shoe or chair. -->

<!-- 	<p> -->
<!-- 	  The concept of default goes much further. When one sees a person in -->
<!-- 	  a sitting posture then, even if every part of his chair is hidden -->
<!-- 	  from view, one will pseudo-see a chair under him. Unless your -->
<!-- 	  attention is drawn to the fact, you never notice that no chair was -->
<!-- 	  actually seen.  This is because the <em>sitting</em> frame includes -->
<!-- 	  a <em>must-be-supported-by</em> sub-frame terminal, and this is -->
<!-- 	  attached to some <em>typical</em> chair- frame, for its default -->
<!-- 	  assignment. {8} -->

<!-- 	<p> -->
<!-- 	  The chair-frame that is selected can depend, however, on the -->
<!-- 	  context.  For default assignments are weak and easy -->
<!-- 	  to <em>displace.</em> If there are other chairs around, the -->
<!-- 	  invisible chair will be assumed to be like one of them. If the scene -->
<!-- 	  is set in a park, then a park-bench frame might be activated to -->
<!-- 	  serve as default. If one then noticed an arm-chair arm, the system -->
<!-- 	  would replace the weakly-attached bench-frame by one that better -->
<!-- 	  suits what was seen &mdash; and one now <em>sees</em> an armchair. -->

<!-- 	<p> -->
<!-- 	  According to the theory in (4), this is done very swiftly because -->
<!-- 	  the -->
<!-- 	  <em>corresponding</em> terminals of related frames are already -->
<!-- 	  pre-connected to one another. This makes it easy to change a -->
<!-- 	  faltering interpretation or a frustrated expectation. Shifting from -->
<!-- 	  one related frame to another should be so fast and efficient as to -->
<!-- 	  be imperceptible to introspection. This is why one so easily -->
<!-- 	  recognizes any chair as <em>a chair,</em>even though particular -->
<!-- 	  chairs are so different from one another. I do not suggest that all -->
<!-- 	  this happens by magic; the interconnecting network is constructed -->
<!-- 	  over a lifetime of experience. In (5) I discuss how new frames arise -->
<!-- 	  usually as revised versions of older ones, bringing those <em>common -->
<!--             terminals</em> along with them. In (6) are more details, but one -->
<!-- 	  must read between the lines of that paper because it does not use -->
<!-- 	  the terminology of frames. -->

<!-- 	<p> -->
<!-- 	  Frames and frame-systems are used at conceptual as well as -->
<!-- 	  perceptual levels, and there we find other kinds of frame-systems -->
<!-- 	  &mdash; families of interconnected frames &mdash; that are not -->
<!-- 	  transformed so easily, hence more effort is noticed. Consider, for -->
<!-- 	  example, Wittgenstein&#39;s paradigmatic question about -->
<!-- 	  defining <em>game.</em> (7) The problem is that there is no property -->
<!-- 	  common to all games, so that the most usual kinds of definition -->
<!-- 	  fail. Not every game has a ball, nor two competing teams; even, -->
<!-- 	  sometimes, there is no notion of -->
<!-- 	  <em>winning.</em> In my view, the explanation is that a word -->
<!-- 	  like <em>game</em> points to a somewhat diffuse <em>system</em> of -->
<!-- 	  prototype frames, among which some frame-shifts are easy, but others -->
<!-- 	  involve more strain.  The analogy between football and chess is -->
<!-- 	  strained only a little, more with solitaire, and so on. Shifting -->
<!-- 	  from one familiar kind of kitchen-chair to another is imperceptible, -->
<!-- 	  but changing a park-bench to an arm-chair would be strain enough -->
<!-- 	  to <em>surprise.</em> -->

<!-- 	<p> -->
<!-- 	  Now I propose that much of commonsense logic itself is based on -->
<!-- 	  learning to make shifts between frames that have terminals in -->
<!-- 	  common. For example, if a situation fits a frame like A implies B, -->
<!-- 	  and B implies C, a simple frame-shift re-represents it as A implies -->
<!-- 	  C. Seen in this light, Freud&#39;s cake story appears to display -->
<!-- 	  some sort of incorrect-logic script in which each consecutive pair -->
<!-- 	  of sentences matches some such tried-and-true kind of reasoning -->
<!-- 	  step. -->

<!-- 	<p> -->
<!-- 	  I presume that when we <em>understand</em> this sort of story, we -->
<!-- 	  represent it in our minds as a series of pairs of overlapping -->
<!-- 	  assignments of things to terminals of such frames. And somewhere -->
<!-- 	  along the way, in the cake story, there is an improper -->
<!-- 	  assignment-change. Is it the payment moving from the cake to the -->
<!-- 	  drink? Is it a pivot between -->
<!-- 	  <em>owns</em> and <em>possesses?</em> Each listener must make his -->
<!-- 	  own theory of what is wrong &mdash; and devise his own way to avoid -->
<!-- 	  this confusion in the future. Some people will do better at this -->
<!-- 	  than others. -->

<!-- 	<p> -->
<!-- 	  METAPHOR: All intelligent persons also possess some larger-scale -->
<!-- 	  frame-systems whose members seemed at first impossibly different -->
<!-- 	  &mdash; like water with electricity, or poetry with music. Yet many -->
<!-- 	  such analogies &mdash; along with the knowledge of how to apply them -->
<!-- 	  &mdash; are among our most powerful tools of thought. They explain -->
<!-- 	  our ability sometimes to to see one thing &mdash; or idea &mdash; as -->
<!-- 	  though it were another, and thus to apply knowledge and experience -->
<!-- 	  gathered in one domain to solve problems in another. It is thus that -->
<!-- 	  we transfer knowledge via the paradigms of Science. We learn to see -->
<!-- 	  gases and fluids as particles, particles as waves, and waves as -->
<!-- 	  envelopes of growing spheres. -->

<!-- 	<p> -->
<!-- 	  How are these powerful connections discovered? For the simple ones, -->
<!-- 	  there is no great problem: some frames are easily recognized as -->
<!-- 	  similar because their terminals accept the same sorts of entities; -->
<!-- 	  these could be located and classified by simple algorithms, e.g., -->
<!-- 	  searches for best match. As for those most subtle, -->
<!-- 	  once-in-a-lifetime insights, whose analogical powers are hidden deep -->
<!-- 	  in the procedural structures that operate on them, we hardly need a -->
<!-- 	  general theory to account for them since &mdash; like favorable -->
<!-- 	  evolutionary mutations &mdash; few are ever discovered by any single -->
<!-- 	  individual, and those can be thereafter transmitted through the -->
<!-- 	  culture. -->

<!-- 	<p> -->
<!-- 	  In any case, putting aside the origins of those rare, greatest -->
<!-- 	  insights, each individual must have his own ways to build new -->
<!-- 	  connections amongst his frames. I will contrast particular methods -->
<!-- 	  against general methods, arguing that the two have problems that -->
<!-- 	  seem somewhat opposite in character &mdash; that the errors -->
<!-- 	  of <em>particular</em> methods can be managed additively, while bugs -->
<!-- 	  in the <em>general</em> methods must be repaired subtractively. This -->
<!-- 	  last point will eventually bring us back to censors. -->

<!-- 	<p> -->
<!-- 	  PARTICULAR ANALOGIES: In the course of thinking, we use different -->
<!-- 	  frames from one moment to the next. But frequently one of the active -->
<!-- 	  frames will fail &mdash; <em>that&#39;s not a door, only a big -->
<!--             window.</em>  Winston, in (8) suggests that whenever such an error -->
<!-- 	  is (somehow) detected, described, and corrected, we can attach to -->
<!-- 	  the failing frame a <em>pointer</em> to some other frame that has -->
<!-- 	  been found to work in this circumstance. The pointer must contain, -->
<!-- 	  of course, a description of the failure circumstance. A family of -->
<!-- 	  frames connected in such a way is called a difference network. {9} -->
<!-- 	  We can explain (4) the definition difficulty (e.g., that of -->
<!-- 	  defining <em>game</em>) by supposing that such words point not to -->
<!-- 	  any single frame, but into such a network. -->

<!-- 	<p> -->
<!-- 	  Any such link between two frames implies a generalization of the -->
<!-- 	  form <em>A&#39;s are like B&#39;s, except for D.</em> Thus, such a -->
<!-- 	  link is a fragment of an analogy. Of course, like any -->
<!-- 	  generalization, it will likely soon fail again and need -->
<!-- 	  refinement. Winston&#39;s thesis (8) suggests ways to do this. The -->
<!-- 	  important point here is that, particular analogies discovered in the -->
<!-- 	  course of experience, can be remembered by adding positive, active -->
<!-- 	  links between frames. -->

<!-- 	<p> -->
<!-- 	  GENERAL ANALOGY METHODS: What if one is confronted with a novel -->
<!-- 	  situation that does not arouse any particular frame? Then, it makes -->
<!-- 	  sense to try some <em>general</em> method, e.g., to compare the -->
<!-- 	  situation to some large class of frames, and, select the one -->
<!-- 	  that <em>best fits.</em> Such a method can do much better than -->
<!-- 	  chance, but what if it yields a result that does more harm than -->
<!-- 	  good? I will argue that one now must build a censor, and that there -->
<!-- 	  is a general principle here that learning theorists have not -->
<!-- 	  appreciated: positive general principles need always to be -->
<!-- 	  supplemented by negative, anecdotal censors. -->

<!-- 	<p> -->
<!-- 	  For, it hardly ever pays to alter a general mechanism to correct a -->
<!-- 	  particular bug. Almost every instance-specific modification of a -->
<!-- 	  best-match mechanism would reduce its general usefulness. So when -->
<!-- 	  the general mechanism yields a bad result, one can only remember to -->
<!-- 	  suppress its subsequent appearances &mdash; that is, to build a -->
<!-- 	  censor. If a child wants his sibling&#39;s toy, he will first try -->
<!-- 	  seizing it &mdash; the most general way to get things one -->
<!-- 	  wants. Once the parents see to it that this is censored, then he can -->
<!-- 	  find other ways. But he must not learn in general not to take things -->
<!-- 	  he wants, lest he become helpless. -->

<!-- 	<p> -->
<!-- 	  Some forms of humor, notably puns, turn on changing the meaning- -->
<!-- 	  sense of a word. (Besides the easily distinguished dictionary -->
<!-- 	  senses, most words have also many others that would never be -->
<!-- 	  separated in a dictionary. <em>Lift,</em> for example, has different -->
<!-- 	  implications when an object weighs one gram, or a thousand, {7} and -->
<!-- 	  really to understand lifting requires a network for making -->
<!-- 	  appropriate shifts among such different micro-senses.) While verbal -->
<!-- 	  sense-shifting can be funny, and even useful, it is dangerous, and -->
<!-- 	  especially hazardous to be subject to the fortuitous, meaningless -->
<!-- 	  sense-shifts that depend on superficial word-sound similarities. In -->
<!-- 	  a fragment of a schizophrenic&#39;s transcript, the patient sees a -->
<!-- 	  penny in the street, says -->
<!-- 	  <em>copper, that&#39;s a conductor,</em> then must run to a street -->
<!-- 	  car to speak to the conductor. Perhaps this disorder is one of -->
<!-- 	  frame-shift control, either disabling the bad-analogy suppressors or -->
<!-- 	  irresponsibly enhancing the general analogy-finder. -->

<!-- 	<p> -->
<!-- 	  The element that seems to me most common to all the different kinds -->
<!-- 	  of humor is that of unexpected frame-substitution, in which a scene -->
<!-- 	  is first described from one viewpoint and then suddenly &mdash; -->
<!-- 	  typically by a single word &mdash; one is made to view all the -->
<!-- 	  scene-elements in another, -->

<!-- 	<p> -->
<!-- 	  quite different way. Some such shifts are insightful, of course, -->
<!-- 	  while others are mere meaningless accidents. Next we turn to a kind -->
<!-- 	  that could be turning points in each individual&#39;s personal -->
<!-- 	  evolution. -->

<!-- 	<p> -->
<!-- 	  IV.  TRAUMATIC COGNITIVE EXPERIENCES -->

<!-- 	<p> -->
<!-- 	  <em>Yields truth when appended to its own quotation</em> -->

<!-- 	<p> -->
<!-- 	  &mdash; W. V. Quine In the popular psychology of our day, Intellect -->
<!-- 	  is seen as straightforward, deliberate, conscious, and emotionally -->
<!-- 	  neutral; but in regard to emotional matters, the public has come -->
<!-- 	  generally to accept the psychoanalytic view that Affect is dominated -->
<!-- 	  by unknown terrors and traumas, lurking in the unconscious since -->
<!-- 	  childhood. Now I want to challenge this -->
<!-- 	  affect-intellect <em>dumbbell.</em> I certainly do not mean to -->
<!-- 	  suggest that there are no differences of kinds in mental affairs -->
<!-- 	  &mdash; only that this particularly popular distinction, however -->
<!-- 	  useful in everyday life, does more harm than good in psychology. (6) -->

<!-- 	<p> -->
<!-- 	  In any case, the Affect-Intellect distinction would lose much of its -->
<!-- 	  force if Reason, too, employed a powerful <em>cognitive -->
<!--             unconscious</em> &mdash; and that is exactly what I shall argue: -->
<!-- 	  that Intellect, too, has its own buried secrets. In Freud&#39;s -->
<!-- 	  scenario, the ego develops largely in contexts of fear of -->
<!-- 	  deprivation, punishment or mutilation; of anxiety about uncertainty -->
<!-- 	  and insecurity; terror of losing the esteem or person of parent or -->
<!-- 	  attachment-figure. New families of censors &mdash; new domains of -->
<!-- 	  repression &mdash; are created when wishes conflict enough with -->
<!-- 	  reality to justify attempting to keep them from becoming conscious. -->

<!-- 	<p> -->
<!-- 	  Does anything like that happen in the intellectual sphere? One might -->
<!-- 	  suppose not, because a necessary element is missing &mdash; that of -->
<!-- 	  a beloved &mdash; or punitive &mdash; authority figure. However, -->
<!-- 	  while Freudian taboos originate from outside, the child needs no -->
<!-- 	  external authority- figure to point out his gross cognitive -->
<!-- 	  failures; he needs no parent to scold him, when an encounter with -->
<!-- 	  paradox throws his mind into a frightening cyclone. The momentary -->
<!-- 	  loss of mental control should provoke anxiety in its own right. -->

<!-- 	<p> -->
<!-- 	  But, one might ask, if we bear the scars of frightening cognitive -->
<!-- 	  experiences, why do they not reveal themselves (like the -->
<!-- 	  affect-laden ones) in nightmares, compulsions, phobias, and the -->
<!-- 	  like? Perhaps they do; it would not show in the interpretations of -->
<!-- 	  present-day psychiatry. But every teacher knows (and fears) the -->
<!-- 	  rigid inhibition of children&#39;s cognitive phobias: <em>I -->
<!--             don&#39;t want to learn this; I couldn&#39;t possibly do that.</em> -->
<!-- 	  Let us speculate on how such fears might originate.  Consider the -->
<!-- 	  paradox of Nearness: Every child must once have said to himself: -->

<!-- 	<p> -->
<!-- 	  Hmmm. Ten is almost Eleven. And Eleven is nearly Twelve. And so on; -->
<!-- 	  Ninety-Nine is nearly a Hundred. But then Ten must be almost a -->
<!-- 	  Hundred! -->

<!-- 	<p> -->
<!-- 	  To an adult, this is not even a stupid joke. But we each must once -->
<!-- 	  have thought something like: <em>there is obviously something wrong -->
<!--             here. Is it in my premises or in my logic? Well, what&#39;s my -->
<!--             premise?  Obviously, that &lsquo;if A is near B, and if B is near C, -->
<!--             then A must be near C.&rsquo; </em> Nothing wrong with that. So -->
<!-- 	  there must be something wrong with my logic. But I&#39;m only using -->
<!-- 	  something like: <em>If A implies B, and if B implies C, then A -->
<!--             implies C.</em> <em>How could that be wrong? No way!</em> -->

<!-- 	<p> -->
<!-- 	  To be sure, not everyone remembers such experiences as frightening. -->
<!-- 	  In fact, ad hominem, readers of essays like this one would more -->
<!-- 	  likely complain that they like such problems and cannot see them as -->
<!-- 	  <em>traumatic.</em> No matter, such readers are just the ones who -->
<!-- 	  have found ways to transform &mdash; what did Freud call it? -->
<!-- 	  &mdash; to sublimate such problems into constructive thinking about -->
<!-- 	  thinking. In any case, in one private manner or another, everyone -->
<!-- 	  somehow comes to deal with such problems, and I see only one -->
<!-- 	  practical way: we must each grow for ourselves some structure, of -->
<!-- 	  large complexity and little elegance, to tell us when &mdash; and -->
<!-- 	  when not &mdash; to trust each such pattern of inference. For -->
<!-- 	  example, we each learn never to repeat a near deduction more than a -->
<!-- 	  few times in any one argument. Furthermore, the accumulation of such -->
<!-- 	  experiences leads us eventually to realize that this is not peculiar -->
<!-- 	  to <em>near</em> alone: perhaps one shouldn&#39;t use any inference -->
<!-- 	  method too many times. What is <em>too many?</em> There is, I fear, -->
<!-- 	  no elegant answer. We each have to learn and master large of bodies -->
<!-- 	  knowledge about the limitations of each species of reasoning. -->

<!-- 	<p> -->
<!-- 	  It might be useful to try to catalog the kinds of cognitive -->
<!-- 	  incidents that must have so baffled each of us in early life. Each -->
<!-- 	  reader must recall the distress of being made to discern the -->
<!-- 	  arbitrary boundaries between one ocean and another, or at trying to -->
<!-- 	  answer <em>which came first, the chicken or the egg?</em> Every -->
<!-- 	  child must have wondered about his origin and from whence came the -->
<!-- 	  first person. Only the dullest child never found for himself some -->
<!-- 	  sort of Zeno paradox, or Achilles and Tortoise problem. I remember -->
<!-- 	  being especially disturbed to discover that there were questions -->
<!-- 	  that adults had no way to answer. -->

<!-- 	<p> -->
<!-- 	  MYSTICAL EXPERIENCE: Another family of disturbances arise when we -->
<!-- 	  question our own purposes. <em>Why should I do this,</em> &mdash; -->
<!-- 	  whatever it is &mdash; one asks, and proposes some answer. But then -->
<!-- 	  one is impelled to continue, <em>why should I want that,</em> and so -->
<!-- 	  forth. There is a not uncommon phenomenon &mdash; sometimes called -->
<!-- 	  mystical experience &mdash; from which a person emerges with the -->
<!-- 	  conviction that some unsolvable problem (like the purpose of -->
<!-- 	  existence) has been completely explained; one can&#39;t remember -->
<!-- 	  quite how, only that it was answered so well as to leave no doubt at -->
<!-- 	  all. This, I venture, reflects some mental mechanism (perhaps one of -->
<!-- 	  last resort) that, in a state of particularly severe turmoil or -->
<!-- 	  stress, can short-circuit the entire intellectual process &mdash; by -->
<!-- 	  creating the illusion that the problem has been settled. Powerful -->
<!-- 	  but dangerous, such a mechanism short-cuts the canons of normal -->
<!-- 	  confirmation. One kind of confusion-cycle is thereby broken, but -->
<!-- 	  this may damage other ways in which sane minds confront beliefs with -->
<!-- 	  evidence. Then, anything can happen. {10} -->

<!-- 	<p> -->
<!-- 	  V. HUMOR AND EVOLUTION If you wish to study a granfalloon just -->
<!-- 	  remove the skin of a toy balloon. -->
	  
<!-- 	  &mdash; Kurt Vonnegut, in Cat&#39;s Cradle In the 1912 edition, -->
<!-- 	  Freud, still perplexed about the purpose of nonsense, recounts a -->
<!-- 	  joke of this form[11]: -->
	  
<!-- 	  A man at the dinner table dipped his hands in the mayonnaise and -->
<!-- 	  then ran them through his hair. When his neighbor looked astonished, -->

<!-- 	<p> -->
<!-- 	  the man apologized: <em>I&#39;m so sorry. I thought it was -->
<!--             spinach.</em> -->

<!-- 	<p> -->
<!-- 	  We have argued that learning about bugs is central to the growth of -->
<!-- 	  reason. But reason itself grows in no vacuum; most of our ideas -->
<!-- 	  &mdash; and our ideas about ideas &mdash; come via our families and -->
<!-- 	  cultures, and this poses some special communication problems. For -->
<!-- 	  one, it is risky to point out the mistakes of a person one wants to -->
<!-- 	  please. So this must be done in some <em>conciliatory</em> manner -->
<!-- 	  &mdash; and humor seems involved in this. For another, if learning -->
<!-- 	  about bugs involves a special kind of memory, then this -->
<!-- 	  communication must somehow engage that memory. In this section we -->
<!-- 	  propose that humor &mdash; and more specifically, laughter &mdash; -->
<!-- 	  is innately enabled to do this, too. -->

<!-- 	<p> -->
<!-- 	  But first we digress to discuss an important methodological problem: -->
<!-- 	  Why is it so hard to explain why jokes are funny? Why, for that -->
<!-- 	  matter, is it so hard to say precisely what is a joke? We have -->
<!-- 	  already mentioned Wittgenstein&#39;s problem of -->
<!-- 	  defining <em>game</em>: one can find no single quality common to all -->
<!-- 	  the different kinds of examples &mdash; and one finds a similar -->
<!-- 	  problem in attempting to define <em>humor.</em> But we did not stop -->
<!-- 	  to ask why this is so. One might suppose it a mere surface -->
<!-- 	  difficulty, and hope that we may yet find a single underlying -->
<!-- 	  structure from which all funny things spring &mdash; some -->
<!-- 	  basic <em>grammar of humor,</em> or <em>comical deep structure.</em> -->
<!-- 	  Not so, I fear; when we look deeper for that underlying structure of -->
<!-- 	  humor we shall still find a vexing lack of unity. I argue that this -->
<!-- 	  is a consequence of the way things usually evolve in biology. -->

<!-- 	<p> -->
<!-- 	  In mechanisms designed by plan, it is reasonable to ask about -->
<!-- 	  purpose or cause. What is the purpose of that beam in this house? -->
<!-- 	  Simple: to hold up this roof &mdash; and, perhaps, to hold those -->
<!-- 	  walls apart. But, when we ask questions about structures created by -->
<!-- 	  evolution, we find that only rarely does one evolutionary increment -->
<!-- 	  serve a single purpose &mdash; and rarely is one alone in serving -->
<!-- 	  any particular purpose. Behavior emerges from a network of -->
<!-- 	  interdependent mechanisms, and one cannot expect any compactly -->
<!-- 	  circumscribed theory (or mechanism) completely to <em>explain</em> -->
<!-- 	  any single surface component of behavior.  What a theory can do, -->
<!-- 	  though, is to describe some fragment of that larger network of -->
<!-- 	  interacting subsystems. -->

<!-- 	<p> -->
<!-- 	  Humor, like games, serves and exploits many different needs and -->
<!-- 	  mechanisms. It lacks sharp, natural boundaries because those -->
<!-- 	  underlying things themselves overlap and exploit one another. When -->
<!-- 	  we employ a word like <em>humor,</em> one has the illusion of -->
<!-- 	  designating something sharper than this kind of complex web of -->
<!-- 	  relations among laughter, faulty reasoning, taboos and prohibitions, -->
<!-- 	  and unconscious suppressor mechanisms. But, I think the very clarity -->
<!-- 	  of words is itself a related illusion; as noted in {7}, language -->
<!-- 	  itself works only because oversimplification is more useful than -->
<!-- 	  realistic confusion &mdash; that is, in real life, if not for -->
<!-- 	  thinking about psychology. -->

<!-- 	<p> -->
<!-- 	  ROLES OF LAUGHTER: Consider what happens when a thought- situation -->
<!-- 	  comes to be perceived as funny or absurd: further reasoning is -->
<!-- 	  drowned in a flood of activity &mdash; furious motions of thorax, -->
<!-- 	  abdomen, head, limbs and face, accompanied by loud barking, -->
<!-- 	  wheezing, and choking noises. To a Martian, an epileptic seizure -->
<!-- 	  would be less alarming. Adults, of course, can train themselves to -->
<!-- 	  suppress this, but that is another matter. -->

<!-- 	<p> -->
<!-- 	  Laughter disrupts reasoning: The laughter reaction is so distracting -->
<!-- 	  as to keep the mind from proceeding further along the prohibited or -->
<!-- 	  ridiculous path it has started. Whatever that line of thought, the -->
<!-- 	  disruption prevents you from <em>taking it seriously,</em> from -->
<!-- 	  acting upon it or considering its further logical consequences. -->

<!-- 	<p> -->
<!-- 	  At the same time, laughter exercises another, complementary -->
<!-- 	  function. -->

<!-- 	<p> -->
<!-- 	  Laughter focuses attention: While disrupting further reasoning, -->
<!-- 	  laughter takes a firm grip on the thought itself, holding up the -->
<!-- 	  absurdity in sharp focus. Perhaps the joke-thought is given full -->
<!-- 	  attention, holding the incongruity in some <em>short-term -->
<!--             memory</em> &mdash; so that <em>censor-learning</em> agency can -->
<!-- 	  absorb it. -->

<!-- 	<p> -->
<!-- 	  Thus <em>humor</em> might serve to mediate the process in which the -->
<!-- 	  censors learn, much as <em>pleasure</em> is often supposed to -->
<!-- 	  mediate ordinary learning. {12} -->

<!-- 	<p> -->
<!-- 	  EVOLUTION OF HUMOR: How might all this have evolved? We conjecture -->
<!-- 	  that it happened while our evolving minds passed through stages of -->
<!-- 	  increasing ability to reflect &mdash; to think not merely about the -->
<!-- 	  physical problems at hand, but about how we should apply our mental -->
<!-- 	  resources to them; in a word, when we were learning to plan. In -->
<!-- 	  order to make realistic plans, we had to learn to take account of -->
<!-- 	  what we could make our minds do. -->

<!-- 	<p> -->
<!-- 	  This ability could not have emerged all at once. There must have -->
<!-- 	  been intermediate steps &mdash; such as the appearance of -->
<!-- 	  multi-level schemes like the one suggested above, in which an A-mind -->
<!-- 	  is monitored by a B-mind. Eventually we became able to symbolize and -->
<!-- 	  manipulate representations of plans, and this allowed the first -->
<!-- 	  direct references to our own mental activities. Now, suddenly, we -->
<!-- 	  could do such tricks as to relate statements to their own -->
<!-- 	  quotations, and make propositions that (for better or for worse) -->
<!-- 	  could discuss their own truth &mdash; as in Quine&#39;s <em>yields -->
<!--             truth</em> tour de force. {13} -->

<!-- 	<p> -->
<!-- 	  In any case, once able to accomplish intricate chains of reasoning, -->
<!-- 	  we became vulnerable to new kinds of bugs: faulty variable bindings, -->
<!-- 	  subtle changes of sense, and more obscurely circular logic. This -->
<!-- 	  same epoch probably saw also the emergence of Language for social -->
<!-- 	  communication, which also converged toward using more concise and -->
<!-- 	  manipulable symbolic representations. And, because we could not -->
<!-- 	  weaken the expressiveness of symbol-manipulation without losing its -->
<!-- 	  power, we had to evolve those censor memories. Of course, what -->
<!-- 	  actually happened was surely not this simple, but we had better -->
<!-- 	  return again to our speculations about laughter. -->

<!-- 	<p> -->
<!-- 	  Laughter&#39;s facial component suggests that it evolved in -->
<!-- 	  connection with social communication. It appears to be derived -->
<!-- 	  (ethologically) in part from a <em>conciliatory</em> expression, but -->
<!-- 	  it includes also a baring of teeth that suggests a -->
<!-- 	  defensive-aggressive mixture. {14} -->

<!-- 	<p> -->
<!-- 	  Laughter&#39;s bizarre vocal component also suggests social -->
<!-- 	  functions that combine ancestral <em>releasers</em> for both -->
<!-- 	  conciliation and aggression.  Perhaps it came somehow to serve as a -->
<!-- 	  signal to induce another person to stop whatever he was doing: -->
<!-- 	  whether because dangerous, pointless, objectionable, ridiculous, or -->
<!-- 	  otherwise forbidden. -->

<!-- 	<p> -->
<!-- 	  Later, this function became internalized. If a person could feel and -->
<!-- 	  hear himself laugh, grimace, and shake, why not exploit these -->
<!-- 	  side-effects also to make one&#39;s own self to stop doing something -->
<!-- 	  ridiculous or prohibited? Perhaps, literally, men first learned to -->
<!-- 	  laugh at their own mistakes, and later learned to censure themselves -->
<!-- 	  in silence. -->

<!-- 	<p> -->
<!-- 	  I make no plea for this particular scenario, only that something of -->
<!-- 	  this general sort must have happened, in which several pre-existing -->
<!-- 	  complexes grew together. They each brought along a variety of older -->
<!-- 	  interactions with other systems and purposes &mdash; that were -->
<!-- 	  exploited to produce the puzzling combinations of conciliation, -->
<!-- 	  aggression, sexuality, and nonsense that are now mixed together in -->
<!-- 	  humor. If other mental structures also share this kind of tangled -->
<!-- 	  ethological ancestry, then a mind grown this way must now resemble a -->
<!-- 	  great spider-web, in which many threads of different biological -->
<!-- 	  purpose intersect in many nodes of different multi-purpose -->
<!-- 	  mechanisms. If so, the goals of psychological theories must be to -->
<!-- 	  describe different fragments of that web &mdash; each to make a map -->
<!-- 	  of some few of those threads and nodes. -->

<!-- 	<p> -->
<!-- 	  By a curious coincidence, our theories of how minds work must -->
<!-- 	  probably have themselves this same peculiar, web-like character -->
<!-- 	  &mdash; albeit for a different reason. For (I think) the only way a -->
<!-- 	  person can understand anything very complicated is to understand it -->
<!-- 	  at each moment only locally &mdash; like the spider itself, seeing -->
<!-- 	  but a few threads and crossings from each viewpoint. Strand by -->
<!-- 	  strand, we build within our minds these webs of theory, from -->
<!-- 	  hard-earned locally intelligible fragments. The mind-spider&#39;s -->
<!-- 	  theory is correct to the extent that the model in his head -->
<!-- 	  corresponds to the mechanism in his head. {15} -->

<!-- 	<p> -->
<!-- 	  Finally it is probably futile to ask precisely what humor -->
<!-- 	  is. Korzybski&#39;s injunction applies here especially: the -->
<!-- 	  word <em>humor</em> points to no real thing. Instead, in each -->
<!-- 	  different person&#39;s mind it points to a slightly different -->
<!-- 	  web-model. We each use &mdash; and mean &mdash; the word a little -->
<!-- 	  differently &mdash; just as we each laugh at different jokes. Now I -->
<!-- 	  do not mean to hint that the problem is unreal, or even that it is -->
<!-- 	  especially incomprehensible. I only want to suggest -->
<!-- 	  that <em>humor</em> may be less a Thing-Part of the mind, and more a -->
<!-- 	  Thing-Theory in the mind. This makes it no less worthy of study, but -->
<!-- 	  one must be clear about what one is doing. If we get confused -->
<!-- 	  between making theories about theories and making theories about -->
<!-- 	  things, we may spin forever. {16} -->

<!-- 	<p> -->
<!-- 	  TIME CONSTANTS: According to our thesis, familiar types of jokes -->
<!-- 	  should seem less funny, because the censors have learned more about -->
<!-- 	  them. Why, then, do some kinds of jokes remain so persistently -->
<!-- 	  funny?  People tire of old nonsense jokes, but not of jokes about -->
<!-- 	  forbidden aspects of sex. Does this falsify our theory? Not -->
<!-- 	  necessarily; it may mean only that the censors for this particular -->
<!-- 	  subject are much slower to learn and to change. Is that plausible? -->

<!-- 	<p> -->
<!-- 	  Most psychological theories of our day &mdash; both popular and -->
<!-- 	  professional &mdash; seem to suppose that all memories are made of -->
<!-- 	  the same stuff, stored in the same huge container. (I argue -->
<!-- 	  otherwise in (6).) But, on reflection, we see that some memories -->
<!-- 	  ought to be less changeable than others. Contemplate, for example, -->
<!-- 	  the plight of a mother with a new infant, that will demand her time -->
<!-- 	  and attention for several years. Why doesn&#39;t she wonder <em>Why -->
<!--             am I doing this,</em> or <em>what could this baby do for me to -->
<!--             justify such a sacrifice.</em> One might argue <em>To preserve the -->
<!--             race,</em> or <em>because you will love it,</em> or <em>because it -->
<!--             will repay you some day,</em> but these would hardly convince any -->
<!-- 	  rational person; raising a child is not, let&#39;s face it, a -->
<!-- 	  notably sensible enterprise. -->

<!-- 	<p> -->
<!-- 	  Conventional wisdom recognizes that love is far from rational, and -->
<!-- 	  holds that an <em>instinctive</em> attachment is somehow created and -->
<!-- 	  somehow protected from casual alteration. Clearly so, but we must -->
<!-- 	  know more about those somehow&#39;s. This maternal self-questioning -->
<!-- 	  doesn&#39;t usually go too far, perhaps because we are protected by -->
<!-- 	  the web of personal pleasure and social compulsion surrounding -->
<!-- 	  child- rearing. But the problem is real, and there are occasional -->
<!-- 	  (and invariably concealed) tragedies in which a young mother&#39;s -->
<!-- 	  frustration overwhelms her attachment. -->

<!-- 	<p> -->
<!-- 	  The simplest way might be to build attachment into a special kind of -->
<!-- 	  memory that, once established, tends to persist for several years. -->
<!-- 	  After all, long time-constants characterize other aspects of -->
<!-- 	  attachment. Some persons always choose different partners of similar -->
<!-- 	  appearance; as though unable to alter a fixed stereotype.  Others -->
<!-- 	  find themselves in the grip of undesired infatuations, that reason -->
<!-- 	  declares inappropriate. And most familiar is the seemingly -->
<!-- 	  inexorable time-span of mourning &mdash; the year or two it takes to -->
<!-- 	  adjust to separation or loss. All these could be by-products of -->
<!-- 	  adaptations of older mechanisms whose slowness was/is of value in -->
<!-- 	  our sociobiological evolution. {17} -->

<!-- 	<p> -->
<!-- 	  Perhaps one can also interpret in this light the prolonged, -->
<!-- 	  mourning-like depression associated with sexual assault, presuming -->
<!-- 	  that the momentary association of violence with sexuality somehow -->
<!-- 	  impairs the entire attachment machinery. The large time-constants -->
<!-- 	  make recovery slow, from a profound disturbance of normal social -->
<!-- 	  attachments. No matter if the victim manages to view the -->
<!-- 	  incident <em>rationally;</em> this does not auto- matically restore -->
<!-- 	  those sluggish mechanisms to their normal state, and one must suffer -->
<!-- 	  the prolonged functional deprivation of an important mind-part. -->

<!-- 	<p> -->
<!-- 	  All this suggests that the curious robustness of sexual humor may -->
<!-- 	  reflect only that the associated censors are among the <em>slow -->
<!--             learners</em> of the mind, like retarded children. Perhaps they -->
<!-- 	  indeed are retarded children &mdash; the early static remnants of -->
<!-- 	  our own early selves. They change only slowly, and our tireless -->
<!-- 	  enjoyment of certain censured subjects may be a side-effect of that -->
<!-- 	  circumstance. -->

<!-- 	<p> -->
<!-- 	  So, we finally conclude: jokes are not really funny at all, but -->
<!-- 	  reflect the most serious of concerns; the pursuit of sobriety -->
<!-- 	  through the suppression of the absurd.  Cambridge, Mass.  May-July, -->
<!-- 	  1980 -->

<!-- 	<p> -->
<!-- 	  NOTES -->

<!-- 	<p> -->
<!-- 	  [NOTE] Freud seemed somewhat puzzled by <em>nonsense jokes</em> and -->
<!-- 	  suggested, to explain the worst of them, that they <em>give the -->
<!--             teller the pleasure of misleading and annoying, by rousing the -->
<!--             expectation of a joke and then frustrating the listener</em> &mdash; -->
<!-- 	  who in turn &mdash; <em>damps down his annoyance by determining to -->
<!--             tell them himself later on.</em> The enjoyment of nonsense, he goes -->
<!-- 	  on, might also reflect a wish to return to a childhood of relaxed, -->
<!-- 	  careless thought in which one <em>puts words together without regard -->
<!--             to the condition that they should make sense, in order to obtain -->
<!--             from them the pleasurable effect of rhythm or rhyme. Little by -->
<!--             little he is forbidden this enjoyment, till all that remains to him -->
<!--             are significant combinations of words. But when he is older attempts -->
<!--             still emerge at disregarding the restrictions that have been -->
<!--             learned</em> (p. 125). In connection with alcoholic cheerfulness, -->
<!-- 	  Freud recounts a pun: <em>It is most instructive to observe how -->
<!--             standards of joking sink as spirits rise</em> &mdash; and later -->
<!-- 	  &mdash; <em>the grown man becomes a child, who finds pleasure in -->
<!--             having the course of this thoughts freely at his disposal without -->
<!--             paying regard to the compulsion of logic</em> (p. 127). (1905) -->

<!-- 	<p> -->
<!-- 	  Freud&#39;s later image of childhood was different, with more -->
<!-- 	  emphasis on fears, frustrations, and the oppression of a growing -->
<!-- 	  self-image that emerges from internal models of authority and -->
<!-- 	  attachment figures. In the present essay&#39;s conception of the -->
<!-- 	  growth of logic in the child, I suggest a comparable self-image of -->
<!-- 	  Rationality &mdash; only here with less need for an external human -->
<!-- 	  model, because confusion automatically imposes its own sanctions. -->

<!-- 	<p> -->
<!-- 	  It was not quite accurate to say that Freud never returned to the -->
<!-- 	  subject, for in 1927 (9) he published a brief essay in which, still -->
<!-- 	  regarding jokes as a source of pleasure, he now portrays humor (in -->
<!-- 	  contrast) as a way to ward off suffering. The super-ego, like a -->
<!-- 	  parent, comforts the frightened childlike ego, repudiating reality -->
<!-- 	  by suggesting that however dangerous the world may seem, it is -->
<!-- 	  nothing but a game for children. Freud is troubled, though, that -->
<!-- 	  this seems out of character for the superego; perhaps the thesis of -->
<!-- 	  this essay resolves that. In any case, all this impinges on the area -->
<!-- 	  of <em>adult theory</em> that I hesitate to discuss here, for the -->
<!-- 	  reasons noted in {16}. -->

<!-- 	<p> -->
<!-- 	  [NOTE 1] The Society of Mind. Some of the ideas in this essay -->
<!-- 	  originated in my earlier work with Seymour Papert, especially the -->
<!-- 	  ideas about the construction of the mind through exploitation of -->
<!-- 	  different agencies by one another. The present paper, along with -->
<!-- 	  (4), (5), (6). and (12) are all related, but I have yet to attempt a -->
<!-- 	  single, comprehensive account. The key idea is to reject the -->
<!-- 	  conventional view of the mind as a Single Agent that either thinks -->
<!-- 	  of something or doesn&#39;t; rather, the mind is composed of many -->
<!-- 	  smaller minds, themselves composed of yet smaller ones. It would -->
<!-- 	  mean little to talk about what these separately <em>think,</em> for -->
<!-- 	  each becomes specialized to perform functions meaningful only -->
<!-- 	  vis--vis those few others that it has connections with. The -->
<!-- 	  phenomenological observations that a -->
<!-- 	  <em>person</em> makes about himself emerge in a very indirect way -->
<!-- 	  from those interactions. -->

<!-- 	<p> -->
<!-- 	  One (of many) reasons to consider decentralized psychological -->
<!-- 	  theories is that they seem potentially better able to provide for -->
<!-- 	  mechanisms that exploit knowledge about knowledge than do the -->
<!-- 	  control structures that have become traditional in the literatures -->
<!-- 	  of AI and of Cognitive Psychology. It is perfectly understandable -->
<!-- 	  that the early years of the <em>Information Processing Approach</em> -->
<!-- 	  should have focussed on the astonishing power of the newly-invented -->
<!-- 	  single-process serial computer. But <em>meta-knowledge</em> is not -->
<!-- 	  easily accommodated by such machines, and I see the strain showing -->
<!-- 	  in attempts to realize more ambitious ideas about intelligent -->
<!-- 	  learning &mdash; viz, that in (10), 11). -->

<!-- 	<p> -->
<!-- 	  [NOTE 2] Partial Mental state. I don&#39;t mean to suggest that the -->
<!-- 	  entire brain ever repeats the some global state. One could say but -->
<!-- 	  little about <em>mental states</em> if one imagined the Mind to be a -->
<!-- 	  single, unitary thing. But if we envision a mind (or brain) as -->
<!-- 	  composed of many partially autonomous <em>agents,</em> then we can -->
<!-- 	  talk of repeating a <em>partial mental state</em> &mdash; that is, a -->
<!-- 	  subset of the states of those agents. This is discussed more -->
<!-- 	  precisely in (6). The notion of partial mental state allows one to -->
<!-- 	  speak of entertaining several partial states at once &mdash; to the -->
<!-- 	  extent they are compatible &mdash; that is, they do not assign -->
<!-- 	  different states to the same individual agents. And even when they -->
<!-- 	  conflict, the concept still has meaning if such conflicts can be -->
<!-- 	  settled within the Society. In (6) I argue that such local -->
<!-- 	  mechanisms for conflict resolution could be the antecedents of what -->
<!-- 	  we know later as reasoning &mdash; useful ways to combine different -->
<!-- 	  fragments of knowledge. -->

<!-- 	<p> -->
<!-- 	  [NOTE 3] Consciousness. As I see it, <em>consciousness</em> -->
<!-- 	  phenomena can emerge from the operation of a <em>self-referent</em> -->
<!-- 	  mechanism when it tries to account for some of what it itself is -->
<!-- 	  doing. I doubt we possess any especially direct and powerful ways to -->
<!-- 	  do this, so we probably do it much as we understand anything else -->
<!-- 	  &mdash; that is, by making and refining models that may never be -->
<!-- 	  particularly accurate.  Technically, discussing such matters is -->
<!-- 	  messy because of the web of different meanings -->
<!-- 	  for <em>self-reference</em> itself. Should we call a system -->
<!-- 	  self-referent just because it operates on data derived from its own -->
<!-- 	  operation? It might be considered so if it can be seen as trying to -->
<!-- 	  describe itself. The self-reference of planning &mdash; as when one -->
<!-- 	  says <em>I shall do X</em> &mdash; is different from simply -->
<!-- 	  expecting to do X, because it entails (usually) subsidiary plans -->
<!-- 	  like <em>I shall remain firm and not allow Y to cause me to -->
<!--             &lsquo;change my mind.&rsquo; </em> Should we call a system -->
<!-- 	  self-referent when, only by accident, a structure inside it happens -->
<!-- 	  to resemble (in an outside observer&#39;s opinion) a larger-scale -->
<!-- 	  description of itself? In any case it seems quite clear that our -->
<!-- 	  psychological self-models are far from technically accurate &mdash; -->
<!-- 	  yet serve a variety of social-heuristic-survival needs. In (12) I -->
<!-- 	  discussed how models that are technically quite wrong can still be -->
<!-- 	  useful; in particular it suggests an explanation of the illusion of -->
<!-- 	  free will. -->

<!-- 	<p> -->
<!-- 	  In general, I see little reason to suppose that -->
<!-- 	  the <em>conscious</em> parts of our minds have any direct access to -->
<!-- 	  our own <em>top-level goals</em> &mdash; or even to suppose that any -->
<!-- 	  such <em>top level</em> exists, i.e. that the mental society has a -->
<!-- 	  strict hierarchy. Even if there were, Evolution probably would have -->
<!-- 	  found a way to block the rest of the mind from being able to examine -->
<!-- 	  it too closely &mdash; if only to keep the logical bull out of the -->
<!-- 	  teleological china shop. {10} In any case I suspect that if there is -->
<!-- 	  a top-level it consists of agencies access to which would reveal -->
<!-- 	  nothing intelligible (for reasons described in {12}). In (5) I -->
<!-- 	  discuss some possible mechanisms that might be -->
<!-- 	  <em>central</em> in thinking, because their use would be as limited, -->
<!-- 	  scarce resources. These might indeed play roles in our articulate, -->
<!-- 	  self-model formulations but, again, those models could be very -->
<!-- 	  unrealistic. -->

<!-- 	<p> -->
<!-- 	  [NOTE 4] Non-monotonic logic. I discussed these problems with logic -->
<!-- 	  very briefly in (4). Doyle&#39;s 1980 thesis (11) has a very -->
<!-- 	  imaginative discussion of such matters. One might ask whether the -->
<!-- 	  safe regions are like separate islands, or is logic generally safe -->
<!-- 	  if we avoid scattered pitfalls. -->

<!-- 	<p> -->
<!-- 	  [NOTE 5] Confusion. When a person can say <em>I&#39;m confused,</em> -->
<!-- 	  he is a large step beyond merely being confused because, presumably, -->
<!-- 	  he has gone on enough to have recognized a somewhat specific -->
<!-- 	  metapsychological condition. -->

<!-- 	<p> -->
<!-- 	  [NOTE 6] Familiar. Schank (13) points out that it is only when one -->
<!-- 	  doesn&#39;t quite</em> recognize something that one thinks <em>that -->
<!-- 	looks familiar.</em> When something is decisively recognized there -->
<!--       is no such phenomenology; one notices the matching process only when -->
<!--       the match is imperfect and strained.</p> -->

<!--     <p> -->
<!--       [NOTE 7] Ambiguity. All but the most childish jokes have two or more -->
<!--       meanings <em>condensed</em> into one expression or situation. It is -->
<!--       commonplace to wonder about non-humorous ambiguities of words and -->
<!--       phrases, and how the mind decides which thought is intended. It is not -->
<!--       so often realized that thoughts themselves can be ambiguous &mdash; -->
<!--       because a (partial) mental state can be a precursor of many others, -->
<!--       depending on the computational context within the mind. (5)</p> -->

<!--     <p> -->
<!--       [NOTE 8] Excuses. This is oversimplified in many ways. Defaults are not -->
<!--       mere conveniences; they are perhaps our most powerful means for making -->
<!--       generalizations, because they activate whatever is -->
<!--       <em>typical</em> of some class by activating the memory of a typical -->
<!--       individual of that class. And even when they are not useful, such -->
<!--       assumptions are usually innocuous &mdash; provided that they are weakly -->
<!--       enough attached so that they are easily displaced by <em>reality.</em> -->
<!--       However, this hypothetical default mechanism has many potential bugs of -->
<!--       its own. In particular, one must not make mistakes about -->
<!--       <em>supported-by</em> for all sorts of personal safety reasons. If there -->
<!--       is no visible support and no intervening object then this is a -->
<!--       levitation absurdity.</p> -->

<!--     <p> -->
<!--       I suspect that ethnic humor exemplifies a larger-scale sociobiological -->
<!--       bug that emerges from the frame mechanism. Why are nonsense jokes are so -->
<!--       often used also to deride alien social groups? A popular theory is that -->
<!--       it provides an opportunity to display aggression, and no doubt this is -->
<!--       true. But there may also be a more technical reason. I argue in (4) that -->
<!--       it is hard to understand a story about a person unless one is provided -->
<!--       with a specific person-frame &mdash; it does not matter how -->
<!--       stereotyped. Communication is simplified when the listener does not have -->
<!--       to choose a frame for himself. Thus bigotry may emerge spontaneously as -->
<!--       a side-effect of this circumstance of representation; when, for example -->
<!--       one makes a joke about stupidity, it is psycho-computationally -->
<!--       convenient to project it onto some stereotype &mdash; preferably alien -->
<!--       to avoid conflict with known reality.  Obviously, this may become a -->
<!--       runaway process, as that stereotype accumulates undeserved -->
<!--       absurdities. Sooner or later one loses track of the humorous origin of -->
<!--       that structure. It will be hard to eradicate prejudice without -->
<!--       understanding the importance (and value) of stereotypes in ordinary -->
<!--       thinking.</p> -->

<!--     <p> -->
<!--       [NOTE 9] Many of the ideas about the importance of discerning -->
<!--       differences came as early as (14) and (5), but (8) had the first clear -->
<!--       idea of a difference-network. More recently, in (16) Winston has -->
<!--       considered using frames for more complex analogies. The serious study -->
<!--       of <em>bugs</em> was perhaps first considered in the work of Papert on -->
<!--       early education (17) and then in the doctoral theses of Sussman (18) and -->
<!--       Goldstein (19).</p> -->

<!--     <p> -->
<!--       [NOTE 10] Defense. Lewis Thomas remarks in (20) that philosophers and -->
<!--       linguists <em>are compelled to use as their sole research instrument the -->
<!-- 	very apparatus they wish to study.</em> He recounts that, while -->
<!--       listening to a proof of Godel&#39;s theorem: <em>just as I was taking it -->
<!-- 	all in, I suddenly felt something like the flicking of a mercury wall -->
<!-- 	switch and it all turned to nonsense in my head</em> and suggests -->
<!--       &mdash; presuming one can tell when this scientist-poet is serious -->
<!--       &mdash; that there is a <em>scrambler in the brain, a protective device -->
<!-- 	preserving the delicate center of the mechanism of language against -->
<!-- 	tinkering and meddling, shielding the mind against information with -->
<!-- 	which it has no intention of getting involved.</em> Perhaps he&#39;s -->
<!--       right.</p> -->

<!--     <p> -->
<!--       [NOTE 11] Spinach. A reader mentioned that she heard this joke about -->
<!--       broccoli, not mayonnaise. This is funnier, because it transfers a -->
<!--       plausible mistake into an implausible context. In Freud&#39;s version -->
<!--       the mistake is already too silly: one could mistake spinach for -->
<!--       broccoli, but not for mayonnaise. I suspect that Freud transposed the -->
<!--       wrong absurdity when he determined to tell it himself later on.  Indeed, -->
<!--       he (p.139) seems particularly annoyed at this joke &mdash; and well he -->
<!--       might be if, indeed, he himself damaged it by spoiling the elegance of -->
<!--       the frame-shift. I would not mention this were it not for the -->
<!--       established tradition of advancing psychiatry by analyzing Freud&#39;s -->
<!--       own writings.</p> -->

<!--     <p> -->
<!--       [NOTE 12] Enjoyment. As Freud demanded, we have to explain why humor is -->
<!--       pleasant, yet is so often about unpleasant &mdash; painful, disgusting, -->
<!--       or forbidden matters. There is nothing really funny about most good -->
<!--       jokes &mdash; except perhaps in the skill with which the content is -->
<!--       disguised.  Now, there is no shortage of explanations of how this -->
<!--       reversal of sign might come about: the censor-energy theory, -->
<!--       the <em>I&#39;m glad it didn&#39;t happen to me</em> theory, the -->
<!--       minimizing the importance of reality theory, and so forth. Yet the -->
<!--       question remains all the more important and difficult because, everyone -->
<!--       supposing the matter to be obvious, no one seems to have proposed any -->
<!--       sophisticated theories of pleasure itself &mdash; so all those -->
<!--       commonsense <em>mini-theories</em> seem built on sand.</p> -->

<!--     <p> -->
<!--       What is pleasure, and why do we like it? It is not a tautology.  Clearly -->
<!--       pleasure involves a complex web concerned with: learning and goals; with -->
<!--       activities one wants to continue and/or repeat; and with anticipations -->
<!--       and rehearsals of such. What makes the issue elusive, I think, is that -->
<!--       we <em>sense</em> pleasure only through an elaborately constructed -->
<!--       illusion &mdash; typical of our tendency to represent things to -->
<!--       ourselves as though they were more coherent than they really are.</p> -->

<!--     <p> -->
<!--       We indulge in such illusions even when we say the seemingly simplest -->
<!--       things of the form <em>I feel xxx.</em> These exemplify a <em>single -->
<!-- 	agent</em> concept of mind, an illusion of coherency that denies that -->
<!--       within the mind different agencies play different roles at the same -->
<!--       moment. For example, one part may be rewarded for disciplining -->
<!--       another. Yet if, as I suppose, the pleasure phenomenon does indeed -->
<!--       involve a complex web of different activities, we still need to explain -->
<!--       why they seem phenomenologically to have so much in common. Here is one -->
<!--       conjecture: what was initially common to all those activities was only a -->
<!--       metapsychological feature &mdash; they were just the ones most subject -->
<!--       to being disturbed by the <em>noise</em> of other members of the Society -->
<!--       of Mind.</p> -->

<!--     <p> -->
<!--       This would create an ecological niche, within that Society, for the -->
<!--       emergence of a special brain center that, when activated by any of them, -->
<!--       tends to depress all the others. (One does not so welcome the offer of -->
<!--       one kind of pleasure, while involved with another.) Once such a center -->
<!--       comes into existence, that very fact would facilitate the formation, in -->
<!--       a growing mind, of a concept or belief in the commonality of the -->
<!--       mechanisms associated with it.</p> -->

<!--     <p> -->
<!--       A second conjecture: such a centralization would better enable each -->
<!--       member of the mental society to be able to tell when it has done -->
<!--       something to satisfy a need of another &mdash; without having to -->
<!--       understand which one, or any of the what or why of it. But note how my -->
<!--       use of the word <em>satisfy</em> betrays my intention by intimating that -->
<!--       same unintended uniformity. It is perhaps this betrayal that fools us -->
<!--       all into thinking it a tautology, unworthy of study, to ask <em>why do -->
<!-- 	we like pleasure.</em>  Seymour Papert has suggested to me yet another, -->
<!--       more sociobiological conjecture about how evolution might have gathered -->
<!--       these ingredients together and provded them with a single, common -->
<!--       output. It would make it easier for a mother to tell when she has -->
<!--       satisfied her child&#39;s need of the moment, without having to learn -->
<!--       specific signs for each such need. Similarly, this would help one person -->
<!--       tell when he is convincing another, and so forth. All that is -->
<!--       accomplished by attaching a suitable collection of different internal -->
<!--       processes to one single <em>consummatory act</em> &mdash; to use -->
<!--       Tinbergen&#39;s term.</p> -->

<!--     <p> -->
<!--       [NOTE 13] My daughter Julie watched <em>yields truth</em> for a while -->
<!--       and then said, <em>well, it&#39;s not exactly a paradox, but it does -->
<!-- 	keep saying that it&#39;s true, back and forth.</em></p> -->

<!--     <p> -->
<!--       [NOTE 14] Displacement. Lorenz (21) and Tinbergen (22) frequently -->
<!--       observed peculiar, seemingly pointless behaviors when an animal is -->
<!--       poised between fight and flight. What better time to consider -->
<!--       negotiating? So, one might a priori expect to find ambiguities in the -->
<!--       primordial germs of social sign-systems.</p> -->

<!--     <p> -->
<!--       [NOTE 15] I don&#39;t mean all this to seem pessimistic. It is not -->
<!--       necessary, in understanding something, to have all one knows about it -->
<!--       active in the mind at one time. One does need to have access to -->
<!--       fragments of maps, at various levels of detail, of what one knows.  The -->
<!--       thesis of Kuipers (23), which proposes a theory of how a person&#39;s -->
<!--       knowledge of a city might be represented in computational terms, might -->
<!--       be re-interpreted as a metaphor for how minds might deal with their own -->
<!--       knowledge.</p> -->

<!--     <p> -->
<!--       [NOTE 16] Theories. There is, I think, a special problem in making -->
<!--       theories about the psychology of adults, in whom cultural evolution has -->
<!--       had its full interaction with individual and organic evolution. Consider -->
<!--       that complex of laughing, smiling, good-natured interactions -->
<!--       called <em>good humor,</em> in which we as often enjoy engaging and -->
<!--       surprising frame-shifts of high quality as we enjoy nonsense worthy only -->
<!--       of being suppressed. The joking ambiance is used as much to develop -->
<!--       analogies as to restrict them &mdash; and my distinction between -->
<!--       positive and negative seems to fall apart. If anything remains uniform -->
<!--       in the different varieties of humor, it is perhaps only that -->
<!--       highlighting of manipulating unexpected frame-shifts &mdash; but in a -->
<!--       bewildering variety of ways. Does this mean the theory is refuted? I -->
<!--       think not, but to explain why I must digress to discuss <em>adult -->
<!-- 	development.</em></p> -->

<!--     <p> -->
<!--       No, a baby theory is not necessarily refuted by an adult counterexample. -->
<!--       Most psychologists have not sufficiently appreciated the full power of -->
<!--       an adult intellect to re-construct itself &mdash; to exploit and -->
<!--       rearrange its earlier components. Stage after stage of intricate -->
<!--       developments are superimposed, in which both internal and cultural -->
<!--       influences modify earlier ones. This process would be complicated enough -->
<!--       if it were spontaneous &mdash; that is, if only internal factors were -->
<!--       involved.  But much of it is also socially institutionalized; everyone -->
<!--       in the culture <em>knows</em> which concerns, and which manners of -->
<!--       behavior, are -->
<!--       <em>appropriate</em> for four-year-olds, nine-year-olds, college -->
<!--       students, or professors of philosophy.</p> -->

<!--     <p> -->
<!--       The most powerful theoreticians of developmental psychology have -->
<!--       struggled to untangle the different principles and forms of these -->
<!--       influences; still only the surface has been touched. We yet know far too -->
<!--       little to confidently declare that such-and-such a behavioral exhibition -->
<!--       either illustrates or refutes a given psychogenetic hypothesis. In my -->
<!--       view, the most profitable activity in the present era is to experiment, -->
<!--       not on people to see if an hypothesis about the mind is true or false, -->
<!--       but on computers to see if a proposed theory-fragment can be made part -->
<!--       of a system that shows mind-like activity. To be sure, this can never -->
<!--       show, by itself, that the theory in question then must resemble a human -->
<!--       mechanism &mdash; but it seems hardly worth trying to verify that until -->
<!--       a theory shows signs of meeting a first condition &mdash; that it be -->
<!--       capable of contributing to life-like activity. In short, we are unlikely -->
<!--       to discover much of that which is, until we discover more of that which -->
<!--       could be.</p> -->

<!--     <p> -->
<!--       [NOTE 17] Attachment. Of course, the sociobiology of reproduction is far -->
<!--       more complicated than suggested here. Provisions for child-raising -->
<!--       conflict in many ways with provisions for gene-dissemination. Many -->
<!--       different sociobiological islands of stability exist, both potentially -->
<!--       and actually.</p> -->

<!--     <p> -->
<!--       An <em>acquisition envelope</em> hypothesis: Here is a different example -->
<!--       of how both individual and social development might be influenced by a -->
<!--       genetic control of a learning-rate. It is a commonplace observation that -->
<!--       persons who learn second languages after adolescence rarely acquire the -->
<!--       phonetic competence of native speakers; they rarely come to speak the -->
<!--       new language <em>without an accent.</em> When told to pronounce -->
<!--       something <em>like this, not like that,</em> they seem to sense too -->
<!--       little difference to know what changes to make. I conjecture that this -->
<!--       reflects a post-pubertal change in a brain mechanism &mdash; and may -->
<!--       illustrate an important way for genetic control to affect cognitive -->
<!--       development.</p> -->

<!--     <p> -->
<!--       More precisely, the conjecture is that (i) phonetic learning occurs in -->
<!--       some particular brain structure whose capacity to learn new -->
<!--       discriminations is (ii) shut off by a genetic mechanism linked to -->
<!--       pubertal changes. It is linked to puberty because that is the biological -->
<!--       moment when one&#39;s role shifts from learning to teaching . -->
<!--       Its <em>evolutionary purpose</em> is to prevent the parent from learning -->
<!--       the child&#39;s language; this makes the child learn the adult language.</p> -->

<!--     <p> -->
<!--       After all, a young parent&#39;s principal goal is not language -->
<!--       instruction &mdash; it is communication. If it were easy for the parent -->
<!--       to adopt the child&#39;s idiosyncratic phonology, that&#39;s what would -->
<!--       happen! But then the parent would learn the child&#39;s language &mdash; -->
<!--       and the child would have less drive, or opportunity, to learn the -->
<!--       adult&#39;s. And, over the span of generations, it would be hard for any -->
<!--       common social language to develop at all!</p> -->

<!--     <p> -->
<!--       When we talk of innate vs. acquired aspects of development, we must face -->
<!--       the problem of encoding for structures whose acquisition cannot be -->
<!--       genetically anticipated &mdash; e.g., details of cognitive or linguistic -->
<!--       structure. Our idea is first to look instead for ways for genetics to -->
<!--       affect directly the <em>acquisition envelopes</em> &mdash; the control -->
<!--       structures that mediate how things are learned. The foregoing hypothesis -->
<!--       illustrates, I think, one way that brain genetics might circumvent the -->
<!--       complexity of devising direct constraints on the representations of -->
<!--       not-yet-acquired cognitive structures.</p> -->

<!--     <p> -->
<!--       REFERENCES</p> -->

<!--     <p> -->
<!--       (0) Sigmund Freud, Jokes and their relation to the Unconscious, 1905, -->
<!--       (transl. Strachey) Standard Edition, vol. 8, Hogarth Press, 1957.</p> -->

<!--     <p> -->
<!--       (1) Jon Doyle, Truth Maintenance Systems for Problem Solving, MIT AI -->
<!--       Lab. Technical Report TR-419, Jan. 1978.</p> -->

<!--     <p> -->
<!--       (2) William A. Kornfeld, Using Parallel Processes for Problem Solving,</p> -->

<!--     <p> -->
<!--       MIT Artificial Intelligence Memo 561, Dec. 1979.</p> -->

<!--     <p> -->
<!--       (3) Alfred Korzybski, Science and Sanity, Science Press, Lancaster -->
<!--       Penn., 1941.</p> -->

<!--     <p> -->
<!--       (4a) Marvin Minsky,<em>A Framework for Representing Knowledge,</em> -->
<!--       Artificial Intelligence Memo No. 306, MIT, AI Lab., June, 1974.</p> -->

<!--     <p> -->
<!--       (4b) Marvin Minsky, <em>A Framework for Representing Knowledge,</em> -->
<!--       condensed version, in The Psychology of Computer Vision, Winston (ed.), -->
<!--       Mcgraw-Hill, 1975.</p> -->

<!--     <p> -->
<!--       (5) Marvin Minsky, <em>Plain Talk About Neurodevelopmental -->
<!-- 	Epistemology,</em> Proceedings of the Fifth International Joint -->
<!--       Conference on Artificial Intelligence, Cambridge, Massachusetts, -->
<!--       August, 1977. Condensed version in Winston and Brown (eds.), -->
<!--       Artificial Intelligence, vol. 1, MIT Press, 1979.</p> -->

<!--     <p> -->
<!--       (6) Marvin,Minsky, <em>K-lines: a Theory of Memory,</em> Cognitive -->
<!--       Science, vol. 4, no. 2, April 1980, pp.117-133.</p> -->

<!--     <p> -->
<!--       (7) L. Wittgenstein, Philosophical Investigations, Oxford 1953.</p> -->

<!--     <p> -->
<!--       (8) Winston, P. H., <em>Learning Structural Descriptions by -->
<!-- 	Examples,</em> in Psychology of Computer Vision, (P.H. Winston, Ed.) -->
<!--       McGraw-Hill, 1975.</p> -->

<!--     <p> -->
<!--       (9) Sigmund Freud, <em>Humour,</em> 1927, (transl. Strachey) Standard -->
<!--       Edition, vol. 21, Hogarth Press, 1957, pp.161-166.</p> -->

<!--     <p> -->
<!--       (10) Randy Davis, <em>Meta-rules: reasoning about control,</em> to -->
<!--       appear in Artificial Intelligence, 1981.</p> -->

<!--     <p> -->
<!--       (11) Jon Doyle, A Model for Deliberation, Action, and Introspection, MIT -->
<!--       Ph.D. Thesis, MIT Artificial Intelligence Laboratory, August 1980.</p> -->

    

<!-- <\!-- <p> -\-> -->
<!-- <\!--       (12) Marvin Minsky, <em>Matter, Mind and Models,</em> Proceedings of -\-> -->
<!-- <\!--       IFIP Congress 1965, May, 1965, pp. 45-49. Reprinted in Semantic -\-> -->
<!-- <\!--       Information Processing, MIT Press, 1968.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (13) Roger Schank, <em>Language and Memory,</em> in Cognitive Science, -\-> -->
<!-- <\!--       1980.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (14) A. Newell, J.C.Shaw and H.A.Simon, Preliminary Description of the -\-> -->
<!-- <\!--       General Problem Solving Program (GPS-1), CIP Working Paper no.  7, -\-> -->
<!-- <\!--       Dec. 1957.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (15) Marvin Minsky, Heuristic Aspects of the Artificial Intelligence -\-> -->
<!-- <\!--       Problem, Lincoln Laboratory, M.I.T., Lexington, Mass., Group Rept. -\-> -->
<!-- <\!--       No. 34-55, ASTIA Doc. No. AS 236885; December, 1956.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (16) Patrick H. Winston, Learning by Understanding Analogies, MIT-AI -\-> -->
<!-- <\!--       memo 520, June 1979.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (17) Seymour Papert, Mindstorms. Children, Computers and Powerful Ideas, -\-> -->
<!-- <\!--       New York, Basic Books, 1980.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (18) Gerald J. Sussman, A Computational Model of Skill Acquisition, MIT -\-> -->
<!-- <\!--       Ph.D. Thesis, MIT Artificial Intelligence Laboratory Technical Report -\-> -->
<!-- <\!--       TR-297, August 1973.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (19) Ira P. Goldstein, Understanding Simple Picture Programs, MIT -\-> -->
<!-- <\!--       Ph.D. Thesis, MIT Artificial Intelligence Laboratory Technical Report -\-> -->
<!-- <\!--       TR-294, April 1974.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (20) Lewis Thomas, <em>The Scrambler in the Mind,</em> in The Medusa and -\-> -->
<!-- <\!--       the Snail, Bantam, 1980.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (21) Konrad Lorenz, King Solomon&#39;s Ring,Thomas Y. Crowell, N.Y., -\-> -->
<!-- <\!--       1961.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (22) Niko Tinbergen, The Study of Instinct, Oxford University Press, -\-> -->
<!-- <\!--       1951.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (23) Benjamin Kuipers, Representing Knowledge of Large-Scale Space, MIT -\-> -->
<!-- <\!--       Ph.D. Thesis, July 1978, MIT Artificial Intelligence Laboratory -\-> -->
<!-- <\!--       Technical Report TR-418</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       ACKNOWLEDGMENTS I thank Howard Cannon, Danny Hillis, William Kornfeld, -\-> -->
<!-- <\!--       David Levitt, Gloria Rudisch, and Richard Stallman for suggestions. -\-> -->
<!-- <\!--       Gosrdon Oro provided the dog-joke.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Computer Music Journal Volume 5, Number 3, Fall 1981</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       MUSIC, MIND AND MEANING This is a revised and updated version of -\-> -->
<!-- <\!--       A.1. Memo No. 616. (An earlier version appears in Music, Mind, and -\-> -->
<!-- <\!--       Brain: The Neuropsychology of Music edited by Manfred Clynes, and -\-> -->
<!-- <\!--       republished by Plenum, New York, 1981 by Marvin Minsky)</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Marvin Minsky Artificial Intelligence Laboratory, MIT Why Do We Like -\-> -->
<!-- <\!--       Music?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Why do we like music? Our culture immerses us in it for hours each day, -\-> -->
<!-- <\!--       and everyone knows how it touches our emotions, but few think of how -\-> -->
<!-- <\!--       music touches other kinds of thought. It is astonishing how little -\-> -->
<!-- <\!--       curiosity we have about so pervasive an <em>environ-mental</em> -\-> -->
<!-- <\!--       influence.  What might we discover if we were to study musical thinking? -\-> -->
<!-- <\!--       Have we the tools for such work? Years ago, when science still feared -\-> -->
<!-- <\!--       meaning, the new field of research called artificial intelligence (AI) -\-> -->
<!-- <\!--       started to supply new ideas about <em>representation of knowledge</em> -\-> -->
<!-- <\!--       that I&#39;ll use here. Are such ideas too alien for anything so -\-> -->
<!-- <\!--       subjective and irrational, aesthetic, and emotional as music? Not at -\-> -->
<!-- <\!--       all. I think the problems are the same and those distinctions wrongly -\-> -->
<!-- <\!--       drawn: only the surface of reason is rational. I don&#39;t mean that -\-> -->
<!-- <\!--       understanding emotion is easy, only that understanding reason is -\-> -->
<!-- <\!--       probably harder. Our culture has a universal myth in which we see -\-> -->
<!-- <\!--       emotion as more complex and obscure than intellect. Indeed, emotion -\-> -->
<!-- <\!--       might be <em>deeper</em> in some sense of prior evolution, but this need -\-> -->
<!-- <\!--       not make it harder to understand; in fact, I think today we actually -\-> -->
<!-- <\!--       know much more about emotion than about reason.  Certainly we know a bit -\-> -->
<!-- <\!--       about the obvious processes of reason &mdash; the ways we organize and -\-> -->
<!-- <\!--       represent ideas we get. But whence come those ideas that so conveniently -\-> -->
<!-- <\!--       fill these envelopes of order? A poverty of language shows how little -\-> -->
<!-- <\!--       this concerns us: we <em>get</em></p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       ideas; they <em>come</em> to us; we are <em>re-minded of</em> them. I -\-> -->
<!-- <\!--       think this shows that ideas come from processes obscured from us and -\-> -->
<!-- <\!--       with which our surface thoughts are almost uninvolved. Instead, we are -\-> -->
<!-- <\!--       entranced with our emotions, which are so easily observed in others and -\-> -->
<!-- <\!--       ourselves. Perhaps the myth persists because emotions (by their nature) -\-> -->
<!-- <\!--       draw attention, while the processes of reason (much more intricate and -\-> -->
<!-- <\!--       delicate) must be private and work best alone.  The old distinctions -\-> -->
<!-- <\!--       among emotion, reason, and aesthetics are like the earth, air, and fire -\-> -->
<!-- <\!--       of an ancient alchemy. We will need much better concepts than these for -\-> -->
<!-- <\!--       a working psychic chemistry.  Much of what we now know of the mind -\-> -->
<!-- <\!--       emerged in this century from other subjects once considered just as -\-> -->
<!-- <\!--       personal and inaccessible but which were explored, for example, by Freud -\-> -->
<!-- <\!--       in his work on adults&#39; dreams and jokes, and by Piaget in his work -\-> -->
<!-- <\!--       on children&#39;s thought and play. Why did such work have to wait for -\-> -->
<!-- <\!--       modern times? Before that, children seemed too childish and humor much -\-> -->
<!-- <\!--       too humorous for science to take them seriously.  Why do we like music? -\-> -->
<!-- <\!--       We all are reluctant, with regard to music and art, to examine our -\-> -->
<!-- <\!--       sources of pleasure or strength. In part we fear success itself &mdash; -\-> -->
<!-- <\!--       we fear that understanding might spoil enjoyment.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Rightly so: art often loses power when its psychological roots are -\-> -->
<!-- <\!--       exposed. No matter; when this happens we will go on, as always, to seek -\-> -->
<!-- <\!--       more robust illusions!  I feel that music theory has gotten stuck by -\-> -->
<!-- <\!--       trying too long to find universals. Of course, we would like to study -\-> -->
<!-- <\!--       Mozart&#39;s music the way scientists analyze the spectrum of a distant -\-> -->
<!-- <\!--       star. Indeed, we find some almost universal practices in every musical -\-> -->
<!-- <\!--       era. But we must view these with suspicion, for they might show no more -\-> -->
<!-- <\!--       than what composers then felt should be universal. If so, the search for -\-> -->
<!-- <\!--       truth in art becomes a travesty in which each era&#39;s practice only -\-> -->
<!-- <\!--       parodies its predecessor&#39;s prejudice. (Imagine -\-> -->
<!-- <\!--       formulating <em>laws</em> for television screenplays, taking them for -\-> -->
<!-- <\!--       natural phenomenon uninfluenced by custom or constraint of commerce.) -\-> -->
<!-- <\!--       The trouble with the search for universal laws of thought is that both -\-> -->
<!-- <\!--       memory and thinking interact and grow together. We do not just learn -\-> -->
<!-- <\!--       about things, we learn ways to think about things; then we learn to -\-> -->
<!-- <\!--       think about thinking itself. Before long, our ways of thinking become so -\-> -->
<!-- <\!--       complicated that we cannot expect to understand their details in terms -\-> -->
<!-- <\!--       of their surface operation, but we might understand the principles that -\-> -->
<!-- <\!--       guide their growth. In much of this article I will speculate about how -\-> -->
<!-- <\!--       listening to music engages the previously acquired personal knowledge of -\-> -->
<!-- <\!--       the listener.  It has become taboo for music theorists to ask why we -\-> -->
<!-- <\!--       like what we like: our seekers have forgotten what they are searching -\-> -->
<!-- <\!--       for. To be sure, we can&#39;t account for tastes, in general, because -\-> -->
<!-- <\!--       people have various preferences. But this means only that we have to -\-> -->
<!-- <\!--       find the causes of this diversity of tastes, and this in turn means we -\-> -->
<!-- <\!--       must see that music theory is not only about music, but about how people -\-> -->
<!-- <\!--       process it. To understand any art, we must look below its surface into -\-> -->
<!-- <\!--       the psychological details of its creation and absorption.  If explaining -\-> -->
<!-- <\!--       minds seems harder than explaining songs, we should remember that -\-> -->
<!-- <\!--       sometimes enlarging problems makes them simpler! The theory of the roots -\-> -->
<!-- <\!--       of equations seemed hard for centuries within its little world of real -\-> -->
<!-- <\!--       numbers, but it suddenly seemed simple once Gauss exposed the larger -\-> -->
<!-- <\!--       world of (so-called) complex numbers. Similarly, music should make more -\-> -->
<!-- <\!--       sense once seen through listeners&#39; minds.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Sonata as Teaching Machine Music makes things in our minds, but -\-> -->
<!-- <\!--       afterward most of them fade away. What remains? In one old story about -\-> -->
<!-- <\!--       Mozart, the wonder child hears a lengthy contrapuntal mass and then -\-> -->
<!-- <\!--       writes down the entire score. (I do not believe such tales, for history -\-> -->
<!-- <\!--       documents so few of them that they seem to be mere legend, though by -\-> -->
<!-- <\!--       that argument Mozart also would seem to be legend.) Most people do not -\-> -->
<!-- <\!--       even remember the themes of an evening&#39;s concert. Yet, when the -\-> -->
<!-- <\!--       tunes are played again, they are recognized. Something must remain in -\-> -->
<!-- <\!--       the mind to cause this, and perhaps what we learn is not the music -\-> -->
<!-- <\!--       itself but a way of hearing it.  Compare a sonata to a teacher. The -\-> -->
<!-- <\!--       teacher gets the pupils&#39; attention, either dramatically or by the -\-> -->
<!-- <\!--       quiet trick of speaking softly.  Next, the teacher presents the elements -\-> -->
<!-- <\!--       carefully, not introducing too many new ideas or developing them too -\-> -->
<!-- <\!--       far, for until the basics are learned the pupils cannot build on -\-> -->
<!-- <\!--       them. So, at first, the teacher repeats a lot. Sonatas, too, explain -\-> -->
<!-- <\!--       first one idea, then another, and then recapitulate it all. (Music has -\-> -->
<!-- <\!--       many forms and there are many ways to teach. I do not say that composers -\-> -->
<!-- <\!--       consciously intend to teach at all, yet they are masters at inventing -\-> -->
<!-- <\!--       forms for exposition, including those that swarm with more ideas and -\-> -->
<!-- <\!--       work our minds much harder.)</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Thus expositions show the basic stuff &mdash; the atoms of impending -\-> -->
<!-- <\!--       chemistries and how some simple compounds can be made from those -\-> -->
<!-- <\!--       atoms. Then, in developments, those now-familiar compounds, made from -\-> -->
<!-- <\!--       bits and threads of beat and tone, can clash or merge, contrast or join -\-> -->
<!-- <\!--       together. We find things that do not fit into familiar frameworks hard -\-> -->
<!-- <\!--       to understand &mdash; such things seem meaningless. I prefer to turn -\-> -->
<!-- <\!--       that around: a thing has meaning only after we have learned some ways to -\-> -->
<!-- <\!--       represent and process what it means, or to understand its parts and how -\-> -->
<!-- <\!--       they are put together.  What is the difference between merely knowing, -\-> -->
<!-- <\!--       (or remembering, or memorizing) and understanding? We all agree that to -\-> -->
<!-- <\!--       understand something, we must know what it means, and that is about as -\-> -->
<!-- <\!--       far as we ever get. I think I know why that happens. A thing or idea -\-> -->
<!-- <\!--       seems meaningful only when we have several different ways to represent -\-> -->
<!-- <\!--       it &mdash; different perspectives and different associations. Then we -\-> -->
<!-- <\!--       can turn it around in our minds, so to speak: however it seems at the -\-> -->
<!-- <\!--       moment, we can see it another way and we never come to a full stop. In -\-> -->
<!-- <\!--       other words, we can think about it. If there were only one way to -\-> -->
<!-- <\!--       represent this thing or idea, we would not call this representation -\-> -->
<!-- <\!--       thinking.  So something has a <em>meaning</em> only when it has a few; -\-> -->
<!-- <\!--       if we understood something just one way, we would not understand it at -\-> -->
<!-- <\!--       all. That is why the seekers of the <em>real</em> meanings never find -\-> -->
<!-- <\!--       them.  This holds true especially for words like understand. That is why -\-> -->
<!-- <\!--       sonatas start simply, as do the best of talks and texts. The basics are -\-> -->
<!-- <\!--       repeated several times before anything larger or more complex is -\-> -->
<!-- <\!--       presented. No one remembers word for word all that is said in a lecture -\-> -->
<!-- <\!--       or all notes that are played in a piece. Yet if we have understood the -\-> -->
<!-- <\!--       lecture or piece once, we now <em>own</em> new networks of knowledge -\-> -->
<!-- <\!--       about each theme and how it changes and relates to others. No one could -\-> -->
<!-- <\!--       remember all of Beethoven&#39;s Fifth Symphony from a single hearing, -\-> -->
<!-- <\!--       but neither could one ever again hear those first four notes as just -\-> -->
<!-- <\!--       four notes! Once a tiny scrap of sound, these four notes have become a -\-> -->
<!-- <\!--       known thing &mdash; a locus in the web of all the other things we know -\-> -->
<!-- <\!--       and whose meanings and significances depend on one another. Learning to -\-> -->
<!-- <\!--       recognize is not the same as memorizing. A mind might build an agent -\-> -->
<!-- <\!--       that can sense a certain stimulus, yet build no agent that can reproduce -\-> -->
<!-- <\!--       it. How could such a mind learn that the first half-subject of -\-> -->
<!-- <\!--       Beethoven&#39;s Fifth &mdash; call it A &mdash; prefigures the second -\-> -->
<!-- <\!--       half &mdash; call it B? It is simple: an agent A that recognizes A sends -\-> -->
<!-- <\!--       a message to another agent B, built to recognize B. That message serves -\-> -->
<!-- <\!--       to <em>lower B&#39;s threshold</em> so that after A hears A, B will -\-> -->
<!-- <\!--       react to smaller hints of B than it would otherwise. As a result, that -\-> -->
<!-- <\!--       mind -\-> -->
<!-- <\!--       <em>expects</em> to hear B after A; that is, it will discern B, given -\-> -->
<!-- <\!--       fewer or more subtle cues, and might <em>complain</em> if it cannot. Yet -\-> -->
<!-- <\!--       that mind cannot reproduce either theme in any generative sense. The -\-> -->
<!-- <\!--       point is that interagent messages need not be in surface music -\-> -->
<!-- <\!--       languages, but can be in codes that influence certain other agents to -\-> -->
<!-- <\!--       behave in different ways.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       (Andor Kovach pointed out to me that composers do not dare use this -\-> -->
<!-- <\!--       simple, four-note motive any more. So memorable was Beethoven&#39;s -\-> -->
<!-- <\!--       treatment that now an accidental hint of it can wreck another piece by -\-> -->
<!-- <\!--       unintentionally distracting the listener.)  If sonatas are lessons, what -\-> -->
<!-- <\!--       are the subjects of those lessons? The answer is in the question! One -\-> -->
<!-- <\!--       thing the Fifth Symphony taught us is how to hear those first four -\-> -->
<!-- <\!--       notes. The surface form is just descending major third, first tone -\-> -->
<!-- <\!--       repeated thrice. At first, that pattern can be heard two different ways: -\-> -->
<!-- <\!--       1) fifth and third in minor mode or 2) third and first, in major. But -\-> -->
<!-- <\!--       once we have heard the symphony, the latter is unthinkable &mdash; a -\-> -->
<!-- <\!--       strange constraint to plant in all our heads! Let us see how it is -\-> -->
<!-- <\!--       taught.  The Fifth declares at once its subject, then its near-identical -\-> -->
<!-- <\!--       twin.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       First comes the theme. Presented in a stark orchestral unison, its minor -\-> -->
<!-- <\!--       mode location in tonality is not yet made explicit, nor is its metric -\-> -->
<!-- <\!--       frame yet clear: the subject stands alone in time. Next comes its -\-> -->
<!-- <\!--       twin. The score itself leaves room to view this transposed counterpart -\-> -->
<!-- <\!--       as a complement or as a new beginning. Until now, fermatas have hidden -\-> -->
<!-- <\!--       the basic metric frame, a pair of twinned four-measure halves. So far we -\-> -->
<!-- <\!--       have only learned to hear those halves as separate wholes.  The next -\-> -->
<!-- <\!--       four-measure metric half-frame shows three versions of the subject, one -\-> -->
<!-- <\!--       on each ascending pitch of the tonic triad. (Now we are sure the key is -\-> -->
<!-- <\!--       minor.) This shows us how the subject can be made to overlap itself, the -\-> -->
<!-- <\!--       three short notes packed perfectly inside the long tone&#39;s -\-> -->
<!-- <\!--       time-space. The second half-frame does the same, with copies of the -\-> -->
<!-- <\!--       complement ascending the dominant seventh chord. This fits the halves -\-> -->
<!-- <\!--       together in that single, most familiar, frame of harmony. In rhythm, -\-> -->
<!-- <\!--       too, the halves are so precisely congruent that there is no room to -\-> -->
<!-- <\!--       wonder how to match them &mdash; and attach them &mdash; into one -\-> -->
<!-- <\!--       eight-measure unit.  The next eight-measure frame explains some more -\-> -->
<!-- <\!--       melodic points: how to smooth the figure&#39;s firmness with passing -\-> -->
<!-- <\!--       tones and how to counterpoise the subject&#39;s own inversion inside the -\-> -->
<!-- <\!--       long note. (I think that this evokes a sort of sinusoidal motion-frame -\-> -->
<!-- <\!--       idea that is later used to represent the second subject.) It also -\-> -->
<!-- <\!--       illustrates compression of harmonic time; seen earlier, this would -\-> -->
<!-- <\!--       obscure the larger rhythmic unit, but now we know enough to place each -\-> -->
<!-- <\!--       metric frame precisely on the after-image of the one before. -\-> -->
      
<!-- <\!--       Cadence. Silence. Almost. Total.  Now it is the second -\-> -->
<!-- <\!--       subject-twin&#39;s turn to stand alone in time.  The conductor must -\-> -->
<!-- <\!--       select a symmetry: he or she can choose to answer prior cadence, to -\-> -->
<!-- <\!--       start anew, or to close the brackets opened at the very start. (Can the -\-> -->
<!-- <\!--       conductor do all at once and maintain the metric frame?) We hear a long, -\-> -->
<!-- <\!--       long unison F (subdominant?) for, underneath that silent surface sound, -\-> -->
<!-- <\!--       we hear our minds rehearsing what was heard.  The next frame reveals the -\-> -->
<!-- <\!--       theme again, descending now by thirds. (We see that it was the dominant -\-> -->
<!-- <\!--       ninth, not subdominant at all. The music fooled us that time, but never -\-> -->
<!-- <\!--       will again.) Then tour de force: the subject climbs, sounding on every -\-> -->
<!-- <\!--       scale degree. This new perspective shows us how to see the four-note -\-> -->
<!-- <\!--       theme as an appogiatura. Then, as it descends on each tonic chord-note, -\-> -->
<!-- <\!--       we are made to see it as a fragment of arpeggio. That last descent -\-> -->
<!-- <\!--       completes a set of all four possibilities, harmonic and directional. (Is -\-> -->
<!-- <\!--       this deliberate didactic thoroughness, or merely the accidental outcome -\-> -->
<!-- <\!--       of the other symmetries?) Finally, the theme&#39;s melodic range is -\-> -->
<!-- <\!--       squeezed to nothing, yet it survives and even gains strength as single -\-> -->
<!-- <\!--       tone. It has always seemed to me a mystery of art, the impact of those -\-> -->
<!-- <\!--       moments in quartets when texture turns to single line and fortepiano -\-> -->
<!-- <\!--       shames sforzando in perceived intensity. But such acts, which on the -\-> -->
<!-- <\!--       surface only cause the structure or intensity to disappear, must make -\-> -->
<!-- <\!--       the largest difference underneath. Shortly, I will propose a scheme in -\-> -->
<!-- <\!--       which a sudden, searching change awakes a lot of mental -\-> -->
<!-- <\!--       difference-finders. This very change wakes yet more difference-finders, -\-> -->
<!-- <\!--       and this awakening wakes still more. That is how sudden silence makes -\-> -->
<!-- <\!--       the whole mind come alive.  We are <em>told</em> all this in just one -\-> -->
<!-- <\!--       minute of the lesson and I have touched but one dimension of its -\-> -->
<!-- <\!--       rhetoric. Besides explaining, teachers beg and threaten, calm and scare; -\-> -->
<!-- <\!--       use gesture, timbre, quaver, and sometimes even silence. This is vital -\-> -->
<!-- <\!--       in music, too.  Indeed, in the Fifth, it is the start of the subject! -\-> -->
<!-- <\!--       Such <em>lessons</em> must teach us as much about triads and triplets as -\-> -->
<!-- <\!--       mathematicians have learned about angles and sides! Think how much we -\-> -->
<!-- <\!--       can learn about minor second intervals from Beethoven&#39;s Grosse Fuge -\-> -->
<!-- <\!--       in E-flat, Opus 133. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       What Use Is Music?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Why on earth should anyone want to learn such things? Geometry is -\-> -->
<!-- <\!--       practical &mdash; for building pyramids, for instance &mdash; but of -\-> -->
<!-- <\!--       what use is musical knowledge? Here is one idea. Each child spends -\-> -->
<!-- <\!--       endless days in curious ways; we call this play. A child stacks and -\-> -->
<!-- <\!--       packs all kinds of blocks and boxes, lines them up, and knocks them -\-> -->
<!-- <\!--       down. What is that all about? Clearly, the child is learning about -\-> -->
<!-- <\!--       space! But how on earth does one learn about time? Can one time fit -\-> -->
<!-- <\!--       inside another?  Can two of them go side by side? In music, we find out! -\-> -->
<!-- <\!--       It is often said that mathematicians are unusually involved in music, -\-> -->
<!-- <\!--       but that musicians are not involved in mathematics. Perhaps both -\-> -->
<!-- <\!--       mathematicians and musicians like to make simple things more -\-> -->
<!-- <\!--       complicated, but mathematics may be too constrained to satisfy that want -\-> -->
<!-- <\!--       entirely, while music can be rigorous or free. The way the mathematics -\-> -->
<!-- <\!--       game is played, most variations lie outside the rules, while music can -\-> -->
<!-- <\!--       insist on perfect canon or tolerate a casual accompaniment. So -\-> -->
<!-- <\!--       mathematicians might need music, but musicians might not need -\-> -->
<!-- <\!--       mathematics. A simpler theory is that since music engages us at earlier -\-> -->
<!-- <\!--       ages, some mathematicians are those missing mathematical musicians. -\-> -->
<!-- <\!--       Most adults have some childlike fascination for making and arranging -\-> -->
<!-- <\!--       larger structures out of smaller ones. One kind of musical understanding -\-> -->
<!-- <\!--       involves building large mental structures out of smaller, musical -\-> -->
<!-- <\!--       parts. Perhaps the drive to build those mental music structures is the -\-> -->
<!-- <\!--       same one that makes us try to understand the world.  (Or perhaps that -\-> -->
<!-- <\!--       drive is just an accidental mutant variant of it; evolution often copies -\-> -->
<!-- <\!--       needless extra stuff, and minds so new as ours must contain a lot of -\-> -->
<!-- <\!--       that.)  Sometimes, though, we use music as a trick to misdirect our -\-> -->
<!-- <\!--       understanding of the world. When thoughts are painful we have no way to -\-> -->
<!-- <\!--       make them stop. We can attempt to turn our minds to other matters, but -\-> -->
<!-- <\!--       doing this (some claim) just submerges the bad thoughts.  Perhaps the -\-> -->
<!-- <\!--       music that some call background music can tranquilize by turning -\-> -->
<!-- <\!--       under-thoughts from bad to neutral, leaving the surface thoughts free of -\-> -->
<!-- <\!--       affect by diverting the unconscious. The structures we assemble in that -\-> -->
<!-- <\!--       detached kind of listening might be wholly solipsistic webs of -\-> -->
<!-- <\!--       meaninglike cross-references that nowhere touch -\-> -->
<!-- <\!--       <em>reality.</em> In such a self-constructed world, we would need no -\-> -->
<!-- <\!--       truth or falsehood, good or evil, pain or joy. Music, in this unpleasant -\-> -->
<!-- <\!--       view, would serve as a fine escape from tiresome thoughts. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Syntactic Theories of Music Contrast two answers to the question, Why do -\-> -->
<!-- <\!--       we like certain tunes? -\-> -->
      
<!-- <\!--       Because they have certain structural features.  Because they resemble -\-> -->
<!-- <\!--       other tunes we like. -\-> -->
      
<!-- <\!--       The first answer has to do with the laws and rules that make tunes -\-> -->
<!-- <\!--       pleasant. In language, we know some laws for sentences; that is, we know -\-> -->
<!-- <\!--       the forms sentences must have to be syntactically acceptable, if not the -\-> -->
<!-- <\!--       things they must have to make them sensible or even pleasant to the -\-> -->
<!-- <\!--       ear. As to melody, it seems, we only know some features that can help -\-> -->
<!-- <\!--       &mdash; we know of no absolutely essential features. I do not expect -\-> -->
<!-- <\!--       much more to come of a search for a compact set of rules for musical -\-> -->
<!-- <\!--       phrases. (The point is not so much what we mean by rule, as how large a -\-> -->
<!-- <\!--       body of knowledge is involved.)  The second answer has to do with -\-> -->
<!-- <\!--       significance outside the tune itself, in the same way that asking, Which -\-> -->
<!-- <\!--       sentences are meaningful?  takes us outside shared linguistic practice -\-> -->
<!-- <\!--       and forces us to look upon each person&#39;s private tangled webs of -\-> -->
<!-- <\!--       thought. Those private webs feed upon themselves, as in all spheres -\-> -->
<!-- <\!--       involving preference: we tend to like things that remind us of the other -\-> -->
<!-- <\!--       things we like. For example, some of us like music that resembles the -\-> -->
<!-- <\!--       songs, carols, rhymes, and hymns we liked in childhood. All this begs -\-> -->
<!-- <\!--       this question: If we like new tunes that are similar to those we already -\-> -->
<!-- <\!--       like, where does our liking for music start? I will come back to this -\-> -->
<!-- <\!--       later.  The term resemble begs a question also: What are the rules of -\-> -->
<!-- <\!--       musical resemblance? I am sure that this depends a lot on how melodies -\-> -->
<!-- <\!--       are <em>represented</em> in each individual mind. In each single mind, -\-> -->
<!-- <\!--       some different <em>mind parts</em> do this different ways: the same tune -\-> -->
<!-- <\!--       seems (at different times) to change its rhythm, mode, or -\-> -->
<!-- <\!--       harmony. Beyond that, individuals differ even more. Some listeners -\-> -->
<!-- <\!--       squirm to symmetries and shapes that others scarcely hear at all and -\-> -->
<!-- <\!--       some fine fugue subjects seem banal to those who sense only a single -\-> -->
<!-- <\!--       line. My guess is that our contrapuntal sensors harmonize each fading -\-> -->
<!-- <\!--       memory with others that might yet be played; perhaps Bach&#39;s mind -\-> -->
<!-- <\!--       could do this several ways at once. Even one such process might suffice -\-> -->
<!-- <\!--       to help an improviser plan what to try to play. next. (To try is -\-> -->
<!-- <\!--       sufficient since improvisers, like stage magicians, know enough vamps -\-> -->
<!-- <\!--       or <em>ways out</em> to keep the music going when bold experiments -\-> -->
<!-- <\!--       fail.)  How is it possible to improvise or comprehend a complex -\-> -->
<!-- <\!--       contrapuntal piece? Simple statistical explanations cannot begin to -\-> -->
<!-- <\!--       describe such processes. Much better are the generative and -\-> -->
<!-- <\!--       transformational (e.g., neo-Schenkerian) methods of syntactic analysis, -\-> -->
<!-- <\!--       but only for the simplest analytic uses. At best, the very aim of -\-> -->
<!-- <\!--       syntax-oriented music theories is misdirected because they aspire to -\-> -->
<!-- <\!--       describe the sentences that minds produce without attempting to describe -\-> -->
<!-- <\!--       how the sentences are produced. Meaning is much more than sentence -\-> -->
<!-- <\!--       structure. We cannot expect to be able to describe the anatomy of the -\-> -->
<!-- <\!--       mind unless we understand its embryology. And so (as with most any other -\-> -->
<!-- <\!--       very complicated matter), science must start with surface systems of -\-> -->
<!-- <\!--       description. But this surface taxonomy, however elegant and -\-> -->
<!-- <\!--       comprehensive in itself, must yield in the end to a deeper, causal -\-> -->
<!-- <\!--       explanation. To understand how memory and process merge -\-> -->
<!-- <\!--       in <em>listening,</em> we will have to learn to use much more -\-> -->
<!-- <\!--       <em>procedural</em> descriptions, such as programs that describe how -\-> -->
<!-- <\!--       processes proceed.  In science, we always first explain things in terms -\-> -->
<!-- <\!--       of what can be observed (earth, water, fire, air). Yet things that come -\-> -->
<!-- <\!--       from complicated processes do not necessarily show their natures on the -\-> -->
<!-- <\!--       surface (The steady pressure of a gas conceals those countless, abrupt -\-> -->
<!-- <\!--       microimpacts.) To speak of what such things might mean or represent, we -\-> -->
<!-- <\!--       have to speak of how they are made.  We cannot describe how the mind is -\-> -->
<!-- <\!--       made without having good ways to describe complicated processes. Before -\-> -->
<!-- <\!--       computers, no languages were good for that. Piaget tried algebra and -\-> -->
<!-- <\!--       Freud tried diagrams; other psychologists used Markov chains and -\-> -->
<!-- <\!--       matrices, but none came to much. Behaviorists, quite properly, had -\-> -->
<!-- <\!--       ceased to speak at all. Linguists flocked to formal syntax, and made -\-> -->
<!-- <\!--       progress for a time but reached a limit: transformational grammar shows -\-> -->
<!-- <\!--       the contents of the registers (so to speak), but has no way to describe -\-> -->
<!-- <\!--       what controls them. This makes it hard to say how surface speech relates -\-> -->
<!-- <\!--       to underlying designation and intent &mdash; a baby-and-bath-water -\-> -->
<!-- <\!--       situation.  The reason I like ideas from AI research is that there we -\-> -->
<!-- <\!--       tend to seek procedural description first, which seems more appropriate -\-> -->
<!-- <\!--       for mental matters.  I do not see why so many theorists find this -\-> -->
<!-- <\!--       approach disturbing. It is true that the new power derived from this -\-> -->
<!-- <\!--       approach has a price: we can say more, with computational description, -\-> -->
<!-- <\!--       but prove less. Yet less is lost than many think, for mathematics never -\-> -->
<!-- <\!--       could prove much about such complicated things. Theorems often tell us -\-> -->
<!-- <\!--       complex truths about the simple things, but only rarely tell us simple -\-> -->
<!-- <\!--       truths about the complex ones. To believe otherwise is wishful thinking -\-> -->
<!-- <\!--       or -\-> -->
<!-- <\!--       <em>mathematics envy.</em> Many musical problems that resist formal -\-> -->
<!-- <\!--       solutions may turn out to be tractable anyway, in future simulations -\-> -->
<!-- <\!--       that grow artificial musical semantic networks, perhaps -\-> -->
<!-- <\!--       by <em>raising</em> simulated infants in traditional musical -\-> -->
<!-- <\!--       cultures. It will be exciting when one of these infants first shows a -\-> -->
<!-- <\!--       hint of real <em>talent.</em></p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Space and Tune When we enter a room, we seem to see it all at once; we -\-> -->
<!-- <\!--       are not permitted this illusion when listening to a symphony. <em>Of -\-> -->
<!-- <\!-- 	course,</em> one might declare, for hearing has to thread a serial path -\-> -->
<!-- <\!--       through time, while sight embraces a space all at once. Actually, it -\-> -->
<!-- <\!--       takes time to see new scenes, though we are not usually aware of -\-> -->
<!-- <\!--       this. That totally compelling sense that we are conscious of seeing -\-> -->
<!-- <\!--       everything in the room instantly and immediately is certainly the -\-> -->
<!-- <\!--       strangest of our -\-> -->
<!-- <\!--       <em>optical</em> illusions.  Music, too, immerses us in seemingly stable -\-> -->
<!-- <\!--       worlds! How can this be, when there is so little of it present at each -\-> -->
<!-- <\!--       moment? I will try to explain this by 1) arguing that hearing music is -\-> -->
<!-- <\!--       like viewing scenery and 2) by asserting that when we hear good music -\-> -->
<!-- <\!--       our minds react in very much the same way they do when we see things. 1 -\-> -->
<!-- <\!--       And make no mistake: I meant to say <em>good</em> music! This little -\-> -->
<!-- <\!--       theory is not meant to work for any senseless bag of musical tricks, but -\-> -->
<!-- <\!--       only for those certain kinds of music that, in their cultural times and -\-> -->
<!-- <\!--       places, command attention and approval.  To see the problem in a -\-> -->
<!-- <\!--       slightly different way, consider cinema. Contrast a novice&#39;s clumsy -\-> -->
<!-- <\!--       patched and pasted reels of film with those that transport us to other -\-> -->
<!-- <\!--       worlds so artfully composed that our own worlds seem shoddy and -\-> -->
<!-- <\!--       malformed. What <em>hides the seams</em> to make great films so much -\-> -->
<!-- <\!--       less than the sum of their parts &mdash; so that we do not see them as -\-> -->
<!-- <\!--       mere sequences of scenes? What makes us feel that we are there and part -\-> -->
<!-- <\!--       of it when we are in fact immobile in our chairs, helpless to deflect an -\-> -->
<!-- <\!--       atom of the projected pattern&#39;s predetermined destiny? I will follow -\-> -->
<!-- <\!--       this idea a little further, then try to explain why good music is both -\-> -->
<!-- <\!--       more and less than sequences of notes.  Our eyes are always flashing -\-> -->
<!-- <\!--       sudden flicks of different pictures to our brains, yet none of that -\-> -->
<!-- <\!--       saccadic action leads to any sense of change or motion in the world; -\-> -->
<!-- <\!--       each thing reposes calmly in its <em>place</em>!  What makes those -\-> -->
<!-- <\!--       objects stay so still while images jump and jerk so?  What makes us such -\-> -->
<!-- <\!--       innate Copernicans? I will first propose how this illusion works in -\-> -->
<!-- <\!--       vision, then in music.  We will find the answer deep within the way the -\-> -->
<!-- <\!--       mind regards itself. When speaking of illusion, we assume that someone -\-> -->
<!-- <\!--       is being fooled. <em>I know those lines are straight,</em> I -\-> -->
<!-- <\!--       say, <em>but they look bent to me.</em> Who are the different I&#39;s -\-> -->
<!-- <\!--       and me&#39;s? We are all convinced that somewhere in each person struts -\-> -->
<!-- <\!--       a single, central self; atomic, indivisible. (And secretly we hope that -\-> -->
<!-- <\!--       it is also indestructible.)  I believe, instead, that inside each mind -\-> -->
<!-- <\!--       work many different agents. (The idea of societies of agents [Minsky -\-> -->
<!-- <\!--       1977; 1980a; 1980b] originated in my work with Seymour Papert.) All we -\-> -->
<!-- <\!--       really need to know about agents is this: each agent knows what happens -\-> -->
<!-- <\!--       to some others, but little of what happens to the rest. It means little -\-> -->
<!-- <\!--       to say, -\-> -->
<!-- <\!--       <em>Eloise was unaware of X</em> unless we say more about which of her -\-> -->
<!-- <\!--       mind-agents were uninvolved with X. Thinking consists of making -\-> -->
<!-- <\!--       mind-agents work together; the very core of fruitful thought is breaking -\-> -->
<!-- <\!--       problems into different kinds of parts and then assigning the parts to -\-> -->
<!-- <\!--       the agents that handle them best. (Among our most important agents are -\-> -->
<!-- <\!--       those that manage these assignments, for they are the agents that embody -\-> -->
<!-- <\!--       what each person knows about what he or she knows. Without these agents -\-> -->
<!-- <\!--       we would be helpless, for we would not know what our knowing is for.) -\-> -->
<!-- <\!--       In that division of labor we call seeing, I will suppose that a certain -\-> -->
<!-- <\!--       mind-agent called feature-finder sends messages (about features it finds -\-> -->
<!-- <\!--       on the retina) to another agent, scene-analyzer.  Scene-analyzer draws -\-> -->
<!-- <\!--       conclusions from the messages it gets and sends its own, in turn, to -\-> -->
<!-- <\!--       other mind-parts. For instance, feature-finder finds and tells about -\-> -->
<!-- <\!--       some scraps of edge and texture; then scene-analyzer finds and tells -\-> -->
<!-- <\!--       that these might fit some bit of shape.  Perhaps those features come -\-> -->
<!-- <\!--       from glimpses of a certain real table leg. But knowing such a thing is -\-> -->
<!-- <\!--       not for agents at this level; scene-analyzer does not know of any such -\-> -->
<!-- <\!--       specific things. All it can do is broadcast something about shape to -\-> -->
<!-- <\!--       hosts of other agents who specialize in recognizing special -\-> -->
<!-- <\!--       things. (Since special things &mdash; like tables, words, or dogs -\-> -->
<!-- <\!--       &mdash; must be involved with memory and learning, there is at least one -\-> -->
<!-- <\!--       such agent for every kind of thing this mind has learned to recognize.) -\-> -->
<!-- <\!--       Thus, we can hope, this message reaches table-maker, an agent -\-> -->
<!-- <\!--       specialized to recognize evidence that a table is in the field of -\-> -->
<!-- <\!--       view. After many such stages, descendants of such messages finally reach -\-> -->
<!-- <\!--       space-builder, an agent that tries to tell of real things in real space. -\-> -->
<!-- <\!--       Now we can see one reason why perception seems so effortless: while -\-> -->
<!-- <\!--       messages from scene-analyzer to table-maker are based on evidence that -\-> -->
<!-- <\!--       feature-finder supplied, the messages themselves need not say what -\-> -->
<!-- <\!--       feature-finder itself did, or how it did it. Partly this is because it -\-> -->
<!-- <\!--       would take scene-analyzer too long to explain all that. In any case, the -\-> -->
<!-- <\!--       recipients could make no use of all that information since they are not -\-> -->
<!-- <\!--       engineers or psychologists, but just little specialized nerve nets. -\-> -->
<!-- <\!--       Only in the past few centuries have painters learned enough technique -\-> -->
<!-- <\!--       and trickery to simulate reality. (Once so informed, they often now -\-> -->
<!-- <\!--       choose different goals.) Thus space-builder, like an ordinary person, -\-> -->
<!-- <\!--       knows nothing of how vision works, perspective, foveae, or blind -\-> -->
<!-- <\!--       spots. We only learn such things in school: millennia of introspection -\-> -->
<!-- <\!--       never led to their suspicion, nor did meditation, transcendental or -\-> -->
<!-- <\!--       mundane. The mind holds tightly to its secrets not from stinginess or -\-> -->
<!-- <\!--       shame, but simply because it does not know them.  Messages, in this -\-> -->
<!-- <\!--       scheme, go various ways. Each motion of the eye or head or body makes -\-> -->
<!-- <\!--       feature-finder start anew, and such motions are responses (by -\-> -->
<!-- <\!--       muscle-moving agents) to messages that scene-analyzer sends when it -\-> -->
<!-- <\!--       needs more details to resolve ambiguities. Scene-analyzer itself -\-> -->
<!-- <\!--       responds to messages from -\-> -->
<!-- <\!--       <em>higher up.</em> For instance, space-builder may have asked, <em>Is -\-> -->
<!-- <\!-- 	that a table?</em> of table-maker, which replies to -\-> -->
<!-- <\!--       itself, <em>Perhaps, but it should have another leg &mdash; -\-> -->
<!-- <\!-- 	there,</em> so it asks scene-analyzer to verify this, and -\-> -->
<!-- <\!--       scene-analyzer gets the job done by making eye-mover look down and to -\-> -->
<!-- <\!--       the left. Nor is scene-understander autonomous: its questions to -\-> -->
<!-- <\!--       scene-analyzer are responses to requests from others. l here need be -\-> -->
<!-- <\!--       no first cause in such a network.  When we look up, we are never -\-> -->
<!-- <\!--       afraid that the ground has disappeared, though it certainly -\-> -->
<!-- <\!--       has <em>dis-appeared.</em> This is because space-builder remembers all -\-> -->
<!-- <\!--       the answers to its questions and never changes any of those answers -\-> -->
<!-- <\!--       without reason; moving our eyes or raising our heads provide no cause -\-> -->
<!-- <\!--       to exorcise that floor inside our current spatial model of the -\-> -->
<!-- <\!--       room. My paper on frame-systems (Minsky 1974) says more about these -\-> -->
<!-- <\!--       concepts. Here we only need these few details.  Now, back to our -\-> -->
<!-- <\!--       illusions. While feature-finder is not instantaneous, it is very, very -\-> -->
<!-- <\!--       fast and a highly parallel pattern matcher. Whatever scene-analyzer -\-> -->
<!-- <\!--       asks, feature-finder answers in an eye flick, a mere tenth of a second -\-> -->
<!-- <\!--       (or less if we have image buffers). More speed comes from the way in -\-> -->
<!-- <\!--       which space-builder can often tell itself, via its own high-speed -\-> -->
<!-- <\!--       model memory, about what has been seen before. I argue that all this -\-> -->
<!-- <\!--       speed is another root of our illusion: if answers seem to come as soon -\-> -->
<!-- <\!--       as questions are asked, they will seem to have been there all along.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       The illusion is enhanced in yet another way by <em>expectation</em> -\-> -->
<!-- <\!--       or <em>default.</em> Those agents know good ways to lie and bluff! -\-> -->
<!-- <\!--       Aroused by only partial evidence that a table is in view, table-maker -\-> -->
<!-- <\!--       supplies space-builder with fictitious details about some <em>typical -\-> -->
<!-- <\!-- 	table</em> while its servants find out more about the real one! Once so -\-> -->
<!-- <\!--       informed, space-builder can quickly move and plan ahead, taking some -\-> -->
<!-- <\!--       risks but ready to make corrections later. This only works, of course, -\-> -->
<!-- <\!--       when prototypes are good and are rightly activated &mdash; that is what -\-> -->
<!-- <\!--       intelligence is all about.  As for <em>awareness</em> of how all such -\-> -->
<!-- <\!--       things are done, there simply is not room for that. Space-builder is too -\-> -->
<!-- <\!--       remote and different to understand how feature-finder does its work of -\-> -->
<!-- <\!--       eye fixation. Each part of the mind is unaware of almost all that -\-> -->
<!-- <\!--       happens in the others.  (That is why we need psychologists; we think we -\-> -->
<!-- <\!--       know what happens in our minds because those agents are so facile -\-> -->
<!-- <\!--       with <em>defaults,</em> but we are almost always wrong.) True, each -\-> -->
<!-- <\!--       agent needs to know which of its servants can do what, but as to how, -\-> -->
<!-- <\!--       that information has no place or use inside those tiny minds inside our -\-> -->
<!-- <\!--       minds.  How do both music and vision build things in our minds? Eye -\-> -->
<!-- <\!--       motions show us real objects; phrases show us musical objects. We</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       <em>learn</em> a room with bodily motions; large musical sections show -\-> -->
<!-- <\!--       us musical <em>places.</em> Walks and climbs move us from room to room; -\-> -->
<!-- <\!--       so do transitions between musical sections. Looking back in vision is -\-> -->
<!-- <\!--       like recapitulation in music; both give us time, at certain points, to -\-> -->
<!-- <\!--       reconfirm or change our conceptions of the whole.  Hearing a theme is -\-> -->
<!-- <\!--       like seeing a thing in a room, a section or movement is like a room, and -\-> -->
<!-- <\!--       a whole sonata is like an entire building. I do not mean to say that -\-> -->
<!-- <\!--       music builds the sorts of things that space-builder does. (That is too -\-> -->
<!-- <\!--       naive a comparison of sound and place.) I do mean to say that composers -\-> -->
<!-- <\!--       stimulate coherency by engaging the same sorts of interagent -\-> -->
<!-- <\!--       coordinations that vision uses to produce its illusion of a stable world -\-> -->
<!-- <\!--       using, of course, different agents. I think the same is true of talk or -\-> -->
<!-- <\!--       writing, the way these very paragraphs make sense &mdash; or sense of -\-> -->
<!-- <\!--       sense &mdash; if any. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Composing and Conducting In seeing, we can move our eyes; lookers can -\-> -->
<!-- <\!--       choose where they shall look, and when. In music we must listen here; -\-> -->
<!-- <\!--       that is, to the part being played now. It is simply no use asking -\-> -->
<!-- <\!--       music-finder to look there because it is not then, now.  If composer and -\-> -->
<!-- <\!--       conductor choose what part we hear, does not this ruin our analogy? When -\-> -->
<!-- <\!--       music-analyzer asks its questions, how can music-finder answer them -\-> -->
<!-- <\!--       unless, miraculously, the music happens to be playing what music-finder -\-> -->
<!-- <\!--       wants at just that very instant? If so, then how can music paint its -\-> -->
<!-- <\!--       scenes unless composers know exactly what the listeners will ask at -\-> -->
<!-- <\!--       every moment? How to ensure &mdash; when music-analyzer wants it now -\-> -->
<!-- <\!--       &mdash; that precisely that -\-> -->
<!-- <\!--       <em>something</em> will be playing now?  That is the secret of music; of -\-> -->
<!-- <\!--       writing it, playing, and conducting!  Music need not, of course, confirm -\-> -->
<!-- <\!--       each listener&#39;s every expectation; each plot demands some -\-> -->
<!-- <\!--       novelty. Whatever the intent, control is required or novelty will turn -\-> -->
<!-- <\!--       to nonsense. If allowed to think too much themselves, the listeners will -\-> -->
<!-- <\!--       find unanswered questions in any score; about accidents of form and -\-> -->
<!-- <\!--       figure, voice and line, temperament and difference-tone.  Composers can -\-> -->
<!-- <\!--       have different goals: to calm and soothe, surprise and shock, tell -\-> -->
<!-- <\!--       tales, stage scenes, teach new things, or tear down prior arts. For some -\-> -->
<!-- <\!--       such purposes composers must use the known forms and frames or else -\-> -->
<!-- <\!--       expect misunderstanding. Of course, when expectations are confirmed too -\-> -->
<!-- <\!--       often the style may seem dull; this is our concern in the next -\-> -->
<!-- <\!--       section. Yet, just as in language, one often best explains a new idea by -\-> -->
<!-- <\!--       using older ones, avoiding jargon or too much lexical innovation. If -\-> -->
<!-- <\!--       readers cannot understand the words themselves, the sentences may <em>be -\-> -->
<!-- <\!-- 	Greek to them.</em>  This is not a matter of a simple hierarchy, in -\-> -->
<!-- <\!--       which each meaning stands on lower-level ones, for example, word, -\-> -->
<!-- <\!--       phrase, sentence, paragraph, and chapter. Things never really work that -\-> -->
<!-- <\!--       way, and jabberwocky shows how sense comes through though many words are -\-> -->
<!-- <\!--       new. In every era some contemporary music changes basic elements yet -\-> -->
<!-- <\!--       exploits established larger forms, but innovations that violate too -\-> -->
<!-- <\!--       drastically the expectations of the culture cannot meet certain kinds of -\-> -->
<!-- <\!--       goals. Of course this will not apply to works whose goals include -\-> -->
<!-- <\!--       confusion and revolt, or when composers try to create things that hide -\-> -->
<!-- <\!--       or expurgate their own intentionality, but in these instances it may be -\-> -->
<!-- <\!--       hard to hold the audience.  Each musical artist must forecast and -\-> -->
<!-- <\!--       predirect the listener&#39;s fixations to draw attention here and -\-> -->
<!-- <\!--       distract it from there &mdash; to force the hearer (again, like a -\-> -->
<!-- <\!--       magician), to ask only the questions that the composition is about to -\-> -->
<!-- <\!--       answer. Only by establishing such pre-established harmony can music make -\-> -->
<!-- <\!--       it seem that something is there. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Rhythm and Redundancy A popular song has 100 measures, 1000 beats. What -\-> -->
<!-- <\!--       must the martians imagine we mean by those measures and beats, measures -\-> -->
<!-- <\!--       and beats! The words themselves reveal an awesome repetitiousness.  Why -\-> -->
<!-- <\!--       isn&#39;t music boring?  Is hearing so like seeing that we need a -\-> -->
<!-- <\!--       hundred glances to build each musical image? Some repetitive musical -\-> -->
<!-- <\!--       textures might serve to remind us of things that persist through time -\-> -->
<!-- <\!--       like wind and stream.  But many sounds occur only once: we must hear a -\-> -->
<!-- <\!--       pin drop now or seek and search for it; that is why we have -\-> -->
<!-- <\!--       no <em>ear-lids.</em> Poetry drops pins, or says each thing once or not -\-> -->
<!-- <\!--       at all. So does some music.  Then why do we tolerate music&#39;s -\-> -->
<!-- <\!--       relentless rhythmic pulse or other repetitive architectural features? -\-> -->
<!-- <\!--       There is no one answer, for we hear in different ways, on different -\-> -->
<!-- <\!--       scales. Some of those ways portray the spans of time directly, but -\-> -->
<!-- <\!--       others speak of musical things, in worlds where time folds over on -\-> -->
<!-- <\!--       itself. And there, I think, is where we use those beats and -\-> -->
<!-- <\!--       measures. Music&#39;s metric frames are transient templates used for -\-> -->
<!-- <\!--       momentary matching. Its rhythms are -\-> -->
<!-- <\!--       <em>synchronization pulses</em> used to match new phrases against old, -\-> -->
<!-- <\!--       the better to contrast them with differences and change. As differences -\-> -->
<!-- <\!--       and change are sensed, the rhythmic frames fade from our -\-> -->
<!-- <\!--       awareness. Their work is done and the messages of higher-level agents -\-> -->
<!-- <\!--       never speak of them; that is why metric music is not boring!  Good music -\-> -->
<!-- <\!--       germinates from tiny seeds. How cautiously we handle novelty, -\-> -->
<!-- <\!--       sandwiching the new between repeated sections of familiar stuff! The -\-> -->
<!-- <\!--       clearest kind of change is near-identity, in thought just as in -\-> -->
<!-- <\!--       vision. Slight shifts in view may best reveal an object&#39;s form or -\-> -->
<!-- <\!--       even show us whether it is there at all.  When we discussed sonatas, we -\-> -->
<!-- <\!--       saw how matching different metric frames helps us to sense the musical -\-> -->
<!-- <\!--       ingredients. Once frames are matched, we can see how altering a single -\-> -->
<!-- <\!--       note at one point will change a major third melodic skip at another -\-> -->
<!-- <\!--       point to smooth passing tones; or will make what was there a seventh -\-> -->
<!-- <\!--       chord into a dominant ninth. Matching lets our minds see different -\-> -->
<!-- <\!--       things, from different times, together. This fusion of those matching -\-> -->
<!-- <\!--       lines of tone from different measures (like television&#39;s separate -\-> -->
<!-- <\!--       lines and frames) lets us make those magic musical pictures in our -\-> -->
<!-- <\!--       minds.  How do our musical agents do this kind of work for us? We must -\-> -->
<!-- <\!--       have organized them into structures that are good at finding differences -\-> -->
<!-- <\!--       between frames. Here is a simplified four-level scheme that might -\-> -->
<!-- <\!--       work. Many such ideas are current in research on vision (Winston 1975). -\-> -->
      
<!-- <\!--       Feature-finders listen for simple time-events, like notes, or peaks, or -\-> -->
<!-- <\!--       pulses. -\-> -->
      
<!-- <\!--       Measure-takers notice certain patterns of time-events like 3/4, 4/4, -\-> -->
<!-- <\!--       6/8. -\-> -->
      
<!-- <\!--       Difference-finders observe that the figure here is same as that one -\-> -->
<!-- <\!--       there, except a perfect fifth above. -\-> -->
      
<!-- <\!--       Structure-builders perceive that three phrases form an almost -\-> -->
<!-- <\!--       regular <em>sequence.</em></p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       The idea of interconnecting feature-finders, difference-finders, and -\-> -->
<!-- <\!--       structure-builders is well exemplified in Winston&#39;s work -\-> -->
<!-- <\!--       (1975). Measure-takers would be kinds of frames, as described in <em>A -\-> -->
<!-- <\!-- 	Framework for Representing Knowledge</em> (Minsky 1974). First, the -\-> -->
<!-- <\!--       feature-finders search the sound stream for the simplest sorts of -\-> -->
<!-- <\!--       musical significance: entrances and envelopes, the tones themselves, the -\-> -->
<!-- <\!--       other little, local things. Then measure-takers look for metric patterns -\-> -->
<!-- <\!--       in those small events and put them into groups, thus finding beats and -\-> -->
<!-- <\!--       postulating rhythmic regularities. Then the difference-finders can begin -\-> -->
<!-- <\!--       to sense events of musical importance; imitations and inversions, -\-> -->
<!-- <\!--       syncopations and suspensions. Once these are found, the -\-> -->
<!-- <\!--       structure-builders can start work on a larger scale.  The entire -\-> -->
<!-- <\!--       four-level agency is just one layer of a larger system in which -\-> -->
<!-- <\!--       analogous structures are repeated on larger scales. At each scale, -\-> -->
<!-- <\!--       another level of order (with its own sorts of things and differences) -\-> -->
<!-- <\!--       makes larger-scale descriptions, and thus consumes another order of -\-> -->
<!-- <\!--       structural form. As a result, notes become figures, figures turn into -\-> -->
<!-- <\!--       phrases, and phrases turn into sequences; and notes become chords, and -\-> -->
<!-- <\!--       chords make up progressions, and so on and on. Relations at each level -\-> -->
<!-- <\!--       turn to things at the next level above and are thus more easily -\-> -->
<!-- <\!--       remembered and compared. This <em>timewarps</em> things together, -\-> -->
<!-- <\!--       changing tone into tonality, note into composition.  The more regular -\-> -->
<!-- <\!--       the rhythm, the easier the matching goes, and the fewer difference -\-> -->
<!-- <\!--       agents are excited further on. Thus once it is used for <em>lining -\-> -->
<!-- <\!-- 	up,</em> the metric structure fades from our attention because it is -\-> -->
<!-- <\!--       represented as fixed and constant (like the floor of the room you are -\-> -->
<!-- <\!--       in), until some metric alteration makes the measure-takers change their -\-> -->
<!-- <\!--       minds. Sic semper all Alberti basses, um-pah-pahs, and ostinati; they -\-> -->
<!-- <\!--       all become imperceptible except when changing. Rhythm has many other -\-> -->
<!-- <\!--       functions, to be sure, and agents for those other functions see things -\-> -->
<!-- <\!--       different ways. Agents used for dancing do attend to rhythm, while other -\-> -->
<!-- <\!--       forms of music demand less steady pulses.  We all experience a -\-> -->
<!-- <\!--       phenomenon we might call persistence of rhythm, in which our minds -\-> -->
<!-- <\!--       maintain the beat through episodes of ambiguity. I presume that this -\-> -->
<!-- <\!--       emerges from a basic feature of how agents are usually assembled; at -\-> -->
<!-- <\!--       every level, many agents of each kind compete (Minsky 1980b). Thus -\-> -->
<!-- <\!--       agents for 3/4, 4/4, and 6/8 compete to find best fits. Once in power, -\-> -->
<!-- <\!--       however, each agent <em>cross-inhibits</em> its competitors. Once 3/4 -\-> -->
<!-- <\!--       takes charge of things, 6/8 will find it hard to</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       <em>get a hearing</em> even if the evidence on its side becomes slightly -\-> -->
<!-- <\!--       better.  When none of the agents has any solid evidence long enough, -\-> -->
<!-- <\!--       agents change at random or take turns. Thus anything gets interesting, -\-> -->
<!-- <\!--       in a way, if it is monotonous enough! We all know how, when a word or -\-> -->
<!-- <\!--       phrase is repeated often enough it, or we, begin to change as restless -\-> -->
<!-- <\!--       searchers start to amplify minutiae and interpret noise as -\-> -->
<!-- <\!--       structure. This happens at all levels because when things are regular at -\-> -->
<!-- <\!--       one level, the difference agents at the next will fail, to be replaced -\-> -->
<!-- <\!--       by other, fresh ones that then re-present the sameness different -\-> -->
<!-- <\!--       ways. (Thus meditation, undirected from the higher mental realms, fares -\-> -->
<!-- <\!--       well with the most banal of repetitious inputs from below.) -\-> -->
<!-- <\!--       Regularities are hidden while expressive nuances are sensed and -\-> -->
<!-- <\!--       emphasized and passed along. Rubato or crescendo, ornament or passing -\-> -->
<!-- <\!--       tone, the alterations at each level become the objects for the next. The -\-> -->
<!-- <\!--       mystery is solved; the brain is so good at sensing differences that it -\-> -->
<!-- <\!--       forgets the things themselves; that is, whenever they are the same. As -\-> -->
<!-- <\!--       for liking music, that depends on what remains.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Sentic Significance Why do we like any tunes in the first place? Do we -\-> -->
<!-- <\!--       simply associate some tunes with pleasant experiences? Should we look -\-> -->
<!-- <\!--       back to the tones and patterns of mother&#39;s voice or heartbeat? Or -\-> -->
<!-- <\!--       could it be that some themes are innately likable? All these theories -\-> -->
<!-- <\!--       could hold truth, and others too, for nothing need have a single cause -\-> -->
<!-- <\!--       inside the mind.  Theories about children need not apply to adults -\-> -->
<!-- <\!--       because (I suspect) human minds do so much self-revising that things can -\-> -->
<!-- <\!--       get detached from their origins. We might end up liking both Art of -\-> -->
<!-- <\!--       Fugue and Musical Offering, mainly because each work&#39;s subject -\-> -->
<!-- <\!--       illuminates the other, which gives each work a richer network of -\-> -->
<!-- <\!--       <em>significance.</em> Dependent circularity need be no paradox here, -\-> -->
<!-- <\!--       for in thinking (unlike logic) two things can support each other in -\-> -->
<!-- <\!--       midair. To be sure, such autonomy is precarious; once detached from -\-> -->
<!-- <\!--       origins, might one not drift strangely awry? Indeed so, and many people -\-> -->
<!-- <\!--       seem quite mad to one another.  In his book Sentics (l978), Manfred -\-> -->
<!-- <\!--       Clynes, a physiologist and pianist, describes certain specific temporal -\-> -->
<!-- <\!--       sensory patterns and claims that each is associated with a certain -\-> -->
<!-- <\!--       common emotional state.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       For example, in his experiments, two particular patterns (that gently -\-> -->
<!-- <\!--       rise and fall) are said to suggest states of love and reverence; two -\-> -->
<!-- <\!--       others (more abrupt) signify anger and hate. He claims that these and -\-> -->
<!-- <\!--       other patterns &mdash; he calls them sentic &mdash; arouse the same -\-> -->
<!-- <\!--       effects through different senses &mdash; that is, embodied as acoustical -\-> -->
<!-- <\!--       intensity, or pitch, or tactile pressure, or even visual motion &mdash; -\-> -->
<!-- <\!--       and that this is cross-cultural. The time lengths of these sentic -\-> -->
<!-- <\!--       shapes, on the order of 1 sec, could correspond to parts of musical -\-> -->
<!-- <\!--       phrases.  Clynes studied the <em>muscular</em> details of instrumental -\-> -->
<!-- <\!--       performances with this in view, and concluded that music can engage -\-> -->
<!-- <\!--       emotions through these sentic signals. Of course, more experiments are -\-> -->
<!-- <\!--       needed to verify that such signals really have the reported effects. -\-> -->
<!-- <\!--       Nevertheless, I would expect to find something of the sort for quite a -\-> -->
<!-- <\!--       different reason: namely, to serve in the early social development of -\-> -->
<!-- <\!--       children. Sentic signals (if they exist) would be quite useful in -\-> -->
<!-- <\!--       helping infants to learn about themselves and others.  All learning -\-> -->
<!-- <\!--       theories require brains to somehow impose -\-> -->
<!-- <\!--       <em>values</em> implicit or explicit in the choice of what to learn to -\-> -->
<!-- <\!--       do.  Most such theories say that certain special signals, called -\-> -->
<!-- <\!--       reinforcers, are involved in this. For certain goals it should suffice -\-> -->
<!-- <\!--       to use some simple, <em>primary</em> physiological stimuli like eating, -\-> -->
<!-- <\!--       drinking, relief of physical discomfort. Human infants must learn social -\-> -->
<!-- <\!--       signals, too.  The early learning theorists in this century assumed that -\-> -->
<!-- <\!--       certain social sounds (for instance, of approval) could become -\-> -->
<!-- <\!--       reinforcers by association with innate reinforcers, but evidence for -\-> -->
<!-- <\!--       this was never found. If parents could exploit some innate sentic cues, -\-> -->
<!-- <\!--       that mystery might be explained.  This might also touch another, deeper -\-> -->
<!-- <\!--       problem: that of how an infant forms an image of its own -\-> -->
<!-- <\!--       mind. Self-images are important for at least two reasons. First, -\-> -->
<!-- <\!--       external reinforcement can only be a part of human learning; the growing -\-> -->
<!-- <\!--       infant must eventually learn to learn from within to free itself from -\-> -->
<!-- <\!--       its parents. With Freud, I think that children must replace and augment -\-> -->
<!-- <\!--       the outside teacher with a self-constructed, inner, parent -\-> -->
<!-- <\!--       image. Second, we need a self-model simply to make realistic plans for -\-> -->
<!-- <\!--       solving ordinary problems. For example, we must know enough about our -\-> -->
<!-- <\!--       own dispositions to be able to assess which plans are feasible. Pure -\-> -->
<!-- <\!--       self-commitment does not work; we simply cannot carry out a plan that we -\-> -->
<!-- <\!--       will find too boring to complete or too vulnerable to other, competing -\-> -->
<!-- <\!--       interests. We need models of our own behavior.  How could a baby be -\-> -->
<!-- <\!--       smart enough to build such a model?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Innate sentic detectors could help by teaching children about their own -\-> -->
<!-- <\!--       affective states. For if distinct signals arouse specific states, the -\-> -->
<!-- <\!--       child can associate those signals with those states. Just knowing that -\-> -->
<!-- <\!--       such states exist, that is, having symbols for them, is half the -\-> -->
<!-- <\!--       battle. If those signals are uniform enough, then from social discourse -\-> -->
<!-- <\!--       one can learn some rules about the behavior caused by those states. Thus -\-> -->
<!-- <\!--       a child might learn that conciliatory signals can change anger to -\-> -->
<!-- <\!--       affection. Given that sort of information, a simple learning machine -\-> -->
<!-- <\!--       should be able to construct a <em>finite-state person-model.</em> This -\-> -->
<!-- <\!--       model would be crude at first, but to get started would be half of the -\-> -->
<!-- <\!--       job.  Once the baby had a crude model of some other, it could be copied -\-> -->
<!-- <\!--       and adapted in work on the baby&#39;s self-model. (This is more -\-> -->
<!-- <\!--       normative and constructional than it is descriptive, as Freud hinted, -\-> -->
<!-- <\!--       for the self-model dictates more than portrays what it purports to -\-> -->
<!-- <\!--       portray.)  With regard to music, it seems possible that we conceal, in -\-> -->
<!-- <\!--       the innocent songs and settings of our children&#39;s musical cultures, -\-> -->
<!-- <\!--       some lessons about successions of our own affective states. Sentically -\-> -->
<!-- <\!--       encrypted, those ballads could encode instructions about conciliation -\-> -->
<!-- <\!--       and affection, aggression and retreat; precisely the knowledge of -\-> -->
<!-- <\!--       signals and states that we need to get along with others. In later life,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       more complex music might illustrate more intricate kinds of compromise -\-> -->
<!-- <\!--       and conflict, ways to fit goals together to achieve more than one thing -\-> -->
<!-- <\!--       at a time. Finally, for grown-ups, our Burgesses and Kubricks fit -\-> -->
<!-- <\!--       Beethoven&#39;s Ninths to Clockwork Oranges.  If you find all this -\-> -->
<!-- <\!--       farfetched, so do I. But before rejecting it entirely, recall the -\-> -->
<!-- <\!--       question, Why do we have music, and let it occupy our lives with no -\-> -->
<!-- <\!--       apparent reason? When no idea seems right, the right one must seem -\-> -->
<!-- <\!--       wrong. -\-> -->
      
<!-- <\!--       Theme and Thing What is the subject of Beethoven&#39;s Fifth Symphony? -\-> -->
<!-- <\!--       Is it just those first four notes? Does it include the twin, transposed -\-> -->
<!-- <\!--       companion too?  What of the other variations, augmentations, and -\-> -->
<!-- <\!--       inversions? Do they all stem from a single prototype? In this case, yes. -\-> -->
<!-- <\!--       Or do they? For later in the symphony the theme appears in triplet form -\-> -->
<!-- <\!--       to serve as countersubject of the scherzo: three notes and one, three -\-> -->
<!-- <\!--       notes and one, three notes and one, still they make four. Melody turns -\-> -->
<!-- <\!--       into monotone rhythm; meter is converted to two equal beats.  Downbeat -\-> -->
<!-- <\!--       now falls on an actual note, instead of a silence. With all of those -\-> -->
<!-- <\!--       changes, the themes are quite different and yet the same.  Neither the -\-> -->
<!-- <\!--       form in the allegro nor the scherzo alone is the prototype; separate and -\-> -->
<!-- <\!--       equal, they span musical time. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Is there some more abstract idea that they both embody? This is like the -\-> -->
<!-- <\!--       problem raised by Wittgenstein (1953) of what words like game mean. In -\-> -->
<!-- <\!--       my paper on frames (Minsky 1974), I argue that for vision, chair can be -\-> -->
<!-- <\!--       described by no single prototype; it is better to use several prototypes -\-> -->
<!-- <\!--       connected in relational networks of similarities and differences I doubt -\-> -->
<!-- <\!--       that even these would represent musical ideas well; there are better -\-> -->
<!-- <\!--       tools in contemporary AI research, such as constraint systems, -\-> -->
<!-- <\!--       conceptual dependency, frame-systems, and semantic networks. Those are -\-> -->
<!-- <\!--       the tools we use today to deal with such problems. (See Computer Music -\-> -->
<!-- <\!--       Journal 4[2] and 4[3], 1980.)  What is a good theme? Without that bad -\-> -->
<!-- <\!--       word good, I do not think the question is well formed because anything -\-> -->
<!-- <\!--       is a theme if everything is music!  So let us split that question into -\-> -->
<!-- <\!--       (1) What mental conditions or processes do pleasant tunes evoke? and (2) -\-> -->
<!-- <\!--       What do we mean by pleasant? Both questions are hard, but the first is -\-> -->
<!-- <\!--       only hard; to answer it will take much thought and experimentation, -\-> -->
<!-- <\!--       which is good. The second question is very different. Philosophers and -\-> -->
<!-- <\!--       scientists have struggled mightily to understand what pain and pleasure -\-> -->
<!-- <\!--       are. I especially like Dennett&#39;s (1978) explanation of why that has -\-> -->
<!-- <\!--       been so difficult. He argues that pain <em>works</em> in different ways -\-> -->
<!-- <\!--       at different times, and all those ways have too little in common for the -\-> -->
<!-- <\!--       usual definition. I agree, but if pain is no single thing, why do we -\-> -->
<!-- <\!--       talk and think as though it were and represent it with such spurious -\-> -->
<!-- <\!--       clarity?  This is no accident: illusions of this sort have special -\-> -->
<!-- <\!--       uses. They play a role connected with a problem facing any society -\-> -->
<!-- <\!--       (inside or outside the mind) that learns from its experience. The -\-> -->
<!-- <\!--       problem is how to assign the credit and blame, for each accomplishment -\-> -->
<!-- <\!--       or failure of the society as a whole, among the myriad agents involved -\-> -->
<!-- <\!--       in everything that happens. To the extent that the agents&#39; actions -\-> -->
<!-- <\!--       are decided locally, so also must these decisions to credit or blame he -\-> -->
<!-- <\!--       made locally.  How, for example, can a mother tell that her child has a -\-> -->
<!-- <\!--       need (or that one has been satisfied) before she has learned specific -\-> -->
<!-- <\!--       signs for each such need? That could be arranged if, by evolution, -\-> -->
<!-- <\!--       signals were combined from many different internal processes concerned -\-> -->
<!-- <\!--       with needs and were provided with a single, common, output &mdash; an -\-> -->
<!-- <\!--       infant&#39;s sentic signal of discomfort (or contentment). Such a -\-> -->
<!-- <\!--       genetically pre-established harmony would evoke a corresponding central -\-> -->
<!-- <\!--       state in the parent. We would feel this as something like the distress -\-> -->
<!-- <\!--       we feel when babies cry.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A signal for satisfaction is also needed. Suppose, among the many things -\-> -->
<!-- <\!--       a child does, there is one that mother likes, which she demonstrates by -\-> -->
<!-- <\!--       making approving sounds. The child has just been walking there, and -\-> -->
<!-- <\!--       holding this just so, and thinking that, and speaking in some certain -\-> -->
<!-- <\!--       way. How can the mind of the child find out which behavior is good? The -\-> -->
<!-- <\!--       trouble is, each aspect of the child&#39;s behavior must result from -\-> -->
<!-- <\!--       little plans the child made before. We cannot reward an act. We can only -\-> -->
<!-- <\!--       reward the agency that selected that strategy, the agent who wisely -\-> -->
<!-- <\!--       activated the first agent, and so on. Alas for the generation of -\-> -->
<!-- <\!--       behaviorists who wastes its mental life by missing this plain and simple -\-> -->
<!-- <\!--       principle.  To reward all those agents and processes, we must propagate -\-> -->
<!-- <\!--       some message that they all can use to credit what they did; the plans -\-> -->
<!-- <\!--       they made, their strategies and computations. These various recipients -\-> -->
<!-- <\!--       have so little in common that such a message of approval, to work at -\-> -->
<!-- <\!--       all, must be extremely simple. Words like good are almost content- free -\-> -->
<!-- <\!--       messages that enable tutors, inside or outside a society, to tell the -\-> -->
<!-- <\!--       members that one or more of them has satisfied some need, and that tutor -\-> -->
<!-- <\!--       need not understand which members did what, or how, or even why.  Words -\-> -->
<!-- <\!--       like satisfy and need have many shifting meanings. Why,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       then, do we seem to understand them? Because they evolve that -\-> -->
<!-- <\!--       same illusion of substantiality that fools us into thinking it -\-> -->
<!-- <\!--       tautologous to ask, Why do we like pleasure? This serves a need: -\-> -->
<!-- <\!--       the levels of social discourse at which we use such clumsy words -\-> -->
<!-- <\!--       as like, or good, or that was fun must coarsely crush together -\-> -->
<!-- <\!--       many different meanings or we will never understand others (or -\-> -->
<!-- <\!--       ourselves) at all. Hence that precious, essential poverty of -\-> -->
<!-- <\!--       word and sign that makes them so hard to define. Thus the word -\-> -->
<!-- <\!--       good is no symbol that simply means or designates, as table -\-> -->
<!-- <\!--       does. Instead, it only names this protean injunction: Activate -\-> -->
<!-- <\!--       all those (unknown) processes that correlate and sift and sort, -\-> -->
<!-- <\!--       in learning, to see what changes (in myself) should now be -\-> -->
<!-- <\!--       made. The word like is just like good, except it is a name we -\-> -->
<!-- <\!--       use when we send such structure-building signals to ourselves. -\-> -->
<!-- <\!--       Most of the <em>uses</em> of music mentioned in this article -\-> -->
<!-- <\!--       &mdash; learning about time, fitting things together, getting -\-> -->
<!-- <\!--       along with others, and suppressing one&#39;s troubles &mdash; -\-> -->
<!-- <\!--       are very <em>functional</em>, but overlook much larger scales -\-> -->
<!-- <\!--       of <em>use.</em> Curt Roads remarked that, <blockquote>Every -\-> -->
<!-- <\!--       world above bare survival is self-constructed; whole cultures -\-> -->
<!-- <\!--       are built around common things people come to -\-> -->
<!-- <\!--       appreciate.</blockquote> These appreciations, represented by -\-> -->
<!-- <\!--       aesthetic agents, play roles in more and more of our decisions: -\-> -->
<!-- <\!--       what we think is beautiful gets linked to what we think is -\-> -->
<!-- <\!--       important. Perhaps, Roads suggests, when groups of mind-agents -\-> -->
<!-- <\!--       cannot agree, they tend to cede decisions to those others more -\-> -->
<!-- <\!--       concerned with what, for better or for worse, we call aesthetic -\-> -->
<!-- <\!--       form and fitness. By having small effects at many little points, -\-> -->
<!-- <\!--       those cumulative preferences for taste and form can shape a -\-> -->
<!-- <\!--       world.  That is another reason why we say we like the music we -\-> -->
<!-- <\!--       like. Liking is the way certain mind-parts make the others learn -\-> -->
<!-- <\!--       the things they need to understand that music. Hence liking land -\-> -->
<!-- <\!--       its relatives is at the very heart of understanding what we -\-> -->
<!-- <\!--       hear. Affect and aesthetic do not lie in other academic worlds -\-> -->
<!-- <\!--       that music theories safely can ignore.  Those other worlds are -\-> -->
<!-- <\!--       academic self-deceptions that we use to make each theorist&#39;s -\-> -->
<!-- <\!--       problem seem like someone else&#39;s. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Acknowledgments I am indebted to conversations and/or improvisations -\-> -->
<!-- <\!-- 	  with Maryann Amacher, John Amuedo, Betty Dexter, Harlan Ellison, -\-> -->
<!-- <\!-- 	  Edward Fredkin, Bernard Greenberg, Danny Hillis, Douglas Hofstadter, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  William Kornfeld, Andor Kovach, David Levitt, Tod Machover, -\-> -->
<!-- <\!-- 	  Charlotte Minsky, Curt Roads, Gloria Rudisch, Frederic Rzewski, and -\-> -->
<!-- <\!-- 	  Stephen Smoliar.  This article is in memory of Irving Fine. -\-> -->
	  
<!-- <\!-- 	  References Clynes, M. 1978. Sentics. New York: Doubleday. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Dennett, D. 1978. <em>Why a Machine Can&#39;t Feel Pain.</em> In -\-> -->
<!-- <\!-- 	  Brainstorms: Philosophical Essays on Mind and -\-> -->
<!-- <\!-- 	  Psychology. Montgomery, Vermont: Bradford Books. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Minsky, M. 1974. <em>A Framework for Representing Knowledge.</em> AI -\-> -->
<!-- <\!-- 	  Memo 306. Cambridge, Massachusetts: M.I.T. Artificial Intelligence -\-> -->
<!-- <\!-- 	  Laboratory. Condensed version in The Psychology of Computer Vision, -\-> -->
<!-- <\!-- 	  P. Winston, ed. 1975. New York: McGraw-Hill, pp. 211-277. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Minsky, M. 1977. <em>Plain Talk About Neurodevelopmental -\-> -->
<!-- <\!--             Epistemology.</em> In Proceedings of the Fifth International Joint -\-> -->
<!-- <\!-- 	  Conference on Artificial Intelligence. Cambridge, Massachusetts: -\-> -->
<!-- <\!-- 	  M.I.T. Artificial Intelligence Laboratory. Condensed in Artificial -\-> -->
<!-- <\!-- 	  Intelligence, P.  Winston and R. Brown, eds. 1979. Cambridge, -\-> -->
<!-- <\!-- 	  Massachusetts: MIT Press, pp. 421-450. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Minsky, M. 1980a. <em>Jokes and the Logic of the Cognitive -\-> -->
<!-- <\!--             Unconscious.</em> AI Memo 603. Cambridge, Massachusetts: M.I.T. -\-> -->
<!-- <\!-- 	  Artificial Intelligence Laboratory. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Minsky, M. 1980b. <em>K-lines: A Theory of Memory.</em> Cognitive -\-> -->
<!-- <\!-- 	  Science 4(2): 117-133. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Roads, C. ed. 1980. Computer Music Journal 4(2) and 4(3). -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Winston, P. H. 1975. <em>Learning Structural Descriptions by -\-> -->
<!-- <\!--             Examples.</em>  In P. Winston, ed. 1975. Psychology of Computer -\-> -->
<!-- <\!-- 	  Vision. New York: McGraw-Hill, pp. 157-209. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Wittgenstein, L. 1953. Philosophical Investigations. Oxford: Oxford -\-> -->
<!-- <\!-- 	  University Press. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  EPILOGUE TO TRUE NAMES -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  <em>The Society of Mind</em> version of the epilogue to Vernor -\-> -->
<!-- <\!-- 	  Vinge&#39;s novel True Names. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Marvin Minsky October 1, 1984 -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  In real life, you often have to deal with things you don&#39;t -\-> -->
<!-- <\!-- 	  completely understand. You drive a car, not knowing how its engine -\-> -->
<!-- <\!-- 	  works.  You ride as passenger in someone else&#39;s car, not knowing -\-> -->
<!-- <\!-- 	  how that driver works. And strangest of all, you sometimes drive -\-> -->
<!-- <\!-- 	  yourself to work, not knowing how you work, yourself.  Then, how do -\-> -->
<!-- <\!-- 	  we manage to cope with things we don&#39;t understand?  And, how do -\-> -->
<!-- <\!-- 	  we ever understand anything in the first place? Almost always, I -\-> -->
<!-- <\!-- 	  think, by using analogies &mdash; by pretending that each alien -\-> -->
<!-- <\!-- 	  thing we see resembles something we already know. Whenever an -\-> -->
<!-- <\!-- 	  object&#39;s internal workings are too strange, complicated, or -\-> -->
<!-- <\!-- 	  unknown to deal with directly, we try to extract what parts of its -\-> -->
<!-- <\!-- 	  behavior seem familiar, and then represent them by familiar symbols -\-> -->
<!-- <\!-- 	  &mdash; that is, by the names of things we already know which we -\-> -->
<!-- <\!-- 	  think behave in similar ways. That way, we make each novelty at -\-> -->
<!-- <\!-- 	  least appear to be like something we already know from our own -\-> -->
<!-- <\!-- 	  pasts. It is a great idea, that use of symbols. It lets our minds -\-> -->
<!-- <\!-- 	  transform the strange into the commonplace. It is the same with -\-> -->
<!-- <\!-- 	  names.  For example, suppose that some architect invented a new way -\-> -->
<!-- <\!-- 	  to go from one place to another: a device which serves in some -\-> -->
<!-- <\!-- 	  respects the normal functions of a door, but one whose form and -\-> -->
<!-- <\!-- 	  mechanism is so entirely outside our past experience that, to see -\-> -->
<!-- <\!-- 	  it, we&#39;d never of think of it as a door, nor guess what purposes -\-> -->
<!-- <\!-- 	  to use it for. No matter: just superimpose, on its exterior, some -\-> -->
<!-- <\!-- 	  decoration which reminds one of a door. We could clothe it in -\-> -->
<!-- <\!-- 	  rectangular shape, add to it a waist-high knob, or push-plate, or a -\-> -->
<!-- <\!-- 	  sign, lettered EXIT in red and white, or do whatever else may seem -\-> -->
<!-- <\!-- 	  appropriate &mdash; and every visitor will know, without a conscious -\-> -->
<!-- <\!-- 	  thought, that pseudo-portal&#39;s purpose, and how to make it do its -\-> -->
<!-- <\!-- 	  job.  At first this idea may seem mere trickery. After all, this new -\-> -->
<!-- <\!-- 	  invention, which we decorate to look like a door, is not really a -\-> -->
<!-- <\!-- 	  door.  It is not at all like what we used to mean by door, to wit: -\-> -->
<!-- <\!-- 	  hinged, swinging slab of wood, cut into wall. The inner details are -\-> -->
<!-- <\!-- 	  all wrong.  Names and symbols, like analogies, are only partial -\-> -->
<!-- <\!-- 	  truths; they work by taking many-levelled descriptions of different -\-> -->
<!-- <\!-- 	  things and chopping off all of what seem the small details &mdash; -\-> -->
<!-- <\!-- 	  that is, the ones which matter least to our presently intended -\-> -->
<!-- <\!-- 	  purposes. But, still, what matters is that whatever symbol or icon, -\-> -->
<!-- <\!-- 	  token or sign we choose should remind us of the use we seek &mdash; -\-> -->
<!-- <\!-- 	  which, for that not-quite-door, should represent some way to go from -\-> -->
<!-- <\!-- 	  one place to another. Who cares how it works, so long as it works! -\-> -->
<!-- <\!-- 	  It does not even matter if that <em>door</em> leads to anywhere: in -\-> -->
<!-- <\!-- 	  TRUE NAMES, nothing ever leads anywhere; instead, the -\-> -->
<!-- <\!-- 	  protagonists&#39; bodies never move at all, but remain plugged-in to -\-> -->
<!-- <\!-- 	  the network while programs change their representations of the -\-> -->
<!-- <\!-- 	  simulated realities! -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Isn&#39;t it interesting how the ordinary brain lacks any real sense -\-> -->
<!-- <\!-- 	  of where it is! To be sure, most modern, educated people know that -\-> -->
<!-- <\!-- 	  thought proceeds inside the head &mdash; but that is something -\-> -->
<!-- <\!-- 	  brains don&#39;t know, unless they&#39;re told. In fact, without the -\-> -->
<!-- <\!-- 	  help of education, brains don&#39;t even know that brains -\-> -->
<!-- <\!-- 	  exist. Perhaps we tend to place the seat of thought behind the face, -\-> -->
<!-- <\!-- 	  because that&#39;s where so many sense-organs are located. And even -\-> -->
<!-- <\!-- 	  that impression is somewhat wrong: for example, the brain-centers -\-> -->
<!-- <\!-- 	  for vision are far away from the eyes, away in the very back of the -\-> -->
<!-- <\!-- 	  head, and no unaided brain would ever suspect this.  An icon&#39;s -\-> -->
<!-- <\!-- 	  job is not at all to represent the truth &mdash; that is, the truth -\-> -->
<!-- <\!-- 	  of how the designated object, or program, works. An icon&#39;s -\-> -->
<!-- <\!-- 	  purpose is, instead, to represent a way an object or a program can -\-> -->
<!-- <\!-- 	  be used! And, since the idea of a use is in the user&#39;s mind -\-> -->
<!-- <\!-- 	  &mdash; and not inside the thing, itself &mdash; the form and figure -\-> -->
<!-- <\!-- 	  of the icon must be suited to the symbols that the user has acquired -\-> -->
<!-- <\!-- 	  in it&#39;s own development. That is, it has to be connected to -\-> -->
<!-- <\!-- 	  whatever mental processes are already one&#39;s most fluent, -\-> -->
<!-- <\!-- 	  expressive, tools for expressing intentions.  This principle, of -\-> -->
<!-- <\!-- 	  choosing symbols and icons which express the functions of things -\-> -->
<!-- <\!-- 	  &mdash; or rather, their users&#39; intended attitudes toward them -\-> -->
<!-- <\!-- 	  &mdash; was already second nature to the designers of earliest fast- -\-> -->
<!-- <\!-- 	  interaction computer systems, namely, the early computer games. In -\-> -->
<!-- <\!-- 	  the 1970s the meaningful-icon idea was developed for personal -\-> -->
<!-- <\!-- 	  computers by Alan Kay&#39;s research group at Xerox, but it was only -\-> -->
<!-- <\!-- 	  in the early 1980s, after further work by Steven Jobs&#39; research -\-> -->
<!-- <\!-- 	  group at Apple Computer, that this concept entered the mainstream of -\-> -->
<!-- <\!-- 	  the computer revolution, in the body of the Macintosh computer. -\-> -->
<!-- <\!-- 	  There have also been a few less-publicized attempts to find iconic -\-> -->
<!-- <\!-- 	  ways to represent, rather than the programs uses, more information -\-> -->
<!-- <\!-- 	  about how the programs work, themselves. That would have value for -\-> -->
<!-- <\!-- 	  the different kind of enterprise, of making it easier for a -\-> -->
<!-- <\!-- 	  programmer to construct new programs by modifying old ones, by -\-> -->
<!-- <\!-- 	  making representations which reveal more about the program&#39;s -\-> -->
<!-- <\!-- 	  structures rather than their functions. Such attempts have been less -\-> -->
<!-- <\!-- 	  successful, on the whole, perhaps because one is forced to delve too -\-> -->
<!-- <\!-- 	  far inside the lower-level details of how the programs work.  But I -\-> -->
<!-- <\!-- 	  am convinced that the days of programming as we know it are -\-> -->
<!-- <\!-- 	  numbered, and that eventually we will construct large computer -\-> -->
<!-- <\!-- 	  systems not by anything resembling today&#39;s meticulous but -\-> -->
<!-- <\!-- 	  conceptually impoverished procedural specifications. Instead, -\-> -->
<!-- <\!-- 	  we&#39;ll express our intentions about what should be done, in -\-> -->
<!-- <\!-- 	  terms, or gestures, or examples, at least as resourceful as our -\-> -->
<!-- <\!-- 	  ordinary, everyday methods for expressing our wishes and -\-> -->
<!-- <\!-- 	  convictions. Then these expressions will be submitted to immense, -\-> -->
<!-- <\!-- 	  intelligent, intention- understanding programs which will themselves -\-> -->
<!-- <\!-- 	  construct the actual, new programs. We shall no longer be burdened -\-> -->
<!-- <\!-- 	  with the need to understand all the smaller details of how computer -\-> -->
<!-- <\!-- 	  codes work. All of that will be left to those great utility -\-> -->
<!-- <\!-- 	  programs, which will perform the arduous tasks of applying what we -\-> -->
<!-- <\!-- 	  have embodied in them, once and for all, of what we know about the -\-> -->
<!-- <\!-- 	  arts of lower-level programming.  Then, once we learn better ways to -\-> -->
<!-- <\!-- 	  tell computers what we want them to get done, we will be able to -\-> -->
<!-- <\!-- 	  return to the more familiar realm of expressing our own wants and -\-> -->
<!-- <\!-- 	  needs. For, in the end, no user really cares about how a program -\-> -->
<!-- <\!-- 	  works, but only about what it does &mdash; in the sense of the -\-> -->
<!-- <\!-- 	  intelligible effects it has on other things with which the user is -\-> -->
<!-- <\!-- 	  concerned.  In order for that to happen, though, we will have to -\-> -->
<!-- <\!-- 	  invent and learn to use new technologies for <em>expressing -\-> -->
<!-- <\!--             intentions.</em> To do this, we will have to break away from our -\-> -->
<!-- <\!-- 	  old, though still evolving, programming languages, which are useful -\-> -->
<!-- <\!-- 	  only for describing processes. But this brings with it some very -\-> -->
<!-- <\!-- 	  serious risks!  The first risk is that it is always dangerous to try -\-> -->
<!-- <\!-- 	  to relieve ourselves of the responsibility of understanding exactly -\-> -->
<!-- <\!-- 	  how our wishes will be realized &mdash; when we leave the choice of -\-> -->
<!-- <\!-- 	  means to any servants we may choose &mdash; no matter whether we -\-> -->
<!-- <\!-- 	  program them or not. For, the greater the range of possible methods -\-> -->
<!-- <\!-- 	  we leave to them, the more we expose ourselves, to accidents and -\-> -->
<!-- <\!-- 	  incidents in which we may not realize, perhaps until it is too late -\-> -->
<!-- <\!-- 	  to turn back, that our goals were misinterpreted, perhaps even -\-> -->
<!-- <\!-- 	  maliciously. We see this in such classic tales of fate as Faust, the -\-> -->
<!-- <\!-- 	  Sorcerer&#39;s Apprentice, or The Monkey&#39;s Paw (W.W. Jacobs).  A -\-> -->
<!-- <\!-- 	  second risk is exposure to the consequences of self-deception. It is -\-> -->
<!-- <\!-- 	  always tempting to say to oneself, when writing a program, or -\-> -->
<!-- <\!-- 	  writing an essay, or, for that matter, doing almost anything, -\-> -->
<!-- <\!-- 	  that <em>I know what I would like to happen, but I can&#39;t quite -\-> -->
<!-- <\!--             express it clearly enough.</em> However, that concept itself -\-> -->
<!-- <\!-- 	  reflects a too-simplistic self-image, which portrays one&#39;s own -\-> -->
<!-- <\!-- 	  self as existing, somewhere in the heart of one&#39;s mind (so to -\-> -->
<!-- <\!-- 	  speak), in the form of a pure, uncomplicated entity which has pure -\-> -->
<!-- <\!-- 	  and unmixed wishes, intentions, and goals. This pre-Freudian image -\-> -->
<!-- <\!-- 	  serves to excuse our frequent appearances of ambivalence; we -\-> -->
<!-- <\!-- 	  convince ourselves that clarifying our intentions is a mere matter -\-> -->
<!-- <\!-- 	  of straightening out the input-output channels between our inner and -\-> -->
<!-- <\!-- 	  outer selves. The trouble is, we simply aren&#39;t made that way, no -\-> -->
<!-- <\!-- 	  matter how we may wish we were.  The ultimate risk comes when we -\-> -->
<!-- <\!-- 	  greedy, lazy, master-minds are able at last to take that final step -\-> -->
<!-- <\!-- 	  &mdash; to design goal-achieving programs which are programmed to -\-> -->
<!-- <\!-- 	  make themselves grow increasingly powerful, by using learning and -\-> -->
<!-- <\!-- 	  self-evolution methods which augment and enhance their own -\-> -->
<!-- <\!-- 	  capabilities. It will be tempting to do this, not just for the gain -\-> -->
<!-- <\!-- 	  in power, but just to decrease our own human effort in the -\-> -->
<!-- <\!-- 	  consideration and formulation of our own desires. If some genie -\-> -->
<!-- <\!-- 	  offered you three wishes, would not your first one be, Tell me, -\-> -->
<!-- <\!-- 	  please, what is it that I want the most! The problem is that, with -\-> -->
<!-- <\!-- 	  such powerful machines, it would require but the slightest accident -\-> -->
<!-- <\!-- 	  of careless design for them to place their goals ahead of ours. The -\-> -->
<!-- <\!-- 	  machines goals may be allegedly benevolent, as with the robots of -\-> -->
<!-- <\!-- 	  With Folded Hands, by Jack Williamson, whose purpose is to protect -\-> -->
<!-- <\!-- 	  us from ourselves. It may be seemingly in our behalf, as in -\-> -->
<!-- <\!-- 	  Colossus, by D. H. Jones, who takes it on itself to save us from an -\-> -->
<!-- <\!-- 	  unsuspected enemy. In the case of Arthur C. Clarke&#39;s HAL, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  the machine we build decides that the mission we have given it is -\-> -->
<!-- <\!-- 	  one we cannot properly appreciate. And in Vernor Vinge&#39;s -\-> -->
<!-- <\!-- 	  computer- game fantasy, True Names, the dreaded Mailman (who -\-> -->
<!-- <\!-- 	  teletypes its messages because it cannot spare the time to don -\-> -->
<!-- <\!-- 	  disguises of dissimulated flesh) simply has ambitious motives of its -\-> -->
<!-- <\!-- 	  very own.  Can a human user build itself a second, larger Self -\-> -->
<!-- <\!-- 	  inside the machine? Is anything like that conceivable? And if it -\-> -->
<!-- <\!-- 	  were, then would those simulated computer-people be in any sense the -\-> -->
<!-- <\!-- 	  same as their humans models before them; would they be genuine -\-> -->
<!-- <\!-- 	  extensions of those real people? Or would they merely be new, -\-> -->
<!-- <\!-- 	  artificial, person-things which resemble their originals only -\-> -->
<!-- <\!-- 	  through some sort of structural coincidence? What would those -\-> -->
<!-- <\!-- 	  super-beings share with those whom they were based upon? To answer -\-> -->
<!-- <\!-- 	  that, we have to think more carefully about what those individuals -\-> -->
<!-- <\!-- 	  were before. -\-> -->
	  
<!-- <\!-- 	  SIMULATED PERSONALITIES. Would it be possible to duplicate the -\-> -->
<!-- <\!-- 	  character of a human person as another Self inside a machine? Is -\-> -->
<!-- <\!-- 	  anything like that conceivable? And if it were, then would those -\-> -->
<!-- <\!-- 	  simulated computer-people be in any sense the same, or genuine -\-> -->
<!-- <\!-- 	  extensions of those real people? Or would they merely be new, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  artificial, person-things which resemble their originals only -\-> -->
<!-- <\!-- 	  through some sort of structural coincidence? To answer that, we have -\-> -->
<!-- <\!-- 	  to think more carefully about what people are &mdash; about the -\-> -->
<!-- <\!-- 	  nature of our selves.  Inside every normal person&#39;s mind there -\-> -->
<!-- <\!-- 	  is a certain portion, which we call the Self, which uses symbols and -\-> -->
<!-- <\!-- 	  representations very much like the magical signs and symbols used by -\-> -->
<!-- <\!-- 	  sorcerers to work their spells. For do we not use magic -\-> -->
<!-- <\!-- 	  incantations, in much the same ways, to control those hosts of -\-> -->
<!-- <\!-- 	  systems within ourselves? How else could one do things one -\-> -->
<!-- <\!-- 	  doesn&#39;t understand?  To begin with, we humans know less about -\-> -->
<!-- <\!-- 	  the insides of our minds than we know about the outside world. Let -\-> -->
<!-- <\!-- 	  me spell that out: compared to what we understand about how real -\-> -->
<!-- <\!-- 	  objects work, we understand virtually nothing about what happens in -\-> -->
<!-- <\!-- 	  the great computers inside our brains. Doesn&#39;t it seem strange -\-> -->
<!-- <\!-- 	  that we can think, not knowing what it means to think? Isn&#39;t it -\-> -->
<!-- <\!-- 	  bizarre that we can get ideas, yet not be able to explain what ideas -\-> -->
<!-- <\!-- 	  are, or how they&#39;re found, or grown, or made? Isn&#39;t it -\-> -->
<!-- <\!-- 	  strange how often we can better understand what our friends do than -\-> -->
<!-- <\!-- 	  what we do ourselves?  Consider again, how, when you drive, you -\-> -->
<!-- <\!-- 	  guide the immense momentum of a car, not knowing how its engine -\-> -->
<!-- <\!-- 	  works, or how its steering-wheel directs the vehicle toward left or -\-> -->
<!-- <\!-- 	  right. Yet, when one comes to think of it, it is the same with our -\-> -->
<!-- <\!-- 	  own bodies; so far as conscious thought is concerned, the way you -\-> -->
<!-- <\!-- 	  operate your mind is very similar: you set yourself in a certain -\-> -->
<!-- <\!-- 	  goal-direction &mdash; much as though to turn a mental steering -\-> -->
<!-- <\!-- 	  wheel to set a course for your thoughts to take. All you are aware -\-> -->
<!-- <\!-- 	  of is some general intention &mdash; It&#39;s time to go: where is -\-> -->
<!-- <\!-- 	  the door?  &mdash; and all the rest takes care of itself. But did -\-> -->
<!-- <\!-- 	  you ever consider the complicated processes involved in such an -\-> -->
<!-- <\!-- 	  ordinary act as, when you walk, to change the direction you&#39;re -\-> -->
<!-- <\!-- 	  going in? It is not just a matter of, say, taking a larger or -\-> -->
<!-- <\!-- 	  smaller step on one side, the way one changes course when rowing a -\-> -->
<!-- <\!-- 	  boat. If that were all you did, when walking, you would tip over and -\-> -->
<!-- <\!-- 	  fall toward the outside of the turn.  Try this experiment: watch -\-> -->
<!-- <\!-- 	  yourself carefully while turning &mdash; and you&#39;ll notice that, -\-> -->
<!-- <\!-- 	  before you start the turn, you tip yourself in advance; this makes -\-> -->
<!-- <\!-- 	  you start to fall toward the inside of the turn; then, when you -\-> -->
<!-- <\!-- 	  catch yourself on the next step, you end up moving in a different -\-> -->
<!-- <\!-- 	  direction. When we examine that more closely, it all turns out to be -\-> -->
<!-- <\!-- 	  dreadfully complicated: hundreds of interconnected muscles, bones, -\-> -->
<!-- <\!-- 	  and joints are all controlled simultaneously, by interacting -\-> -->
<!-- <\!-- 	  programs which locomotion-scientists still barely comprehend. Yet -\-> -->
<!-- <\!-- 	  all your conscious mind need do, or say, or think, is Go that way! -\-> -->
<!-- <\!-- 	  &mdash; assuming that it makes sense to speak of the conscious mind -\-> -->
<!-- <\!-- 	  as thinking anything at all. So far as one can see, we guide the -\-> -->
<!-- <\!-- 	  vast machines inside ourselves, not by using technical and -\-> -->
<!-- <\!-- 	  insightful schemes based on knowing how the underlying mechanisms -\-> -->
<!-- <\!-- 	  work, but by tokens, signs, and symbols which are entirely as -\-> -->
<!-- <\!-- 	  fanciful as those of Vinge&#39;s sorcery. It even makes one wonder -\-> -->
<!-- <\!-- 	  if it&#39;s fair for us to gain our ends by casting spells upon our -\-> -->
<!-- <\!-- 	  helpless hordes of mental under-thralls.  Now, if we take this only -\-> -->
<!-- <\!-- 	  one more step, we see that, just as we walk without thinking, we -\-> -->
<!-- <\!-- 	  also think without thinking! That is, we just as casually exploit -\-> -->
<!-- <\!-- 	  the agencies which carry out our mental work.  Suppose you have a -\-> -->
<!-- <\!-- 	  hard problem. You think about it for a while; then after a time you -\-> -->
<!-- <\!-- 	  find a solution. Perhaps the answer comes to you suddenly; you get -\-> -->
<!-- <\!-- 	  an idea and say, Aha, I&#39;ve got it. I&#39;ll do such and -\-> -->
<!-- <\!-- 	  such. But then, were someone to ask how you did it, how you found -\-> -->
<!-- <\!-- 	  the solution, you simply would not know how to reply. People usually -\-> -->
<!-- <\!-- 	  are able to say only things like this: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  <em>I suddenly realized . . .</em> -\-> -->
<!-- <\!-- 	  <em>I just got this idea . . .</em> -\-> -->
<!-- <\!-- 	  <em>It occurred to me that . . . </em> -\-> -->
<!-- <\!-- 	  <em>It came to me . . .</em> -\-> -->
	  
<!-- <\!-- 	  If people really knew how their minds work, we wouldn&#39;t so often -\-> -->
<!-- <\!-- 	  act on motives which we don&#39;t suspect, nor would we have such -\-> -->
<!-- <\!-- 	  varied theories in Psychology. Why, when we&#39;re asked how people -\-> -->
<!-- <\!-- 	  come upon their good ideas, are we reduced to superficial -\-> -->
<!-- <\!-- 	  reproductive metaphors, to talk about <em>conceiving</em> -\-> -->
<!-- <\!-- 	  or <em>gestating,</em> or even <em>giving birth</em> to thoughts? We -\-> -->
<!-- <\!-- 	  even speak of <em>ruminating</em> or <em>digesting</em> &mdash; as -\-> -->
<!-- <\!-- 	  though the mind were anywhere but in the head. And, worst of all, we -\-> -->
<!-- <\!-- 	  see ourselves as set adrift upon some chartless mental sea, with -\-> -->
<!-- <\!-- 	  minds like floating nets which wait to catch whatever sudden -\-> -->
<!-- <\!-- 	  thought-fish may get trapped inside! If we could see inside our -\-> -->
<!-- <\!-- 	  minds we&#39;d surely say more useful things than <em>Wait. I&#39;m -\-> -->
<!-- <\!--             thinking.</em>  People frequently tell me that they&#39;re -\-> -->
<!-- <\!-- 	  absolutely certain that no computer could ever be sentient, -\-> -->
<!-- <\!-- 	  conscious, self-willed, or in any other way <em>aware</em> of -\-> -->
<!-- <\!-- 	  itself. They&#39;re often shocked when I ask back what makes them -\-> -->
<!-- <\!-- 	  sure that they, themselves, possess these admirable qualities. The -\-> -->
<!-- <\!-- 	  reply is that, if they&#39;re sure of anything at all, it is that -\-> -->
<!-- <\!-- 	  I&#39;m aware &mdash; hence I&#39;m aware.  Yet, what do such -\-> -->
<!-- <\!-- 	  convictions really mean? Since <em>Self-awareness</em> ought to be -\-> -->
<!-- <\!-- 	  an awareness of what&#39;s going on within one&#39;s mind, no -\-> -->
<!-- <\!-- 	  realist could maintain for long that people really have much -\-> -->
<!-- <\!-- 	  insight, in the literal sense of seeing-in.  Isn&#39;t it remarkable -\-> -->
<!-- <\!-- 	  how certainly we feel that we&#39;re self-aware &mdash; that we have -\-> -->
<!-- <\!-- 	  such broad abilities to know what&#39;s happening inside ourselves? -\-> -->
<!-- <\!-- 	  The evidence for that is weak, indeed. It is true that some people -\-> -->
<!-- <\!-- 	  seem to have special excellences, which we sometimes call -\-> -->
<!-- <\!-- 	  <em>insights,</em> for assessing the attitudes and motivations of -\-> -->
<!-- <\!-- 	  other people. And certain individuals even sometimes make good -\-> -->
<!-- <\!-- 	  evaluations of themselves. But that doesn&#39;t justify our using -\-> -->
<!-- <\!-- 	  names like insight or self-awareness for such abilities. Why not -\-> -->
<!-- <\!-- 	  simply call them <em>person-sights</em> -\-> -->
<!-- <\!-- 	  or <em>person-awarenesses?</em> Is there really reason to suppose -\-> -->
<!-- <\!-- 	  that skills like these are very different from the ways we learn the -\-> -->
<!-- <\!-- 	  other kinds of things we learn? Instead of seeing them -\-> -->
<!-- <\!-- 	  as <em>seeing-in,</em> we could regard them as quite the opposite: -\-> -->
<!-- <\!-- 	  just one more way of <em>figuring out.</em> Perhaps we learn about -\-> -->
<!-- <\!-- 	  ourselves the same ways that we learn about un-self-ish things. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The fact is, the parts of ourselves which we -\-> -->
<!-- <\!-- 	  call <em>self-aware</em> are only a small fraction of the entire -\-> -->
<!-- <\!-- 	  mind. They work by building simulated worlds of their own &mdash; -\-> -->
<!-- <\!-- 	  worlds which are greatly simplified, in comparison with either the -\-> -->
<!-- <\!-- 	  real world outside, or with the immense computer systems inside the -\-> -->
<!-- <\!-- 	  brain: systems which no one can pretend, today, to understand. And -\-> -->
<!-- <\!-- 	  our worlds of simulated awareness are worlds of simple magic, -\-> -->
<!-- <\!-- 	  wherein each and every imagined object is invested with meanings and -\-> -->
<!-- <\!-- 	  purposes. Consider how one can scarcely but see a hammer except as -\-> -->
<!-- <\!-- 	  something to hammer with, or see a ball except as something to throw -\-> -->
<!-- <\!-- 	  and catch. Why are we so constrained to perceive things, not as they -\-> -->
<!-- <\!-- 	  are, but as they can be used? Because the highest levels of our mind -\-> -->
<!-- <\!-- 	  are goal-directed problem-solvers.  That is to say that all the -\-> -->
<!-- <\!-- 	  machines inside our heads evolved, originally, to meet various -\-> -->
<!-- <\!-- 	  built-in or acquired needs, for comfort and nutrition, for defense -\-> -->
<!-- <\!-- 	  and for reproduction. Later, over the past few million years, we -\-> -->
<!-- <\!-- 	  evolved even more powerful sub-machines which, in ways we don&#39;t -\-> -->
<!-- <\!-- 	  yet understand, seem to correlate and analyze to discover which -\-> -->
<!-- <\!-- 	  kinds of actions cause which sorts of effects; in a word, to -\-> -->
<!-- <\!-- 	  discover what we call knowledge. And though we often like to think -\-> -->
<!-- <\!-- 	  that knowledge is abstract, and that our search for it is pure and -\-> -->
<!-- <\!-- 	  good in itself &mdash; still, we ultimately use it for its ability -\-> -->
<!-- <\!-- 	  to tell us what to do to to gain whichever ends we seek (even when -\-> -->
<!-- <\!-- 	  we conclude that in order to do that, we may first need to gain yet -\-> -->
<!-- <\!-- 	  more and more knowledge). Thus, because, as we say, <em>knowledge is -\-> -->
<!-- <\!--             power,</em> our knowledge itself is enmeshed in those webs of ways -\-> -->
<!-- <\!-- 	  we reach our goals. And that&#39;s the key: it isn&#39;t any use for -\-> -->
<!-- <\!-- 	  us to know, unless our knowledge tells us what to do. This is so -\-> -->
<!-- <\!-- 	  wrought into the conscious mind&#39;s machinery that it seems -\-> -->
<!-- <\!-- 	  foolishness to say it: no knowledge is of any use unless we have a -\-> -->
<!-- <\!-- 	  use for it.  Now we come to the point of consciousness: it is the -\-> -->
<!-- <\!-- 	  part of the mind most specialized for knowing how to use the other -\-> -->
<!-- <\!-- 	  systems which lie hidden in the mind. But it is not a specialist in -\-> -->
<!-- <\!-- 	  knowing how those systems actually work, inside -\-> -->
<!-- <\!-- 	  themselves. Sometimes, of course, it pays to know such things: if -\-> -->
<!-- <\!-- 	  you know how something works then you&#39;ll be better at repairing -\-> -->
<!-- <\!-- 	  it when it breaks; furthermore, the better you understand a -\-> -->
<!-- <\!-- 	  mechanism, the easier to find new ways to adapt it to other -\-> -->
<!-- <\!-- 	  purposes.  Thus, a person who sustains an injured leg may begin, for -\-> -->
<!-- <\!-- 	  the first time, consciously to make theories about how walking -\-> -->
<!-- <\!-- 	  works: To turn to the left, I&#39;ll have to push myself that way -\-> -->
<!-- <\!-- 	  &mdash; and then one has to figure out, with what? Similarly, when -\-> -->
<!-- <\!-- 	  we&#39;re forced to face an unusually hard problem, we sometimes -\-> -->
<!-- <\!-- 	  become more reflective, and try to understand something of how the -\-> -->
<!-- <\!-- 	  rest of the mind ordinarily solves problems; at such times one finds -\-> -->
<!-- <\!-- 	  oneself saying such things as, Now I must get organized. Why -\-> -->
<!-- <\!-- 	  can&#39;t I concentrate on the important questions and not get -\-> -->
<!-- <\!-- 	  distracted by those other inessential details?  Paradoxically, it is -\-> -->
<!-- <\!-- 	  often at those very moments &mdash; the times when our minds come -\-> -->
<!-- <\!-- 	  closer than usual to comprehending how they themselves work, and we -\-> -->
<!-- <\!-- 	  perhaps succeed in engaging what little knowledge we do have about -\-> -->
<!-- <\!-- 	  our own mechanisms, so that we can alter or repair them &mdash; -\-> -->
<!-- <\!-- 	  paradoxically, these are often just the times when, consciously, we -\-> -->
<!-- <\!-- 	  think our mental processes are not working so well and, as we say, -\-> -->
<!-- <\!-- 	  we feel <em>confused.</em> Nonetheless, even these -\-> -->
<!-- <\!-- 	  more <em>conscious</em> attempts at self-inspection still remain -\-> -->
<!-- <\!-- 	  mostly confined to the pragmatic, magic world of symbol-signs. No -\-> -->
<!-- <\!-- 	  human being seems ever to have succeeded in using self-analysis to -\-> -->
<!-- <\!-- 	  discover much about how the programs underneath might really work. -\-> -->
<!-- <\!-- 	  I say again that we, too, drive ourselves &mdash; our minds, our -\-> -->
<!-- <\!-- 	  cars, our bodies and our games &mdash; the self-same ways. The -\-> -->
<!-- <\!-- 	  players of our computer-game machines control and guide what happens -\-> -->
<!-- <\!-- 	  in their great machines: by using symbols, spells and images &mdash; -\-> -->
<!-- <\!-- 	  as well as secret, private names. And we, ourselves &mdash; that is, -\-> -->
<!-- <\!-- 	  the parts of us that we call <em>consciousness</em> &mdash; do very -\-> -->
<!-- <\!-- 	  much the same: in effect, we sit in front of mental -\-> -->
<!-- <\!-- 	  computer-terminals, attempting to steer and guide the great unknown -\-> -->
<!-- <\!-- 	  engines of the mind, not by understanding how those engines work, -\-> -->
<!-- <\!-- 	  but just by selecting simple names from menu-lists of symbols which -\-> -->
<!-- <\!-- 	  appear, from time to time, upon our mental screen-displays.  But -\-> -->
<!-- <\!-- 	  really, when one thinks of it, it scarcely could be otherwise! -\-> -->
<!-- <\!-- 	  Consider what would happen if our minds indeed could really see -\-> -->
<!-- <\!-- 	  inside themselves. What could possibly be worse than to be presented -\-> -->
<!-- <\!-- 	  with a clear view of the trillion-wire networks of our nerve-cell -\-> -->
<!-- <\!-- 	  connections? Our scientists have peered at those structures for -\-> -->
<!-- <\!-- 	  years with powerful microscopes, yet failed to come up with -\-> -->
<!-- <\!-- 	  comprehensive theories of what those networks do and how.  What -\-> -->
<!-- <\!-- 	  about the claims of mystical thinkers that there are other, better -\-> -->
<!-- <\!-- 	  ways to see the mind? One way they recommend is learning how to -\-> -->
<!-- <\!-- 	  train the conscious mind to stop its usual sorts of thoughts and -\-> -->
<!-- <\!-- 	  then attempt (by holding very still) to see and hear the fine -\-> -->
<!-- <\!-- 	  details of mental life. Would that be any different, or better, than -\-> -->
<!-- <\!-- 	  seeing them through instruments? Perhaps &mdash; except that it -\-> -->
<!-- <\!-- 	  doesn&#39;t face the fundamental problem of how to understand a -\-> -->
<!-- <\!-- 	  complicated thing! For, if we suspend our usual ways of thinking, -\-> -->
<!-- <\!-- 	  we&#39;ll be bereft of all the parts of mind already trained to -\-> -->
<!-- <\!-- 	  interpret complicated phenomena. Anyway, even if one could observe -\-> -->
<!-- <\!-- 	  and detect the signals which emerge from other, normally -\-> -->
<!-- <\!-- 	  inaccessible portions of the mind, these would probably make no -\-> -->
<!-- <\!-- 	  sense to the systems involved with consciousness. To see why not, -\-> -->
<!-- <\!-- 	  let&#39;s return once more to understanding such simple things as -\-> -->
<!-- <\!-- 	  how we walk.  Suppose that, when you walk about, you were indeed -\-> -->
<!-- <\!-- 	  able to see and hear the signals in your spinal chord and lower -\-> -->
<!-- <\!-- 	  brain. Would you be able to make any sense of them? Perhaps, but not -\-> -->
<!-- <\!-- 	  easily. Indeed, it is easy to do such experiments, using simple -\-> -->
<!-- <\!-- 	  bio-feedback devices to make those signals audible and visible; the -\-> -->
<!-- <\!-- 	  result is that one may indeed more quickly learn to perform a new -\-> -->
<!-- <\!-- 	  skill, such as better using an injured limb. However, just as -\-> -->
<!-- <\!-- 	  before, this does not appear to work through gaining a conscious -\-> -->
<!-- <\!-- 	  understanding of how those circuits work; instead the experience is -\-> -->
<!-- <\!-- 	  very much like business as usual; we gain control by acquiring just -\-> -->
<!-- <\!-- 	  one more form of semi-conscious symbol-magic. Presumably what -\-> -->
<!-- <\!-- 	  happens is that a new control system is assembled somewhere in the -\-> -->
<!-- <\!-- 	  nervous system, and interfaced with superficial signals we can know -\-> -->
<!-- <\!-- 	  about. However, bio-feedback does not appear to provide any -\-> -->
<!-- <\!-- 	  different insights into how learning works than do our ordinary, -\-> -->
<!-- <\!-- 	  built-in senses.  In any case, our locomotion-scientists have been -\-> -->
<!-- <\!-- 	  tapping such signals for decades, using electronic -\-> -->
<!-- <\!-- 	  instruments. Using that data, they have been able to develop various -\-> -->
<!-- <\!-- 	  partial theories about the kinds of interactions and -\-> -->
<!-- <\!-- 	  regulation-systems which are involved.  However, these theories have -\-> -->
<!-- <\!-- 	  not emerged from relaxed meditation about, or passive observation -\-> -->
<!-- <\!-- 	  of, those complicated biological signals; what little we have -\-> -->
<!-- <\!-- 	  learned has come from deliberate and intense exploitation of the -\-> -->
<!-- <\!-- 	  accumulated discoveries of three centuries of our scientists&#39; -\-> -->
<!-- <\!-- 	  and mathematicians&#39; study of analytical mechanics and a century -\-> -->
<!-- <\!-- 	  of newer theories about servo-control engineering. It is generally -\-> -->
<!-- <\!-- 	  true in science that mere observational <em>insights</em> rarely -\-> -->
<!-- <\!-- 	  lead to new understandings. One must first have some glimmerings of -\-> -->
<!-- <\!-- 	  the form of some new theory, or of a novel method for describing -\-> -->
<!-- <\!-- 	  processes: one needs a <em>new idea.</em> Some other avenue must -\-> -->
<!-- <\!-- 	  supply new magic tokens for us to use to represent -\-> -->
<!-- <\!-- 	  the <em>causes</em> and the -\-> -->
<!-- <\!-- 	  <em>purposes</em> of those phenomena. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  But where do we get the new ideas we need? For any single -\-> -->
<!-- <\!-- 	  individual, of course, most concepts come from the societies and -\-> -->
<!-- <\!-- 	  cultures that one grows up in. As for the rest of our ideas, the -\-> -->
<!-- <\!-- 	  ones we -\-> -->
<!-- <\!-- 	  <em>get</em> all by ourselves, these, too, come from societies -\-> -->
<!-- <\!-- 	  &mdash; but, now, the ones inside our individual minds. For, a human -\-> -->
<!-- <\!-- 	  mind is not in any real sense a single entity, nor does a brain have -\-> -->
<!-- <\!-- 	  a single, central way to work. Brains do not secrete thought the way -\-> -->
<!-- <\!-- 	  livers secrete bile; a brain consists of a huge assembly of -\-> -->
<!-- <\!-- 	  different sorts of sub-machines parts which each do different kinds -\-> -->
<!-- <\!-- 	  of jobs &mdash; each useful to some other parts. For example, we use -\-> -->
<!-- <\!-- 	  distinct sections of the brain for hearing the sounds of words, as -\-> -->
<!-- <\!-- 	  opposed to recognizing other kinds of natural sounds or musical -\-> -->
<!-- <\!-- 	  pitches. There is even solid evidence that there is a special part -\-> -->
<!-- <\!-- 	  of the brain which is specialized for seeing and recognizing faces, -\-> -->
<!-- <\!-- 	  as opposed to visual perception of other, ordinary things. I suspect -\-> -->
<!-- <\!-- 	  that there are, inside the cranium, perhaps as many as a hundred -\-> -->
<!-- <\!-- 	  different kinds of computers, each with a somewhat different basic -\-> -->
<!-- <\!-- 	  architecture; these have been accumulating over the past four -\-> -->
<!-- <\!-- 	  hundred million years of our evolution. They are wired together into -\-> -->
<!-- <\!-- 	  a great multi-resource network of specialists, in which each section -\-> -->
<!-- <\!-- 	  knows how to call on certain other sections to get things done which -\-> -->
<!-- <\!-- 	  serve their purposes. And each sub-system uses different styles of -\-> -->
<!-- <\!-- 	  programming, and different forms of representations; there is no -\-> -->
<!-- <\!-- 	  standard language-code.  Accordingly, if one part of that Society of -\-> -->
<!-- <\!-- 	  Mind were to inquire about another part, the two would most likely -\-> -->
<!-- <\!-- 	  turn out to use substantially different languages and -\-> -->
<!-- <\!-- 	  architectures. In such a case, if A were to ask B a question about -\-> -->
<!-- <\!-- 	  how it works, then how could B understand that question, and how -\-> -->
<!-- <\!-- 	  could A understand the answer?  Communication is often difficult -\-> -->
<!-- <\!-- 	  enough between two different human tongues. But the signals used by -\-> -->
<!-- <\!-- 	  the different portions of the human mind are even less likely to be -\-> -->
<!-- <\!-- 	  even remotely as similar as two human dialects with -\-> -->
<!-- <\!-- 	  sometimes-corresponding roots. More likely, they are simply too -\-> -->
<!-- <\!-- 	  different to communicate at all &mdash; except through symbols which -\-> -->
<!-- <\!-- 	  initiate their use.  Now, one might ask, Then, how do people doing -\-> -->
<!-- <\!-- 	  different jobs communicate, when they have different backgrounds, -\-> -->
<!-- <\!-- 	  thoughts, and purposes? The answer is that this problem is easier, -\-> -->
<!-- <\!-- 	  because a person knows so much more than do the smaller fragment of -\-> -->
<!-- <\!-- 	  that person&#39;s mind. And, besides, we all are raised in similar -\-> -->
<!-- <\!-- 	  ways, and this provides a solid base of common knowledge. But, even -\-> -->
<!-- <\!-- 	  so, we overestimate how well we actually communicate.  The many jobs -\-> -->
<!-- <\!-- 	  that people do may seem different on the surface, but they are all -\-> -->
<!-- <\!-- 	  very much the same, to the extent that they all have a common base -\-> -->
<!-- <\!-- 	  in what we like to call <em>common sense</em> &mdash; that is, the -\-> -->
<!-- <\!-- 	  knowledge shared by all of us. This means that we do not really need -\-> -->
<!-- <\!-- 	  to tell each other as much as we suppose. Often, when we -\-> -->
<!-- <\!-- 	  <em>explain</em> something, we scarcely explain anything new at all; -\-> -->
<!-- <\!-- 	  instead, we merely show some examples of what we mean, and some -\-> -->
<!-- <\!-- 	  non-examples; these indicate to the listener how to link up various -\-> -->
<!-- <\!-- 	  structures already known. In short, we often just -\-> -->
<!-- <\!-- 	  tell <em>which</em> instead of <em>what.</em>  Consider how poorly -\-> -->
<!-- <\!-- 	  people can communicate about so many seemingly simple things. We -\-> -->
<!-- <\!-- 	  can&#39;t say how we balance on a bicycle, or how we tell a shadow -\-> -->
<!-- <\!-- 	  from a real thing, or, even how one fetches facts from -\-> -->
<!-- <\!-- 	  memory. Again, one might complain, It isn&#39;t fair to complain -\-> -->
<!-- <\!-- 	  about our inability to express things about things like seeing or -\-> -->
<!-- <\!-- 	  balancing or remembering. Those are things we learned before we even -\-> -->
<!-- <\!-- 	  learned to speak! But, though that criticism is fair in some -\-> -->
<!-- <\!-- 	  respects, it also illustrates how hard communication must be for all -\-> -->
<!-- <\!-- 	  the sub-parts of the mind which never learned to talk at all &mdash; -\-> -->
<!-- <\!-- 	  and these are most of what we are. The idea of <em>meaning</em> -\-> -->
<!-- <\!-- 	  itself is really a matter of size and scale: it only makes sense to -\-> -->
<!-- <\!-- 	  ask what something means in a system which is large enough to have -\-> -->
<!-- <\!-- 	  many meanings. In very small systems, the idea of something having a -\-> -->
<!-- <\!-- 	  meaning becomes as vacuous as saying that a brick is a very small -\-> -->
<!-- <\!-- 	  house.  Now it is easy enough to say that the mind is a society, but -\-> -->
<!-- <\!-- 	  that idea by itself is useless unless we can say more about how it -\-> -->
<!-- <\!-- 	  is organized. If all those specialized parts were equally -\-> -->
<!-- <\!-- 	  competitive, there would be only anarchy, and the more we learned, -\-> -->
<!-- <\!-- 	  the less we&#39;d be able to do. So there must be some kind of -\-> -->
<!-- <\!-- 	  administration, perhaps organized roughly in hierarchies, like the -\-> -->
<!-- <\!-- 	  divisions and subdivisions of an industry or of a human political -\-> -->
<!-- <\!-- 	  society. What would those levels do? In all the large societies we -\-> -->
<!-- <\!-- 	  know which work efficiently, the lower levels exercise the more -\-> -->
<!-- <\!-- 	  specialized working skills, while the higher levels are concerned -\-> -->
<!-- <\!-- 	  with longer-range plans and goals. And this is another fundamental -\-> -->
<!-- <\!-- 	  reason why it is so hard to translate between our conscious and -\-> -->
<!-- <\!-- 	  unconscious thoughts! The kinds of terms and symbols we use on the -\-> -->
<!-- <\!-- 	  conscious level are primarily for expressing our goals and plans for -\-> -->
<!-- <\!-- 	  using what we believe we can do &mdash; while the workings of those -\-> -->
<!-- <\!-- 	  lower level resources are represented in unknown languages of -\-> -->
<!-- <\!-- 	  process and mechanism. So when our conscious probes try to descend -\-> -->
<!-- <\!-- 	  into the myriads of smaller and smaller sub-machines which make the -\-> -->
<!-- <\!-- 	  mind, they encounter alien representations, used for increasingly -\-> -->
<!-- <\!-- 	  specialized purposes.  Why is it so hard to translate between -\-> -->
<!-- <\!-- 	  conscious and unconscious thoughts? Because their languages are so -\-> -->
<!-- <\!-- 	  different. The kinds of terms and symbols we use on the conscious -\-> -->
<!-- <\!-- 	  level are primarily for expressing choices between, and uses of, -\-> -->
<!-- <\!-- 	  things we know &mdash; but those things, themselves, are represented -\-> -->
<!-- <\!-- 	  in very different ways. Furthermore, as we descend into the myriads -\-> -->
<!-- <\!-- 	  of smaller and smaller sub-machines which make the mind, the -\-> -->
<!-- <\!-- 	  representations they use for their concerns become more and more -\-> -->
<!-- <\!-- 	  specialized; that is, they must use smaller and smaller -\-> -->
<!-- <\!-- 	  inner <em>languages</em> &mdash; and that makes special problems of -\-> -->
<!-- <\!-- 	  a different sort.  The trouble is, these tiny -\-> -->
<!-- <\!-- 	  inner <em>languages</em> soon become incomprehensible, for a reason -\-> -->
<!-- <\!-- 	  which is simple and inescapable. This is not the same as the -\-> -->
<!-- <\!-- 	  familiar difficulty of translating between two different human -\-> -->
<!-- <\!-- 	  languages; we understand the nature of that problem: it is that -\-> -->
<!-- <\!-- 	  human languages are so huge and rich that it is hard to narrow -\-> -->
<!-- <\!-- 	  meanings down: we call that <em>ambiguity.</em> But, when we try to -\-> -->
<!-- <\!-- 	  understand the tiny languages at the lowest levels of the mind, we -\-> -->
<!-- <\!-- 	  have the opposite problem &mdash; because the smaller the two -\-> -->
<!-- <\!-- 	  languages, the harder it will be to translate between them, not -\-> -->
<!-- <\!-- 	  because there are too many meanings but too few. The fewer things -\-> -->
<!-- <\!-- 	  two systems do, the less likely that something one of them can do -\-> -->
<!-- <\!-- 	  will correspond to anything at all the other one can do. And then, -\-> -->
<!-- <\!-- 	  no translation is possible. Why is this worse than when there is -\-> -->
<!-- <\!-- 	  much ambiguity?  Because, although that problem seems very hard, -\-> -->
<!-- <\!-- 	  still, even when a problem seems hopelessly complicated, there -\-> -->
<!-- <\!-- 	  always can be hope. But, when a problem is hopelessly simple, there -\-> -->
<!-- <\!-- 	  can&#39;t be any hope at all!  Now, finally, let&#39;s return to the -\-> -->
<!-- <\!-- 	  question of how much a simulated life inside a world inside a -\-> -->
<!-- <\!-- 	  machine could be like our ordinary, real life, <em>out here</em>? My -\-> -->
<!-- <\!-- 	  answer, as you know by now, is that it could be very much the same -\-> -->
<!-- <\!-- 	  &mdash; since we, ourselves, as we&#39;ve seen, already exist as -\-> -->
<!-- <\!-- 	  processes imprisoned in machines inside machines! Our mental worlds -\-> -->
<!-- <\!-- 	  are already filled with wondrous, magical, symbol-signs, which add -\-> -->
<!-- <\!-- 	  to everything we <em>see</em> a meaning and significance. In fact, -\-> -->
<!-- <\!-- 	  all educated people have already learned how different are our -\-> -->
<!-- <\!-- 	  mental worlds than the <em>real world</em> our scientists talk -\-> -->
<!-- <\!-- 	  about. All educated people already know how different is our mental -\-> -->
<!-- <\!-- 	  world than the <em>real world</em> our scientists know.  Consider -\-> -->
<!-- <\!-- 	  the table in your dining room: &mdash; your conscious mind sees it -\-> -->
<!-- <\!-- 	  as having familiar functions, forms, ands purposes. A table is <em>a -\-> -->
<!-- <\!--             thing to put things on.</em> However, our science tells us that this -\-> -->
<!-- <\!-- 	  is only in the mind; the only thing that&#39;s <em>really there</em> -\-> -->
<!-- <\!-- 	  is a society of countless molecules; the table seems to hold its -\-> -->
<!-- <\!-- 	  shape only because some of those molecules are constrained to -\-> -->
<!-- <\!-- 	  vibrate near one another, because of certain properties of the -\-> -->
<!-- <\!-- 	  force-fields which keep them from pursuing independent -\-> -->
<!-- <\!-- 	  courses. Similarly, when you hear a spoken word, your mind -\-> -->
<!-- <\!-- 	  attributes sense and meaning to that sound &mdash; whereas, in -\-> -->
<!-- <\!-- 	  physics, the word is merely a fluctuating pressure on your ear, -\-> -->
<!-- <\!-- 	  caused by the collisions of myriads of molecules of air &mdash; that -\-> -->
<!-- <\!-- 	  is, of particles whose distances, this time are less constrained. -\-> -->
<!-- <\!-- 	  And so &mdash; let&#39;s face it now, once and for all: each one of -\-> -->
<!-- <\!-- 	  us already has experienced what it is like to be simulated by a -\-> -->
<!-- <\!-- 	  computer!  Ridiculous, most people say, at first: I certainly -\-> -->
<!-- <\!-- 	  don&#39;t feel like a machine!  But what makes us so sure of that? -\-> -->
<!-- <\!-- 	  How could one claim to know how something feels, until one has -\-> -->
<!-- <\!-- 	  experienced it? Consider that either you are a machine or you&#39;re -\-> -->
<!-- <\!-- 	  not. Then, if, as you say, you aren&#39;t a machine, then you are -\-> -->
<!-- <\!-- 	  scarcely in any position of authority to say how it feels to be a -\-> -->
<!-- <\!-- 	  machine.  Very well, but, surely then, if I were a machine, then at -\-> -->
<!-- <\!-- 	  least I would be in a position to know that!  Hah. That is a -\-> -->
<!-- <\!-- 	  typically human, thoughtless presumption. It amounts to claiming -\-> -->
<!-- <\!-- 	  that, <em>I think, therefore I know how thinking works.</em> But as -\-> -->
<!-- <\!-- 	  we&#39;ve seen, there are so many levels of machinery between our -\-> -->
<!-- <\!-- 	  conscious thoughts and how they&#39;re made that to say such a thing -\-> -->
<!-- <\!-- 	  is as absurd as to say, <em>I drive, therefore I know how engines -\-> -->
<!-- <\!--             work!</em>  Still, even if the brain is a kind of computer, you must -\-> -->
<!-- <\!-- 	  admit that its scale is unimaginably large. A human brain contains -\-> -->
<!-- <\!-- 	  many billions of brain cells &mdash; and, probably, each cell is -\-> -->
<!-- <\!-- 	  extremely complicated by itself.  Then, each cell is interlinked in -\-> -->
<!-- <\!-- 	  complicated ways to thousands or millions of other cells. You can -\-> -->
<!-- <\!-- 	  use the word machine for that but, surely, no one could ever build -\-> -->
<!-- <\!-- 	  anything of that magnitude!  I am entirely sympathetic with the -\-> -->
<!-- <\!-- 	  spirit of this objection. When one is compared to a machine, one -\-> -->
<!-- <\!-- 	  feels belittled, as though one is being regarded as trivial. And, -\-> -->
<!-- <\!-- 	  indeed, such a comparison is truly insulting &mdash; so long as the -\-> -->
<!-- <\!-- 	  name <em>machine</em> still carries the same meaning it had in times -\-> -->
<!-- <\!-- 	  gone by. For thousands of years, we have used such words to arouse -\-> -->
<!-- <\!-- 	  images of pulleys, levers, locomotives, typewriters, and simple -\-> -->
<!-- <\!-- 	  other sorts of things; similarly, in modern times, the -\-> -->
<!-- <\!-- 	  word <em>computer</em> has evoked thoughts about adding and -\-> -->
<!-- <\!-- 	  subtracting digits, and storing them unchanged in tiny -\-> -->
<!-- <\!-- 	  so-called <em>memories.</em> However those words no longer serve our -\-> -->
<!-- <\!-- 	  new purposes, to describe machines that think like us; for such -\-> -->
<!-- <\!-- 	  uses, those old terms have become false names for what we want to -\-> -->
<!-- <\!-- 	  say. Just as <em>house</em> may stand for either more, or nothing -\-> -->
<!-- <\!-- 	  more, than wood and stone, our minds may be described as nothing -\-> -->
<!-- <\!-- 	  more, and, yet far more, then just machines.  As to the question of -\-> -->
<!-- <\!-- 	  scale itself, those objections are almost wholly out-of-date. They -\-> -->
<!-- <\!-- 	  made sense in 1950, before any computer could store even a mere -\-> -->
<!-- <\!-- 	  million bits. They still made sense in 1960, when a million bits -\-> -->
<!-- <\!-- 	  cost a million dollars. But, today, that same amount of memory costs -\-> -->
<!-- <\!-- 	  but a hundred dollars (and our governments have even made the -\-> -->
<!-- <\!-- 	  dollars smaller, too) &mdash; and there already exist computers with -\-> -->
<!-- <\!-- 	  billions of bits. At the moment I am writing this, some of my -\-> -->
<!-- <\!-- 	  friends are building a computer which itself includes a million -\-> -->
<!-- <\!-- 	  smaller computers. When we finally discover how to make intelligent -\-> -->
<!-- <\!-- 	  programs, the task of building the machines for them to inhabit will -\-> -->
<!-- <\!-- 	  very likely be a problem already solved. Already, the smallest parts -\-> -->
<!-- <\!-- 	  of our present-day machines are approaching the size of cells, and -\-> -->
<!-- <\!-- 	  only certain inefficiencies make them too hot to pack together even -\-> -->
<!-- <\!-- 	  more closely.  The only thing missing is most of the knowledge -\-> -->
<!-- <\!-- 	  we&#39;ll need to make such machines intelligent. Indeed, as you -\-> -->
<!-- <\!-- 	  might guess from all this, the focus of my own research in -\-> -->
<!-- <\!-- 	  Artificial Intelligence is to find ways to connect structures with -\-> -->
<!-- <\!-- 	  functions through the use of symbols.  When, if ever, will that get -\-> -->
<!-- <\!-- 	  done? Never say <em>Never.</em> -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  WHY PEOPLE THINK COMPUTERS CAN&#39;T Marvin Minsky, MIT March 1984. -\-> -->
<!-- <\!-- 	  Revised version of an article from the AAAI&#39;s <em>AI -\-> -->
<!-- <\!--             Magazine.</em> -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Most people think computers cannot think. That is, really think. Not -\-> -->
<!-- <\!-- 	  now or ever. Everyone knows that computers do many things that no -\-> -->
<!-- <\!-- 	  person could do without <em>thinking.</em> But when you get right -\-> -->
<!-- <\!-- 	  down to it, most people are convinced that this is just a mimic of -\-> -->
<!-- <\!-- 	  the real thing: illusions of intelligence, machines can&#39;t ever -\-> -->
<!-- <\!-- 	  understand past what it takes to take commands.  When computers -\-> -->
<!-- <\!-- 	  first appeared, their designers intended them for nothing but doing -\-> -->
<!-- <\!-- 	  huge, mindless numerical computations. That&#39;s why the things -\-> -->
<!-- <\!-- 	  were called <em>computers.</em> Yet even then some envisioned -\-> -->
<!-- <\!-- 	  what&#39;s now called <em>Artificial Intelligence</em> &mdash; -\-> -->
<!-- <\!-- 	  or <em>AI.</em> They saw that computers might possibly go beyond -\-> -->
<!-- <\!-- 	  arithmetic, and maybe imitate the processes that go on inside human -\-> -->
<!-- <\!-- 	  brains.  Today, with robots everywhere in industry and movie films, -\-> -->
<!-- <\!-- 	  most people think AI has gone much further than it has. Yet still, -\-> -->
<!-- <\!-- 	  <em>computer experts</em> say machines will never really think. If -\-> -->
<!-- <\!-- 	  so, how could they be so smart, and yet so dumb? -\-> -->
	  
<!-- <\!-- 	  Can Machines Be Creative? -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We naturally admire our Einsteins and Beethovens, and wonder if -\-> -->
<!-- <\!-- 	  computers ever could create such wondrous theories or symphonies. -\-> -->
<!-- <\!-- 	  Most people think that creativity requires some -\-> -->
<!-- <\!-- 	  special <em>gift</em> that simply cannot be explained. If so, then -\-> -->
<!-- <\!-- 	  no computer could create &mdash; since, clearly, anything machines -\-> -->
<!-- <\!-- 	  can do can be explained.  To see what&#39;s wrong with that, we must -\-> -->
<!-- <\!-- 	  avoid one naive trap. We mustn&#39;t only look at works our culture -\-> -->
<!-- <\!-- 	  views as very great, until we first get good ideas about how -\-> -->
<!-- <\!-- 	  ordinary people do ordinary things. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We can&#39;t expect to guess, right off, how great composers write -\-> -->
<!-- <\!-- 	  great symphonies. I don&#39;t believe that there&#39;s much -\-> -->
<!-- <\!-- 	  difference between ordinary thought and highly creative thought. I -\-> -->
<!-- <\!-- 	  don&#39;t blame anyone for not being able to do everything the most -\-> -->
<!-- <\!-- 	  creative people do. I don&#39;t blame them for not being able to -\-> -->
<!-- <\!-- 	  explain it, either. I do object to the idea that, just because we -\-> -->
<!-- <\!-- 	  can&#39;t explain it now, then no one ever could imagine how -\-> -->
<!-- <\!-- 	  creativity works.  We shouldn&#39;t intimidate ourselves by our -\-> -->
<!-- <\!-- 	  admiration of our Beethovens and Einsteins. Instead, we ought to be -\-> -->
<!-- <\!-- 	  annoyed by our ignorance of how we get ideas &mdash; and not just -\-> -->
<!-- <\!-- 	  our <em>creative</em> ones.  We&#39;re so accustomed to the marvels -\-> -->
<!-- <\!-- 	  of the unusual that we forget how little we know about the marvels -\-> -->
<!-- <\!-- 	  of ordinary thinking. Perhaps our superstitions about creativity -\-> -->
<!-- <\!-- 	  serve some other needs, such as supplying us with heroes with such -\-> -->
<!-- <\!-- 	  special qualities that, somehow, our deficiencies seem more -\-> -->
<!-- <\!-- 	  excusable.  Do outstanding minds differ from ordinary minds in any -\-> -->
<!-- <\!-- 	  special way? I don&#39;t believe that there is anything special in a -\-> -->
<!-- <\!-- 	  genius, except a rare, unlikely combination of ingredients, none -\-> -->
<!-- <\!-- 	  very special by itself.  There must be some intense concern with -\-> -->
<!-- <\!-- 	  some subject, but that&#39;s common enough. There also must be great -\-> -->
<!-- <\!-- 	  proficiency in that subject; -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  this, too, is not so rare; we call it craftsmanship. There has to be -\-> -->
<!-- <\!-- 	  enough self-confidence to stand against the scorn of peers; alone, -\-> -->
<!-- <\!-- 	  we call that stubbornness. And certainly, there must be common -\-> -->
<!-- <\!-- 	  sense. As I see it, any ordinary person who can understand an -\-> -->
<!-- <\!-- 	  ordinary conversation has already in his head most of what our -\-> -->
<!-- <\!-- 	  heroes have.  So, why can&#39;t <em>ordinary, common sense</em> -\-> -->
<!-- <\!-- 	  &mdash; when better balanced and more fiercely motivated &mdash; -\-> -->
<!-- <\!-- 	  make anyone a genius.  So still we have to ask, why doesn&#39;t -\-> -->
<!-- <\!-- 	  everyone acquire such a combination? First, of course, it&#39;s -\-> -->
<!-- <\!-- 	  sometimes just the accident of finding a novel way to look at -\-> -->
<!-- <\!-- 	  things. But, then, there may be certain kinds of difference &mdash; -\-> -->
<!-- <\!-- 	  in degree. One is in how such people learn to manage what they -\-> -->
<!-- <\!-- 	  learn: beneath the surface of their mastery, creative people must -\-> -->
<!-- <\!-- 	  have unconscious administrative skills that knit the many things -\-> -->
<!-- <\!-- 	  they know together. The other difference is in why some people learn -\-> -->
<!-- <\!-- 	  so many more and better skills. A good composer masters many skills -\-> -->
<!-- <\!-- 	  of phrase and theme &mdash; but so does anyone who talks coherently. -\-> -->
<!-- <\!-- 	  Why do some people learn so much so well? The simplest hypothesis is -\-> -->
<!-- <\!-- 	  that they&#39;ve come across some better ways to learn!  Perhaps -\-> -->
<!-- <\!-- 	  such <em>gifts</em> are little more than tricks -\-> -->
<!-- <\!-- 	  of <em>higher-order</em> -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  expertise. Just as one child learns to re-arrange its -\-> -->
<!-- <\!-- 	  building-blocks in clever ways, another child might learn to play, -\-> -->
<!-- <\!-- 	  inside its head, arranging how it learns!  Our cultures don&#39;t -\-> -->
<!-- <\!-- 	  encourage us to think much about learning.  Instead we regard it as -\-> -->
<!-- <\!-- 	  something that just happens to us. But learning must itself consist -\-> -->
<!-- <\!-- 	  of sets of skills we grow ourselves; we start with only some of them -\-> -->
<!-- <\!-- 	  and slowly grow the rest. Why don&#39;t more people keep on learning -\-> -->
<!-- <\!-- 	  more and better learning skills? Because it&#39;s not rewarded right -\-> -->
<!-- <\!-- 	  away, its payoff has a long delay. When children play with pails and -\-> -->
<!-- <\!-- 	  sand, they&#39;re usually concerned with goals like filling pails -\-> -->
<!-- <\!-- 	  with sand. But once a child concerns itself instead with how to -\-> -->
<!-- <\!-- 	  better learn, then that might lead to exponential learning growth! -\-> -->
<!-- <\!-- 	  Each better way to learn would lead to better ways to learn &mdash; -\-> -->
<!-- <\!-- 	  and this could magnify itself into an awesome, qualitative -\-> -->
<!-- <\!-- 	  change. Thus, first-rank -\-> -->
<!-- <\!-- 	  <em>creativity</em> could be just the consequence of little -\-> -->
<!-- <\!-- 	  childhood accidents.  So why is genius so rare, if each has almost -\-> -->
<!-- <\!-- 	  all it takes? Perhaps because our evolution works with mindless -\-> -->
<!-- <\!-- 	  disrespect for individuals.  I&#39;m sure no culture could survive, -\-> -->
<!-- <\!-- 	  where everyone finds different ways to think. If so, how sad, for -\-> -->
<!-- <\!-- 	  that means genes for genius would need, instead of nurturing, a -\-> -->
<!-- <\!-- 	  frequent weeding out. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Common Sense. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We can hardly expect to be able to make machines do wonders before -\-> -->
<!-- <\!-- 	  we find how to make them do ordinary, sensible things. The earliest -\-> -->
<!-- <\!-- 	  computer programs were little more than simple lists and loops of -\-> -->
<!-- <\!-- 	  commands like <em>Do this. Do that. Do this and that and this again -\-> -->
<!-- <\!--             until that happens.</em> Most people still write programs in such -\-> -->
<!-- <\!-- 	  languages (like BASIC or FORTRAN) which force you to imagine -\-> -->
<!-- <\!-- 	  everything your program will do from one moment to the -\-> -->
<!-- <\!-- 	  next. Let&#39;s call this <em>do now</em> programming.  Before long, -\-> -->
<!-- <\!-- 	  AI researchers found new ways to make programs. In their <em>General -\-> -->
<!-- <\!--             Problem Solver</em> system, built in the late 1950s &mdash; Allen -\-> -->
<!-- <\!-- 	  Newell, J. C. Shaw and Herbert A. Simon showed ways to describe -\-> -->
<!-- <\!-- 	  processes in terms of statements like <em>If the difference between -\-> -->
<!-- <\!--             what you have and what you want is of kind D, then try to change -\-> -->
<!-- <\!--             that difference by using method M.</em> This and other ideas led to -\-> -->
<!-- <\!-- 	  what we call <em>means-ends</em> and <em>do if needed</em> -\-> -->
<!-- <\!-- 	  programming methods. Such programs automatically apply rules -\-> -->
<!-- <\!-- 	  whenever they&#39;re needed, so the programmers don&#39;t have to -\-> -->
<!-- <\!-- 	  anticipate when that will happen. This started an era of programs -\-> -->
<!-- <\!-- 	  that could solve problems in ways their programmers could not -\-> -->
<!-- <\!-- 	  anticipate, because the programs could be told what sorts of things -\-> -->
<!-- <\!-- 	  to try, without knowing in advance which would work. Everyone knows -\-> -->
<!-- <\!-- 	  that if you try enough different things at random, eventually you -\-> -->
<!-- <\!-- 	  can do anything. But when that takes a million billion trillion -\-> -->
<!-- <\!-- 	  years, like those monkeys hitting random typewriter keys, it&#39;s -\-> -->
<!-- <\!-- 	  not intelligence &mdash; just Evolution. The new systems didn&#39;t -\-> -->
<!-- <\!-- 	  do things randomly, but used <em>advice</em> about what was likely -\-> -->
<!-- <\!-- 	  to work on each kind of problem. So, instead of wandering around at -\-> -->
<!-- <\!-- 	  random, such programs could sort of feel around, the way you&#39;d -\-> -->
<!-- <\!-- 	  climb a hill in the dark by always moving up the slope. The only -\-> -->
<!-- <\!-- 	  trouble was a tendency to get stuck on smaller peaks, and never find -\-> -->
<!-- <\!-- 	  the real mountain tops.  Since then, much AI research has been aimed -\-> -->
<!-- <\!-- 	  at finding more -\-> -->
<!-- <\!-- 	  <em>global</em> methods, to get past different ways of getting -\-> -->
<!-- <\!-- 	  stuck, by making programs take larger views and plan ahead. Still, -\-> -->
<!-- <\!-- 	  no one has discovered a <em>completely general</em> way to always -\-> -->
<!-- <\!-- 	  find the best method &mdash; and no one expects to.  Instead, today, -\-> -->
<!-- <\!-- 	  many AI researchers aim toward programs that will match patterns in -\-> -->
<!-- <\!-- 	  memory to decide what to do next. I like to think of this as <em>do -\-> -->
<!-- <\!--             something sensible</em> programming. A few researchers &mdash; too -\-> -->
<!-- <\!-- 	  few, I think &mdash; experiment with programs that can learn and -\-> -->
<!-- <\!-- 	  reason by analogy. These programs will someday recognize which old -\-> -->
<!-- <\!-- 	  experiences in memory are most analogous to new situations, so that -\-> -->
<!-- <\!-- 	  they can <em>remember</em> which methods worked best on similar -\-> -->
<!-- <\!-- 	  problems in the past. -\-> -->
	  
<!-- <\!-- 	  Can Computers Understand? -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Can we make computers understand what we tell them? In 1965, Daniel -\-> -->
<!-- <\!-- 	  Bobrow wrote one of the first Rule-Based Expert Systems. It was -\-> -->
<!-- <\!-- 	  called <em>STUDENT</em> and it was able to solve a variety of -\-> -->
<!-- <\!-- 	  high-school algebra <em>word problems</em> like these: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The distance from New York to Los Angeles is 3000 miles. If the -\-> -->
<!-- <\!-- 	  average speed of a jet plane is 600 miles per hour, find the time it -\-> -->
<!-- <\!-- 	  takes to travel from New York to Los Angeles by jet. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Bill&#39;s father&#39;s uncle is twice as old as Bill&#39;s -\-> -->
<!-- <\!-- 	  father. Two years from now Bill&#39;s father will be three times as -\-> -->
<!-- <\!-- 	  old as Bill. The sum of their ages is 92. Find Bill&#39;s age. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Most students find these problems much harder than just solving the -\-> -->
<!-- <\!-- 	  formal equations of high school algebra. That&#39;s just cook-book -\-> -->
<!-- <\!-- 	  stuff &mdash; but to solve the informal word problems, you have to -\-> -->
<!-- <\!-- 	  figure out what equations to solve and, to do that, you must -\-> -->
<!-- <\!-- 	  understand what the words and sentences mean. Did STUDENT -\-> -->
<!-- <\!-- 	  understand? It used a lot of tricks. It was programmed to guess -\-> -->
<!-- <\!-- 	  that <em>is</em> usually means -\-> -->
<!-- <\!-- 	  <em>equals.</em> It didn&#39;t even try to figure out -\-> -->
<!-- <\!-- 	  what <em>Bill&#39;s fathers&#39; uncle</em> means &mdash; it only -\-> -->
<!-- <\!-- 	  noticed that this phrase resembles <em>Bill&#39;s father.</em> It -\-> -->
<!-- <\!-- 	  didn&#39;t know that <em>age</em> and <em>old</em> refer to time, -\-> -->
<!-- <\!-- 	  but it took them to represent numbers to be put in equations. With a -\-> -->
<!-- <\!-- 	  couple of hundred such word-trick-facts, STUDENT sometimes managed -\-> -->
<!-- <\!-- 	  to get the right answers.  Then dare we say that -\-> -->
<!-- <\!-- 	  STUDENT <em>understands</em> those words?  Why bother. Why fall into -\-> -->
<!-- <\!-- 	  the trap of feeling that we must define old words like <em>mean</em> -\-> -->
<!-- <\!-- 	  and <em>understand</em>? It&#39;s great when words help us get good -\-> -->
<!-- <\!-- 	  ideas, but not when they confuse us. The question should be: does -\-> -->
<!-- <\!-- 	  STUDENT avoid the <em>real meanings</em> by using tricks?  Or is it -\-> -->
<!-- <\!-- 	  that what we call meanings really are just clever bags of tricks? -\-> -->
<!-- <\!-- 	  Let&#39;s take a classic thought-example, such as what a number -\-> -->
<!-- <\!-- 	  means. STUDENT obviously knows some arithmetic, in the sense that it -\-> -->
<!-- <\!-- 	  can find such sums as <em>5 plus 7 is 12.</em> But does it -\-> -->
<!-- <\!-- 	  understand numbers in any other sense &mdash; say, what -\-> -->
<!-- <\!-- 	  5 <em>is</em> &mdash; or, for that matter, what are <em>plus</em> -\-> -->
<!-- <\!-- 	  or <em>is</em>? What would you say if I asked you, <em>What is -\-> -->
<!-- <\!--             Five</em>? Early in this century, the philosophers Bertrand Russell -\-> -->
<!-- <\!-- 	  and Alfred North Whitehead proposed a new way to define numbers. -\-> -->
<!-- <\!-- 	  <em>Five,</em> they said, is <em>the set of all possible sets with -\-> -->
<!-- <\!--             five members.</em>  This set includes each set of five ball-point -\-> -->
<!-- <\!-- 	  pens, and every litter of five kittens. Unhappily, it also includes -\-> -->
<!-- <\!-- 	  such sets as <em>the Five things you&#39;d least expect</em> -\-> -->
<!-- <\!-- 	  and <em>the five smallest numbers not included in this set</em> -\-> -->
<!-- <\!-- 	  &mdash; and these lead to bizarre inconsistencies and paradoxes. The -\-> -->
<!-- <\!-- 	  basic goal was to find perfect definitions for ordinary words and -\-> -->
<!-- <\!-- 	  ideas.  But even to make the idea work for Mathematics, getting -\-> -->
<!-- <\!-- 	  around these inconsistencies made the Russell-Whitehead theory too -\-> -->
<!-- <\!-- 	  complicated for practical common-sense use. Educators once actually -\-> -->
<!-- <\!-- 	  tried to make children use this theory of sets, in the <em>New -\-> -->
<!-- <\!--             Mathematics</em> movement of the 1960s; it only further set apart -\-> -->
<!-- <\!-- 	  those who liked mathematics from those who dreaded it. I think the -\-> -->
<!-- <\!-- 	  trouble was, it tried to get around a basic fact of mind: what -\-> -->
<!-- <\!-- 	  something means to me depends to some extent on many other things I -\-> -->
<!-- <\!-- 	  know.  What if we built machines that weren&#39;t based on rigid -\-> -->
<!-- <\!-- 	  definitions? -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Won&#39;t they just drown in paradox, equivocation, inconsistency? -\-> -->
<!-- <\!-- 	  Relax! Most of what we people <em>know</em> AI ready overflows with -\-> -->
<!-- <\!-- 	  contradictions; still we survive. The best we can do is be -\-> -->
<!-- <\!-- 	  reasonably careful; let&#39;s just make our machines that careful, -\-> -->
<!-- <\!-- 	  too. If there remain some chances of mistake, well, that&#39;s just -\-> -->
<!-- <\!-- 	  life. -\-> -->
	  
<!-- <\!-- 	  Webs of Meaning. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  If every meaning in a mind depends on other meanings in that mind, -\-> -->
<!-- <\!-- 	  does that make things too ill-defined to make a scientific project -\-> -->
<!-- <\!-- 	  work? No, even when thing go in circles, there still are scientific -\-> -->
<!-- <\!-- 	  things to do! Just make new kinds of theories &mdash; about those -\-> -->
<!-- <\!-- 	  circles themselves! The older theories only tried to hide the -\-> -->
<!-- <\!-- 	  circularities. But that lost all the richness of our wondrous human -\-> -->
<!-- <\!-- 	  meaning-webs; the networks in our human minds are probably more -\-> -->
<!-- <\!-- 	  complex than any other structure Science ever contemplated in the -\-> -->
<!-- <\!-- 	  past. Accordingly, the detailed theories of Artificial Intelligence -\-> -->
<!-- <\!-- 	  will probably need, eventually, some very complicated theories. But -\-> -->
<!-- <\!-- 	  that&#39;s life, too.  Let&#39;s go back to what numbers mean. This -\-> -->
<!-- <\!-- 	  time, to make things easier, we&#39;ll think about Three. I&#39;m -\-> -->
<!-- <\!-- 	  arguing that Three, for us, has no one single, basic definition, but -\-> -->
<!-- <\!-- 	  is a web of different processes that each get meaning from the -\-> -->
<!-- <\!-- 	  others. Consider all the roles <em>Three</em> plays. One way we tell -\-> -->
<!-- <\!-- 	  a Three is to recite <em>One, Two, Three,</em> while pointing to the -\-> -->
<!-- <\!-- 	  different things. To do it right, of course, you have to -\-> -->
	  
<!-- <\!-- 	  1) touch each thing once, and 2) not touch any twice. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  One way is to count out loud while you pick up each object and -\-> -->
<!-- <\!-- 	  remove it. Children learn to do such things in their heads or, when -\-> -->
<!-- <\!-- 	  that&#39;s too hard, to use tricks like finger-pointing. Another way -\-> -->
<!-- <\!-- 	  to tell a Three is to use some Standard Set of Three things. Then -\-> -->
<!-- <\!-- 	  bring that set of things to the other set, and match them -\-> -->
<!-- <\!-- 	  one-to-one: if all are matched and none are left, then there were -\-> -->
<!-- <\!-- 	  Three. That <em>standard Three</em> need not be things, for words -\-> -->
<!-- <\!-- 	  like <em>one, two, three</em> work just as well. For Five we have a -\-> -->
<!-- <\!-- 	  wider choice. One can think of it as groups of Two and Three, or One -\-> -->
<!-- <\!-- 	  and Four. Or, one can think of some familiar shapes &mdash; a -\-> -->
<!-- <\!-- 	  pentagon, an X, a V, a cross, an aeroplane; they all make Fives. -\-> -->
<!-- <\!-- 	  Because each trick works in different situations, our power stems -\-> -->
<!-- <\!-- 	  from being able to shift from one trick to another. To ask which -\-> -->
<!-- <\!-- 	  meaning is correct &mdash; to count, or match, or group &mdash; is -\-> -->
<!-- <\!-- 	  foolishness.  Each has its uses and its ways to support the -\-> -->
<!-- <\!-- 	  others. None has much power by itself, but together they make a -\-> -->
<!-- <\!-- 	  versatile skill-system.  Instead of flimsy links in chains of -\-> -->
<!-- <\!-- 	  definitions in the mind, each word we use can activate big webs of -\-> -->
<!-- <\!-- 	  different ways to deal with things, to use them, to remember them, -\-> -->
<!-- <\!-- 	  to compare them, and so forth. With multiply-connected -\-> -->
<!-- <\!-- 	  knowledge-nets, you can&#39;t get stuck. When any sense of meaning -\-> -->
<!-- <\!-- 	  fails, you can switch to another. The mathematician&#39;s way, once -\-> -->
<!-- <\!-- 	  you get into the slightest trouble, you&#39;re stuck for good!  Why, -\-> -->
<!-- <\!-- 	  then, do mathematicians stick to slender chains, each thing -\-> -->
<!-- <\!-- 	  depending on as few things as is possible? The answer is ironic: -\-> -->
<!-- <\!-- 	  mathematicians want to get stuck! When anything goes wrong, they -\-> -->
<!-- <\!-- 	  want to be the first to notice it. The best way to be sure of that -\-> -->
<!-- <\!-- 	  is having everything collapse at once! To them, fragility is not -\-> -->
<!-- <\!-- 	  bad, because it helps them find the perfect proof, lest any single -\-> -->
<!-- <\!-- 	  thing they think be inconsistent with any other one. That&#39;s fine -\-> -->
<!-- <\!-- 	  for Mathematics; in fact, that&#39;s what much of mathematics -\-> -->
<!-- <\!-- 	  is. It&#39;s just not good Psychology. Let&#39;s face it, our minds -\-> -->
<!-- <\!-- 	  will always hold some beliefs that turn out wrong. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  I think it&#39;s bad psychology, when teachers shape our -\-> -->
<!-- <\!-- 	  children&#39;s mathematics into long, thin, fragile, definition -\-> -->
<!-- <\!-- 	  tower-chains, instead of robust cross-connected webs. Those chains -\-> -->
<!-- <\!-- 	  break at their weakest links, those towers topple at the slightest -\-> -->
<!-- <\!-- 	  shove. And that&#39;s what happens to a child&#39;s mind in -\-> -->
<!-- <\!-- 	  mathematics class, who only takes a moment just to watch a pretty -\-> -->
<!-- <\!-- 	  cloud go by. The purposes of ordinary people are not the same as -\-> -->
<!-- <\!-- 	  those of mathematicians and philosophers, who want to simplify by -\-> -->
<!-- <\!-- 	  having just as few connections as can be. In real life, the best -\-> -->
<!-- <\!-- 	  ideas are cross-connected as can be.  Perhaps that&#39;s why our -\-> -->
<!-- <\!-- 	  culture makes most children so afraid of mathematics. We think we -\-> -->
<!-- <\!-- 	  help them get things right, by making things go wrong most times! -\-> -->
<!-- <\!-- 	  Perhaps, instead, we ought to help them build more robust networks -\-> -->
<!-- <\!-- 	  in their heads. -\-> -->
	  
<!-- <\!-- 	  Castles in the Air. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The secret of what something means lies in the ways that it connects -\-> -->
<!-- <\!-- 	  to all the other things we know. The more such links, the more a -\-> -->
<!-- <\!-- 	  thing will mean to us. The joke comes when someone looks for -\-> -->
<!-- <\!-- 	  the <em>real</em> meaning of anything. For, if something had just -\-> -->
<!-- <\!-- 	  one meaning, that is, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  if it were only connected to just one other thing, then it would -\-> -->
<!-- <\!-- 	  scarcely -\-> -->
<!-- <\!-- 	  <em>mean</em> at all!  That&#39;s why I think we shouldn&#39;t -\-> -->
<!-- <\!-- 	  program our machines that way, with clear and simple logic -\-> -->
<!-- <\!-- 	  definitions. A machine programmed that way might -\-> -->
<!-- <\!-- 	  never <em>really</em> understand anything &mdash; any more than a -\-> -->
<!-- <\!-- 	  person would. Rich, multiply-connected networks provide enough -\-> -->
<!-- <\!-- 	  different ways to use knowledge that when one way doesn&#39;t work, -\-> -->
<!-- <\!-- 	  you can try to figure out why. When there are many meanings in a -\-> -->
<!-- <\!-- 	  network, you can turn things around in your mind and look at them -\-> -->
<!-- <\!-- 	  from different perspectives; when you get stuck, you can try another -\-> -->
<!-- <\!-- 	  view. That&#39;s what we mean by thinking!  That&#39;s why I dislike -\-> -->
<!-- <\!-- 	  logic, and prefer to work with webs of circular definitions. Each -\-> -->
<!-- <\!-- 	  gives meaning to the rest. There&#39;s nothing wrong with liking -\-> -->
<!-- <\!-- 	  several different tunes, each one the more because it contrasts with -\-> -->
<!-- <\!-- 	  the others. There&#39;s nothing wrong with ropes &mdash; or knots, -\-> -->
<!-- <\!-- 	  or woven cloth &mdash; in which each strand helps hold the other -\-> -->
<!-- <\!-- 	  strands together &mdash; or apart! There&#39;s nothing very wrong, -\-> -->
<!-- <\!-- 	  in this strange sense, with having all one&#39;s mind a castle in -\-> -->
<!-- <\!-- 	  the air!  To summarize: of course no computer could understand -\-> -->
<!-- <\!-- 	  anything real &mdash; or even what a number is &mdash; if forced to -\-> -->
<!-- <\!-- 	  single ways to deal with them. But neither could a child or -\-> -->
<!-- <\!-- 	  philosopher. So such concerns are not about computers at all, but -\-> -->
<!-- <\!-- 	  about our foolish quest for meanings that stand by themselves, -\-> -->
<!-- <\!-- 	  outside any context. Our questions about thinking machines should -\-> -->
<!-- <\!-- 	  really be questions about our own minds. -\-> -->
	  
<!-- <\!-- 	  Are Humans Self-Aware? -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Most people assume that computers can&#39;t be conscious, or -\-> -->
<!-- <\!-- 	  self-aware; at best they can only simulate the appearance of -\-> -->
<!-- <\!-- 	  this. Of course, this assumes that we, as humans, are -\-> -->
<!-- <\!-- 	  self-aware. But are we? I think not.  I know that sounds ridiculous, -\-> -->
<!-- <\!-- 	  so let me explain.  If by awareness we mean knowing what is in our -\-> -->
<!-- <\!-- 	  minds, then, as every clinical psychologist knows, people are only -\-> -->
<!-- <\!-- 	  very slightly self-aware, and most of what they think about -\-> -->
<!-- <\!-- 	  themselves is guess-work. We seem to build up networks of theories -\-> -->
<!-- <\!-- 	  about what is in our minds, and we mistake these apparent visions -\-> -->
<!-- <\!-- 	  for what&#39;s really going on. To put it bluntly, most of what -\-> -->
<!-- <\!-- 	  our <em>consciousness</em> reveals to us is just <em>made up.</em> -\-> -->
<!-- <\!-- 	  Now, I don&#39;t mean that we&#39;re not aware of sounds and sights, -\-> -->
<!-- <\!-- 	  or even of some parts of thoughts. I&#39;m only saying that -\-> -->
<!-- <\!-- 	  we&#39;re not aware of much of what goes on inside our minds. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  When people talk, the physics is quite clear: our voices shake the -\-> -->
<!-- <\!-- 	  air; this makes your ear-drums move &mdash; and then computers in -\-> -->
<!-- <\!-- 	  your head convert those waves into constituents of words. These -\-> -->
<!-- <\!-- 	  somehow then turn into strings of symbols representing words, so now -\-> -->
<!-- <\!-- 	  there&#39;s somewhere in your head that <em>represents</em> a -\-> -->
<!-- <\!-- 	  sentence. What happens next?  When light excites your retinas, this -\-> -->
<!-- <\!-- 	  causes events in your brain that correspond to texture, edges, color -\-> -->
<!-- <\!-- 	  patches, and the like. Then these, in turn, are somehow fused -\-> -->
<!-- <\!-- 	  to <em>represent</em> a shape or outline of a thing. What happens -\-> -->
<!-- <\!-- 	  then?  We all comprehend these simple ideas. But there remains a -\-> -->
<!-- <\!-- 	  hard problem, still. What entity or mechanism carries on from there? -\-> -->
<!-- <\!-- 	  We&#39;re used to saying simply, that&#39;s the <em>self.</em> -\-> -->
<!-- <\!-- 	  What&#39;s wrong with that idea?  Our standard concept of the self -\-> -->
<!-- <\!-- 	  is that deep inside each mind resides a special, -\-> -->
<!-- <\!-- 	  central <em>self</em> that does the real mental work for us, a -\-> -->
<!-- <\!-- 	  little person deep down there to hear and see and understand -\-> -->
<!-- <\!-- 	  what&#39;s going on. Call this the <em>Single Agent</em> theory. It -\-> -->
<!-- <\!-- 	  isn&#39;t hard to see why every culture gets attached to this -\-> -->
<!-- <\!-- 	  idea. No matter how ridiculous it may seem, scientifically, it -\-> -->
<!-- <\!-- 	  underlies all principles of law, work, and morality. Without it, all -\-> -->
<!-- <\!-- 	  our canons of responsibility would fail of blame or virtue, right or -\-> -->
<!-- <\!-- 	  wrong. What use would solving problems be, without that myth; how -\-> -->
<!-- <\!-- 	  could we have societies at all?  The trouble is, we cannot build -\-> -->
<!-- <\!-- 	  good theories of the mind that way.  In every field, as Scientists -\-> -->
<!-- <\!-- 	  we&#39;re always forced to recognize that what we see as single -\-> -->
<!-- <\!-- 	  things &mdash; like rocks or clouds, or even minds &mdash; must -\-> -->
<!-- <\!-- 	  sometimes be described as made of other kinds of things. We&#39;ll -\-> -->
<!-- <\!-- 	  have to understand that Self, itself, is not a single thing. -\-> -->
	  
<!-- <\!-- 	  New Theories about Minds and Machines. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  It is too easy to say things like, <em>Computers can&#39;t do (XXX), -\-> -->
<!-- <\!--             because they have no feelings, or thoughts.</em> But here&#39;s a -\-> -->
<!-- <\!-- 	  way to turn such sayings into foolishness. Change them to read -\-> -->
<!-- <\!-- 	  like this:<em>Computers can&#39;t do (XXX), because all they can -\-> -->
<!-- <\!--             do is execute incredibly intricate processes, perhaps millions at -\-> -->
<!-- <\!--             a time.</em> Now, such objections seem less convincing &mdash; yet -\-> -->
<!-- <\!-- 	  all we did was face one simple, complicated fact: we really -\-> -->
<!-- <\!-- 	  don&#39;t yet know what the limits of computers are. Now let&#39;s -\-> -->
<!-- <\!-- 	  face the other simple fact: our notions of the human mind are just -\-> -->
<!-- <\!-- 	  as primitive.  Why are we so reluctant to admit how little is -\-> -->
<!-- <\!-- 	  known about how the mind works? It must come partly from our -\-> -->
<!-- <\!-- 	  normal tendency to repress problems that seem discouraging. But -\-> -->
<!-- <\!-- 	  there are deeper reasons, too, for wanting to believe in the -\-> -->
<!-- <\!-- 	  uniqueness and inexplicability of Self. Perhaps we fear that too -\-> -->
<!-- <\!-- 	  much questioning might tear the veils that clothe our mental -\-> -->
<!-- <\!-- 	  lives.  To me there is a special irony when people say machines -\-> -->
<!-- <\!-- 	  cannot have minds, because I feel we&#39;re only now beginning to -\-> -->
<!-- <\!-- 	  see how minds possibly could work &mdash; using insights that came -\-> -->
<!-- <\!-- 	  directly from attempts to see what complicated machines can do. Of -\-> -->
<!-- <\!-- 	  course we&#39;re nowhere near a clear and complete theory &mdash; -\-> -->
<!-- <\!-- 	  yet. But in retrospect, it now seems strange that anyone could -\-> -->
<!-- <\!-- 	  ever hope to understand such things before they knew much more -\-> -->
<!-- <\!-- 	  about machines. Except, of course, if they believed that minds are -\-> -->
<!-- <\!-- 	  not complex at all.  Now, you might ask, if the ordinary concept -\-> -->
<!-- <\!-- 	  of Self is so wrong, what would I recommend in its place? To begin -\-> -->
<!-- <\!-- 	  with, for social purposes, I don&#39;t recommend changing anything -\-> -->
<!-- <\!-- 	  &mdash; it&#39;s too risky. But for the technical enterprise of -\-> -->
<!-- <\!-- 	  making intelligent machines, we need better theories of how -\-> -->
<!-- <\!-- 	  to <em>represent,</em> inside computers, the kinds of webs of -\-> -->
<!-- <\!-- 	  knowledge and know-how that figure in everyone&#39;s common-sense -\-> -->
<!-- <\!-- 	  knowledge systems. We must develop programs that know, say, what -\-> -->
<!-- <\!-- 	  numbers mean, instead of just being able to add and subtract -\-> -->
<!-- <\!-- 	  them. We must experiment with all sorts of common-sense knowledge, -\-> -->
<!-- <\!-- 	  and knowledge about that as well.  Such is the focus of some -\-> -->
<!-- <\!-- 	  present-day AI research. True, most of the world of <em>Computer -\-> -->
<!-- <\!--             Science</em> is involved with building large, useful, but shallow -\-> -->
<!-- <\!-- 	  practical systems, a few courageous students are trying to make -\-> -->
<!-- <\!-- 	  computers use other kinds of thinking, representing different -\-> -->
<!-- <\!-- 	  kinds of knowledge, sometimes, in several different ways, so that -\-> -->
<!-- <\!-- 	  their programs won&#39;t get stuck at fixed ideas. Most important -\-> -->
<!-- <\!-- 	  of all, perhaps, is making such machines learn from their own -\-> -->
<!-- <\!-- 	  experience. Once we know more about such things, we can start to -\-> -->
<!-- <\!-- 	  study ways to weave these different schemes together. Finally, -\-> -->
<!-- <\!-- 	  we&#39;ll get machines that think about themselves and make up -\-> -->
<!-- <\!-- 	  theories, good or bad, of how they, themselves might -\-> -->
<!-- <\!-- 	  work. Perhaps, when our machines get to that stage, we&#39;ll find -\-> -->
<!-- <\!-- 	  it very easy to tell it has happened. For, at that point, -\-> -->
<!-- <\!-- 	  they&#39;ll probably object to being called machines. To accept -\-> -->
<!-- <\!-- 	  that will be difficult, but only by this sacrifice will machines -\-> -->
<!-- <\!-- 	  free us from our false mottoes. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Knowledge and Common Sense. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We&#39;ve all enjoyed those jokes about the stupid and literal -\-> -->
<!-- <\!-- 	  behavior of computers. They send us silly checks and bills for -\-> -->
<!-- <\!-- 	  $0.00. They can&#39;t tell when we mean <em>hyphen</em> from when we -\-> -->
<!-- <\!-- 	  mean minus They don&#39;t mind being caught in endless loops, doing -\-> -->
<!-- <\!-- 	  the same thing over again a billion times. This total lack of common -\-> -->
<!-- <\!-- 	  sense is one more reason people think that no machine could have a -\-> -->
<!-- <\!-- 	  mind. It&#39;s not just that they do only what they&#39;re told, -\-> -->
<!-- <\!-- 	  it&#39;s also that they&#39;re so dumb it&#39;s almost impossible to -\-> -->
<!-- <\!-- 	  tell them how to do things right.  Isn&#39;t it odd, when you think -\-> -->
<!-- <\!-- 	  about it, how even the earliest AI programs excelled -\-> -->
<!-- <\!-- 	  at <em>advanced</em> subjects, yet had no common sense?  A 1961 -\-> -->
<!-- <\!-- 	  program written by James Slagle could solve calculus problems at the -\-> -->
<!-- <\!-- 	  level of college students; it even got an A on an MIT exam. But it -\-> -->
<!-- <\!-- 	  wasn&#39;t till around 1970 that we managed to construct a robot -\-> -->
<!-- <\!-- 	  program that could see and move well enough to handle ordinary -\-> -->
<!-- <\!-- 	  things like children&#39;s building blocks and do things like stack -\-> -->
<!-- <\!-- 	  them up, take them down, rearrange them, and put them in boxes.  Why -\-> -->
<!-- <\!-- 	  could we make programs do those grown-up things before we could make -\-> -->
<!-- <\!-- 	  them do those childish things? The answer is a somewhat unexpected -\-> -->
<!-- <\!-- 	  paradox: much <em>expert</em> adult thinking is basically much -\-> -->
<!-- <\!-- 	  simpler than what happens in a child&#39;s ordinary play! It can be -\-> -->
<!-- <\!-- 	  harder to be a novice than to be an expert! This is because, -\-> -->
<!-- <\!-- 	  sometimes, what an expert needs to know and do can be quite simple -\-> -->
<!-- <\!-- 	  &mdash; only, it may be very hard to discover, or learn, in the -\-> -->
<!-- <\!-- 	  first place. Thus, Galileo had to be smart indeed, to see the need -\-> -->
<!-- <\!-- 	  for calculus. He didn&#39;t manage to invent it. Yet any good -\-> -->
<!-- <\!-- 	  student can learn it today.  The surprising thing, thus, was that -\-> -->
<!-- <\!-- 	  when it was finished, Slagle&#39;s program needed only about a -\-> -->
<!-- <\!-- 	  hundred <em>facts</em> to solve its college-level calculus -\-> -->
<!-- <\!-- 	  problems. Most of them were simple rules about algebra. But others -\-> -->
<!-- <\!-- 	  were about how to guess which of two problems is likely to be -\-> -->
<!-- <\!-- 	  easier; that that kind of knowledge is especially important, because -\-> -->
<!-- <\!-- 	  it helps the program make good judgments about what to do -\-> -->
<!-- <\!-- 	  next. Without this such programs only thrash about; with it they -\-> -->
<!-- <\!-- 	  seem much more purposeful. Why do human students take so long to -\-> -->
<!-- <\!-- 	  learn such rules? We do not know.  Today we know much more about -\-> -->
<!-- <\!-- 	  making such <em>expert</em> programs &mdash; but we still don&#39;t -\-> -->
<!-- <\!-- 	  know much more about making programs with more <em>common -\-> -->
<!-- <\!--             sense.</em> Consider all the different things that children do, when -\-> -->
<!-- <\!-- 	  they play with their blocks. To build a little house one has to mix -\-> -->
<!-- <\!-- 	  and match many different kinds of knowledge: about shapes and -\-> -->
<!-- <\!-- 	  colors, space and time, support and balance, stress and strain, -\-> -->
<!-- <\!-- 	  speed, cost, and keeping track. An expert sometimes can get by with -\-> -->
<!-- <\!-- 	  deep but narrow bodies of knowledge &mdash; but common sense is, -\-> -->
<!-- <\!-- 	  technically, a lot more complicated.  Most ordinary computer -\-> -->
<!-- <\!-- 	  programs do just the things they&#39;re programmed for. Some AI -\-> -->
<!-- <\!-- 	  programs are more flexible; when anything goes wrong, they can back -\-> -->
<!-- <\!-- 	  up to some previous decision and try something else. But even that -\-> -->
<!-- <\!-- 	  is much too crude a base for much intelligence. To make them really -\-> -->
<!-- <\!-- 	  smart, we&#39;ll have to make them more reflective. A person tries, -\-> -->
<!-- <\!-- 	  when things go wrong, to understand what&#39;s going wrong, instead -\-> -->
<!-- <\!-- 	  of just attempting something else. We look for causal explanations, -\-> -->
<!-- <\!-- 	  or excuses, and, when we find them, add them to our networks of -\-> -->
<!-- <\!-- 	  belief and understanding. We do intelligent learning. Someday -\-> -->
<!-- <\!-- 	  programs, too, could do such things &mdash; but first we&#39;d need -\-> -->
<!-- <\!-- 	  a lot more research to find out how. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Unconscious Fears and Phobias. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  I&#39;ll bet that when we try to make machines more sensible, -\-> -->
<!-- <\!-- 	  we&#39;ll find that learning what is wrong turns out to be as -\-> -->
<!-- <\!-- 	  important as learning what&#39;s correct. In order to succeed, it -\-> -->
<!-- <\!-- 	  helps to know the likely ways to fail. Freud talked about censors in -\-> -->
<!-- <\!-- 	  our minds, that keep us from forbidden acts or thoughts. And, though -\-> -->
<!-- <\!-- 	  those censors were proposed to regulate our social activity, I think -\-> -->
<!-- <\!-- 	  we use such censors, too, for ordinary problem solving &mdash; to -\-> -->
<!-- <\!-- 	  know what not to do. Perhaps we learn a new one each time anything -\-> -->
<!-- <\!-- 	  goes wrong, by constructing a process to recognize similar -\-> -->
<!-- <\!-- 	  circumstances, in some -\-> -->
<!-- <\!-- 	  <em>subconscious memory.</em>  This idea is not popular in -\-> -->
<!-- <\!-- 	  contemporary psychology, perhaps because censors only suppress -\-> -->
<!-- <\!-- 	  behavior, so their activity is invisible on the surface. When a -\-> -->
<!-- <\!-- 	  person makes a good decision, we tend to ask what <em>line of -\-> -->
<!-- <\!--             thought</em> lies behind it. But we don&#39;t so often ask what -\-> -->
<!-- <\!-- 	  thousand prohibitions might have warded off a thousand bad -\-> -->
<!-- <\!-- 	  alternatives. If censors work inside our minds, to keep us from -\-> -->
<!-- <\!-- 	  mistakes and absurdities, why can&#39;t we feel that happening? -\-> -->
<!-- <\!-- 	  Because, I suppose, so many thousands of them work at once that, if -\-> -->
<!-- <\!-- 	  you had to think about them, you&#39;d never get much done. They -\-> -->
<!-- <\!-- 	  have to ward off bad ideas before you <em>get</em> those bad ideas. -\-> -->
<!-- <\!-- 	  Perhaps this is one reason why so much of human thought is -\-> -->
<!-- <\!-- 	  <em>unconscious.</em> Each idea that we have time to contemplate -\-> -->
<!-- <\!-- 	  must be a product of many events that happen deeper and earlier in -\-> -->
<!-- <\!-- 	  the mind.  Each conscious thought must be the end of processes in -\-> -->
<!-- <\!-- 	  which it must compete with other proto-thoughts, perhaps by pleading -\-> -->
<!-- <\!-- 	  little briefs in little courts. But all that we do sense of that are -\-> -->
<!-- <\!-- 	  just the final sentences.  And how, indeed, could it be otherwise? -\-> -->
<!-- <\!-- 	  There&#39;s no way any part of the mind could know everything that -\-> -->
<!-- <\!-- 	  happens in the rest. Our conscious minds must be like high -\-> -->
<!-- <\!-- 	  executives, who can&#39;t be burdened with the small -\-> -->
<!-- <\!-- 	  details. There&#39;s only time for summaries from other, smaller -\-> -->
<!-- <\!-- 	  parts of mind, that know much more about much less; the ones that do -\-> -->
<!-- <\!-- 	  the real work. -\-> -->
	  
<!-- <\!-- 	  Self-Conscious Computers. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Then, is it possible to program a computer to be self-conscious? -\-> -->
<!-- <\!-- 	  People usually expect the answer to be <em>no.</em> What if we -\-> -->
<!-- <\!-- 	  answered that machines are capable, in principle, of even more and -\-> -->
<!-- <\!-- 	  better consciousness than people?  I think this could be done by -\-> -->
<!-- <\!-- 	  providing machines with ways to examine their own mechanisms while -\-> -->
<!-- <\!-- 	  they are working. In principle, at least, this seems possible; we -\-> -->
<!-- <\!-- 	  already have some simple AI programs that can understand a little -\-> -->
<!-- <\!-- 	  about how some simpler programs work. (There is a technical problem -\-> -->
<!-- <\!-- 	  about the program being fast enough, to keep up with itself, but -\-> -->
<!-- <\!-- 	  that can be solved by keeping records.) The trouble is, we still -\-> -->
<!-- <\!-- 	  know far too little, yet, to make programs with enough common sense -\-> -->
<!-- <\!-- 	  to understand even how today&#39;s simple AI problem-solving -\-> -->
<!-- <\!-- 	  programs work. But once we learn to make machines that are smart -\-> -->
<!-- <\!-- 	  enough to understand such things, I see no special problem in giving -\-> -->
<!-- <\!-- 	  them the <em>self-insight</em> they would need to understand, -\-> -->
<!-- <\!-- 	  change, and improve themselves.  This might not be so wise to -\-> -->
<!-- <\!-- 	  do. But what if it turns out that the only way to make computers -\-> -->
<!-- <\!-- 	  much smarter is to make them more self- conscious? For example, it -\-> -->
<!-- <\!-- 	  might turn out to be too risky to assign a robot to undertake some -\-> -->
<!-- <\!-- 	  important, long-range task, without some -\-> -->
<!-- <\!-- 	  <em>insight</em> about it&#39;s own abilities. If we don&#39;t want -\-> -->
<!-- <\!-- 	  it to start projects it can&#39;t finish, we&#39;d better have it -\-> -->
<!-- <\!-- 	  know what it can do. If we want it versatile enough to solve new -\-> -->
<!-- <\!-- 	  kinds of problems, it may need to be able to understand how it -\-> -->
<!-- <\!-- 	  already solves easier problems. In other words, it may turn out that -\-> -->
<!-- <\!-- 	  any really robust problem solver will need to understand itself -\-> -->
<!-- <\!-- 	  enough to change itself. Then, if that goes on long enough, why -\-> -->
<!-- <\!-- 	  can&#39;t those artificial creatures reach for richer mental lives -\-> -->
<!-- <\!-- 	  than people have? Our own evolution must have constrained the wiring -\-> -->
<!-- <\!-- 	  of our brains in many ways. But here we have more options now, since -\-> -->
<!-- <\!-- 	  we can wire machines in any way we wish.  It will be a long time -\-> -->
<!-- <\!-- 	  before we learn enough about common sense reasoning to make machines -\-> -->
<!-- <\!-- 	  as smart as people are. Today, we already know quite a lot about -\-> -->
<!-- <\!-- 	  making useful, specialized, <em>expert</em> systems. We still -\-> -->
<!-- <\!-- 	  don&#39;t know how to make them able to improve themselves in -\-> -->
<!-- <\!-- 	  interesting ways. But when we answer such questions, then we&#39;ll -\-> -->
<!-- <\!-- 	  have to face another, even stranger, one. When we learn how, then -\-> -->
<!-- <\!-- 	  should we build machines that might be somehow <em>better</em> than -\-> -->
<!-- <\!-- 	  ourselves? We&#39;re lucky that we have to leave that choice to -\-> -->
<!-- <\!-- 	  future generations. I&#39;m sure they won&#39;t want to build the -\-> -->
<!-- <\!-- 	  things that well unless they find good reasons to.  Just as -\-> -->
<!-- <\!-- 	  Evolution changed man&#39;s view of Life, AI will change mind&#39;s -\-> -->
<!-- <\!-- 	  view of Mind. As we find more ways to make machines behave more -\-> -->
<!-- <\!-- 	  sensibly, we&#39;ll also learn more about our mental processes. In -\-> -->
<!-- <\!-- 	  its course, we will find new ways to think about <em>thinking</em> -\-> -->
<!-- <\!-- 	  and about -\-> -->
<!-- <\!-- 	  <em>feeling.</em> Our view of them will change from opaque mysteries -\-> -->
<!-- <\!-- 	  to complex yet still comprehensible webs of ways to represent and -\-> -->
<!-- <\!-- 	  use ideas. Then those ideas, in turn, will lead to new machines, and -\-> -->
<!-- <\!-- 	  those, in turn, will give us new ideas. No one can tell where that -\-> -->
<!-- <\!-- 	  will lead and only one thing&#39;s sure right now: there&#39;s -\-> -->
<!-- <\!-- 	  something wrong with any claim to know, today, of any basic -\-> -->
<!-- <\!-- 	  differences between the minds of men and those of possible machines. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  This Prologue and Epilogue appear at the beginning of the newest -\-> -->
<!-- <\!-- 	  edition of Perceptrons, published by the MIT Press. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  PROLOGUE AND EPILOGUE TO PERCEPTRONS: A View from 1987 Minsky-Papert -\-> -->
<!-- <\!-- 	  PROLOGUE This book is about perceptrons &mdash; the simplest kinds -\-> -->
<!-- <\!-- 	  of learning machines. However, its deeper purpose is to find more -\-> -->
<!-- <\!-- 	  general insights into the interconnected subjects of parallel -\-> -->
<!-- <\!-- 	  computation, pattern recognition, knowledge representation, and -\-> -->
<!-- <\!-- 	  learning. It is only because one cannot think productively about -\-> -->
<!-- <\!-- 	  such matters without studying specific examples, that we focused on -\-> -->
<!-- <\!-- 	  theories of perceptrons in particular. In preparing this edition, we -\-> -->
<!-- <\!-- 	  were tempted to <em>bring those theories up to date.</em> But when -\-> -->
<!-- <\!-- 	  we found that little of significance had changed since 1969, when -\-> -->
<!-- <\!-- 	  the book was first published, we concluded that it would be more -\-> -->
<!-- <\!-- 	  useful to keep the original text and add an epilogue, so that the -\-> -->
<!-- <\!-- 	  book could still be read in its original form. Indeed, one reason -\-> -->
<!-- <\!-- 	  why progress in this field has been so slow is that researchers -\-> -->
<!-- <\!-- 	  unfamiliar with its history have continued to make many of the same -\-> -->
<!-- <\!-- 	  mistakes that others have made before them.  Some readers may find -\-> -->
<!-- <\!-- 	  it shocking to hear it said that little of significance has happened -\-> -->
<!-- <\!-- 	  in this field. Have not perceptron-like networks &mdash; under the -\-> -->
<!-- <\!-- 	  new name connectionism &mdash; become a major subject of discussion -\-> -->
<!-- <\!-- 	  at gatherings of psychologists and computer scientists? Has not -\-> -->
<!-- <\!-- 	  there been a <em>connectionist revolution?</em> Certainly yes, in -\-> -->
<!-- <\!-- 	  that there is a great deal of interest and discussion. Possibly yes, -\-> -->
<!-- <\!-- 	  in the sense that discoveries have been made that may, in time, turn -\-> -->
<!-- <\!-- 	  out to be of fundamental importance. But certainly no, in that there -\-> -->
<!-- <\!-- 	  has been little clear-cut change in the conceptual basis of the -\-> -->
<!-- <\!-- 	  field.  The issues that give rise to excitement today seem much the -\-> -->
<!-- <\!-- 	  same as those that were responsible for previous rounds of -\-> -->
<!-- <\!-- 	  excitement. The issues that were then obscure remain obscure today -\-> -->
<!-- <\!-- 	  because no one yet knows how to tell which of the present -\-> -->
<!-- <\!-- 	  discoveries are fundamental and which are superficial. Our position -\-> -->
<!-- <\!-- 	  remains what it was when we wrote the book: We believe this realm of -\-> -->
<!-- <\!-- 	  work to be immensely important and rich, but we expect its growth to -\-> -->
<!-- <\!-- 	  require a degree of critical analysis that its more romantic -\-> -->
<!-- <\!-- 	  advocates have always been reluctant to pursue &mdash; perhaps -\-> -->
<!-- <\!-- 	  because the spirit of connectionism seems itself to go somewhat -\-> -->
<!-- <\!-- 	  against the grain of analytic rigor.  In the next few pages we will -\-> -->
<!-- <\!-- 	  try to portray recent events in the field of parallel-network -\-> -->
<!-- <\!-- 	  learning machines as taking place within the historical context of a -\-> -->
<!-- <\!-- 	  war between antagonistic tendencies called symbolist and -\-> -->
<!-- <\!-- 	  connectionist. Many of the participants in this history see -\-> -->
<!-- <\!-- 	  themselves as divided on the question of strategies for thinking -\-> -->
<!-- <\!-- 	  &mdash; a division which seems to pervade our culture, engaging not -\-> -->
<!-- <\!-- 	  only those interested in building models of mental functions but -\-> -->
<!-- <\!-- 	  also writers, educators, therapists, and philosophers. Too many -\-> -->
<!-- <\!-- 	  people too often speak as though the strategies of thought fall -\-> -->
<!-- <\!-- 	  naturally into two groups whose attributes seem diametrically -\-> -->
<!-- <\!-- 	  opposed in character: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  symbolic . . . . . . connectionist logical . . . . . . analogical -\-> -->
<!-- <\!-- 	  serial . . . . . . .parallel discrete . . . . . . continuous -\-> -->
<!-- <\!-- 	  localized . . . . . . distributed hierarchical -\-> -->
<!-- <\!-- 	  . . . . . . heterarchical left-brained . . . . . . right-brained -\-> -->
	  
<!-- <\!-- 	  This broad division makes no sense to us, because these attributes -\-> -->
<!-- <\!-- 	  are largely independent of one another; for example, the very same -\-> -->
<!-- <\!-- 	  system could combine symbolic, analogical, serial, continuous, and -\-> -->
<!-- <\!-- 	  localized aspects. Nor do many of those pairs imply clear opposites; -\-> -->
<!-- <\!-- 	  at best they merely indicate some possible extremes among some wider -\-> -->
<!-- <\!-- 	  range of possibilities. And although many good theories begin by -\-> -->
<!-- <\!-- 	  making distinctions, we feel that in subjects as broad as these -\-> -->
<!-- <\!-- 	  there is less to be gained from sharpening boundaries than from -\-> -->
<!-- <\!-- 	  seeking useful intermediates. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The 1940s: Neural Networks The 1940s saw the emergence of the simple -\-> -->
<!-- <\!-- 	  yet powerful concept that the natural components of mind-like -\-> -->
<!-- <\!-- 	  machines were simple abstractions based on the behavior of -\-> -->
<!-- <\!-- 	  biological nerve cells &mdash; and that such machines could be built -\-> -->
<!-- <\!-- 	  by interconnecting such elements. In their 1943 manifesto A Logical -\-> -->
<!-- <\!-- 	  Calculus of the Ideas Immanent in Nervous Activity, Warren McCulloch -\-> -->
<!-- <\!-- 	  and Walter Pitts presented the first sophisticated discussion -\-> -->
<!-- <\!-- 	  of <em>neuro-logical networks,</em> in which they combined new ideas -\-> -->
<!-- <\!-- 	  about finite state machines, linear threshold decision elements, and -\-> -->
<!-- <\!-- 	  logical representations of various forms of behavior and memory. In -\-> -->
<!-- <\!-- 	  1947, they published a second monumental essay, How We Know -\-> -->
<!-- <\!-- 	  Universals, which described network architectures capable, in -\-> -->
<!-- <\!-- 	  principle, of recognizing spatial patterns in a manner invariant -\-> -->
<!-- <\!-- 	  under groups of geometric transformations.  From such ideas emerged -\-> -->
<!-- <\!-- 	  the intellectual movement called cybernetics, which attempted to -\-> -->
<!-- <\!-- 	  combine many concepts from biology, psychology, engineering, and -\-> -->
<!-- <\!-- 	  mathematics. The cybernetics era produced a flood of architectural -\-> -->
<!-- <\!-- 	  schemes for making neural networks recognize, track, memorize, and -\-> -->
<!-- <\!-- 	  perform many other useful functions. The decade ended with the -\-> -->
<!-- <\!-- 	  publication of Donald Hebb&#39;s book The Organization of Behavior, -\-> -->
<!-- <\!-- 	  the first attempt to base a large scale theory of psychology on -\-> -->
<!-- <\!-- 	  conjectures about neural networks. The central idea of Hebb&#39;s -\-> -->
<!-- <\!-- 	  book was that such networks might learn by constructing internal -\-> -->
<!-- <\!-- 	  representations of concepts in the form of what Hebb -\-> -->
<!-- <\!-- 	  called <em>cell-assemblies</em> &mdash; subfamilies of neurons that -\-> -->
<!-- <\!-- 	  would learn to support one another&#39;s activities. There had been -\-> -->
<!-- <\!-- 	  earlier attempts to explain psychology in terms -\-> -->
<!-- <\!-- 	  of <em>connections</em> or -\-> -->
<!-- <\!-- 	  <em>associations,</em> but perhaps because those connections were -\-> -->
<!-- <\!-- 	  merely between symbols or ideas rather than between mechanisms those -\-> -->
<!-- <\!-- 	  theories seemed then too insubstantial to be taken seriously by -\-> -->
<!-- <\!-- 	  theorists seeking models for mental mechanisms. Even after -\-> -->
<!-- <\!-- 	  Hebb&#39;s proposal, it was years before research in artificial -\-> -->
<!-- <\!-- 	  intelligence found suitably convincing ways to make symbolic -\-> -->
<!-- <\!-- 	  concepts seem concrete. -\-> -->
	  
	  
<!-- <\!-- 	  The 1950s: Learning in Neural Networks The cybernetic era opened up -\-> -->
<!-- <\!-- 	  the prospect of making mind-like machines. The earliest workers in -\-> -->
<!-- <\!-- 	  that field sought specific architectures that could perform specific -\-> -->
<!-- <\!-- 	  functions. However, in view of the fact that animals can learn to do -\-> -->
<!-- <\!-- 	  many things they aren&#39;t built to do, the goal soon changed to -\-> -->
<!-- <\!-- 	  making machines that could learn. Now, the concept of learning is -\-> -->
<!-- <\!-- 	  ill defined, because there is no clear-cut boundary between the -\-> -->
<!-- <\!-- 	  simplest forms of memory and complex procedures for making -\-> -->
<!-- <\!-- 	  predictions and generalizations about things never seen. Most of the -\-> -->
<!-- <\!-- 	  early experiments were based on the idea of -\-> -->
<!-- <\!-- 	  <em>reinforcing</em> actions that had been successful in the past -\-> -->
<!-- <\!-- 	  &mdash; a concept already popular in behavioristic psychology. In -\-> -->
<!-- <\!-- 	  order for reinforcement to be applied to a system, the system must -\-> -->
<!-- <\!-- 	  be capable of generating a sufficient variety of actions from which -\-> -->
<!-- <\!-- 	  to choose and the system needs some criterion of relative -\-> -->
<!-- <\!-- 	  success. These are also the same prerequisites for -\-> -->
<!-- <\!-- 	  the <em>hill-climbing</em> machines that we discuss in section 11.6 -\-> -->
<!-- <\!-- 	  and in the epilogue.  Perhaps the first reinforcement-based network -\-> -->
<!-- <\!-- 	  learning system was a machine built by Minsky in 1951. It consisted -\-> -->
<!-- <\!-- 	  of forty electronic units interconnected by a network of links, each -\-> -->
<!-- <\!-- 	  of which had an adjustable probability of receiving activation -\-> -->
<!-- <\!-- 	  signals and then transmitting them to other units. It learned by -\-> -->
<!-- <\!-- 	  means of a reinforcement process in which each positive or negative -\-> -->
<!-- <\!-- 	  judgment about the machine&#39;s behavior was translated into a -\-> -->
<!-- <\!-- 	  small change (of corresponding magnitude and sign) in the -\-> -->
<!-- <\!-- 	  probabilities associated with whichever connections had recently -\-> -->
<!-- <\!-- 	  transmitted signals. The 1950s saw many other systems that exploited -\-> -->
<!-- <\!-- 	  simple forms of learning, and this led to a professional specialty -\-> -->
<!-- <\!-- 	  called adaptive control.  Today, people often speak of neural -\-> -->
<!-- <\!-- 	  networks as offering a promise of machines that do not need to be -\-> -->
<!-- <\!-- 	  programmed. But speaking of those old machines in that way stands -\-> -->
<!-- <\!-- 	  history upon its head, since the concept of programming had barely -\-> -->
<!-- <\!-- 	  appeared at that time. When modern serial computers finally arrived, -\-> -->
<!-- <\!-- 	  it became a great deal easier to experiment with learning schemes, -\-> -->
<!-- <\!-- 	  and it became much easier to perform experiments in the field -\-> -->
<!-- <\!-- 	  of <em>self-organizing systems.</em> However, the availability of -\-> -->
<!-- <\!-- 	  computers also opened up other avenues of research into -\-> -->
<!-- <\!-- 	  learning. Perhaps the most notable example of this was Arthur -\-> -->
<!-- <\!-- 	  Samuel&#39;s research on programming computers to learn to play -\-> -->
<!-- <\!-- 	  checkers. (See Bibliographic Notes.) Using a success-based reward -\-> -->
<!-- <\!-- 	  system, Samuel&#39;s 1959 and 1967 programs attained masterful -\-> -->
<!-- <\!-- 	  levels of performance. In developing those procedures, Samuel -\-> -->
<!-- <\!-- 	  encountered and described two fundamental questions: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Credit assignment. Given some existing ingredients, how does one -\-> -->
<!-- <\!-- 	  decide how much to credit each of them for each of the machine&#39;s -\-> -->
<!-- <\!-- 	  accomplishments? In Samuel&#39;s machine, the weights are assigned -\-> -->
<!-- <\!-- 	  by correlation with success. -\-> -->
	  
<!-- <\!-- 	  Inventing novel predicates. If the existing ingredients are -\-> -->
<!-- <\!-- 	  inadequate, how does one invent new ones? Samuel&#39;s machine tests -\-> -->
<!-- <\!-- 	  products of some pre-existing terms. -\-> -->
	  
<!-- <\!-- 	  Most researchers tried to bypass these questions either by ignoring -\-> -->
<!-- <\!-- 	  them or by using brute force or by trying to discover powerful and -\-> -->
<!-- <\!-- 	  generally applicable methods. Few researchers tried to use them as -\-> -->
<!-- <\!-- 	  guides to thoughtful research. We ourselves do not believe that any -\-> -->
<!-- <\!-- 	  completely general solution to them can exist and we argue, in our -\-> -->
<!-- <\!-- 	  epilogue, that awareness of these issues should lead to making a -\-> -->
<!-- <\!-- 	  model of mind that can accumulate a multiplicity of specialized -\-> -->
<!-- <\!-- 	  methods.  By the end of the 1950s the field of neural network -\-> -->
<!-- <\!-- 	  research had become virtually dormant. In part this was because -\-> -->
<!-- <\!-- 	  there had not been many important discoveries for a long time. But -\-> -->
<!-- <\!-- 	  it was also partly because there had been important advances in -\-> -->
<!-- <\!-- 	  artificial intelligence, using new kinds of models based on serial -\-> -->
<!-- <\!-- 	  processing of symbolic expressions. New landmarks appeared in the -\-> -->
<!-- <\!-- 	  form of working computer programs that solved quite respectably -\-> -->
<!-- <\!-- 	  difficult problems. In the wake of these accomplishments, theories -\-> -->
<!-- <\!-- 	  based upon connections among symbols suddenly seemed more -\-> -->
<!-- <\!-- 	  satisfactory. And although we and some other workers maintained -\-> -->
<!-- <\!-- 	  allegiances to both approaches, intellectual battle lines began to -\-> -->
<!-- <\!-- 	  form along such conceptual fronts as parallel versus serial -\-> -->
<!-- <\!-- 	  processing, learning versus programming, and emergence versus -\-> -->
<!-- <\!-- 	  analytic description. -\-> -->
	  
<!-- <\!-- 	  The 1960s: Connectionists and Symbolists Interest in connectionist -\-> -->
<!-- <\!-- 	  networks revived dramatically in 1962 with the publication of Frank -\-> -->
<!-- <\!-- 	  Rosenblatt&#39;s book, Principles of Neurodynamics, in which he -\-> -->
<!-- <\!-- 	  defined the machines he named perceptrons and proved many theorems -\-> -->
<!-- <\!-- 	  about them. (See Bibliographic Notes.) The basic idea was so simply -\-> -->
<!-- <\!-- 	  and clearly defined that it was feasible to prove an amazing theorem -\-> -->
<!-- <\!-- 	  (theorem 11.1 below) which stated that a perceptron would learn to -\-> -->
<!-- <\!-- 	  do anything that it was possible to program it to do. And the -\-> -->
<!-- <\!-- 	  connectionists of the 1960s were indeed able to make perceptrons -\-> -->
<!-- <\!-- 	  learn to do certain things &mdash; but not other things. Usually, -\-> -->
<!-- <\!-- 	  when failure occurred, neither prolonging the training experiments -\-> -->
<!-- <\!-- 	  nor building larger machines helped. All perceptrons would fail to -\-> -->
<!-- <\!-- 	  learn to do those things, and once again the work in this field -\-> -->
<!-- <\!-- 	  stalled.  Arthur Samuel&#39;s two questions can help us see why -\-> -->
<!-- <\!-- 	  perceptrons worked as well as they did. First, Rosenblatt&#39;s -\-> -->
<!-- <\!-- 	  credit assignment method turned out to be as effective as any such -\-> -->
<!-- <\!-- 	  method could be.  When the answer is obtained, in effect, by adding -\-> -->
<!-- <\!-- 	  up the contributions of many processes that have no significant -\-> -->
<!-- <\!-- 	  interactions among themselves, then the best one can do is reward -\-> -->
<!-- <\!-- 	  them in proportion to how much each of them contributed. (Actually, -\-> -->
<!-- <\!-- 	  with perceptrons, one never rewards success; one only punishes -\-> -->
<!-- <\!-- 	  failures.) And Rosenblatt offered the simplest possible approach to -\-> -->
<!-- <\!-- 	  the problem of inventing new parts. You don&#39;t have to invent new -\-> -->
<!-- <\!-- 	  parts if enough parts are provided from the start. Once it became -\-> -->
<!-- <\!-- 	  clear that these tactics would work in certain circumstances but not -\-> -->
<!-- <\!-- 	  in others, most workers searched for methods that worked in -\-> -->
<!-- <\!-- 	  general. However, in our book we turned in a different -\-> -->
<!-- <\!-- 	  direction. Instead of trying to find a method that would work in -\-> -->
<!-- <\!-- 	  every possible situation, we sought to find ways to understand why -\-> -->
<!-- <\!-- 	  the particular method used in the perceptron would succeed in some -\-> -->
<!-- <\!-- 	  situations but not in others. It turned out that perceptrons could -\-> -->
<!-- <\!-- 	  usually solve the types of problems that we characterize (in section -\-> -->
<!-- <\!-- 	  0.8) as being of low <em>order.</em> With those problems, one can -\-> -->
<!-- <\!-- 	  indeed sometimes get by with making ingredients at random and then -\-> -->
<!-- <\!-- 	  selecting the ones that work. However, problems of -\-> -->
<!-- <\!-- 	  higher <em>orders</em> require too many such ingredients for this to -\-> -->
<!-- <\!-- 	  be feasible.  This style of analysis was the first to show that -\-> -->
<!-- <\!-- 	  there are fundamental limitations on the kinds of patterns that -\-> -->
<!-- <\!-- 	  perceptrons can ever learn to recognize. How did the scientists -\-> -->
<!-- <\!-- 	  involved with such matters react to this? One popular version is -\-> -->
<!-- <\!-- 	  that the publication of our book so discouraged research on learning -\-> -->
<!-- <\!-- 	  in network machines that a promising line of research was -\-> -->
<!-- <\!-- 	  interrupted. Our version is that progress had already come to a -\-> -->
<!-- <\!-- 	  virtual halt because of the lack of adequate basic theories, and the -\-> -->
<!-- <\!-- 	  lessons in this book provided the field with new momentum &mdash; -\-> -->
<!-- <\!-- 	  albeit, paradoxically, by redirecting its immediate concerns. To -\-> -->
<!-- <\!-- 	  understand the situation, one must recall that by the mid 1960s -\-> -->
<!-- <\!-- 	  there had been a great many experiments with perceptrons, but no one -\-> -->
<!-- <\!-- 	  had been able to explain why they were able to learn to recognize -\-> -->
<!-- <\!-- 	  certain kinds of patterns and not others. Was this in the nature of -\-> -->
<!-- <\!-- 	  the learning procedures? Did it depend on the sequences in which the -\-> -->
<!-- <\!-- 	  patterns were presented? Were the machines simply too small in -\-> -->
<!-- <\!-- 	  capacity?  What we discovered was that the traditional analysis of -\-> -->
<!-- <\!-- 	  learning machines &mdash; and of perceptrons in particular &mdash; -\-> -->
<!-- <\!-- 	  had looked in the wrong direction. Most theorists had tried to focus -\-> -->
<!-- <\!-- 	  only on the mathematical structure of what was common to all -\-> -->
<!-- <\!-- 	  learning &mdash; and the theories to which this had led were too -\-> -->
<!-- <\!-- 	  general and too weak to explain which patterns perceptrons could -\-> -->
<!-- <\!-- 	  learn to recognize. As our analysis in chapter 2 shows, this -\-> -->
<!-- <\!-- 	  actually had nothing to with learning at all; it has to do with the -\-> -->
<!-- <\!-- 	  relationships between the perceptron&#39;s architecture and the -\-> -->
<!-- <\!-- 	  characters of the problems that were being presented to it. The -\-> -->
<!-- <\!-- 	  trouble appeared when perceptrons had no way to represent the -\-> -->
<!-- <\!-- 	  knowledge required for solving certain problems. The moral was that -\-> -->
<!-- <\!-- 	  one simply cannot learn enough by studying learning by itself; one -\-> -->
<!-- <\!-- 	  also has to understand the nature of what one wants to learn. This -\-> -->
<!-- <\!-- 	  can be expressed as a principle that applies not only to perceptrons -\-> -->
<!-- <\!-- 	  but to every sort of learning machine: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  No machine can learn to recognize X unless it possesses, at least -\-> -->
<!-- <\!-- 	  potentially, some scheme for representing X. -\-> -->
	  
	  
<!-- <\!-- 	  The 1970s. Representation of Knowledge Why were so few discoveries -\-> -->
<!-- <\!-- 	  about network machines made since the work of Rosenblatt? It has -\-> -->
<!-- <\!-- 	  sometimes been suggested that the -\-> -->
<!-- <\!-- 	  <em>pessimism</em> of this book was responsible for the fact that -\-> -->
<!-- <\!-- 	  connectionism was in a relative eclipse until recent research broke -\-> -->
<!-- <\!-- 	  through the limitations that we had purported to establish. Indeed, -\-> -->
<!-- <\!-- 	  this book has been described as having been intended to demonstrate -\-> -->
<!-- <\!-- 	  that perceptrons (and all other network machines) are too limited to -\-> -->
<!-- <\!-- 	  deserve further attention. Certainly many of the best researchers -\-> -->
<!-- <\!-- 	  turned away from network machines for quite some time, but those -\-> -->
<!-- <\!-- 	  present-day connectionists who regard that as regrettable have -\-> -->
<!-- <\!-- 	  failed to understand the place in which they stand in history. As we -\-> -->
<!-- <\!-- 	  said earlier, it seems to us that the effect of Perceptrons was not -\-> -->
<!-- <\!-- 	  simply to interrupt a healthy line of research. That redirection of -\-> -->
<!-- <\!-- 	  concern was no arbitrary diversion; it was a necessary interlude. To -\-> -->
<!-- <\!-- 	  make further progress, connectionists would have to take time off -\-> -->
<!-- <\!-- 	  and develop adequate ideas about the representation of knowledge. In -\-> -->
<!-- <\!-- 	  the epilogue we shall explain why that was a prerequisite for -\-> -->
<!-- <\!-- 	  understanding more complex types of network machines.  In any case, -\-> -->
<!-- <\!-- 	  the 1970s became the golden age of a new field of research into the -\-> -->
<!-- <\!-- 	  representation of knowledge and it was not only connectionist -\-> -->
<!-- <\!-- 	  learning that was placed on hold; it also happened to research on -\-> -->
<!-- <\!-- 	  learning in the field of artificial intelligence. For example, -\-> -->
<!-- <\!-- 	  although Patrick Winston&#39;s 1970 doctoral thesis (See -\-> -->
<!-- <\!-- 	  <em>Learning Structural Definitions from Examples,</em> in The -\-> -->
<!-- <\!-- 	  Psychology of Computer Vision, ed. P. H. Winston, McGraw-Hill, -\-> -->
<!-- <\!-- 	  1975.) was clearly a major advance, the next decade of AI research -\-> -->
<!-- <\!-- 	  showed surprisingly little attention to that subject. In several -\-> -->
<!-- <\!-- 	  other related fields, such as cognitive psychology, many researchers -\-> -->
<!-- <\!-- 	  set aside their interest in the study of learning in favor of -\-> -->
<!-- <\!-- 	  examining the representation of knowledge in many different contexts -\-> -->
<!-- <\!-- 	  and forms. The result was the very rapid development of many new and -\-> -->
<!-- <\!-- 	  powerful ideas, among them, frames, scripts, conceptual dependency, -\-> -->
<!-- <\!-- 	  nonmonotonic logic, production systems, semantic networks, -\-> -->
<!-- <\!-- 	  word-expert parsers, analogy generators, relational databases, -\-> -->
<!-- <\!-- 	  cooperative processes, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  K-lines, and planning procedures.  These ideas about the analysis of -\-> -->
<!-- <\!-- 	  knowledge and its embodiments, in turn, had strong effects not only -\-> -->
<!-- <\!-- 	  in the heart of artificial intelligence, but also in many areas of -\-> -->
<!-- <\!-- 	  psychology, brain science, and applied expert systems. Consequently, -\-> -->
<!-- <\!-- 	  although not all of them recognize this, a good deal of what young -\-> -->
<!-- <\!-- 	  researchers do today is based on what was learned about the -\-> -->
<!-- <\!-- 	  representation of knowledge since Perceptrons was published. As was -\-> -->
<!-- <\!-- 	  asserted above, their not knowing that history often leads them to -\-> -->
<!-- <\!-- 	  repeat mistakes of the past. For example, many contemporary -\-> -->
<!-- <\!-- 	  experimenters assume that, because the perceptron networks discussed -\-> -->
<!-- <\!-- 	  in this book are not exactly the same as those in use today, these -\-> -->
<!-- <\!-- 	  theorems no longer apply. Yet, as we will show in our epilogue, most -\-> -->
<!-- <\!-- 	  of the lessons of the theorems still apply. -\-> -->
	  
	  
<!-- <\!-- 	  The 1980s: The Revival of Learning Machines What could account for -\-> -->
<!-- <\!-- 	  the recent resurgence of interest in network machines? What turned -\-> -->
<!-- <\!-- 	  the tide in the battle between the connectionists and the -\-> -->
<!-- <\!-- 	  symbolists? Was it that symbolic AI had run out of steam? Was it the -\-> -->
<!-- <\!-- 	  important new ideas in Connectionism? Was it the prospect of new, -\-> -->
<!-- <\!-- 	  massively parallel hardware? Or did the new interest reflect a -\-> -->
<!-- <\!-- 	  cultural turn toward holism?  Whatever the answer, a more important -\-> -->
<!-- <\!-- 	  question is: Are there inherent incompatibilities between those -\-> -->
<!-- <\!-- 	  connectionist and symbolist views? The answer to that depends on the -\-> -->
<!-- <\!-- 	  extent to which one regards each separate connectionist scheme as a -\-> -->
<!-- <\!-- 	  self-standing system. If one were to ask whether any particular, -\-> -->
<!-- <\!-- 	  homogeneous network could serve as a model for a brain, the answer -\-> -->
<!-- <\!-- 	  (we claim) would be, clearly, no. But if we consider each such -\-> -->
<!-- <\!-- 	  network as a possible model for a part of a brain, then those two -\-> -->
<!-- <\!-- 	  overviews are clearly complementary.  This is why we see no reason -\-> -->
<!-- <\!-- 	  to choose sides. We expect a great many new ideas to emerge from the -\-> -->
<!-- <\!-- 	  study of symbol-based theories and experiments. And we expect the -\-> -->
<!-- <\!-- 	  future of network-based learning machines to be rich beyond -\-> -->
<!-- <\!-- 	  imagining. As we say in section 0.3, the solemn experts who -\-> -->
<!-- <\!-- 	  complained most about the -\-> -->
<!-- <\!-- 	  <em>exaggerated claims</em> of the cybernetic enthusiasts were, on -\-> -->
<!-- <\!-- 	  balance, in the wrong. It is just as clear to us today as it was 20 -\-> -->
<!-- <\!-- 	  years ago that the marvelous abilities of the human brain must -\-> -->
<!-- <\!-- 	  emerge from the parallel activity of vast assemblies of -\-> -->
<!-- <\!-- 	  interconnected nerve cells. But, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  as we explain in our epilogue, the marvelous powers of the brain -\-> -->
<!-- <\!-- 	  emerge not from any single, uniformly structured connectionist -\-> -->
<!-- <\!-- 	  network but from highly evolved arrangements of smaller, specialized -\-> -->
<!-- <\!-- 	  networks which are interconnected in very specific ways.  The -\-> -->
<!-- <\!-- 	  movement of research interest between the poles of connectionist -\-> -->
<!-- <\!-- 	  learning and symbolic reasoning may provide a fascinating subject -\-> -->
<!-- <\!-- 	  for the sociology of science, but workers inside those fields must -\-> -->
<!-- <\!-- 	  understand that these poles are artificial simplifications. It can -\-> -->
<!-- <\!-- 	  be most revealing to study neural nets in their purest forms, or to -\-> -->
<!-- <\!-- 	  do the same with elegant theories about formal reasoning. Such -\-> -->
<!-- <\!-- 	  isolated studies often help in the disentangling of different types -\-> -->
<!-- <\!-- 	  of mechanisms, insights, and principles. But it never makes any -\-> -->
<!-- <\!-- 	  sense to choose either of those two views as one&#39;s only model of -\-> -->
<!-- <\!-- 	  the mind. Both are partial and manifestly useful views of a reality -\-> -->
<!-- <\!-- 	  of which science is still far from a comprehensive understanding. -\-> -->
	  
<!-- <\!-- 	  EPILOGUE: THE NEW CONNECTIONISM When perceptron-like machines came -\-> -->
<!-- <\!-- 	  on the scene, we found that in order to understand their -\-> -->
<!-- <\!-- 	  capabilities we needed some new ideas. It was not enough simply to -\-> -->
<!-- <\!-- 	  examine the machines themselves, or the procedures used to make them -\-> -->
<!-- <\!-- 	  learn. Instead, we had to find new ways to understand the problems -\-> -->
<!-- <\!-- 	  they would be asked to solve. This is why our book turned out to be -\-> -->
<!-- <\!-- 	  concerned less with perceptrons per se than with concepts that could -\-> -->
<!-- <\!-- 	  help us see the relation between patterns and the types of parallel -\-> -->
<!-- <\!-- 	  machine architectures that might or might not be able to recognize -\-> -->
<!-- <\!-- 	  them.  Why was it so important to develop theories about parallel -\-> -->
<!-- <\!-- 	  machines? One reason was that the emergence of serial computers -\-> -->
<!-- <\!-- 	  quickly led to a very respectable body of useful ideas about -\-> -->
<!-- <\!-- 	  algorithms and algorithmic languages, many of them based on a -\-> -->
<!-- <\!-- 	  half-century&#39;s previous theories about logic and effective -\-> -->
<!-- <\!-- 	  computability. But similarly powerful ideas about parallel -\-> -->
<!-- <\!-- 	  computation did not develop nearly so rapidly &mdash; partly because -\-> -->
<!-- <\!-- 	  massively parallel hardware did not become available until much -\-> -->
<!-- <\!-- 	  later and partly because much less knowledge that might be relevant -\-> -->
<!-- <\!-- 	  had been accumulated in the mathematical past &mdash; perhaps -\-> -->
<!-- <\!-- 	  because that subject was inherently more difficult. Today, however, -\-> -->
<!-- <\!-- 	  it is feasible either to simulate or to actually assemble huge and -\-> -->
<!-- <\!-- 	  complex arrangements of interacting elements. Consequently, theories -\-> -->
<!-- <\!-- 	  about parallel computation have now become of immediate and intense -\-> -->
<!-- <\!-- 	  concern to workers in physics, engineering, management, and many -\-> -->
<!-- <\!-- 	  other disciplines &mdash; and especially to workers involved with -\-> -->
<!-- <\!-- 	  brain science, psychology, and artificial intelligence.  Perhaps -\-> -->
<!-- <\!-- 	  this is why the past few years have seen new and heated discussions -\-> -->
<!-- <\!-- 	  of network machines as part of an intellectually aggressive movement -\-> -->
<!-- <\!-- 	  to establish a paradigm for artificial intelligence and cognitive -\-> -->
<!-- <\!-- 	  modeling. Indeed, this growth of activity and interest has been so -\-> -->
<!-- <\!-- 	  swift that people talk about a <em>connectionist revolution.</em> -\-> -->
<!-- <\!-- 	  The purpose of this epilogue, added in 1987, is to help present-day -\-> -->
<!-- <\!-- 	  students to use the ideas presented in Perceptrons to put the new -\-> -->
<!-- <\!-- 	  results into perspective and to formulate more clearly the research -\-> -->
<!-- <\!-- 	  questions suggested by them. To do this succinctly, we adopt the -\-> -->
<!-- <\!-- 	  strategy of focusing on one particularly example of modern -\-> -->
<!-- <\!-- 	  connectionist writing. Recently, David Rumelhart, James McClelland, -\-> -->
<!-- <\!-- 	  and fourteen other collaborators published a two volume work that -\-> -->
<!-- <\!-- 	  has become something of a connectionist manifesto: Parallel -\-> -->
<!-- <\!-- 	  Distributed Processing (MIT Press, 1986). We shall take this book -\-> -->
<!-- <\!-- 	  (henceforth referred to as PDP) as our connectionist text. What we -\-> -->
<!-- <\!-- 	  say about this particular text will not, of course, apply literally -\-> -->
<!-- <\!-- 	  to other writing on this subject, but thoughtful readers will seize -\-> -->
<!-- <\!-- 	  the general point through the particular case. In most of this -\-> -->
<!-- <\!-- 	  epilogue we shall discuss the examples in PDP from inside the -\-> -->
<!-- <\!-- 	  connectionist perspective, in order to flag certain problems that we -\-> -->
<!-- <\!-- 	  do not expect to be soluble within the framework of any single, -\-> -->
<!-- <\!-- 	  homogeneous machine. At the end, however, we shall consider the same -\-> -->
<!-- <\!-- 	  problems from the perspective of the overview we call <em>society of -\-> -->
<!-- <\!--             mind</em> &mdash; a conceptual framework that makes it much more -\-> -->
<!-- <\!-- 	  feasible to exploit collections of specialized accomplishments.  PDP -\-> -->
<!-- <\!-- 	  describes Perceptrons as pessimistic about the prospects for -\-> -->
<!-- <\!-- 	  connectionist machinery: -\-> -->
	  
<!-- <\!-- 	  even though multilayer linear threshold networks are potentially -\-> -->
<!-- <\!-- 	  much more powerful . . . it was the limitations on what perceptrons -\-> -->
<!-- <\!-- 	  could possibly learn that led to Minsky and Papert&#39;s (1969) -\-> -->
<!-- <\!-- 	  pessimistic evaluation of the perceptron. Unfortunately, that -\-> -->
<!-- <\!-- 	  evaluation has incorrectly tainted more interesting and powerful -\-> -->
<!-- <\!-- 	  networks of linear threshold and other nonlinear units. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  As we shall see, the limitations of the one-step perceptrons in no -\-> -->
<!-- <\!-- 	  way apply to the more complex networks. (PDP, vol.1, p.65) -\-> -->
	  
<!-- <\!-- 	  We scarcely recognize ourselves in this description, and we -\-> -->
<!-- <\!-- 	  recommend rereading the remarks in section 0.3 about romanticism and -\-> -->
<!-- <\!-- 	  rigor. We reiterate our belief that the romantic claims have been -\-> -->
<!-- <\!-- 	  less wrong than the pompous criticisms. But we also reiterate that -\-> -->
<!-- <\!-- 	  the discipline can grow only when it makes a parallel effort to -\-> -->
<!-- <\!-- 	  critically evaluate its apparent accomplishments. Our own work in -\-> -->
<!-- <\!-- 	  Perceptrons is based on the interaction between an enthusiastic -\-> -->
<!-- <\!-- 	  pursuit of models of new phenomena and a rigorous search for ways to -\-> -->
<!-- <\!-- 	  understand the limitations of these models.  In any case, such -\-> -->
<!-- <\!-- 	  citations have given our book the reputation of being mainly -\-> -->
<!-- <\!-- 	  concerned with what perceptrons cannot do, and of having concluded -\-> -->
<!-- <\!-- 	  with a qualitative evaluation that the subject was not -\-> -->
<!-- <\!-- 	  important. Certainly, some chapters prove that various important -\-> -->
<!-- <\!-- 	  predicates have perceptron coefficients that grow unmanageably -\-> -->
<!-- <\!-- 	  large. But many chapters show that other predicates can be -\-> -->
<!-- <\!-- 	  surprisingly tractable. It is no more apt to describe our -\-> -->
<!-- <\!-- 	  mathematical theorems as pessimistic than it would be to say the -\-> -->
<!-- <\!-- 	  same about deducing the conservation of momentum from the laws of -\-> -->
<!-- <\!-- 	  mechanics. Theorems are theorems, and the history of science amply -\-> -->
<!-- <\!-- 	  demonstrates how discovering limiting principles can lead to deeper -\-> -->
<!-- <\!-- 	  understanding. But this happens only when those principles are taken -\-> -->
<!-- <\!-- 	  seriously, so we exhort contemporary connectionist researchers to -\-> -->
<!-- <\!-- 	  consider our results seriously as sources of research questions -\-> -->
<!-- <\!-- 	  instead of maintaining that they <em>in no way apply.</em> -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  What Perceptrons Can&#39;t Do To put our results into perspective, -\-> -->
<!-- <\!-- 	  let us recall the situation in the early 1960s. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Many people were impressed by the fact that initially unstructured -\-> -->
<!-- <\!-- 	  networks composed of very simple devices could be made to perform -\-> -->
<!-- <\!-- 	  many interesting tasks &mdash; by processes that could be seen as -\-> -->
<!-- <\!-- 	  remarkably like some forms of learning. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  A different fact seemed to have impressed only a few people: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  while those networks did well on certain tasks, and failed on -\-> -->
<!-- <\!-- 	  certain other tasks, there was no theory to explain what made the -\-> -->
<!-- <\!-- 	  difference &mdash; particularly when they seemed to work well on -\-> -->
<!-- <\!-- 	  small &mdash; call them toy &mdash; problems but broke down with -\-> -->
<!-- <\!-- 	  larger problems of the same kind. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Our goal was to develop analytic tools to give us better ideas about -\-> -->
<!-- <\!-- 	  what made the difference. But finding a comprehensive theory of -\-> -->
<!-- <\!-- 	  parallel computation seemed infeasible, because the subject was -\-> -->
<!-- <\!-- 	  simply too general. What we had to do was sharpen our ideas by -\-> -->
<!-- <\!-- 	  working with some subclass of parallel machines that would be -\-> -->
<!-- <\!-- 	  sufficiently powerful to perform significant computations, that -\-> -->
<!-- <\!-- 	  would also share at least some of the features that made such -\-> -->
<!-- <\!-- 	  networks attractive to those who sought a deeper understanding of -\-> -->
<!-- <\!-- 	  the brain, and that would also be mathematically simple enough to -\-> -->
<!-- <\!-- 	  permit theoretical analysis. This is why we used the abstract -\-> -->
<!-- <\!-- 	  definition of perceptron given in this book. The perceptron seemed -\-> -->
<!-- <\!-- 	  powerful enough in function, suggestive enough in architecture, and -\-> -->
<!-- <\!-- 	  simple enough in its mathematical definition, yet understanding the -\-> -->
<!-- <\!-- 	  range and character of its capabilities presented challenging -\-> -->
<!-- <\!-- 	  puzzles. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Our prime example of such a puzzle was the recognition of -\-> -->
<!-- <\!-- 	  connectedness. It took us many months of work to capture in a formal -\-> -->
<!-- <\!-- 	  proof our strong intuition that perceptrons were unable to represent -\-> -->
<!-- <\!-- 	  that predicate. Perhaps the most instructive aspect of that whole -\-> -->
<!-- <\!-- 	  process was that we were guided by a flawed intuition to the proof -\-> -->
<!-- <\!-- 	  that perceptrons cannot recognize the connectivity in any general or -\-> -->
<!-- <\!-- 	  practical sense. We had assumed that perceptrons could not even -\-> -->
<!-- <\!-- 	  detect the connectivity of hole-free blobs &mdash; because, as we -\-> -->
<!-- <\!-- 	  supposed, no local forms of evidence like those in figure 5.7 could -\-> -->
<!-- <\!-- 	  correlate with the correct decision. Yet, as we saw in subsection -\-> -->
<!-- <\!-- 	  5.8.1, if a figure is known to have no holes, then a low order -\-> -->
<!-- <\!-- 	  perceptron can decide on its connectivity; this we had not initially -\-> -->
<!-- <\!-- 	  believed to be possible. It is hard to imagine better evidence to -\-> -->
<!-- <\!-- 	  show how artificial it is to separate -\-> -->
<!-- <\!-- 	  <em>negative</em> from <em>positive</em> results in this kind of -\-> -->
<!-- <\!-- 	  investigation. To explain how this experience affected us, we must -\-> -->
<!-- <\!-- 	  abstract what we learned from it.  First we learned to reformulate -\-> -->
<!-- <\!-- 	  questions like <em>Can perceptrons perform a certain task?</em> -\-> -->
<!-- <\!-- 	  Strictly speaking, it is misleading to say that perceptrons cannot -\-> -->
<!-- <\!-- 	  recognize connectedness, &mdash; since for any particular size of -\-> -->
<!-- <\!-- 	  retina we can make a perceptron that will recognize any predicate by -\-> -->
<!-- <\!-- 	  providing enough phi&#39;s of sufficiently high order. What we did -\-> -->
<!-- <\!-- 	  show was that the general predicate requires perceptrons of -\-> -->
<!-- <\!-- 	  unbounded order. More generally, we learned to replace globally -\-> -->
<!-- <\!-- 	  qualitative questions about what perceptrons cannot do with -\-> -->
<!-- <\!-- 	  questions in the spirit of what is now called computational -\-> -->
<!-- <\!-- 	  complexity. Many of our results are of the form M=f(R), where R is a -\-> -->
<!-- <\!-- 	  measure of the size of the problem and M is the magnitude of some -\-> -->
<!-- <\!-- 	  parameter of a perceptron (such as the order of its predicates, how -\-> -->
<!-- <\!-- 	  many of them might be required, the information content of the -\-> -->
<!-- <\!-- 	  coefficients, or the number of cycles needed for learning to -\-> -->
<!-- <\!-- 	  converge). The study of such relationships gave us a better sense of -\-> -->
<!-- <\!-- 	  what is likely to go wrong when one tries to enlarge the scale of a -\-> -->
<!-- <\!-- 	  perceptron-like computation. In serial computing it was already well -\-> -->
<!-- <\!-- 	  known that certain algorithms depending on search processes would -\-> -->
<!-- <\!-- 	  require numbers of steps of computation that increase exponentially -\-> -->
<!-- <\!-- 	  with the size of the problem. Much less was known about such matters -\-> -->
<!-- <\!-- 	  in the case of parallel machines.  The second lesson was that in -\-> -->
<!-- <\!-- 	  order to understand what perceptrons can do we would have to develop -\-> -->
<!-- <\!-- 	  some theories of -\-> -->
<!-- <\!-- 	  <em>problem domains</em> and not simply a <em>theory of -\-> -->
<!-- <\!--             perceptrons.</em> In previous work on networks, from McCulloch and -\-> -->
<!-- <\!-- 	  Pitts to Rosenblatt, even the best theorists had tried to formulate -\-> -->
<!-- <\!-- 	  general purpose theories about the kind of network they were -\-> -->
<!-- <\!-- 	  interested in. Rosenblatt&#39;s convergence theory is an example of -\-> -->
<!-- <\!-- 	  how such investigation can lead to powerful results. But something -\-> -->
<!-- <\!-- 	  qualitatively different was needed to explain why perceptrons could -\-> -->
<!-- <\!-- 	  recognize the &mdash; connectedness of hole-free blobs yet be unable -\-> -->
<!-- <\!-- 	  to recognize connectedness in general.  For this we needed a bridge -\-> -->
<!-- <\!-- 	  between a theory about the computing device and a theory about the -\-> -->
<!-- <\!-- 	  content of the computation. The reason why our group invariance -\-> -->
<!-- <\!-- 	  theorem was so useful here was that it had one foot on the geometric -\-> -->
<!-- <\!-- 	  side and one on the computational side.  Our study of the perceptron -\-> -->
<!-- <\!-- 	  was an attempt to understand general principles through the study of -\-> -->
<!-- <\!-- 	  a special case. Even today, we still know very little, in general, -\-> -->
<!-- <\!-- 	  about how the costs of parallel computation are affected by -\-> -->
<!-- <\!-- 	  increases in the scale of problems.  Only the cases we understand -\-> -->
<!-- <\!-- 	  can serve as bases for conjectures about what will happen in other -\-> -->
<!-- <\!-- 	  situations. Thus, until there is evidence to the contrary, we are -\-> -->
<!-- <\!-- 	  inclined to project the significance of our results to other -\-> -->
<!-- <\!-- 	  networks related to perceptrons. In the past few years, many -\-> -->
<!-- <\!-- 	  experiments have demonstrated that various new types of learning -\-> -->
<!-- <\!-- 	  machines, composed of multiple layers of perceptron- like elements, -\-> -->
<!-- <\!-- 	  can be made to solve many kinds of small-scale problems.  Some of -\-> -->
<!-- <\!-- 	  those experimenters believe that these performances can be -\-> -->
<!-- <\!-- 	  economically extended to larger problems without encountering the -\-> -->
<!-- <\!-- 	  limitations we have shown to apply to single-layer perceptrons. -\-> -->
<!-- <\!-- 	  Shortly, we shall take a closer look at some of those results and -\-> -->
<!-- <\!-- 	  see that much of what we learned about simple perceptrons will still -\-> -->
<!-- <\!-- 	  remain quite pertinent. It certainly is true that most of the -\-> -->
<!-- <\!-- 	  theorems in this book are explicitly about machines with a single -\-> -->
<!-- <\!-- 	  layer of adjustable connection weights. But this does not imply (as -\-> -->
<!-- <\!-- 	  many modern connectionists assume) that our conclusions don&#39;t -\-> -->
<!-- <\!-- 	  apply to multilayered machines. To be sure, those proofs no longer -\-> -->
<!-- <\!-- 	  apply unchanged, because their antecedent conditions have -\-> -->
<!-- <\!-- 	  changed. But the phenomena they describe will often still -\-> -->
<!-- <\!-- 	  persist. One must examine them, case by case.  For example, all our -\-> -->
<!-- <\!-- 	  conclusions about order-limited predicates (see section 0.7) -\-> -->
<!-- <\!-- 	  continue to apply to networks with multiple layers, because the -\-> -->
<!-- <\!-- 	  order of any unit in a given layer is bounded by the product of the -\-> -->
<!-- <\!-- 	  orders of the units in earlier layers. Since many of our arguments -\-> -->
<!-- <\!-- 	  about order constrain the representations of group-invariant -\-> -->
<!-- <\!-- 	  predicates, we suspect that many of those conclusions, too, will -\-> -->
<!-- <\!-- 	  apply to multilayer nets. For example, multilayer networks will be -\-> -->
<!-- <\!-- 	  no more able to recognize connectedness than are perceptrons. (This -\-> -->
<!-- <\!-- 	  is not to say that multilayer networks do not have advantages. For -\-> -->
<!-- <\!-- 	  example, the product rule can yield logarithmic reductions in the -\-> -->
<!-- <\!-- 	  orders and numbers of units required to compute certain high-order -\-> -->
<!-- <\!-- 	  predicates. Furthermore, units that are arranged in loops can be of -\-> -->
<!-- <\!-- 	  effectively unbounded order; hence, some such networks will be able -\-> -->
<!-- <\!-- 	  to recognize connectedness by using internal serial processing.) -\-> -->
<!-- <\!-- 	  Thus, in some cases our conclusions will remain provably true and in -\-> -->
<!-- <\!-- 	  other cases they will be clearly false. In the middle there are many -\-> -->
<!-- <\!-- 	  results that we still think may hold, but we do not know any formal -\-> -->
<!-- <\!-- 	  proofs. In the next section we shall show how some of the -\-> -->
<!-- <\!-- 	  experiments reported in PDP lend credence to some such conjectures. -\-> -->
	  
<!-- <\!-- 	  Recognizing Symmetry In this section we contrast two different -\-> -->
<!-- <\!-- 	  networks, both of which recognize symmetrical patterns defined on a -\-> -->
<!-- <\!-- 	  six-point linear retina.  To be precise, we would like to recognize -\-> -->
<!-- <\!-- 	  the predicate X is symmetric about the midpoint of R. Figure 1 shows -\-> -->
<!-- <\!-- 	  a simple way to represent this is as a perceptron that uses R -\-> -->
<!-- <\!-- 	  phi-units, each of order 2. Each one of them will locally detect a -\-> -->
<!-- <\!-- 	  deviation from symmetry at two particular retinal points. -\-> -->
	  

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Figure 2 shows the result of an experiment from PDP. It depicts a -\-> -->
<!-- <\!-- 	  network that represents psi-symmetry in quite a different way. -\-> -->
<!-- <\!-- 	  Amazingly, this network uses only two phi-functions &mdash; albeit -\-> -->
<!-- <\!-- 	  ones of order R.  (We have replaced PDP&#39;s fractional -\-> -->
<!-- <\!-- 	  coefficients with functionally equivalent integers.) -\-> -->

<!-- <\!-- 	<p> -\-> -->
	  

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The weights displayed in figure 14.2 were produced by a learning -\-> -->
<!-- <\!-- 	  procedure that we shall describe shortly. For the moment, we want to -\-> -->
<!-- <\!-- 	  focus not on the learning problem but on the character of the -\-> -->
<!-- <\!-- 	  coefficients themselves. We share the sense of excitement the PDP -\-> -->
<!-- <\!-- 	  experimenters must have experienced as their machine converged to -\-> -->
<!-- <\!-- 	  this strange solution, in which this predicate seems to be portrayed -\-> -->
<!-- <\!-- 	  as having a more holistic character that would be suggested by its -\-> -->
<!-- <\!-- 	  conjunctively local representation. However, one must ask certain -\-> -->
<!-- <\!-- 	  questions before celebrating this as a significant discovery. In PDP -\-> -->
<!-- <\!-- 	  it is recognized that the lower level coefficients appear to be -\-> -->
<!-- <\!-- 	  growing exponentially &mdash; yet no alarm is expressed about -\-> -->
<!-- <\!-- 	  this. In fact, anyone who reads section 7.3 should recognize such a -\-> -->
<!-- <\!-- 	  network as employing precisely the type of computational structure -\-> -->
<!-- <\!-- 	  that we called stratification. Then, in the case of network 2, the -\-> -->
<!-- <\!-- 	  learning procedure required 1,208 cycles through each of the 64 -\-> -->
<!-- <\!-- 	  possible examples &mdash; a total of 77,312 trials (large enough to -\-> -->
<!-- <\!-- 	  make us wonder if the time for this procedure to determine suitable -\-> -->
<!-- <\!-- 	  coefficients increases exponentially with the size of the -\-> -->
<!-- <\!-- 	  retina). PDP does not address this question. What happens when the -\-> -->
<!-- <\!-- 	  retina has 100 elements? If such a network required on the order of -\-> -->
<!-- <\!-- 	  2200 trials to learn, most observers would lose interest.  This -\-> -->
<!-- <\!-- 	  observation shows most starkly how we and the authors of PDP differ -\-> -->
<!-- <\!-- 	  in interpreting the implications of our theory. Our -\-> -->
<!-- <\!-- 	  <em>pessimistic evaluation of the perceptron</em> was the assertion -\-> -->
<!-- <\!-- 	  that although certain problems can easily by solved by perceptrons -\-> -->
<!-- <\!-- 	  on small scales, the computational costs become prohibitive when the -\-> -->
<!-- <\!-- 	  problem is scaled up. The authors of PDP seem not to recognize that -\-> -->
<!-- <\!-- 	  the coefficients of this symmetry machine confirm that thesis -\-> -->
<!-- <\!-- 	  &mdash; and celebrate this performance on a toy problem as a -\-> -->
<!-- <\!-- 	  success, rather than asking whether it could become a -\-> -->
<!-- <\!-- 	  profoundly <em>bad</em> form of behavior when scaled up to problems -\-> -->
<!-- <\!-- 	  of larger size.  Both of these networks are in the class of what we -\-> -->
<!-- <\!-- 	  called Gamba perceptrons in section 13.1 &mdash; that is, ordinary -\-> -->
<!-- <\!-- 	  perceptrons whose phi- -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  functions are themselves perceptrons of order 1. Accordingly, we are -\-> -->
<!-- <\!-- 	  uncomfortable about the remark in PDP that <em>multilayer linear -\-> -->
<!-- <\!--             threshold networks are potentially much more powerful than -\-> -->
<!-- <\!--             single-layer perceptrons.</em> Of course they are, in various ways -\-> -->
<!-- <\!-- 	  &mdash; and chapter 8 of PDP describes several studies of multilayer -\-> -->
<!-- <\!-- 	  perceptron- like devices. However, most of them &mdash; like figure -\-> -->
<!-- <\!-- 	  2 above &mdash; still belong to the class of networks discussed in -\-> -->
<!-- <\!-- 	  Perceptrons.  Also in chapter 8 of PDP, similar methods are applied -\-> -->
<!-- <\!-- 	  to the problem of recognizing parity &mdash; and the very -\-> -->
<!-- <\!-- 	  construction described in our section 13.1, through which a Gamba -\-> -->
<!-- <\!-- 	  perceptron can recognize parity, is rediscovered. Figure 3 shows the -\-> -->
<!-- <\!-- 	  result. -\-> -->
	  

<!-- <\!-- 	<p> -\-> -->
	  

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  To learn these coefficients, the procedure described in PDP required -\-> -->
<!-- <\!-- 	  2,825 cycles through the 16 possible input patterns, thus consuming -\-> -->
<!-- <\!-- 	  45,200 trials for the network to learn to compute the parity -\-> -->
<!-- <\!-- 	  predicate for only four inputs. Is this a good result or a bad -\-> -->
<!-- <\!-- 	  result? We cannot tell without more knowledge about why the -\-> -->
<!-- <\!-- 	  procedure requires so many trials. Until one has some theory of -\-> -->
<!-- <\!-- 	  that, there is no way to assess the significance of any such -\-> -->
<!-- <\!-- 	  experimental result; all one can say is that 45,200 = 45,200. In -\-> -->
<!-- <\!-- 	  section 10.1 we saw that if a perceptron&#39;s phi-functions include -\-> -->
<!-- <\!-- 	  only masks, the parity predicate requires doubly exponential -\-> -->
<!-- <\!-- 	  coefficients. If we were sure that that was happening, this would -\-> -->
<!-- <\!-- 	  suggest to us that we should represent 45,200 (approximately) as 224 -\-> -->
<!-- <\!-- 	  rather than, say, as 216. However, here we suspect that this would -\-> -->
<!-- <\!-- 	  be wrong because the input units aren&#39;t masks, but predicates -\-> -->
<!-- <\!-- 	  &mdash; apparently provided from the start &mdash; that already know -\-> -->
<!-- <\!-- 	  how to <em>count.</em> These make the problem much, much easier. In -\-> -->
<!-- <\!-- 	  any case, the lesson of Perceptrons is that one cannot interpret the -\-> -->
<!-- <\!-- 	  meaning of such an experimental report without first making further -\-> -->
<!-- <\!-- 	  probes. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Learning We haven&#39;t yet said how those networks learned. PDP -\-> -->
<!-- <\!-- 	  describes a learning procedure called the <em>Generalized Delta -\-> -->
<!-- <\!--             Rule</em> &mdash; we&#39;ll call it GD &mdash; as a new breakthrough -\-> -->
<!-- <\!-- 	  in connectionist research. To explain its importance, they depict as -\-> -->
<!-- <\!-- 	  follows the theoretical situation they inherited: -\-> -->
	  
<!-- <\!-- 	  A further argument advanced by Minsky and Papert against -\-> -->
<!-- <\!-- 	  perceptron-like models with hidden units is that there was no -\-> -->
<!-- <\!-- 	  indication how such multilayer networks were to be trained. One of -\-> -->
<!-- <\!-- 	  the appealing features of the one-layer perceptron is the existence -\-> -->
<!-- <\!-- 	  of a powerful learning procedure, the perceptron convergence -\-> -->
<!-- <\!-- 	  procedure of Rosenblatt. In Minsky and Papert&#39;s day, there was -\-> -->
<!-- <\!-- 	  no such powerful learning procedure for the more complex multilayer -\-> -->
<!-- <\!-- 	  systems. This is no longer true. . . . The GD procedure provides a -\-> -->
<!-- <\!-- 	  direct generalization of the perceptron learning procedure which can -\-> -->
<!-- <\!-- 	  be applied to arbitrary networks with multiple layers and feedback -\-> -->
<!-- <\!-- 	  among layers. This procedure can, in principle, learn arbitrary -\-> -->
<!-- <\!-- 	  functions including, of course, parity and connectedness. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  In Minsky and Papert&#39;s day, indeed! In this section we shall -\-> -->
<!-- <\!-- 	  explain why, although the GD learning procedure embodies some useful -\-> -->
<!-- <\!-- 	  ideas, it does not justify such sweeping claims. But in order to -\-> -->
<!-- <\!-- 	  explain why, and to see how the approach in the current wave of -\-> -->
<!-- <\!-- 	  connectionism differs from that in Perceptrons, we must first -\-> -->
<!-- <\!-- 	  examine with some care the relationship between two branches of -\-> -->
<!-- <\!-- 	  perceptron theory which could be called <em>theory of learning</em> -\-> -->
<!-- <\!-- 	  and <em>theory of representation.</em> To begin with, one might -\-> -->
<!-- <\!-- 	  paraphrase the above quotation as saying that until recently -\-> -->
<!-- <\!-- 	  connectionism had been paralyzed by the following dilemma: -\-> -->
	  
<!-- <\!-- 	  Perceptrons could learn anything that they could represent, but they -\-> -->
<!-- <\!-- 	  were too limited in what they could represent. -\-> -->
	  
<!-- <\!-- 	  Multilayered networks were less limited in what they could -\-> -->
<!-- <\!-- 	  represent, but they had no reliable learning procedure. -\-> -->
	  
<!-- <\!-- 	  According to the classical theory of perceptrons, those limitations -\-> -->
<!-- <\!-- 	  on representability depend on such issues as whether a given -\-> -->
<!-- <\!-- 	  predicate P can be represented as a perceptron defined by a given -\-> -->
<!-- <\!-- 	  set PHI on a given retina, whether P is of finite order, whether P -\-> -->
<!-- <\!-- 	  can be realized with coefficients of bounded size, whether -\-> -->
<!-- <\!-- 	  properties of several representable predicates are inherited by -\-> -->
<!-- <\!-- 	  combinations of those predicates, and so forth. All the results in -\-> -->
<!-- <\!-- 	  the first half of our book are involved with these sorts of -\-> -->
<!-- <\!-- 	  representational issues. Now, when one speaks about <em>powerful -\-> -->
<!-- <\!--             learning procedures,</em> the situation is complicated by the fact -\-> -->
<!-- <\!-- 	  that, given enough input units of sufficiently high order, even -\-> -->
<!-- <\!-- 	  simple perceptrons can represent &mdash; and therefore learn &mdash; -\-> -->
<!-- <\!-- 	  arbitrary functions. Consequently, it makes no sense to speak -\-> -->
<!-- <\!-- 	  about <em>power</em> in absolute terms. Such statements must refer -\-> -->
<!-- <\!-- 	  to relative measures of sizes and scales.  As for learning, the -\-> -->
<!-- <\!-- 	  dependability of Rosenblatt&#39;s Perceptron Convergence theorem of -\-> -->
<!-- <\!-- 	  section 11.1 &mdash; let&#39;s call it PC for short &mdash; is very -\-> -->
<!-- <\!-- 	  impressive: If it is possible at all to represent a predicate P as a -\-> -->
<!-- <\!-- 	  linear threshold function of a given set of predicates PHI, then the -\-> -->
<!-- <\!-- 	  PC procedure will eventually discover some particular set of -\-> -->
<!-- <\!-- 	  coefficients that actually represents P. However this is not, in -\-> -->
<!-- <\!-- 	  itself, a sufficient reason, in itself, to consider PC interesting -\-> -->
<!-- <\!-- 	  and important, because that theorem says nothing about the crucial -\-> -->
<!-- <\!-- 	  issue of efficiency. PC is not interesting merely because it -\-> -->
<!-- <\!-- 	  provides a systematic way to find suitable coefficients. One could -\-> -->
<!-- <\!-- 	  always take recourse, instead, to simple, brute force search &mdash; -\-> -->
<!-- <\!-- 	  because, given that some solution exists, one could simply search -\-> -->
<!-- <\!-- 	  through all possible integer coefficient vectors, in order of -\-> -->
<!-- <\!-- 	  increasing magnitude, until no further <em>errors</em> occurred. But -\-> -->
<!-- <\!-- 	  no one would consider such an exhaustive process to be an -\-> -->
<!-- <\!-- 	  interesting foundation for a learning theory.  What, then, makes PC -\-> -->
<!-- <\!-- 	  seem significant? That it discovers those coefficients in ways that -\-> -->
<!-- <\!-- 	  are intriguing in several other important respects. The PC procedure -\-> -->
<!-- <\!-- 	  seems to satisfy many of the intuitive requirements of those who are -\-> -->
<!-- <\!-- 	  concerned with modeling what really happens in a biological nervous -\-> -->
<!-- <\!-- 	  system. It also appeals to both our engineering aesthetic and our -\-> -->
<!-- <\!-- 	  psychological aesthetic by serving simultaneously as both a form of -\-> -->
<!-- <\!-- 	  guidance by error correction and a form of hill-climbing. In terms -\-> -->
<!-- <\!-- 	  of computational efficiency, PC seems much more efficient than -\-> -->
<!-- <\!-- 	  brute-force procedures (although we have no rigorous and general -\-> -->
<!-- <\!-- 	  theory of the conditions under which that will be true). Finally, PC -\-> -->
<!-- <\!-- 	  is so simple, mathematically, as to make one wish to believe that it -\-> -->
<!-- <\!-- 	  reflects something real. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Hill-Climbing and the Generalized Delta Procedure -\-> -->
	  
<!-- <\!-- 	  Suppose we want to find the maximum value of a given function -\-> -->
<!-- <\!-- 	  F(x,y,z, . . . ) of n variables. The extreme brute force solution is -\-> -->
<!-- <\!-- 	  to calculate the function for all sets of values for the variables, -\-> -->
<!-- <\!-- 	  and then select the point for which F had the largest value. The -\-> -->
<!-- <\!-- 	  approach we called hill-climbing in section 11.3 is a local -\-> -->
<!-- <\!-- 	  procedure designed to attempt to find that global maximum. To make -\-> -->
<!-- <\!-- 	  this subject more concrete, it is useful to think of the -\-> -->
<!-- <\!-- 	  two-dimensional case in which the x-y plane is the ground and z = -\-> -->
<!-- <\!-- 	  F(x, y) is the elevation of the point (x, y, z) on the surface of a -\-> -->
<!-- <\!-- 	  real physical hill. Now, imagine standing on the hill in a fog so -\-> -->
<!-- <\!-- 	  dense that only the immediate vicinity is visible.  Then the only -\-> -->
<!-- <\!-- 	  resort is to use some diameter limited local process. The best-known -\-> -->
<!-- <\!-- 	  method is the method known as <em>steepest ascent,</em> discussed in -\-> -->
<!-- <\!-- 	  section 11.6. First determine the slope of the surface in various -\-> -->
<!-- <\!-- 	  directions from the point where you are standing, then choose the -\-> -->
<!-- <\!-- 	  direction that most increases your altitude and take a step of a -\-> -->
<!-- <\!-- 	  certain size in that direction. The hope is that, by thus climbing -\-> -->
<!-- <\!-- 	  the slope, you will eventually reach the highest point.  It is both -\-> -->
<!-- <\!-- 	  well known and obvious that hill-climbing does not always work. The -\-> -->
<!-- <\!-- 	  simplest way to fail is to get stuck upon a local maximum &mdash; an -\-> -->
<!-- <\!-- 	  isolated peak whose altitude is relatively insignificant. There -\-> -->
<!-- <\!-- 	  simply is no local way for a hill-climbing procedure to be sure that -\-> -->
<!-- <\!-- 	  it has reached a global maximum rather than some local feature of -\-> -->
<!-- <\!-- 	  topography (such as a peak, ridge, or plain) on which it may get -\-> -->
<!-- <\!-- 	  trapped. We showed in section 11.6 that PC is equivalent (in a -\-> -->
<!-- <\!-- 	  peculiar sense) to a hill-climbing procedure that works its way to -\-> -->
<!-- <\!-- 	  the top of a hill whose geometry can actually be proved not to have -\-> -->
<!-- <\!-- 	  any such troublesome local features &mdash; provided that there -\-> -->
<!-- <\!-- 	  actually exists some perceptron-weight vector solution A* to the -\-> -->
<!-- <\!-- 	  problem. Thus, one could argue that perceptrons <em>work</em> on -\-> -->
<!-- <\!-- 	  those problems not because of any particular virtue of the -\-> -->
<!-- <\!-- 	  perceptrons or of their hill-climbing procedures but because the -\-> -->
<!-- <\!-- 	  hills for those soluble problems have clean topographies. What are -\-> -->
<!-- <\!-- 	  the prospects of finding a learning procedure that works equally -\-> -->
<!-- <\!-- 	  well on all problems, and not merely on those that have linearly -\-> -->
<!-- <\!-- 	  separable decision functions? The authors of PDP maintain that they -\-> -->
<!-- <\!-- 	  have indeed discovered one: -\-> -->
	  
<!-- <\!-- 	  Although our learning results do not guarantee that we can find a -\-> -->
<!-- <\!-- 	  solution for all solvable problems, our analyses and results have -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  shown that, as a practical matter, the error propagation scheme -\-> -->
<!-- <\!-- 	  leads to solutions in virtually every case. In short, we believe -\-> -->
<!-- <\!-- 	  that we have answered Minsky and Papert&#39;s challenge and have -\-> -->
<!-- <\!-- 	  found a learning result sufficiently powerful to demonstrate that -\-> -->
<!-- <\!-- 	  their pessimism about learning in multilayer machines was -\-> -->
<!-- <\!-- 	  misplaced. (PDP vol. 1, p. 361) -\-> -->
	  
<!-- <\!-- 	  But the experiments in PDP, though interesting and ingenious, do not -\-> -->
<!-- <\!-- 	  actually demonstrate any such thing. In fact, their <em>powerful new -\-> -->
<!-- <\!--             learning result</em> is nothing other than a straightforward -\-> -->
<!-- <\!-- 	  hill-climbing algorithm &mdash; with all the problems that this -\-> -->
<!-- <\!-- 	  entails. To see how GD works, assume we are given a network of units -\-> -->
<!-- <\!-- 	  interconnected by weighted, unidirectional links. Certain of these -\-> -->
<!-- <\!-- 	  units are connected to input terminals, and certain others are -\-> -->
<!-- <\!-- 	  regarded as output units. We want to teach this network to respond -\-> -->
<!-- <\!-- 	  to each (vector) input pattern Xp with a specified output vector -\-> -->
<!-- <\!-- 	  Yp. How can we find a set of weights {wij} that will accomplish -\-> -->
<!-- <\!-- 	  this? We could try to do it by hill-climbing on the space of -\-> -->
<!-- <\!-- 	  W&#39;s, provided that we could define a suitable measure of -\-> -->
<!-- <\!-- 	  relative altitude or <em>success.</em> One problem is that there -\-> -->
<!-- <\!-- 	  cannot be any standard, universal way to measure errors, -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  because each type of error has different costs in different -\-> -->
<!-- <\!-- 	  situations.  But let us set that issue aside and do what scientists -\-> -->
<!-- <\!-- 	  often do when they can&#39;t think of anything better: sum the -\-> -->
<!-- <\!-- 	  squares of the differences. So, if Y (W,X) is the network&#39;s -\-> -->
<!-- <\!-- 	  output vector for internal weights W and inputs X, define the -\-> -->
<!-- <\!-- 	  altitude function E(W) to be this sum -\-> -->
	  
<!-- <\!-- 	  E(W) = &mdash; SIGMA (all input patterns p) [Yp &mdash; Y(W, Xp)]2 -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  In other words, we compute our measure of success by presenting -\-> -->
<!-- <\!-- 	  successively each stimulus Xp to the network. Then we compute the -\-> -->
<!-- <\!-- 	  (vector) difference between the actual output and the desired -\-> -->
<!-- <\!-- 	  output.  Finally, we add up the squares of the magnitudes of those -\-> -->
<!-- <\!-- 	  differences.  (The minus sign is simply for thinking of climbing up -\-> -->
<!-- <\!-- 	  instead of down.)  The error function E will then have a maximum -\-> -->
<!-- <\!-- 	  possible value of zero, which will be achieved if and only if the -\-> -->
<!-- <\!-- 	  machine performs perfectly.  Otherwise there will be at least one -\-> -->
<!-- <\!-- 	  error and E(W) will be negative.  Then all we have to is climb the -\-> -->
<!-- <\!-- 	  hill E(W) defined over the (high-dimensional) space of weight -\-> -->
<!-- <\!-- 	  vectors W. If our path reaches a W for which E(W) is zero, our -\-> -->
<!-- <\!-- 	  problem will be solved and we will be able to say that our machine -\-> -->
<!-- <\!-- 	  has <em>learned from its experience.</em>  We&#39;ll use a process -\-> -->
<!-- <\!-- 	  that climbs this hill by the method of steepest ascent. We can do -\-> -->
<!-- <\!-- 	  this by estimating, at every step, the partial derivatives dE/dwij -\-> -->
<!-- <\!-- 	  of the total error with respect to each component of the weight -\-> -->
<!-- <\!-- 	  vector. This tells us the direction of the gradient vector dE/dW, -\-> -->
<!-- <\!-- 	  and we then proceed to move a certain distance in that -\-> -->
<!-- <\!-- 	  direction. This is the mathematical character of the Generalized -\-> -->
<!-- <\!-- 	  Delta procedure, and it differs in no significant way from older -\-> -->
<!-- <\!-- 	  forms of diameter-limited gradient followers.  Before such a -\-> -->
<!-- <\!-- 	  procedure can be employed, there is an obstacle to overcome. One -\-> -->
<!-- <\!-- 	  cannot directly apply the method of gradient ascent to networks that -\-> -->
<!-- <\!-- 	  contain threshold units. This is because the derivative of a -\-> -->
<!-- <\!-- 	  step-function is zero, whenever it exists, and hence no gradient is -\-> -->
<!-- <\!-- 	  defined. To get around this, PDP applies a smoothing function to -\-> -->
<!-- <\!-- 	  make those threshold functions differentiable. The trick is to -\-> -->
<!-- <\!-- 	  replace the threshold function for each unit with a monotonic and -\-> -->
<!-- <\!-- 	  differentiable function of the sum of that unit&#39;s inputs. This -\-> -->
<!-- <\!-- 	  permits the output of each unit to encode information about the sum -\-> -->
<!-- <\!-- 	  of its inputs while still retaining an approximation to the -\-> -->
<!-- <\!-- 	  perceptron&#39;s decision-making ability. Then gradient ascent -\-> -->
<!-- <\!-- 	  becomes more feasible. However, we suspect that this smoothing trick -\-> -->
<!-- <\!-- 	  may entail a large (and avoidable) cost when the predicate to be -\-> -->
<!-- <\!-- 	  learned is actually a composition of linear threshold -\-> -->
<!-- <\!-- 	  functions. There ought to be a more efficient alternative based on -\-> -->
<!-- <\!-- 	  how much each weight must be changed, for each stimulus, to make the -\-> -->
<!-- <\!-- 	  local input sum cross the threshold.  In what sense is the -\-> -->
<!-- <\!-- 	  particular hill-climbing procedure GD more powerful than the -\-> -->
<!-- <\!-- 	  perceptron&#39;s PC? Certainly GD can be applied to more networks -\-> -->
<!-- <\!-- 	  than PC can, because PC can operate only on the connections between -\-> -->
<!-- <\!-- 	  one layer of phi-units and a single output unit.  GD, however, can -\-> -->
<!-- <\!-- 	  modify the weights in an arbitrary multilayered network, including -\-> -->
<!-- <\!-- 	  nets containing loops. Thus, in contrast to the perceptron (which is -\-> -->
<!-- <\!-- 	  equipped with some fixed set of phi&#39;s that can never be -\-> -->
<!-- <\!-- 	  changed), GD can be regarded as able to change the weights inside -\-> -->
<!-- <\!-- 	  the phi&#39;s. Thus GD promises, in effect, to be able discover -\-> -->
<!-- <\!-- 	  useful new phi-functions &mdash; and many of the experiments -\-> -->
<!-- <\!-- 	  reported in PDP demonstrate that this often works. -\-> -->
	  
<!-- <\!-- 	  A natural way to estimate the gradient of E(W) is to estimate -\-> -->
<!-- <\!-- 	  dE/dwij by running through the entire set of inputs for each -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  weight. However, for large networks and large problems, that could -\-> -->
<!-- <\!-- 	  be a horrendous computation. Fortunately, in a highly connected -\-> -->
<!-- <\!-- 	  network, all those many components of the gradient are not -\-> -->
<!-- <\!-- 	  independent of one another, but are constrained by the -\-> -->
<!-- <\!-- 	  algebraic <em>chain rule</em> for the derivatives of composite -\-> -->
<!-- <\!-- 	  functions. One can exploit those constraints to reduce the amount of -\-> -->
<!-- <\!-- 	  computation by applying the chain rule formula, recursively, to the -\-> -->
<!-- <\!-- 	  mathematical description of the network.  This recursive computation -\-> -->
<!-- <\!-- 	  is called <em>back-propagation</em> in PDP. It can substantially -\-> -->
<!-- <\!-- 	  reduce the amount of calculation for each hill-climbing step, in -\-> -->
<!-- <\!-- 	  networks with many connections.  (Simple perceptrons have too few -\-> -->
<!-- <\!-- 	  connections for this to be of any benefit.) We have the impression -\-> -->
<!-- <\!-- 	  that many people in the connectionist community do not understand -\-> -->
<!-- <\!-- 	  that this is merely a particular way to compute a gradient, and have -\-> -->
<!-- <\!-- 	  assumed instead that back-propagation is a new learning scheme that -\-> -->
<!-- <\!-- 	  somehow gets around the basic limitations of hill-climbing. -\-> -->
	  
<!-- <\!-- 	  Clearly GD would be far more valuable than PC if it could be made to -\-> -->
<!-- <\!-- 	  be both efficient and dependable. But virtually nothing has been -\-> -->
<!-- <\!-- 	  proved about the range of problems upon which GD works both -\-> -->
<!-- <\!-- 	  efficiently and dependably. Indeed, GD can fail to find a solution -\-> -->
<!-- <\!-- 	  when one exists, so in that narrow sense, it could be considered -\-> -->
<!-- <\!-- 	  less powerful than PC.  In the early years of cybernetics, everyone -\-> -->
<!-- <\!-- 	  understood that hill-climbing was always available for working easy -\-> -->
<!-- <\!-- 	  problems, but that it almost always became impractical for problems -\-> -->
<!-- <\!-- 	  of larger sizes and complexities. We were very pleased to discover -\-> -->
<!-- <\!-- 	  (see section 11.6) that PC could be represented as hill-climbing; -\-> -->
<!-- <\!-- 	  however, that very fact led us to wonder whether such procedures -\-> -->
<!-- <\!-- 	  could dependably be generalized, even to the limited class of -\-> -->
<!-- <\!-- 	  multi-layer machines that we named Gamba Perceptrons. The situation -\-> -->
<!-- <\!-- 	  seems not to have changed much today &mdash; we have seen no -\-> -->
<!-- <\!-- 	  contemporary connectionist publication that casts much new -\-> -->
<!-- <\!-- 	  theoretical light on the situation.  Then why has GD become so -\-> -->
<!-- <\!-- 	  popular in recent years? In part this is because it is so widely -\-> -->
<!-- <\!-- 	  applicable, and because it does indeed yield new results (at least -\-> -->
<!-- <\!-- 	  on problems of rather small scale). Its reputation also gains, we -\-> -->
<!-- <\!-- 	  think, from its being presented in forms that share, albeit to a -\-> -->
<!-- <\!-- 	  lesser degree, the biological plausibility of PC. But we fear that -\-> -->
<!-- <\!-- 	  its reputation also stems from unfamiliarity with the manner in -\-> -->
<!-- <\!-- 	  which hill-climbing methods deteriorate when confronted with larger -\-> -->
<!-- <\!-- 	  scale problems.  In any case, little good can come from statements -\-> -->
<!-- <\!-- 	  like <em>as a practical matter, GD leads to solutions in virtually -\-> -->
<!-- <\!--             every case</em> or <em>GD can, in principle, learn arbitrary -\-> -->
<!-- <\!--             functions.</em> Such pronouncements are not merely technically -\-> -->
<!-- <\!-- 	  wrong; more significantly, the pretense that problems do not exist -\-> -->
<!-- <\!-- 	  can deflect us from valuable insights that could come from examining -\-> -->
<!-- <\!-- 	  things more carefully. As the field of connectionism becomes more -\-> -->
<!-- <\!-- 	  mature, the quest for a general solution to all learning problems -\-> -->
<!-- <\!-- 	  will evolve into an understanding of which types of learning -\-> -->
<!-- <\!-- 	  processes are likely to work on which classes of problems. And this -\-> -->
<!-- <\!-- 	  means that, past a certain point, we won&#39;t be able to get by -\-> -->
<!-- <\!-- 	  with vacuous generalities about hill-climbing. We will really need -\-> -->
<!-- <\!-- 	  to know a great deal more about the nature of those surfaces for -\-> -->
<!-- <\!-- 	  each specific realm of problems that we want to solve.  On the -\-> -->
<!-- <\!-- 	  positive side, we applaud those who bravely and romantically are -\-> -->
<!-- <\!-- 	  empirically applying hill-climbing methods to many new domains for -\-> -->
<!-- <\!-- 	  the first time, and we expect such work to result in important -\-> -->
<!-- <\!-- 	  advances. Certainly these researchers are exploring networks with -\-> -->
<!-- <\!-- 	  architectures far more complex than those of perceptrons, and some -\-> -->
<!-- <\!-- 	  of their experiments already have shown indications of new phenomena -\-> -->
<!-- <\!-- 	  that are well worth trying to understand. -\-> -->
	  
	  
<!-- <\!-- 	  Scaling Problems Up in Size Experiments with toy-scale problems have -\-> -->
<!-- <\!-- 	  proved as fruitful in artificial intelligence as in other areas of -\-> -->
<!-- <\!-- 	  science and engineering.  Many techniques and principles that -\-> -->
<!-- <\!-- 	  ultimately found real applications were discovered and honed in -\-> -->
<!-- <\!-- 	  microworlds small enough to comprehend yet rich enough to challenge -\-> -->
<!-- <\!-- 	  our thinking. But not every phenomenon encountered in dealing with -\-> -->
<!-- <\!-- 	  small models can be usefully scaled up. Looking at the relative -\-> -->
<!-- <\!-- 	  thickness of the legs of an ant and an elephant reminds us that -\-> -->
<!-- <\!-- 	  physical structures do not always scale linearly: an ant magnified a -\-> -->
<!-- <\!-- 	  thousand times would collapse under its own weight. Much of the -\-> -->
<!-- <\!-- 	  theory of computational complexity is concerned with questions of -\-> -->
<!-- <\!-- 	  scale. If it takes 100 steps to solve a certain kind of equation -\-> -->
<!-- <\!-- 	  with 4 terms, how many steps will it take to solve the same kind of -\-> -->
<!-- <\!-- 	  equation with 8 terms? Only 200, if the problem scales linearly. But -\-> -->
<!-- <\!-- 	  for other problems it will take not twice 100 but 100 squared.  For -\-> -->
<!-- <\!-- 	  example, the Gamba perceptron of figure 2 needs only two -\-> -->
<!-- <\!-- 	  phi-functions rather than the six required in figure 1. In neither -\-> -->
<!-- <\!-- 	  of these two toy-sized networks does the number seem alarmingly -\-> -->
<!-- <\!-- 	  large.  One network has fewer units; the other has smaller -\-> -->
<!-- <\!-- 	  coefficients. But when we examine how those numbers grow with -\-> -->
<!-- <\!-- 	  retinas of increasing size, we discover that whereas the -\-> -->
<!-- <\!-- 	  coefficients of figure 1 remain constant, those of figure 2 grow -\-> -->
<!-- <\!-- 	  exponentially. And, presumably, a similar price must be paid again -\-> -->
<!-- <\!-- 	  in the number of repetitions required in order to learn.  In the -\-> -->
<!-- <\!-- 	  examination of theories of learning and problem solving, the study -\-> -->
<!-- <\!-- 	  of such growths in cost is not merely one more aspect to be taken -\-> -->
<!-- <\!-- 	  into account; in a sense, it is the only aspect worth considering. -\-> -->
<!-- <\!-- 	  This is because so many problems can be solved <em>in principle</em> -\-> -->
<!-- <\!-- 	  by using exhaustive search through a suitable space of states. Of -\-> -->
<!-- <\!-- 	  course, the trouble with that in practice is that there is usually -\-> -->
<!-- <\!-- 	  an exponential increase in the numbers of steps required for an -\-> -->
<!-- <\!-- 	  exhaustive search, when the scale of the problem is -\-> -->
<!-- <\!-- 	  enlarged. Consequently, solving toy problems by methods related to -\-> -->
<!-- <\!-- 	  exhaustive search rarely leads to practical solutions to larger -\-> -->
<!-- <\!-- 	  problems. For example, though it is easy to make an -\-> -->
<!-- <\!-- 	  exhaustive-search machine that never loses a game of noughts and -\-> -->
<!-- <\!-- 	  crosses, it is infeasible to do the same for chess. We do not know -\-> -->
<!-- <\!-- 	  if this fact is significant, but many of the small examples -\-> -->
<!-- <\!-- 	  described in PDP could have been solved as quickly by means of -\-> -->
<!-- <\!-- 	  exhaustive search &mdash; that is, by systematically assigning and -\-> -->
<!-- <\!-- 	  testing all combinations of small integer weights.  When we started -\-> -->
<!-- <\!-- 	  our research on perceptrons, we had seen many interesting -\-> -->
<!-- <\!-- 	  demonstrations of perceptrons solving problems of very small scale, -\-> -->
<!-- <\!-- 	  but not doing so well when those problems were scaled up. We -\-> -->
<!-- <\!-- 	  wondered what was going wrong. Our first <em>handle</em> on how to -\-> -->
<!-- <\!-- 	  think about scaling came with the concept of the order of a -\-> -->
<!-- <\!-- 	  predicate.  If a problem is of order N, then the number of phi&#39;s -\-> -->
<!-- <\!-- 	  for the corresponding perceptron need not increase any faster than -\-> -->
<!-- <\!-- 	  as the Nth power of R.  Then, whenever we could show that a given -\-> -->
<!-- <\!-- 	  problem was of low order, we usually could demonstrate that -\-> -->
<!-- <\!-- 	  perceptron-like networks could do surprisingly well on that -\-> -->
<!-- <\!-- 	  problem. On the other hand, once we developed the more difficult -\-> -->
<!-- <\!-- 	  techniques for showing that certain other problems have unbounded -\-> -->
<!-- <\!-- 	  order, this raised alarming warning flags about extending their -\-> -->
<!-- <\!-- 	  solutions to larger domains. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Unbounded order was not the only source of scaling failures. -\-> -->
<!-- <\!-- 	  Another source &mdash; and one we had not anticipated until the -\-> -->
<!-- <\!-- 	  later stages of our work &mdash; involved the size, or rather the -\-> -->
<!-- <\!-- 	  information content, of the coefficients. The information stored in -\-> -->
<!-- <\!-- 	  connectionist systems is embodied in the strengths or weights of the -\-> -->
<!-- <\!-- 	  connections between units. The idea that learning can take place by -\-> -->
<!-- <\!-- 	  changing such strengths has a ring of biological plausibility, but -\-> -->
<!-- <\!-- 	  that plausibility fades away if those strengths are to be -\-> -->
<!-- <\!-- 	  represented by numbers that must be accurate to ten or twenty -\-> -->
<!-- <\!-- 	  decimal orders of significance. -\-> -->
	  
<!-- <\!-- 	  The Problem of Sampling Variance Our description of the Generalized -\-> -->
<!-- <\!-- 	  Delta Rule assumes that it is feasible to computing the new value of -\-> -->
<!-- <\!-- 	  E(W) at every step of the climb. The processes discussed in chapter -\-> -->
<!-- <\!-- 	  8 of PDP typically require only on the order of 100,000 iterations, -\-> -->
<!-- <\!-- 	  a range that is easily accessible to computers (but that might in -\-> -->
<!-- <\!-- 	  some cases strain our sense of biological plausibility). However, it -\-> -->
<!-- <\!-- 	  will not be practical, with larger problems, to cycle through all -\-> -->
<!-- <\!-- 	  possible input patterns. This means that when precise measures of -\-> -->
<!-- <\!-- 	  E(W) are unavailable, we will be forced to act, instead, on the -\-> -->
<!-- <\!-- 	  basis of incomplete samples &mdash; for example, by making a small -\-> -->
<!-- <\!-- 	  hill-climbing step after each reaction to a stimulus.  (See the -\-> -->
<!-- <\!-- 	  discussion of complete vs. incremental methods in subsection -\-> -->
<!-- <\!-- 	  12.1.1.) When we can no longer compute dE/dW precisely but can only -\-> -->
<!-- <\!-- 	  estimate its components, then the actual derivative will be masked -\-> -->
<!-- <\!-- 	  by a certain amount of sampling noise. The text of PDP argues that -\-> -->
<!-- <\!-- 	  using sufficiently small steps can force the resulting trajectory to -\-> -->
<!-- <\!-- 	  come arbitrarily close to that which would result from knowing dE/dW -\-> -->
<!-- <\!-- 	  precisely. When we tried to prove this, we were led to suspect that -\-> -->
<!-- <\!-- 	  the choice of step size may depend so much on the higher derivatives -\-> -->
<!-- <\!-- 	  of the smoothing functions that large-scale problems could require -\-> -->
<!-- <\!-- 	  too many steps for such methods to be practical.  So far as we could -\-> -->
<!-- <\!-- 	  tell, every experiment described in chapter 8 of PDP involved making -\-> -->
<!-- <\!-- 	  a complete cycle through all possible input situations before making -\-> -->
<!-- <\!-- 	  any change in weights. Whenever this is feasible, it completely -\-> -->
<!-- <\!-- 	  eliminates sampling noise &mdash; and then even the most minute -\-> -->
<!-- <\!-- 	  correlations can become reliably detectable, because the variance is -\-> -->
<!-- <\!-- 	  zero. But no person or animal ever faces situations that are so -\-> -->
<!-- <\!-- 	  simple and arranged in so orderly a manner as to provide such cycles -\-> -->
<!-- <\!-- 	  of teaching examples. Moving from small to large problems will often -\-> -->
<!-- <\!-- 	  demand this transition from exhaustive to statistical sampling, and -\-> -->
<!-- <\!-- 	  we suspect that in many realistic situations the resulting sampling -\-> -->
<!-- <\!-- 	  noise would mask the signal completely. We suspect that many who -\-> -->
<!-- <\!-- 	  read the connectionist literature are not aware of this phenomenon, -\-> -->
<!-- <\!-- 	  which dims some of the prospects of successfully applying certain -\-> -->
<!-- <\!-- 	  learning procedures to large scale problems. -\-> -->
	  
	  
<!-- <\!-- 	  Problems of Scaling In principle, connectionist networks offer all -\-> -->
<!-- <\!-- 	  the potential of universal computing devices. However, our examples -\-> -->
<!-- <\!-- 	  of order and coefficient size suggest that various kinds of scaling -\-> -->
<!-- <\!-- 	  problems are likely to become obstacles to attempts to exploit that -\-> -->
<!-- <\!-- 	  potential. Fortunately, our analysis of perceptrons does not suggest -\-> -->
<!-- <\!-- 	  that connectionist networks need always encounter these -\-> -->
<!-- <\!-- 	  obstacles. Indeed, this book is rich in surprising examples of tasks -\-> -->
<!-- <\!-- 	  that simple perceptrons can perform, using relatively low-order -\-> -->
<!-- <\!-- 	  units and small coefficients.  However, our analysis does show that -\-> -->
<!-- <\!-- 	  parallel networks are, in general, subject to serious scaling -\-> -->
<!-- <\!-- 	  phenomena.Consequently, researchers who propose such models must -\-> -->
<!-- <\!-- 	  show that, in their context, those phenomena do not occur. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The authors of PDP seem disinclined to face such problems. They seem -\-> -->
<!-- <\!-- 	  content to argue that, although we showed that single-layer networks -\-> -->
<!-- <\!-- 	  cannot solve certain problems, we did not know that there could -\-> -->
<!-- <\!-- 	  exist a powerful learning procedure for multilayer networks &mdash; -\-> -->
<!-- <\!-- 	  to which our theorems no longer apply. However, strictly speaking, -\-> -->
<!-- <\!-- 	  it is wrong to formulate our findings in terms of what perceptrons -\-> -->
<!-- <\!-- 	  can and cannot do. As we pointed out above, perceptrons of -\-> -->
<!-- <\!-- 	  sufficiently large order can represent any finite predicate. A -\-> -->
<!-- <\!-- 	  better description of what we did is that, in certain cases, we -\-> -->
<!-- <\!-- 	  established the computational costs of what perceptrons can do as a -\-> -->
<!-- <\!-- 	  function of increasing problem size. The authors of PDP show little -\-> -->
<!-- <\!-- 	  concern for such issues, and usually seem content with experiments -\-> -->
<!-- <\!-- 	  in which small multilayer networks solve particular instances of -\-> -->
<!-- <\!-- 	  small problems.  What should one conclude from such examples? A -\-> -->
<!-- <\!-- 	  person who thinks in terms of can versus can&#39;t will be tempted -\-> -->
<!-- <\!-- 	  to suppose that if toy machines can do something, then larger -\-> -->
<!-- <\!-- 	  machines may well do it better. One must always probe into the -\-> -->
<!-- <\!-- 	  practicality of a proposed learning algorithm. It is no use to say -\-> -->
<!-- <\!-- 	  that <em>procedure P is capable of learning to recognize pattern -\-> -->
<!-- <\!--             X</em> unless one can show that this can be done in less time and at -\-> -->
<!-- <\!-- 	  less cost than with exhaustive search. For example, in the case of -\-> -->
<!-- <\!-- 	  symmetry, the authors of PDP actually recognized that the -\-> -->
<!-- <\!-- 	  coefficients were growing as powers of 2, yet they did not seem to -\-> -->
<!-- <\!-- 	  regard this as suggesting that the experiment worked only because of -\-> -->
<!-- <\!-- 	  its very small size. But scientists who exploit the insights gained -\-> -->
<!-- <\!-- 	  from studying the single-layer case might draw quite different -\-> -->
<!-- <\!-- 	  conclusions.  The authors of PDP recognize that GD is a form of -\-> -->
<!-- <\!-- 	  hill-climber, but they speak as though becoming trapped on local -\-> -->
<!-- <\!-- 	  maxima were rarely a serious problem. In reporting their experiments -\-> -->
<!-- <\!-- 	  with learning the XOR predicate, they remark that this -\-> -->
<!-- <\!-- 	  occurred <em>in only two cases in hundreds of times.</em> However, -\-> -->
<!-- <\!-- 	  that experiment involved only the toy problem of learning to compute -\-> -->
<!-- <\!-- 	  the XOR of two arguments. We conjecture that learning XOR for larger -\-> -->
<!-- <\!-- 	  numbers of variables will become increasingly intractable as we -\-> -->
<!-- <\!-- 	  increase the numbers of input variables, because by its nature the -\-> -->
<!-- <\!-- 	  underlying parity function is absolutely uncorrelated with any -\-> -->
<!-- <\!-- 	  function of fewer variables.  Therefore, there can exist no useful -\-> -->
<!-- <\!-- 	  correlations among the outputs of the lower-order units involved in -\-> -->
<!-- <\!-- 	  computing it, and that leads us to suspect that there is little to -\-> -->
<!-- <\!-- 	  gain from following whatever paths are indicated by the artificial -\-> -->
<!-- <\!-- 	  introduction of smoothing functions that cause partial derivatives -\-> -->
<!-- <\!-- 	  to exist.  The PDP experimenters encountered a more serious local -\-> -->
<!-- <\!-- 	  maximum problem when trying to make a network learn to add two -\-> -->
<!-- <\!-- 	  binary numbers &mdash; a problem that contains an embedded XOR -\-> -->
<!-- <\!-- 	  problem.  When working with certain small networks, the system got -\-> -->
<!-- <\!-- 	  stuck reliably. However, the experimenters discovered an interesting -\-> -->
<!-- <\!-- 	  way to get around this difficulty by introducing longer chains of -\-> -->
<!-- <\!-- 	  intermediate units. We encourage the reader to study the discussion -\-> -->
<!-- <\!-- 	  starting on page 341 of PDP and to try to make a more complete -\-> -->
<!-- <\!-- 	  theoretical analysis of this problem. We suspect that further study -\-> -->
<!-- <\!-- 	  of this case will show that hill-climbing procedures can indeed get -\-> -->
<!-- <\!-- 	  multilayer networks to learn to do multidigit addition. However, -\-> -->
<!-- <\!-- 	  such a study should be carried out not to show that <em>networks are -\-> -->
<!-- <\!--             good</em> but to see which network architectures are most suitable -\-> -->
<!-- <\!-- 	  for enabling the information required for <em>carrying</em> to flow -\-> -->
<!-- <\!-- 	  easily from the smaller to the larger digits. In the PDP experiment, -\-> -->
<!-- <\!-- 	  the network appears to us to have started on the road toward -\-> -->
<!-- <\!-- 	  inventing the technique known to computer engineers as <em>carry -\-> -->
<!-- <\!--             jumping.</em>  To what extent can hill-climbing systems be made to -\-> -->
<!-- <\!-- 	  solve hard problems? One might object that this is a wrong question -\-> -->
<!-- <\!-- 	  because -\-> -->
<!-- <\!-- 	  <em>hard</em> is so ill defined. The lesson of Perceptrons is that -\-> -->
<!-- <\!-- 	  we must find ways to make such questions meaningful. In the case of -\-> -->
<!-- <\!-- 	  hill-climbing, we need to find ways to characterize the types of -\-> -->
<!-- <\!-- 	  problems that lead to the various obstacles to climbing hills, -\-> -->
<!-- <\!-- 	  instead of ignoring those difficulties or trying to find universal -\-> -->
<!-- <\!-- 	  ways to get around them. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  THE SOCIETY OF MIND Sizes and Scales of Mental Agencies The -\-> -->
<!-- <\!-- 	  preceding section was written as though it ought to be the principal -\-> -->
<!-- <\!-- 	  goal of research on network models to determine in which situations -\-> -->
<!-- <\!-- 	  it will be feasible to scale their operations up to deal with -\-> -->
<!-- <\!-- 	  increasingly complicated problems. But now we propose a somewhat -\-> -->
<!-- <\!-- 	  shocking alternative: Perhaps the scale of the toy problem is that -\-> -->
<!-- <\!-- 	  on which, in physiological actuality, much of the functioning of -\-> -->
<!-- <\!-- 	  intelligence operates. Accepting this thesis leads into a way of -\-> -->
<!-- <\!-- 	  thinking very different from that of the connectionist movement. We -\-> -->
<!-- <\!-- 	  have used the phrase <em>Society of Mind</em> to refer to the idea -\-> -->
<!-- <\!-- 	  that mind is made up of a large number of components, or -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  <em>agents,</em> each of which would operate on the scale of what, -\-> -->
<!-- <\!-- 	  if taken in isolation, would be little more than a toy problem. (See -\-> -->
<!-- <\!-- 	  Marvin Minsky, The Society of Mind, [Simon & Schuster, 1987] and -\-> -->
<!-- <\!-- 	  Seymour Papert, Mindstorms [Basic Books, 1982].)  To illustrate this -\-> -->
<!-- <\!-- 	  idea, let&#39;s try to compare the performance of the symmetry -\-> -->
<!-- <\!-- 	  perceptron in PDP with human behavior. An adult human can usually -\-> -->
<!-- <\!-- 	  recognize and appreciate the symmetries of a kaleidoscope, and that -\-> -->
<!-- <\!-- 	  sort of example leads one to imagine that people do very much better -\-> -->
<!-- <\!-- 	  than simple perceptrons. But how much can people actually do? Most -\-> -->
<!-- <\!-- 	  people would be hard put to be certain about the symmetry of a large -\-> -->
<!-- <\!-- 	  pattern. For example, how long does it take you to decide whether or -\-> -->
<!-- <\!-- 	  not the following pattern is symmetrical? -\-> -->
	  
<!-- <\!-- 	  DB4HWUK85HCNZEWJKRKJWEZNCH58KUWH4BD In many situations, humans -\-> -->
<!-- <\!-- 	  clearly have abilities far in excess of what could be accounted for -\-> -->
<!-- <\!-- 	  through such mechanisms as GD. But when we take those skills apart, -\-> -->
<!-- <\!-- 	  or try to find out how they were learned, we expect to find that -\-> -->
<!-- <\!-- 	  they were made by processes that somehow combined the work (already -\-> -->
<!-- <\!-- 	  done in the past) of many smaller agencies, none of which, -\-> -->
<!-- <\!-- 	  separately, need to work on scales much larger than those in PDP. Is -\-> -->
<!-- <\!-- 	  this hypothesis consistent with the PDP style of connectionism? Yes, -\-> -->
<!-- <\!-- 	  insofar as the computations of the nervous system can be represented -\-> -->
<!-- <\!-- 	  as the operation of networks. But no, insofar as the mode of -\-> -->
<!-- <\!-- 	  operation of those component networks (as we imagine them) raises -\-> -->
<!-- <\!-- 	  theoretical issues of a different kind. We do not expect procedures -\-> -->
<!-- <\!-- 	  such as GD to be able to produce such societies. Something else is -\-> -->
<!-- <\!-- 	  needed.  What that something must be depends on how we try to extend -\-> -->
<!-- <\!-- 	  the range of small connectionist models. We see two principal -\-> -->
<!-- <\!-- 	  alternatives.  We could extend them either by scaling up small -\-> -->
<!-- <\!-- 	  connectionist models or by combining small-scale elements into some -\-> -->
<!-- <\!-- 	  larger organization.  In the first case, we would expect to -\-> -->
<!-- <\!-- 	  encounter theoretical obstacles to maintaining GD&#39;s -\-> -->
<!-- <\!-- 	  effectiveness on larger, deeper nets. And despite the reputed -\-> -->
<!-- <\!-- 	  efficacy of other alleged remedies for the deficiencies of -\-> -->
<!-- <\!-- 	  hill-climbing, such as <em>annealing,</em> we stay with our research -\-> -->
<!-- <\!-- 	  conjecture that no such procedures will work very well on large -\-> -->
<!-- <\!-- 	  scale nets, except in the case of problems that turn out to be of -\-> -->
<!-- <\!-- 	  low order in some appropriate sense. The second alternative is to -\-> -->
<!-- <\!-- 	  employ a variety of smaller networks rather than try to scale up a -\-> -->
<!-- <\!-- 	  single one. And if we choose (as we do) to move in that direction, -\-> -->
<!-- <\!-- 	  our focus of concern as theoretical psychologists must turn towards -\-> -->
<!-- <\!-- 	  the organizing of small nets into effective large systems. The idea -\-> -->
<!-- <\!-- 	  that the lowest levels of thinking and learning may operate on -\-> -->
<!-- <\!-- 	  toy-like scales fits many of our commonsense impressions of -\-> -->
<!-- <\!-- 	  psychology. For example, in the realm of language, any normal person -\-> -->
<!-- <\!-- 	  can parse a great many kinds of sentences, but none of them past a -\-> -->
<!-- <\!-- 	  certain bound of involuted complexity. We all fall down with -\-> -->
<!-- <\!-- 	  expressions like <em>the cheese that the rat that the cat that the -\-> -->
<!-- <\!--             dog bit chased ate.</em> In the realm of vision, no one can count -\-> -->
<!-- <\!-- 	  great numbers of things, in parallel, at a single glance. Instead, -\-> -->
<!-- <\!-- 	  we learn to <em>estimate.</em> Indeed, the visual joke in figure 0.1 -\-> -->
<!-- <\!-- 	  shows how humans share perceptrons&#39; inability to easily count -\-> -->
<!-- <\!-- 	  and match. A similar example is embodied in the twin spirals of -\-> -->
<!-- <\!-- 	  figure 5.1.  The spiral example was intended to emphasize not only -\-> -->
<!-- <\!-- 	  that low-order perceptrons cannot perceive connectedness, but that -\-> -->
<!-- <\!-- 	  humans have similar limitations. However, a determined person can -\-> -->
<!-- <\!-- 	  solve the problem, given enough time, by switching to the use of -\-> -->
<!-- <\!-- 	  certain sorts of serial mental processes. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Beyond Perceptrons No single-method learning scheme can operate -\-> -->
<!-- <\!-- 	  efficiently for every possible type of task. We cannot expect any -\-> -->
<!-- <\!-- 	  one particular type of machine to account for any large portion of -\-> -->
<!-- <\!-- 	  human psychology. For example, in certain situations it is best to -\-> -->
<!-- <\!-- 	  carefully accumulate experience, but when our time is limited, it is -\-> -->
<!-- <\!-- 	  necessary to make hasty generalizations and act accordingly. No -\-> -->
<!-- <\!-- 	  single scheme can do all things. Our human semblance of intelligence -\-> -->
<!-- <\!-- 	  emerged from how the brain evolved a multiplicity of different ways -\-> -->
<!-- <\!-- 	  to deal with different problem realms. We see this as a principle -\-> -->
<!-- <\!-- 	  that underlies the mind&#39;s reality, and we interpret the need for -\-> -->
<!-- <\!-- 	  many kinds of mechanisms not as a pessimistic and scientifically -\-> -->
<!-- <\!-- 	  constraining limitation but as the fundamental source of many of the -\-> -->
<!-- <\!-- 	  phenomena that artificial intelligence and psychology have always -\-> -->
<!-- <\!-- 	  sought to understand. The power of the brain stems not from any -\-> -->
<!-- <\!-- 	  single, fixed, universal principle. Instead it comes from having -\-> -->
<!-- <\!-- 	  evolved (in both the individual and the darwinian senses) of a -\-> -->
<!-- <\!-- 	  variety of ways to develop new mechanisms and to adapt older ones to -\-> -->
<!-- <\!-- 	  perform new functions.  Instead of seeking a way to get around that -\-> -->
<!-- <\!-- 	  need for diversity, we have come to try to develop Society of Mind -\-> -->
<!-- <\!-- 	  theories that will recognize and exploit the idea that brains are -\-> -->
<!-- <\!-- 	  based on many different kinds of interacting mechanisms.  Several -\-> -->
<!-- <\!-- 	  kinds of evidence impel us toward this view. One is the great -\-> -->
<!-- <\!-- 	  variety of different and specific functions embodied in the -\-> -->
<!-- <\!-- 	  brain&#39;s biology. Another is the similarly great variety of -\-> -->
<!-- <\!-- 	  phenomena in the psychology of intelligence. And from a much more -\-> -->
<!-- <\!-- 	  abstract viewpoint, we cannot help but be impressed with the -\-> -->
<!-- <\!-- 	  practical limitations of each -\-> -->
<!-- <\!-- 	  <em>general</em> scheme that has been proposed &mdash; and with the -\-> -->
<!-- <\!-- 	  theoretical opacity of questions about how they behave when we try -\-> -->
<!-- <\!-- 	  to scale their applications past the toy problems for which they -\-> -->
<!-- <\!-- 	  were first conceived.  Our research on perceptrons and on other -\-> -->
<!-- <\!-- 	  computational schemes has left us with a pervasive bias against -\-> -->
<!-- <\!-- 	  seeking a general, domain- independent theory of <em>how neural -\-> -->
<!-- <\!--             networks work.</em> Instead, we ought to look for ways in which -\-> -->
<!-- <\!-- 	  particular types of network models can support the development of -\-> -->
<!-- <\!-- 	  models of particular domains of mental function &mdash; and vice -\-> -->
<!-- <\!-- 	  versa. Thus, our understanding of the perceptron&#39;s ability to -\-> -->
<!-- <\!-- 	  perform geometric tasks was actually based on theories that were -\-> -->
<!-- <\!-- 	  more concerned with geometry than with networks. And this example is -\-> -->
<!-- <\!-- 	  supported by a broad body of experience in other areas of artificial -\-> -->
<!-- <\!-- 	  intelligence. Perhaps this is why the current preoccupation of -\-> -->
<!-- <\!-- 	  connectionist theorists with the search for general learning -\-> -->
<!-- <\!-- 	  algorithms evokes for us two aspects of the early history of -\-> -->
<!-- <\!-- 	  computation.  First we are reminded of the long line of theoretical -\-> -->
<!-- <\!-- 	  work that culminated in the <em>pessimistic</em> theories of Godel -\-> -->
<!-- <\!-- 	  and Turing about the limitations on effective computability. Yet the -\-> -->
<!-- <\!-- 	  realization that there can be no general purpose decision procedure -\-> -->
<!-- <\!-- 	  for mathematics had not the slightest dampening effect on research -\-> -->
<!-- <\!-- 	  on mathematics or in computer science. On the contrary, awareness of -\-> -->
<!-- <\!-- 	  those limiting discoveries helped motivate the growth of rich -\-> -->
<!-- <\!-- 	  cultures involved with classifying and understanding more -\-> -->
<!-- <\!-- 	  specialized algorithmic methods. In other words, it was the -\-> -->
<!-- <\!-- 	  realization that seeking overgeneral solution methods would be as -\-> -->
<!-- <\!-- 	  fruitless as &mdash; and equivalent to &mdash; trying to solve the -\-> -->
<!-- <\!-- 	  (unsolvable) halting problem for Turing machines. Abandoning this -\-> -->
<!-- <\!-- 	  then led to seeking progress in more productive directions.  Our -\-> -->
<!-- <\!-- 	  second thought is about how the early research in artificial -\-> -->
<!-- <\!-- 	  intelligence tended to focus on general-purpose algorithms for -\-> -->
<!-- <\!-- 	  reasoning and problem solving. Those general methods will always -\-> -->
<!-- <\!-- 	  play their roles, but the most successful applications of AI -\-> -->
<!-- <\!-- 	  research gained much of their practical power from applying specific -\-> -->
<!-- <\!-- 	  knowledge to specific domains. Perhaps this work has now moved too -\-> -->
<!-- <\!-- 	  far toward ignoring general theoretical considerations, but by now -\-> -->
<!-- <\!-- 	  we have learned to be skeptical about the practical power of -\-> -->
<!-- <\!-- 	  unrestrained generality. -\-> -->
	  
<!-- <\!-- 	  Interaction and Insulation Evolution seems to have anticipated these -\-> -->
<!-- <\!-- 	  discoveries. Although the nervous system appears to be a network, it -\-> -->
<!-- <\!-- 	  is very far from being a single, uniform, highly interconnected -\-> -->
<!-- <\!-- 	  assembly of units that each have similar relationships to the -\-> -->
<!-- <\!-- 	  others. Nor are all brain cells similarly affected by the same -\-> -->
<!-- <\!-- 	  processes. It would be better to think of the brain not as a single -\-> -->
<!-- <\!-- 	  network whose elements operate in accord with a uniform set of -\-> -->
<!-- <\!-- 	  principles but as a network whose components are themselves networks -\-> -->
<!-- <\!-- 	  having a large variety of different architectures and control -\-> -->
<!-- <\!-- 	  systems. This <em>Society of Mind</em> idea has led our research -\-> -->
<!-- <\!-- 	  perspective away from the search for algorithms, such as GD, that -\-> -->
<!-- <\!-- 	  were hoped to work across many domains. Instead, we were led into -\-> -->
<!-- <\!-- 	  trying to understand what specific kinds of processing would serve -\-> -->
<!-- <\!-- 	  specific domains.  We recognize that the idea of distributed, -\-> -->
<!-- <\!-- 	  cooperative processing has a powerful appeal to common sense as well -\-> -->
<!-- <\!-- 	  to computational and biological science. Our research instincts tell -\-> -->
<!-- <\!-- 	  us to discover as much as we can about distributed processes. But -\-> -->
<!-- <\!-- 	  there is another concept, complementary to distribution, that is no -\-> -->
<!-- <\!-- 	  less strongly supported by the same sources of intuition. We&#39;ll -\-> -->
<!-- <\!-- 	  call it insulation.  Certain parallel computations are by their -\-> -->
<!-- <\!-- 	  nature synergistic and cooperative: each part makes the others -\-> -->
<!-- <\!-- 	  easier. But the And/Or of theorem 4.0 shows that under other -\-> -->
<!-- <\!-- 	  circumstances, attempting to make the same network perform two -\-> -->
<!-- <\!-- 	  simple tasks at the same time leads to a task that has a far greater -\-> -->
<!-- <\!-- 	  order of difficulty. In those sorts of circumstances, there will be -\-> -->
<!-- <\!-- 	  a clear advantage to having mechanisms, not to connect things -\-> -->
<!-- <\!-- 	  together, but to keep such tasks apart. How can this be done in a -\-> -->
<!-- <\!-- 	  connectionist net? Some recent work hints that even simple -\-> -->
<!-- <\!-- 	  multilayer perceptron-like nets can learn to segregate themselves -\-> -->
<!-- <\!-- 	  into quasi-separate components &mdash; and that suggests (at least -\-> -->
<!-- <\!-- 	  in principle) research on uniform learning procedures. But it also -\-> -->
<!-- <\!-- 	  raises the question of how to relate those almost separate parts. In -\-> -->
<!-- <\!-- 	  fact, research on networks in which different parts do different -\-> -->
<!-- <\!-- 	  things &mdash; and learn those things in different ways &mdash; has -\-> -->
<!-- <\!-- 	  become our principal personal concern. And that leads us to ask how -\-> -->
<!-- <\!-- 	  such systems could develop managers for deciding, in different -\-> -->
<!-- <\!-- 	  circumstances, which of those diverse procedures to use.  For -\-> -->
<!-- <\!-- 	  example, consider all the specialized agencies that the human brain -\-> -->
<!-- <\!-- 	  employs to deal with the visual perception of spatial -\-> -->
<!-- <\!-- 	  scenes. Although we still know little about how all those different -\-> -->
<!-- <\!-- 	  agencies work, the end result is surely even more complex than what -\-> -->
<!-- <\!-- 	  we described in section 13.4. Beyond that, human scene-analysis also -\-> -->
<!-- <\!-- 	  engages our memories and goals. Furthermore, in addition to all the -\-> -->
<!-- <\!-- 	  systems we humans use to dissect two-dimensional scenes into objects -\-> -->
<!-- <\!-- 	  and relationships, we also possess machinery for exploiting -\-> -->
<!-- <\!-- 	  stereoscopic vision. Indeed, there appear to be many such agencies -\-> -->
<!-- <\!-- 	  &mdash; distinct ones that employ, for example, motion cues, -\-> -->
<!-- <\!-- 	  disparities, central correlations of the Julesz type, and -\-> -->
<!-- <\!-- 	  memory-based frame-array-like systems that enable us to imagine and -\-> -->
<!-- <\!-- 	  virtually -\-> -->
<!-- <\!-- 	  <em>see</em> the occluded sides of familiar objects. Beyond those, -\-> -->
<!-- <\!-- 	  we seem also to have been supplied with many other visual agencies, -\-> -->
<!-- <\!-- 	  for example, ones that are destined to learn to recognize faces and -\-> -->
<!-- <\!-- 	  expressions, visual cliffs, threatening movements, sexual -\-> -->
<!-- <\!-- 	  attractants, and who knows how many others that have not been -\-> -->
<!-- <\!-- 	  discovered yet.  What mechanisms manage and control the use of all -\-> -->
<!-- <\!-- 	  those diverse agencies? And from where do those managers come? -\-> -->
	  
<!-- <\!-- 	  Stages of Development In Mindstorms and in The Society of Mind, we -\-> -->
<!-- <\!-- 	  explained how the idea of intermediate, hidden processes might well -\-> -->
<!-- <\!-- 	  account for some phenomena discovered by Piaget in his experiments -\-> -->
<!-- <\!-- 	  on how children develop their concepts about the <em>conservation of -\-> -->
<!-- <\!--             quantity.</em> We introduced a theory of mental growth based on -\-> -->
<!-- <\!-- 	  inserting, at various times, new inner layers of <em>management</em> -\-> -->
<!-- <\!-- 	  into already existing networks. In particular, we argued that, to -\-> -->
<!-- <\!-- 	  learn to make certain types of comparisons, a child&#39;s mind must -\-> -->
<!-- <\!-- 	  construct a multilayer structure that we call a Society-of-More. The -\-> -->
<!-- <\!-- 	  lower levels of that net contain agents specialized to make a -\-> -->
<!-- <\!-- 	  variety of spatial and temporal observations. Then the higher level -\-> -->
<!-- <\!-- 	  agents learn to classify, and then control, the activities of the -\-> -->
<!-- <\!-- 	  lower ones. We certainly would like to see a demonstration of a -\-> -->
<!-- <\!-- 	  learning process that could spontaneously produce the several levels -\-> -->
<!-- <\!-- 	  of agents needed to embody a concept as complex as that. Chapter 17 -\-> -->
<!-- <\!-- 	  of The Society of Mind offers several different reasons why this -\-> -->
<!-- <\!-- 	  might be very difficult to do &mdash; except in systems under -\-> -->
<!-- <\!-- 	  systematic controls, both temporal and architectural.  We suspect -\-> -->
<!-- <\!-- 	  that it would require far too long, in comparison with an -\-> -->
<!-- <\!-- 	  infant&#39;s months of life, to create sophisticated agencies -\-> -->
<!-- <\!-- 	  entirely by undirected, spontaneous learning. Each specialized -\-> -->
<!-- <\!-- 	  network must begin with promising ingredients that come either from -\-> -->
<!-- <\!-- 	  prior stages of development or from some structural endowment that -\-> -->
<!-- <\!-- 	  emerged in the course of organic evolution.  When should new layers -\-> -->
<!-- <\!-- 	  of control be introduced? If managers are empowered too soon, when -\-> -->
<!-- <\!-- 	  their workers still are too immature, they won&#39;t be able to -\-> -->
<!-- <\!-- 	  accomplish enough. (If every agent could learn from birth, they -\-> -->
<!-- <\!-- 	  would all be overwhelmed by infantile ideas.) But if the managers -\-> -->
<!-- <\!-- 	  arrive too late, that will retard all further growth. Ideally, every -\-> -->
<!-- <\!-- 	  agency&#39;s development would be controlled by yet another agency -\-> -->
<!-- <\!-- 	  equipped to introduce new agents just when they are needed &mdash; -\-> -->
<!-- <\!-- 	  that is, when enough has been learned to justify the start of -\-> -->
<!-- <\!-- 	  another stage. However, that would require a good deal of expertise -\-> -->
<!-- <\!-- 	  on the controlling agency&#39;s part. Another way much easier to -\-> -->
<!-- <\!-- 	  evolve would simply enable various agencies to establish new -\-> -->
<!-- <\!-- 	  connections at genetically predetermined times (perhaps while also -\-> -->
<!-- <\!-- 	  causing lower level parts to slow further growth). A scheme like -\-> -->
<!-- <\!-- 	  that could benefit a population on the whole, although it might -\-> -->
<!-- <\!-- 	  handicap individuals who, for one reason or another, happen to move -\-> -->
<!-- <\!-- 	  ahead of or behind that inborn <em>schedule.</em> In any case, there -\-> -->
<!-- <\!-- 	  are many reasons to suspect that the parts of any system as complex -\-> -->
<!-- <\!-- 	  as a human mind must grow through sequences of stage-like episodes. -\-> -->
	  
<!-- <\!-- 	  Architecture and Specialization The tradition of connectionism has -\-> -->
<!-- <\!-- 	  always tried to establish two claims: that connectionist networks -\-> -->
<!-- <\!-- 	  can accomplish interesting tasks and that they can learn to do those -\-> -->
<!-- <\!-- 	  things with no explicit programming. But a closer look reveals that -\-> -->
<!-- <\!-- 	  rarely are those two virtues present in the same device. It is true -\-> -->
<!-- <\!-- 	  that networks, taken as a class, can do virtually anything. However, -\-> -->
<!-- <\!-- 	  each particular type of network can best learn only certain types of -\-> -->
<!-- <\!-- 	  things. Each particular network we have seen seems relatively -\-> -->
<!-- <\!-- 	  limited. Yet our wondrous brains are themselves composed of -\-> -->
<!-- <\!-- 	  connected networks of cells.  We think that the difference in -\-> -->
<!-- <\!-- 	  abilities comes from the fact that a brain is not a single, -\-> -->
<!-- <\!-- 	  uniformly structured network. Instead, each brain contains hundreds -\-> -->
<!-- <\!-- 	  of different types of machines, interconnected in specific ways -\-> -->
<!-- <\!-- 	  which predestine that brain to become a large, diverse society of -\-> -->
<!-- <\!-- 	  partially specialized agencies. We are born with specific parts of -\-> -->
<!-- <\!-- 	  our brains to serve every sense and muscle group, and with perhaps -\-> -->
<!-- <\!-- 	  separate sections involved with physical and social matters (e.g., -\-> -->
<!-- <\!-- 	  natural sounds versus social speech, inanimate scenes versus facial -\-> -->
<!-- <\!-- 	  expressions, mechanical contacts versus social caresses).  Our -\-> -->
<!-- <\!-- 	  brains also embody proto-specialists involved with hunger, laughter, -\-> -->
<!-- <\!-- 	  anger, fear &mdash; and hundreds of other functions and perhaps many -\-> -->
<!-- <\!-- 	  others that scientists have not yet isolated. Many thousands of -\-> -->
<!-- <\!-- 	  genes must be involved both in constructing specific internal -\-> -->
<!-- <\!-- 	  architectures for each of those highly evolved brain centers and in -\-> -->
<!-- <\!-- 	  laying out the nerve bundles that interconnect them. And although -\-> -->
<!-- <\!-- 	  each such system is embodied in the form of a network-based learning -\-> -->
<!-- <\!-- 	  system, each almost surely also learns in accord with somewhat -\-> -->
<!-- <\!-- 	  different principles.  Why did our brains evolve so as to contain so -\-> -->
<!-- <\!-- 	  many specialized parts? Could not a single, uniform network learn to -\-> -->
<!-- <\!-- 	  structure itself into divisions with appropriate architectures and -\-> -->
<!-- <\!-- 	  processes? We think that this would be impractical because of the -\-> -->
<!-- <\!-- 	  problem of representing knowledge. In order for a machine to learn -\-> -->
<!-- <\!-- 	  to recognize or perform X, be it a pattern or a process, that -\-> -->
<!-- <\!-- 	  machine must in one sense or another learn to represent or embody -\-> -->
<!-- <\!-- 	  X. Doing that efficiently must exploit some happy triadic -\-> -->
<!-- <\!-- 	  relationship between the structure of X, the learning procedure, and -\-> -->
<!-- <\!-- 	  the initial architecture of the network. It makes no sense to seek -\-> -->
<!-- <\!-- 	  the <em>best</em> network architecture or learning procedure because -\-> -->
<!-- <\!-- 	  it makes no sense to say that any network is efficient by itself; -\-> -->
<!-- <\!-- 	  that makes sense only in the context of some class of problems to be -\-> -->
<!-- <\!-- 	  solved. Different kinds of networks lend themselves best to -\-> -->
<!-- <\!-- 	  different kinds of representations and to making different sorts of -\-> -->
<!-- <\!-- 	  generalizations. This means that the study of networks in general -\-> -->
<!-- <\!-- 	  must include attempts, like those in this book, to classify problems -\-> -->
<!-- <\!-- 	  and learning processes; but it must also include attempts to -\-> -->
<!-- <\!-- 	  classify the network architectures. This is why we maintain that the -\-> -->
<!-- <\!-- 	  scientific future of connectionism is tied not to seek some single, -\-> -->
<!-- <\!-- 	  universal scheme to solve all problems at once but to the evolution -\-> -->
<!-- <\!-- 	  of a many-faceted technology of <em>brain design</em> that -\-> -->
<!-- <\!-- 	  encompasses good technical theories about the analysis of learning -\-> -->
<!-- <\!-- 	  procedures, of useful architectures, and of organizational -\-> -->
<!-- <\!-- 	  principles to use when assembling those components into larger -\-> -->
<!-- <\!-- 	  systems. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Symbolic Versus Distributed Let us now return to the conflict posed -\-> -->
<!-- <\!-- 	  in our prologue: the war between the connectionists and the -\-> -->
<!-- <\!-- 	  symbolists. We hope to make peace by exploiting both sides. -\-> -->
	  
<!-- <\!-- 	  There are important virtues in the use of parallel distributed -\-> -->
<!-- <\!-- 	  networks. They certainly often offer advantages in simplicity and in -\-> -->
<!-- <\!-- 	  speed. And above all else they offer us ways to learn new skills -\-> -->
<!-- <\!-- 	  without the pain and suffering that might come from comprehending -\-> -->
<!-- <\!-- 	  how. On the darker side, they can limit large- scale growth because -\-> -->
<!-- <\!-- 	  what any distributed network learns is likely to be quite opaque to -\-> -->
<!-- <\!-- 	  other networks connected to it.  Symbolic systems yield gains of -\-> -->
<!-- <\!-- 	  their own, in versatility and unlimited growth. Above all else they -\-> -->
<!-- <\!-- 	  offer us the prospect that computers share: of not being bound by -\-> -->
<!-- <\!-- 	  the small details of the parts of which they are composed. But that, -\-> -->
<!-- <\!-- 	  too, has its darker side: symbolic processes can evolve worlds of -\-> -->
<!-- <\!-- 	  their own, utterly divorced from their origins. Perceptrons can -\-> -->
<!-- <\!-- 	  never go insane &mdash; but the same cannot be said of a brain. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Now, what are symbols, anyway? We usually conceive of them as -\-> -->
<!-- <\!-- 	  compact things that represent more complex things. But what, then, -\-> -->
<!-- <\!-- 	  do we mean by represent? It simply makes no sense, by itself, to say -\-> -->
<!-- <\!-- 	  that <em>S represents T,</em> because the significance of a symbol -\-> -->
<!-- <\!-- 	  depends on at least three participants: on S, on T, and on the -\-> -->
<!-- <\!-- 	  context of some process or user U. What, for example, connects the -\-> -->
<!-- <\!-- 	  word <em>table</em> to any actual, physical table? Since the words -\-> -->
<!-- <\!-- 	  people use are the words people learn, clearly the answer must be -\-> -->
<!-- <\!-- 	  that there is no direct relationship between S and T but that there -\-> -->
<!-- <\!-- 	  is a more complex triadic relationship that connects a symbol, a -\-> -->
<!-- <\!-- 	  thing, and a process that is active in some person&#39;s -\-> -->
<!-- <\!-- 	  mind. Furthermore, when the term symbol is used in the context of -\-> -->
<!-- <\!-- 	  network psychology, it usually refers to something that is -\-> -->
<!-- <\!-- 	  reassignable so that it can be made to represent different things -\-> -->
<!-- <\!-- 	  and so that the symbol-using processes can learn to deal with -\-> -->
<!-- <\!-- 	  different symbols.  What do we mean by distributed? This usually -\-> -->
<!-- <\!-- 	  refers to a system in which each end-effect comes not from any -\-> -->
<!-- <\!-- 	  single, localized element-part, but from the interactions of many -\-> -->
<!-- <\!-- 	  contributors, all working at the same time. Accordingly, in order to -\-> -->
<!-- <\!-- 	  make a desired change in the output of a distributed system, one -\-> -->
<!-- <\!-- 	  must usually alter a great many components. And changing the output -\-> -->
<!-- <\!-- 	  of any particular component will rarely have a large effect in any -\-> -->
<!-- <\!-- 	  particular circumstance; instead, such changes will tend to have -\-> -->
<!-- <\!-- 	  small effects in many different circumstances.  Symbols are tokens -\-> -->
<!-- <\!-- 	  or handles with which one specialist can manipulate representations -\-> -->
<!-- <\!-- 	  within another specialist. But now, suppose that we want one agency -\-> -->
<!-- <\!-- 	  to be able to exploit the knowledge in another agency. So long as we -\-> -->
<!-- <\!-- 	  stay inside a particular agency, it may be feasible to use -\-> -->
<!-- <\!-- 	  representations that involve great hosts of internal interactions -\-> -->
<!-- <\!-- 	  and dependencies. But the fine details of such a representation -\-> -->
<!-- <\!-- 	  would be meaningless to any outside agency that lacks the access of -\-> -->
<!-- <\!-- 	  the capacity to learn to deal with all that detail. Indeed, if each -\-> -->
<!-- <\!-- 	  representation in the first agency involves activities that are -\-> -->
<!-- <\!-- 	  uniformly distributed over a very large network, then direct -\-> -->
<!-- <\!-- 	  communication to the other agency would require so many connection -\-> -->
<!-- <\!-- 	  paths that both agencies would end up enmeshed together into a -\-> -->
<!-- <\!-- 	  single, uniform net &mdash; and then all the units of both would -\-> -->
<!-- <\!-- 	  interact.  How, then, could networks support symbolic forms of -\-> -->
<!-- <\!-- 	  activities? -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We conjecture that, inside the brain, agencies with different jobs -\-> -->
<!-- <\!-- 	  are usually constrained to communicate with one another only through -\-> -->
<!-- <\!-- 	  neurological bottlenecks (i.e., connections between relatively small -\-> -->
<!-- <\!-- 	  numbers of units that are specialized to serve as symbolic -\-> -->
<!-- <\!-- 	  recognizers and memorizers). The recognizers learn to encode -\-> -->
<!-- <\!-- 	  significant features of the representation active in the first -\-> -->
<!-- <\!-- 	  network, and the memorizers learn to evoke an activity that can -\-> -->
<!-- <\!-- 	  serve a corresponding function in the receiving network. But in -\-> -->
<!-- <\!-- 	  order to prevent those features from interfering too much with one -\-> -->
<!-- <\!-- 	  another, there must be an adequate degree of insulation between the -\-> -->
<!-- <\!-- 	  units that serve these purposes. And that need for insulation can -\-> -->
<!-- <\!-- 	  lead to genuine conflicts between the use of symbolic and -\-> -->
<!-- <\!-- 	  distributed representations. This is because distributed -\-> -->
<!-- <\!-- 	  representations make it hard to combine (in arbitrary, learnable -\-> -->
<!-- <\!-- 	  ways) the different fragments of knowledge embodied in different -\-> -->
<!-- <\!-- 	  representations. The difficulty arises because the more distributed -\-> -->
<!-- <\!-- 	  is the representation of each fragment, the fewer fragments can be -\-> -->
<!-- <\!-- 	  simultaneously active without interfering with one -\-> -->
<!-- <\!-- 	  another. Sometimes those interactions can be useful but, in general, -\-> -->
<!-- <\!-- 	  they will be destructive. This is discussed briefly in section 8.2 -\-> -->
<!-- <\!-- 	  of The Society of Mind: -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  <em>The advantages of distributed systems are not alternatives to -\-> -->
<!-- <\!--             the advantages of insulated systems; the two are complementary. To -\-> -->
<!-- <\!--             say that the brain may be composed of distributed systems is not -\-> -->
<!-- <\!--             the same as saying that it is a distributed system &mdash; that -\-> -->
<!-- <\!--             is, a single network in which all functions are uniformly -\-> -->
<!-- <\!--             distributed. We do not believe that any brain of that sort could -\-> -->
<!-- <\!--             work, because the interactions would be uncontrollable. To be -\-> -->
<!-- <\!--             sure, we have to explain how different ideas can become connected -\-> -->
<!-- <\!--             to one another &mdash; but we must also explain what keeps our -\-> -->
<!-- <\!--             separate memories intact.  For example, we praised the power of -\-> -->
<!-- <\!--             metaphors that allow us to mix the ideas we have in different -\-> -->
<!-- <\!--             realms &mdash; but all that power would be lost if all our -\-> -->
<!-- <\!--             metaphors got mixed! Similarly, the architecture of a mind-society -\-> -->
<!-- <\!--             must encourage the formation and maintenance of distinct levels of -\-> -->
<!-- <\!--             management by preventing the formation of connections between -\-> -->
<!-- <\!--             agencies whose messages have no mutual significance. Some -\-> -->
<!-- <\!--             theorists have assumed that distributed systems are inherently -\-> -->
<!-- <\!--             both robust and versatile but, actually, those attributes are more -\-> -->
<!-- <\!--             likely to conflict. Systems with too many interactions of -\-> -->
<!-- <\!--             different types will tend to be -\-> -->

<!-- <\!--             <p> -\-> -->
<!-- <\!--               fragile, while systems with too many interactions of similar -\-> -->
<!-- <\!--               types will tend to be too redundant to adapt to novel situations -\-> -->
<!-- <\!--               and requirements.</em> -\-> -->
	  
<!-- <\!-- 	  A larger-scale problem is that the use of widely distributed -\-> -->
<!-- <\!-- 	  representations will tend to oppose the formulation of knowledge -\-> -->
<!-- <\!-- 	  about knowledge. This is because information embodied in distributed -\-> -->
<!-- <\!-- 	  form will tend to relatively inaccessible for use as a subject upon -\-> -->
<!-- <\!-- 	  which other knowledge-based processes can operate. Consequently (we -\-> -->
<!-- <\!-- 	  conjecture), systems that use highly distributed representations -\-> -->
<!-- <\!-- 	  will tend to become conceptual dead ends as a result of their -\-> -->
<!-- <\!-- 	  putting performance so far ahead of comprehension as to retard the -\-> -->
<!-- <\!-- 	  growth of reflective thought. Too much diffusing of information can -\-> -->
<!-- <\!-- 	  make it virtually impossible (for other portions of the brain) to -\-> -->
<!-- <\!-- 	  find out how results, however useful, are obtained. This would make -\-> -->
<!-- <\!-- 	  it very difficult to dissect out the components that might otherwise -\-> -->
<!-- <\!-- 	  be used to construct meaningful variations and generalizations. Of -\-> -->
<!-- <\!-- 	  course, such problems won&#39;t become evident in experiments with -\-> -->
<!-- <\!-- 	  systems that do only simple things, but we can expect to see such -\-> -->
<!-- <\!-- 	  problems grow when systems try to learn to do more complex -\-> -->
<!-- <\!-- 	  things. With highly distributed systems, we should anticipate that -\-> -->
<!-- <\!-- 	  the accumulation of internal interactions may eventually lead to -\-> -->
<!-- <\!-- 	  intractable credit assignment problems. Perhaps the only ultimate -\-> -->
<!-- <\!-- 	  escape from the limitations of internal interactions is to evolve -\-> -->
<!-- <\!-- 	  toward organizations in which each network affects others primarily -\-> -->
<!-- <\!-- 	  through the use of serial operations and specialized -\-> -->
<!-- <\!-- 	  short-term-memory systems, for although seriality is relatively -\-> -->
<!-- <\!-- 	  slow, its use makes it possible to produce and control interactions -\-> -->
<!-- <\!-- 	  between activities that occur at different and separate places and -\-> -->
<!-- <\!-- 	  times. -\-> -->
	  
<!-- <\!-- 	  The Parallel Paradox It is often argued that the use of distributed -\-> -->
<!-- <\!-- 	  representations enables a system to exploit the advantages of -\-> -->
<!-- <\!-- 	  parallel processing. But what are the advantages of parallel -\-> -->
<!-- <\!-- 	  processing? Suppose that a certain task involves two unrelated -\-> -->
<!-- <\!-- 	  parts. To deal with both concurrently, we would have to maintain -\-> -->
<!-- <\!-- 	  their representations in two decoupled agencies, both active at the -\-> -->
<!-- <\!-- 	  same time. Then, should either of those agencies become involved -\-> -->
<!-- <\!-- 	  with two or more subtasks, we&#39;d have to deal with each of them -\-> -->
<!-- <\!-- 	  with no more than a quarter of the available resources! If that -\-> -->
<!-- <\!-- 	  proceeded on and on, the system would become so fragmented that each -\-> -->
<!-- <\!-- 	  job would end up with virtually no resources assigned to it. In this -\-> -->
<!-- <\!-- 	  regard, distribution may oppose parallelism: the more distributed a -\-> -->
<!-- <\!-- 	  system is &mdash; that is, the more intimately its parts interact -\-> -->
<!-- <\!-- 	  &mdash; the fewer different things it can do at the same time. On -\-> -->
<!-- <\!-- 	  the other side, the more we do separately in parallel, the less -\-> -->
<!-- <\!-- 	  machinery can be assigned to each element of what we do, and that -\-> -->
<!-- <\!-- 	  ultimately leads to increasing fragmentation and incompetence.  This -\-> -->
<!-- <\!-- 	  is not to say that distributed representations and parallel -\-> -->
<!-- <\!-- 	  processing are always incompatible. When we simultaneously activate -\-> -->
<!-- <\!-- 	  two distributed representations in the same network, they will be -\-> -->
<!-- <\!-- 	  forced to interact. In favorable circumstances, those interactions -\-> -->
<!-- <\!-- 	  can lead to useful parallel computations, such as the satisfaction -\-> -->
<!-- <\!-- 	  of simultaneous constraints. But that will not happen in general; it -\-> -->
<!-- <\!-- 	  will occur only when the representations happen to mesh in suitably -\-> -->
<!-- <\!-- 	  fortunate ways. Such problems will be especially serious when we try -\-> -->
<!-- <\!-- 	  to train distributed systems to deal with problems that require any -\-> -->
<!-- <\!-- 	  sort of structural analysis in which the system must represent -\-> -->
<!-- <\!-- 	  relationships between substructures of related types &mdash; that -\-> -->
<!-- <\!-- 	  is, problems that are likely to demand the same structural -\-> -->
<!-- <\!-- 	  resources. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  On the positive side, there are potential virtues to embodying -\-> -->
<!-- <\!-- 	  knowledge in the form of networks of units with weighted -\-> -->
<!-- <\!-- 	  interconnections. For example, distributed representations can -\-> -->
<!-- <\!-- 	  sometimes be used to gain the robustness of redundancy, to make -\-> -->
<!-- <\!-- 	  machines that continue to work despite having injured, damaged, or -\-> -->
<!-- <\!-- 	  unreliable components. They can embody extremely simple learning -\-> -->
<!-- <\!-- 	  algorithms, which operate in parallel with great speed. -\-> -->
	  
<!-- <\!-- 	  Representations and Generalizations It is often said that -\-> -->
<!-- <\!-- 	  distributed representations are inherently possessed of useful -\-> -->
<!-- <\!-- 	  holistic qualities; for example, that they have innate tendencies to -\-> -->
<!-- <\!-- 	  recognize wholes from partial cues &mdash; even for patterns they -\-> -->
<!-- <\!-- 	  have not encountered before. Phenomena of that sort are often -\-> -->
<!-- <\!-- 	  described with such words as generalization, induction, or gestalt. -\-> -->
<!-- <\!-- 	  Such phenomena certainly can emerge from connectionist assemblies. -\-> -->
<!-- <\!-- 	  The problem is that, for any body of experience, there are always -\-> -->
<!-- <\!-- 	  many kinds of generalizations that can be made. The ones made by any -\-> -->
<!-- <\!-- 	  particular network are likely to be inappropriate unless there -\-> -->
<!-- <\!-- 	  happens to be an appropriate relationship between the network&#39;s -\-> -->
<!-- <\!-- 	  architecture and the manner in which the problem is -\-> -->
<!-- <\!-- 	  represented. What makes architectures and representations -\-> -->
<!-- <\!-- 	  appropriate? One way to answer that is to study how they affect -\-> -->
<!-- <\!-- 	  which signals will be treated as similar.  Consider the problem of -\-> -->
<!-- <\!-- 	  comparing an arbitrary input pattern with a collection of patterns -\-> -->
<!-- <\!-- 	  in memory, to find which memory is most similar to that stimulus. In -\-> -->
<!-- <\!-- 	  section 12.7 we conjectured that solving best-match problems will -\-> -->
<!-- <\!-- 	  always be very tedious when serial hardware is used. PDP suggests -\-> -->
<!-- <\!-- 	  another view in regard to parallel, distributed machines: <em>This -\-> -->
<!-- <\!--             is precisely the kind of problem that is readily implemented using -\-> -->
<!-- <\!--             highly parallel algorithms of the kind we consider.</em> This is in -\-> -->
<!-- <\!-- 	  some ways plausible, since a sufficiently parallel machine could -\-> -->
<!-- <\!-- 	  simultaneously match an input pattern against every pattern in its -\-> -->
<!-- <\!-- 	  memory. And yet the assertion is quaintly naive, since best-match -\-> -->
<!-- <\!-- 	  means different things in different circumstances. Which answers -\-> -->
<!-- <\!-- 	  should be accepted as best always depends on the domain of -\-> -->
<!-- <\!-- 	  application. The very same stimulus may signify food to one animal, -\-> -->
<!-- <\!-- 	  companionship to another, and a dangerous predator to a third. Thus -\-> -->
<!-- <\!-- 	  there can be no single, universal measure of how well two -\-> -->
<!-- <\!-- 	  descriptions match; every context requires appropriate schemes. -\-> -->
<!-- <\!-- 	  Because of this, distributed networks do not magically provide -\-> -->
<!-- <\!-- 	  solutions to such best match problems. Instead, the functional -\-> -->
<!-- <\!-- 	  architecture of each particular network imposes its own particular -\-> -->
<!-- <\!-- 	  sort of metrical structure on the space of stimuli. Such structures -\-> -->
<!-- <\!-- 	  may often be useful. Yet, that can give us no assurance that the -\-> -->
<!-- <\!-- 	  outcome will correspond to what an expert observer would consider to -\-> -->
<!-- <\!-- 	  be the very best match, given that observer&#39;s view of what would -\-> -->
<!-- <\!-- 	  be the most appropriate response in the current context or problem -\-> -->
<!-- <\!-- 	  realm.  We certainly do not mean to suggest that networks cannot -\-> -->
<!-- <\!-- 	  perform useful matching functions. We merely mean to emphasize that -\-> -->
<!-- <\!-- 	  different problems entail different matching criteria, and that no -\-> -->
<!-- <\!-- 	  particular type of network can induce a topology of similarity or -\-> -->
<!-- <\!-- 	  nearness that is appropriate for every realm. Instead, we must -\-> -->
<!-- <\!-- 	  assume that over the course of time, each specialized portion of the -\-> -->
<!-- <\!-- 	  brain has evolved a particular type of architecture that is -\-> -->
<!-- <\!-- 	  reasonably likely to induce similarity relationships that are useful -\-> -->
<!-- <\!-- 	  in performing the functions to which that organ is likely (or -\-> -->
<!-- <\!-- 	  destined) to be assigned. Perhaps an important activity of future -\-> -->
<!-- <\!-- 	  connectionist research will be to develop networks that can learn to -\-> -->
<!-- <\!-- 	  embody wide ranges of different, context-dependent types of matching -\-> -->
<!-- <\!-- 	  functions. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  We have also often heard the view that machines that employ -\-> -->
<!-- <\!-- 	  localized or symbolic representations must be inherently less -\-> -->
<!-- <\!-- 	  capable than are distributed machines of insight, consciousness, or -\-> -->
<!-- <\!-- 	  sense of self. We think this stands things on their heads. It is -\-> -->
<!-- <\!-- 	  because our brains primarily exploit connectionist schemes that we -\-> -->
<!-- <\!-- 	  possess such small degrees of consciousness, in the sense that we -\-> -->
<!-- <\!-- 	  have so little insight into the nature of our own conceptual -\-> -->
<!-- <\!-- 	  machinery. We agree that distributed representations are probably -\-> -->
<!-- <\!-- 	  used in virtually every part of the brain. Consequently, each agency -\-> -->
<!-- <\!-- 	  must learn to exploit the abilities of the others without having -\-> -->
<!-- <\!-- 	  direct access to compact representations of what happens inside -\-> -->
<!-- <\!-- 	  those other agencies. This makes direct insight infeasible; the best -\-> -->
<!-- <\!-- 	  such agencies can do is attempt to construct their own models of the -\-> -->
<!-- <\!-- 	  others on the basis of approximate, pragmatic models based on -\-> -->
<!-- <\!-- 	  presuppositions and concepts already embodied in the observing -\-> -->
<!-- <\!-- 	  agency. Because of this, what appear to us to be direct insights -\-> -->
<!-- <\!-- 	  into ourselves must be rarely genuine and usually -\-> -->
<!-- <\!-- 	  conjectural. Accordingly, we expect distributed representations to -\-> -->
<!-- <\!-- 	  tend to produce systems with only limited abilities to reflect -\-> -->
<!-- <\!-- 	  accurately on how they do what they do. Thinking about thinking, we -\-> -->
<!-- <\!-- 	  maintain, requires the use of representations that are localized -\-> -->
<!-- <\!-- 	  enough that they can be dissected and rearranged. Besides, -\-> -->
<!-- <\!-- 	  distributed representations spread out the information that goes -\-> -->
<!-- <\!-- 	  into them. The result of this is to mix and obscure the effects of -\-> -->
<!-- <\!-- 	  their separate elements. Thus their use must entail a heavy price; -\-> -->
<!-- <\!-- 	  surely, many of them must become <em>conceptual dead ends</em> -\-> -->
<!-- <\!-- 	  because the performances that they produce emerge from processes -\-> -->
<!-- <\!-- 	  that other agencies cannot comprehend. In other words, when the -\-> -->
<!-- <\!-- 	  representations of concepts are distributed, this will tend to -\-> -->
<!-- <\!-- 	  frustrate attempts of other agencies to adapt and transfer those -\-> -->
<!-- <\!-- 	  concepts to other contexts.  How much, then, can we expect from -\-> -->
<!-- <\!-- 	  connectionist systems? Much more than the above remarks might -\-> -->
<!-- <\!-- 	  suggest, since reflective thought is the lesser part of what our -\-> -->
<!-- <\!-- 	  minds do. Most probably, we think, the human brain is, in the main, -\-> -->
<!-- <\!-- 	  composed of large numbers of relatively small distributed systems, -\-> -->
<!-- <\!-- 	  arranged by embryology into a complex society that is controlled in -\-> -->
<!-- <\!-- 	  part (but only in part) by serial, symbolic systems that are added -\-> -->
<!-- <\!-- 	  later. But the subsymbolic systems that do most of the work from -\-> -->
<!-- <\!-- 	  underneath must, by their very character, block all the other parts -\-> -->
<!-- <\!-- 	  of the brain from knowing much about how they work. And this, -\-> -->
<!-- <\!-- 	  itself, could help explain how people do so many things yet have -\-> -->
<!-- <\!-- 	  such incomplete ideas of how those things are actually done. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  First appeared in Scanning, Vol. 10, 128-138 (1988) -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  MEMOIR ON INVENTING THE CONFOCAL SCANNING MISCROSCOPE Marvin Minsky, -\-> -->
<!-- <\!-- 	  MIT Editorial Note In this issue, we carry an article which we -\-> -->
<!-- <\!-- 	  invited Prof. Marvin Minsky to write about his invention of the -\-> -->
<!-- <\!-- 	  confocal scanning microscope. This is not a question of recognizing -\-> -->
<!-- <\!-- 	  priority for a scientific insight or discovery. It is much more a -\-> -->
<!-- <\!-- 	  question of raising the problem of how it can be possible that such -\-> -->
<!-- <\!-- 	  an immensely important idea can go unrecognized for such a very long -\-> -->
<!-- <\!-- 	  period. It may possibly be the case that after more research we find -\-> -->
<!-- <\!-- 	  that yet another person discovered the same idea. That does not -\-> -->
<!-- <\!-- 	  matter. The fact is that Minsky invented such a microscope identical -\-> -->
<!-- <\!-- 	  with the concept later developed extensively by Egger and Davidovits -\-> -->
<!-- <\!-- 	  at Yale and by Shepherd and Wilson in Oxford and Brakenhoff and -\-> -->
<!-- <\!-- 	  colleagues in Amsterdam etc.  The circumstances are also remarkable -\-> -->
<!-- <\!-- 	  in that Minsky only published his invention as a patent. Yet he not -\-> -->
<!-- <\!-- 	  only built a microscope and made it work and it was the kind of -\-> -->
<!-- <\!-- 	  prototype of which we would be proud but he showed it to a number of -\-> -->
<!-- <\!-- 	  people who went away impressed but nevertheless failed to adopt the -\-> -->
<!-- <\!-- 	  concept.  We have also secured a copy of Minsky&#39;s original -\-> -->
<!-- <\!-- 	  letter to his patent agent, which we reproduce verbatim to indicate -\-> -->
<!-- <\!-- 	  the clarity with which he was able to describe the concept and the -\-> -->
<!-- <\!-- 	  future potential.  The original patent is also excellent reading, -\-> -->
<!-- <\!-- 	  but that is quite freely available. We have only copied the figures -\-> -->
<!-- <\!-- 	  from that publication. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  A. Boyde, Editor Memoir on Inventing the Confocal Scanning -\-> -->
<!-- <\!-- 	  Microscope Marvin Minsky This is what I remember about inventing the -\-> -->
<!-- <\!-- 	  confocal scanning microscope in 1955. It happened while I was making -\-> -->
<!-- <\!-- 	  a transition between two other theoretical preoccupations and I have -\-> -->
<!-- <\!-- 	  never thought back to that period until Alan Boyde suggested writing -\-> -->
<!-- <\!-- 	  this memoir. When I read the following account, the plot seems more -\-> -->
<!-- <\!-- 	  coherent now than it ever did in those times of the past. Perhaps, -\-> -->
<!-- <\!-- 	  though, those activities which seemed to me the most spontaneous -\-> -->
<!-- <\!-- 	  were actually those which unconsciously were managed the most -\-> -->
<!-- <\!-- 	  methodically.  The story actually begins in childhood, for my father -\-> -->
<!-- <\!-- 	  was an ophthalmologist and our home was simply full of lenses, -\-> -->
<!-- <\!-- 	  prisms, and diaphragms. I took all his instruments apart, and he -\-> -->
<!-- <\!-- 	  quietly put them together again. Later, when I was an undergraduate -\-> -->
<!-- <\!-- 	  at Harvard in the class of 1950, there were new wonders every day. I -\-> -->
<!-- <\!-- 	  studied mathematics with Andrew Gleason, neurophysiology with John -\-> -->
<!-- <\!-- 	  Welsh, neuroanatomy with Marcus Singer, psychology with George -\-> -->
<!-- <\!-- 	  Miller, and classical mechanics with Herbert Goldstein. But perhaps -\-> -->
<!-- <\!-- 	  the most amazing experience of all was in a laboratory course -\-> -->
<!-- <\!-- 	  wherein a student had to reproduce great physics experiments of the -\-> -->
<!-- <\!-- 	  past. To ink a zone plate onto glass and see it focus on a screen; -\-> -->
<!-- <\!-- 	  to watch a central fringe emerge as the lengths of two paths become -\-> -->
<!-- <\!-- 	  the same; to measure those lengths to the millionth part with -\-> -->
<!-- <\!-- 	  nothing but mirrors and beams of light &mdash; I had never seen any -\-> -->
<!-- <\!-- 	  things so strange.  For graduate studies I moved to Princeton to -\-> -->
<!-- <\!-- 	  study more mathematics and biology, and wrote a theoretical thesis -\-> -->
<!-- <\!-- 	  on connectionistic learning machines &mdash; that is, on networks of -\-> -->
<!-- <\!-- 	  devices based on what little was known about nerve cells. (For, as -\-> -->
<!-- <\!-- 	  long as I can remember, I was entranced by all kinds of machinery -\-> -->
<!-- <\!-- 	  &mdash; and, early in my college years, tried to find out how the -\-> -->
<!-- <\!-- 	  great machines that we call brains managed to feel and learn and -\-> -->
<!-- <\!-- 	  think.) I studied everything available about the physiology, -\-> -->
<!-- <\!-- 	  anatomy, and embryology of the nervous system. But there simply were -\-> -->
<!-- <\!-- 	  too many gaps; nothing was known about how brains -\-> -->
<!-- <\!-- 	  learn. Nevertheless, it occurred to me, you might be able to figure -\-> -->
<!-- <\!-- 	  that out &mdash; if only you knew how those brain cells were -\-> -->
<!-- <\!-- 	  connected to each other. Then you could attempt some of what is now -\-> -->
<!-- <\!-- 	  called <em>reverse engineering</em> &mdash; to guess what those -\-> -->
<!-- <\!-- 	  circuit&#39;s components do from knowing both what the circuits do -\-> -->
<!-- <\!-- 	  and how their parts are connected. But I was horrified to learn that -\-> -->
<!-- <\!-- 	  even those connection schemes had never been properly mapped at -\-> -->
<!-- <\!-- 	  all. To be sure, a good deal was known about the shapes of certain -\-> -->
<!-- <\!-- 	  types of nerve cells, because of the miraculous way in which the -\-> -->
<!-- <\!-- 	  Golgi treatment tends to pick out a few neurons and then stain all -\-> -->
<!-- <\!-- 	  the fibres that extend from them. But this permits you to visualize -\-> -->
<!-- <\!-- 	  only one cell at a time, whereas to obtain the required wiring -\-> -->
<!-- <\!-- 	  diagram you need to make visible all the cells in a three -\-> -->
<!-- <\!-- 	  dimensional region. And here was a critical obstacle: the tissue of -\-> -->
<!-- <\!-- 	  the central nervous system is solidly packed with interwoven parts -\-> -->
<!-- <\!-- 	  of cells.  Consequently, if you succeed in staining all of them, you -\-> -->
<!-- <\!-- 	  simply can&#39;t see anything. This is not merely a problem of -\-> -->
<!-- <\!-- 	  opacity because, if you put enough light in, some will come out. The -\-> -->
<!-- <\!-- 	  serious problem is scattering. Unless you can confine each view to a -\-> -->
<!-- <\!-- 	  thin enough plane, nothing comes out but a meaningless blur. Too -\-> -->
<!-- <\!-- 	  little signal compared to the noise: the problem kept frustrating -\-> -->
<!-- <\!-- 	  me.  After completing that doctoral thesis, I had the great fortune -\-> -->
<!-- <\!-- 	  to be invited to become a Junior Fellow at Harvard. That three-year -\-> -->
<!-- <\!-- 	  membership in the Harvard Society of Fellows carries unique -\-> -->
<!-- <\!-- 	  privileges; there is no obligation to have students, -\-> -->
<!-- <\!-- 	  responsibilities, or supervisors, and all doors to the university -\-> -->
<!-- <\!-- 	  are opened; one is bound only by a simple oath to seek whatever -\-> -->
<!-- <\!-- 	  seems the truth. This freedom was just what I needed then because I -\-> -->
<!-- <\!-- 	  was making a change in course. With the instruments of the time so -\-> -->
<!-- <\!-- 	  weak, there seemed little chance to understand brains, at least at -\-> -->
<!-- <\!-- 	  the microscopic level. So, during those years I began to imagine -\-> -->
<!-- <\!-- 	  another approach. Perhaps we could work the other way; begin with -\-> -->
<!-- <\!-- 	  the large-scale things minds do and try to break those processes -\-> -->
<!-- <\!-- 	  down into smaller and smaller ingredients. Perhaps such studies -\-> -->
<!-- <\!-- 	  could help us to guess more about the low-level processes that might -\-> -->
<!-- <\!-- 	  be found in brains. Then, perhaps we could combine what we learned -\-> -->
<!-- <\!-- 	  from both <em>top down</em> and -\-> -->
<!-- <\!-- 	  <em>bottom up</em> points of view &mdash; and eventually close in on -\-> -->
<!-- <\!-- 	  the problem from two directions.  In the course of time, that new -\-> -->
<!-- <\!-- 	  top down approach did indeed become productive: it soon assumed the -\-> -->
<!-- <\!-- 	  fanciful name, Artificial Intelligence (AI). But that is a different -\-> -->
<!-- <\!-- 	  story, and the only part that is relevant here was what happened to -\-> -->
<!-- <\!-- 	  me in that interlude. I now felt that while it might take decades to -\-> -->
<!-- <\!-- 	  learn enough more about the brain, AI could be tackled straight away -\-> -->
<!-- <\!-- 	  &mdash; but my ideas about doing this were not yet quite mature -\-> -->
<!-- <\!-- 	  enough. So (it seems to me in retrospect) while those ideas were -\-> -->
<!-- <\!-- 	  incubating I had to keep my hands busy and solving that problem of -\-> -->
<!-- <\!-- 	  scattered light became my conscious obsession. Edward Purcell, a -\-> -->
<!-- <\!-- 	  Senior Fellow of the Society of Fellows, obtained for me a workroom -\-> -->
<!-- <\!-- 	  in the Lyman laboratory of Physics, with a window facing Harvard -\-> -->
<!-- <\!-- 	  Yard and permission to use whatever shops and equipment I might -\-> -->
<!-- <\!-- 	  need. (That room had once been Theodore Lyman&#39;s office. Under an -\-> -->
<!-- <\!-- 	  old sheet of shelf paper I found a bit of diffraction grating that -\-> -->
<!-- <\!-- 	  had likely been ruled, I was awed to think, by the master -\-> -->
<!-- <\!-- 	  spectroscopist himself.) One day it occurred to me that the way to -\-> -->
<!-- <\!-- 	  avoid all that scattered light was to never allow any unnecessary -\-> -->
<!-- <\!-- 	  light to enter in the first place. An ideal microscope would examine -\-> -->
<!-- <\!-- 	  each point of the specimen and measure the amount of light scattered -\-> -->
<!-- <\!-- 	  or absorbed by that point. But if we try to make many such -\-> -->
<!-- <\!-- 	  measurements at the same time then every focal image point will be -\-> -->
<!-- <\!-- 	  clouded by aberrant rays of scattered light deflected by or from -\-> -->
<!-- <\!-- 	  points of the specimen that are not the point you&#39;re looking at. -\-> -->
<!-- <\!-- 	  Most of those extra rays would be gone if we could illuminate only -\-> -->
<!-- <\!-- 	  one specimen point at a time. There is no way to eliminate every -\-> -->
<!-- <\!-- 	  possible such ray, because of multiple scattering, but it is easy to -\-> -->
<!-- <\!-- 	  remove all rays not initially aimed at the focal point; just use a -\-> -->
<!-- <\!-- 	  second microscope (instead of a condenser lens) to image a pinhole -\-> -->
<!-- <\!-- 	  aperture on a single point of the specimen. This reduces the amount -\-> -->
<!-- <\!-- 	  of light in the specimen by orders of magnitude without reducing the -\-> -->
<!-- <\!-- 	  focal brightness at all. Still, some of the initially focused light -\-> -->
<!-- <\!-- 	  will be scattered by out-of-focus specimen points onto other points -\-> -->
<!-- <\!-- 	  in the image plane. But we can reject those rays, as well, by -\-> -->
<!-- <\!-- 	  placing a second pinhole aperture in the image plane that lies -\-> -->
<!-- <\!-- 	  beyond the exit side of the objective lens. We end up with an -\-> -->
<!-- <\!-- 	  elegant, symmetrical geometry: a pinhole and an objective lens on -\-> -->
<!-- <\!-- 	  each side of the specimen. (We could also employ a reflected light -\-> -->
<!-- <\!-- 	  scheme by placing a single lens and pinhole on only one side of the -\-> -->
<!-- <\!-- 	  specimen &mdash; and using a half-silvered mirror to separate the -\-> -->
<!-- <\!-- 	  entering and exiting rays.) This brings an extra premium because the -\-> -->
<!-- <\!-- 	  diffraction patterns of both pinhole apertures are multiplied -\-> -->
<!-- <\!-- 	  coherently: the central peak is sharpened and the resolution is -\-> -->
<!-- <\!-- 	  increased. (One can think of the lenses on both sides of the -\-> -->
<!-- <\!-- 	  microscope combining, in effect, to form a single, larger lens, thus -\-> -->
<!-- <\!-- 	  increasing the difference in light path lengths for point-pairs in -\-> -->
<!-- <\!-- 	  the object plane.)  The price of single-point illumination is being -\-> -->
<!-- <\!-- 	  able to measure only one point at a time. This is why a confocal -\-> -->
<!-- <\!-- 	  microscope must scan the specimen point by point and that can take a -\-> -->
<!-- <\!-- 	  long time because we must add all the time intervals it takes to -\-> -->
<!-- <\!-- 	  collect enough light to measure each image point. That amount of -\-> -->
<!-- <\!-- 	  time could be reduced by using a brighter light &mdash; but there -\-> -->
<!-- <\!-- 	  were no lasers in those days. I began by using a carbon arc, the -\-> -->
<!-- <\!-- 	  brightest source available.  Maintaining this was such a chore that -\-> -->
<!-- <\!-- 	  I had to replace it by a second best source: zirconium arcs, though -\-> -->
<!-- <\!-- 	  less intense, were a great deal more dependable. The output was -\-> -->
<!-- <\!-- 	  measured with a low noise photomultiplier which Francis Pipkin -\-> -->
<!-- <\!-- 	  helped me design. Finally, the image was reconstructed on the screen -\-> -->
<!-- <\!-- 	  of a military surplus long persistence radar scope. The image -\-> -->
<!-- <\!-- 	  remained visible for about ten seconds, which was also how long it -\-> -->
<!-- <\!-- 	  took to make each scan.  The most serious design problem was -\-> -->
<!-- <\!-- 	  choosing between moving the specimen or moving the beam. (So far as -\-> -->
<!-- <\!-- 	  I know, all modern confocal microscopes use moving mirrors or -\-> -->
<!-- <\!-- 	  scanning disks.) At first it seemed more elegant to deflect a -\-> -->
<!-- <\!-- 	  weightless beam of light than to move a massive specimen. But -\-> -->
<!-- <\!-- 	  daunted by the problem of maintaining the three-dimensional -\-> -->
<!-- <\!-- 	  alignment of two tiny moving apertures, I decided that it would be -\-> -->
<!-- <\!-- 	  easier to keep the optics fixed and move the stage. I also was -\-> -->
<!-- <\!-- 	  reluctant to use the single-lens reflected light scheme because of -\-> -->
<!-- <\!-- 	  wanting to <em>see</em> the image right away! (Not only would dark -\-> -->
<!-- <\!-- 	  field be inherently dimmer, but there would also be the fourfold -\-> -->
<!-- <\!-- 	  brightness loss that beam splitters always bring.) A more patient -\-> -->
<!-- <\!-- 	  scientist would have accepted longer exposure times and assembled -\-> -->
<!-- <\!-- 	  the pictures as photographs &mdash; which would have produced -\-> -->
<!-- <\!-- 	  permanent records rather than transient subjective impressions. In -\-> -->
<!-- <\!-- 	  retrospect it occurs to me that this concern for real-time speed may -\-> -->
<!-- <\!-- 	  have been what delayed the use of this scheme for almost thirty -\-> -->
<!-- <\!-- 	  years.  I demonstrated the confocal microscope to many visitors, but -\-> -->
<!-- <\!-- 	  they never seemed very much impressed with what they saw on that -\-> -->
<!-- <\!-- 	  radar screen. Only later did I realize that it is not enough for an -\-> -->
<!-- <\!-- 	  instrument merely to have a high resolving power; one must also make -\-> -->
<!-- <\!-- 	  the image look sharp. Perhaps the human brain requires a certain -\-> -->
<!-- <\!-- 	  degree of foveal compression in order to engage its foremost visual -\-> -->
<!-- <\!-- 	  abilities.  In any case, I should have used film &mdash; or at least -\-> -->
<!-- <\!-- 	  have installed a smaller screen!  Once I decided to move the stage, -\-> -->
<!-- <\!-- 	  this was not hard to accomplish.  The specimen was mounted between -\-> -->
<!-- <\!-- 	  two cover slips and attached to a flexible platform that was -\-> -->
<!-- <\!-- 	  supported by two strips of spring metal. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  A simple magnetic solenoid flexed the platform vertically with a 60 -\-> -->
<!-- <\!-- 	  hertz sinusoidal waveform, while a similar device deflected the -\-> -->
<!-- <\!-- 	  platform horizontally with a much slower, sawtooth waveform.  The -\-> -->
<!-- <\!-- 	  same electric signals (with some blanking and some corrections in -\-> -->
<!-- <\!-- 	  phase) also scanned the image onto the screen. Thus the stage-moving -\-> -->
<!-- <\!-- 	  system was little more complex than an orthogonal pair of tuning -\-> -->
<!-- <\!-- 	  forks. The optical system was not hard to align and proved able to -\-> -->
<!-- <\!-- 	  resolve points closer than a micrometer apart, using 45x objectives -\-> -->
<!-- <\!-- 	  in air. I never got around to using oil immersion for fear that it -\-> -->
<!-- <\!-- 	  would restrict the depth to which different focal planes could be -\-> -->
<!-- <\!-- 	  examined, and because the viscosity might constrain the size of scan -\-> -->
<!-- <\!-- 	  or tear apart the specimen.  There is also a theoretical advantage -\-> -->
<!-- <\!-- 	  to moving the stage rather than the beam: the lenses of such a -\-> -->
<!-- <\!-- 	  system need to be corrected only for the family of rays that -\-> -->
<!-- <\!-- 	  intersect the optical axis at a single focal point. In principle, -\-> -->
<!-- <\!-- 	  that could lead to better lens designs because such systems need no -\-> -->
<!-- <\!-- 	  corrections at all for lateral aberrations. In practice, however, -\-> -->
<!-- <\!-- 	  for visible light, opticians can already make wide field lenses that -\-> -->
<!-- <\!-- 	  approach theoretical perfection. (This was another thing about -\-> -->
<!-- <\!-- 	  optics I had always found astonishing: the mathematical way in which -\-> -->
<!-- <\!-- 	  the radial symmetry of a lens causes odd order terms of series -\-> -->
<!-- <\!-- 	  expansions to cancel out, so that you can obtain sixth order -\-> -->
<!-- <\!-- 	  accuracy by making only two kinds of corrections, of second and -\-> -->
<!-- <\!-- 	  fourth order. It almost seems too good to be true that such simple -\-> -->
<!-- <\!-- 	  combinations of spherical surfaces &mdash; the very shapes that are -\-> -->
<!-- <\!-- 	  the easiest to fabricate &mdash; can transform entire four -\-> -->
<!-- <\!-- 	  dimensional families of rays in such orderly ways.) However, the -\-> -->
<!-- <\!-- 	  advantages of combining stage scanning with paraxial optics could -\-> -->
<!-- <\!-- 	  still turn out to be indispensable, for example, for microscopes in -\-> -->
<!-- <\!-- 	  the X-ray domain for which refractive lenses and half-silvered -\-> -->
<!-- <\!-- 	  mirrors may never turn out to be feasible.  In constructing the -\-> -->
<!-- <\!-- 	  actual prototype, the electronic aspects seemed easy enough because, -\-> -->
<!-- <\!-- 	  a few years earlier, I had already built a learning machine (to -\-> -->
<!-- <\!-- 	  simulate those neuronal nets) &mdash; and that system contained -\-> -->
<!-- <\!-- 	  several hundred vacuum tube circuits. But the world of machining was -\-> -->
<!-- <\!-- 	  new to me. Constructing an optical instrument was to live in a world -\-> -->
<!-- <\!-- 	  where the critical issue of each day was how to clamp some bar of -\-> -->
<!-- <\!-- 	  steel to the baseplate of a milling machine, what sort of cutter and -\-> -->
<!-- <\!-- 	  speed to use, and how to keep the workpiece cool. I became obsessed -\-> -->
<!-- <\!-- 	  with finding ways to reduce the thermal expansion under the wheel of -\-> -->
<!-- <\!-- 	  a grinding machine; no matter how flat a surface seemed, I&#39;d -\-> -->
<!-- <\!-- 	  find new bumps the following day. (Perhaps I was haunted by -\-> -->
<!-- <\!-- 	  Lyman&#39;s ghost.) By the time the prototype was complete, I -\-> -->
<!-- <\!-- 	  understood how the principles of kinematic design made most of that -\-> -->
<!-- <\!-- 	  precision unnecessary. I could have saved months. Still, the machine -\-> -->
<!-- <\!-- 	  shop experience was not wasted. A decade later, it helped me to -\-> -->
<!-- <\!-- 	  build a singularly versatile robotic arm and hand.  Scanning is far -\-> -->
<!-- <\!-- 	  more practical today because we can use computers to transform and -\-> -->
<!-- <\!-- 	  enhance the images. In those days computers were just becoming -\-> -->
<!-- <\!-- 	  available and my friend Russell Kirsch was already doing some of the -\-> -->
<!-- <\!-- 	  first experiments on image analysis. He persuaded me to try some -\-> -->
<!-- <\!-- 	  experiments, using the SEAC computer at the Bureau of -\-> -->
<!-- <\!-- 	  Standards. However, that early machine&#39;s memory was too small -\-> -->
<!-- <\!-- 	  for those images, and we did not yet have adequate devices for -\-> -->
<!-- <\!-- 	  digitizing the signals. In subsequent years, both Kirsch and I -\-> -->
<!-- <\!-- 	  continued to pursue those same ideas &mdash; of closing in on the -\-> -->
<!-- <\!-- 	  vision problem by combining bottom-up concepts of feature extraction -\-> -->
<!-- <\!-- 	  with top-down theories about the syntactic and semantic structures -\-> -->
<!-- <\!-- 	  of images.  Eventually, Kirsch applied those techniques -\-> -->
<!-- <\!-- 	  to <em>parsing</em> pictures of actual cells, while I pursued the -\-> -->
<!-- <\!-- 	  subject of making computers recognize more commonplace sorts of -\-> -->
<!-- <\!-- 	  things. I should mention that I was also working with George Field -\-> -->
<!-- <\!-- 	  (who also helped with the microscope design) on how to use computers -\-> -->
<!-- <\!-- 	  to enhance astronomical images. Such schemes later became practical -\-> -->
<!-- <\!-- 	  but at that time they, too, were defeated by the cost of memory. I -\-> -->
<!-- <\!-- 	  returned to physical optics only once more, in the middle 1960s, in -\-> -->
<!-- <\!-- 	  building computer controlled scanners for our mechanical robotics -\-> -->
<!-- <\!-- 	  project and in studying the feasibility of using somewhat similar -\-> -->
<!-- <\!-- 	  systems in conjunction with radiation therapy.  I also pursued -\-> -->
<!-- <\!-- 	  another dream &mdash; of a microscope, not optical, but entirely -\-> -->
<!-- <\!-- 	  mechanical. Perhaps there were structures that could not be seen -\-> -->
<!-- <\!-- 	  &mdash; because they could not be selectively stained. What, for -\-> -->
<!-- <\!-- 	  example, served to hold the nucleus away from the walls of a cell? -\-> -->
<!-- <\!-- 	  Perhaps there was a scaffolding of invisible fibres that one might -\-> -->
<!-- <\!-- 	  recognize by plucking them &mdash; and then measure the strain, or -\-> -->
<!-- <\!-- 	  see other things move. I examined the various micromanipulators that -\-> -->
<!-- <\!-- 	  already existed but, finding none that seemed suitable, I designed -\-> -->
<!-- <\!-- 	  one which I hoped to use in conjunction with my new -\-> -->
<!-- <\!-- 	  microscope. Again, the Society of Fellows came to my aid, this time -\-> -->
<!-- <\!-- 	  in the person of Carroll Williams, who invited me to build it in his -\-> -->
<!-- <\!-- 	  laboratory. The new micromanipulator was extremely simple: I mounted -\-> -->
<!-- <\!-- 	  the voice coils of three loudspeakers at right angles and connected -\-> -->
<!-- <\!-- 	  them with stiff wires to a diagonally mounted needle probe. The -\-> -->
<!-- <\!-- 	  needle could be moved in any spatial direction, simply by changing -\-> -->
<!-- <\!-- 	  the current in the three coils. The only hard part was replacing the -\-> -->
<!-- <\!-- 	  coil suspensions with materials free from mechanical hysteresis. The -\-> -->
<!-- <\!-- 	  resulting probe could be swiftly moved with precision better than -\-> -->
<!-- <\!-- 	  100 nanometers, over a range of more than a millimeter.  (This -\-> -->
<!-- <\!-- 	  sensitivity was at first limited by power supply noise. This was -\-> -->
<!-- <\!-- 	  solved by using batteries.) To control the probe, my childhood -\-> -->
<!-- <\!-- 	  classmate Edward Feder, who was now also working in Williams&#39; -\-> -->
<!-- <\!-- 	  laboratory, constructed a three-dimensional electrical joystick by -\-> -->
<!-- <\!-- 	  attaching three conductive sheets to the sides of a tank of salt -\-> -->
<!-- <\!-- 	  water.  Everyone seemed to like this instrument, so we left it -\-> -->
<!-- <\!-- 	  around in the laboratory, but it was never actually put to use, and -\-> -->
<!-- <\!-- 	  I have no idea what became of it. I had planned to measure the -\-> -->
<!-- <\!-- 	  infinitesimal forces by applying very high frequency vibrations to a -\-> -->
<!-- <\!-- 	  microelectrode mounted on the probe and correlating the waveforms -\-> -->
<!-- <\!-- 	  against the needle deflections (as observed through the scanning -\-> -->
<!-- <\!-- 	  microscope). I never got around to this because, by 1956, AI was -\-> -->
<!-- <\!-- 	  already on the march. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  This is what I remember now, and it may not all be -\-> -->
<!-- <\!-- 	  accurate. I&#39;ve never had much conscious sense of making careful, -\-> -->
<!-- <\!-- 	  long range plans, but have simply worked from day to day without -\-> -->
<!-- <\!-- 	  keeping notes or schedules, or writing down the things I did. I -\-> -->
<!-- <\!-- 	  never published anything about that earliest learning machine, or -\-> -->
<!-- <\!-- 	  about the micromanipulator, or even about that robot arm. In the -\-> -->
<!-- <\!-- 	  case of the scanning microscope, it was fortunate that my -\-> -->
<!-- <\!-- 	  brother-in-law, Morton Amster, not only liked the instrument but -\-> -->
<!-- <\!-- 	  also happened to be a patent attorney. Otherwise I might have never -\-> -->
<!-- <\!-- 	  documented it at all.  The learning machine and the micromanipulator -\-> -->
<!-- <\!-- 	  disappeared long ago but, only today, while writing this, I managed -\-> -->
<!-- <\!-- 	  to find the microscope, encrusted with thirty years of rust. I -\-> -->
<!-- <\!-- 	  cleaned it up, took this photograph, and started to write an -\-> -->
<!-- <\!-- 	  appropriate caption &mdash; but then found the right thing in a -\-> -->
<!-- <\!-- 	  carbon copy of a letter to Amster dated November 18, 1955. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Chapter from Emotions and Psychopathology, Manfred Clynes and Jack -\-> -->
<!-- <\!-- 	  Panksepp, eds., Plenum Press, N.Y., 1988 -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  EMOTIONS AND THE SOCIETY OF MIND Marvin Minsky, MIT This essay is -\-> -->
<!-- <\!-- 	  mainly based on ideas described in more detail in a book [1] that -\-> -->
<!-- <\!-- 	  was published since the conference. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  What on Earth could emotions be, if they aren&#39;t thoughts and -\-> -->
<!-- <\!-- 	  they aren&#39;t things? What enables a mind to thrill to the sound -\-> -->
<!-- <\!-- 	  of a trumpet or be jealous of a rival? And what makes such matters -\-> -->
<!-- <\!-- 	  so hard to understand? Certain problems are hard to solve because -\-> -->
<!-- <\!-- 	  they are genuinely intricate but, sometimes, when a subject seems -\-> -->
<!-- <\!-- 	  intractably mysterious, the difficulty stems instead from flaws in -\-> -->
<!-- <\!-- 	  our own attitudes. The problem itself might not be so hard, but if -\-> -->
<!-- <\!-- 	  the way we&#39;ve framed it is wrong, then may find clues by -\-> -->
<!-- <\!-- 	  studying the character of our own confusion. Emotions seem -\-> -->
<!-- <\!-- 	  mysterious for both kinds of reasons. There can be no doubt that -\-> -->
<!-- <\!-- 	  emotions come from truly intricate machinery. But we then proceed to -\-> -->
<!-- <\!-- 	  make matters worse because our own emotions interfere with how we -\-> -->
<!-- <\!-- 	  think about them. For any problem so complex, we must do what -\-> -->
<!-- <\!-- 	  science always does: propose a model with simple parts &mdash; -\-> -->
<!-- <\!-- 	  setting aside, at least at first, all but their most essential -\-> -->
<!-- <\!-- 	  details. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Mini-Theory 1. The brain consists of several nearly separate -\-> -->
<!-- <\!-- 	  thinking machines; we&#39;ll call them <em>protospecialists.</em> -\-> -->
<!-- <\!-- 	  Usually, in infancy, only one of them is active at a time, while the -\-> -->
<!-- <\!-- 	  others tend to be suppressed.  Each protospecialist is a highly -\-> -->
<!-- <\!-- 	  evolved goal-mechanism concerned with some important need such as -\-> -->
<!-- <\!-- 	  nutrition, reproduction, or defense. The psychological conditions -\-> -->
<!-- <\!-- 	  that correspond to those activities are what we recognize as -\-> -->
<!-- <\!-- 	  emotions such as hunger, affection and attachment, or anger and -\-> -->
<!-- <\!-- 	  fear, and so forth. Each of our most basic emotions involves the -\-> -->
<!-- <\!-- 	  activity of a distinct division of the brain, as suggested in -\-> -->
<!-- <\!-- 	  section 16.3 of [1]. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Each emotion thus imposes a different personality on the mind as a -\-> -->
<!-- <\!-- 	  whole. Once we understand this, it is easier to see why it is so -\-> -->
<!-- <\!-- 	  difficult to think clearly about our emotions. For if each emotion -\-> -->
<!-- <\!-- 	  is virtually a separate mind, and if none of those protospecialists -\-> -->
<!-- <\!-- 	  knows much about the other ones, then, naturally, emotions will seem -\-> -->
<!-- <\!-- 	  mysterious. <em>Mysterious to whom?</em> one is tempted to ask -\-> -->
<!-- <\!-- 	  &mdash; and then we fall into a fatal trap: the Fallacy of the -\-> -->
<!-- <\!-- 	  Single Self.  For, as adults, we feel compelled to think that -\-> -->
<!-- <\!-- 	  somewhere, deep down in the mind, exists some central entity that -\-> -->
<!-- <\!-- 	  experiences all of our feelings and thoughts. But nothing of that -\-> -->
<!-- <\!-- 	  sort exists. As infants, our minds have separate parts; then they -\-> -->
<!-- <\!-- 	  develop closer ties; but never are all those different thoughts all -\-> -->
<!-- <\!-- 	  shared by any particular part of the mind. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Some readers may be horrified at picturing a baby&#39;s mind as made -\-> -->
<!-- <\!-- 	  of nearly-separate agencies. But we&#39;ll never understand how -\-> -->
<!-- <\!-- 	  emotions grow, without some theories of how they start. One evidence -\-> -->
<!-- <\!-- 	  for separateness is the suddenness with which our infants switch -\-> -->
<!-- <\!-- 	  from contentment or calmness to anger or rage. Older children show -\-> -->
<!-- <\!-- 	  less sudden and drastic changes in mood, and their expressions -\-> -->
<!-- <\!-- 	  suggest more complex mixtures of emotions and dispositions. This -\-> -->
<!-- <\!-- 	  suggests that we begin composed of almost -\-> -->
<!-- <\!-- 	  separate <em>protospecialists</em> that each accumulate their -\-> -->
<!-- <\!-- 	  private memories. Then, through the course of infancy and childhood, -\-> -->
<!-- <\!-- 	  these fragments of the mind learn various ways to exploit the -\-> -->
<!-- <\!-- 	  others. But because they each evolved to use rather different -\-> -->
<!-- <\!-- 	  processes for different kinds of purposes, they are each endowed -\-> -->
<!-- <\!-- 	  with somewhat different ways to represent the knowledge that they -\-> -->
<!-- <\!-- 	  acquire. In section 6.12 of [1] we explain why makes it hard for -\-> -->
<!-- <\!-- 	  there ever to be good communication among the different -\-> -->
<!-- <\!-- 	  protospecialists. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Mini-theory 2. As the child grows, each primitive protospecialist -\-> -->
<!-- <\!-- 	  grows level after level of new memory and management machinery.  One -\-> -->
<!-- <\!-- 	  result of this process is to make those specialists become less -\-> -->
<!-- <\!-- 	  separated. This is because those newer levels tend to be shared. But -\-> -->
<!-- <\!-- 	  those primitive perspectives still remain in place below the -\-> -->
<!-- <\!-- 	  managers of the adult mind, and are used for many purposes &mdash; -\-> -->
<!-- <\!-- 	  and each division of the mind has its own particular view of what -\-> -->
<!-- <\!-- 	  the other divisions do. Now, whenever we experience a substantial -\-> -->
<!-- <\!-- 	  change in emotional state, this involves a substantial transfer of -\-> -->
<!-- <\!-- 	  control from one division to another. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Naturally, that will alter what we think and, in particular, it will -\-> -->
<!-- <\!-- 	  alter what we think about what emotions are and what they do. So -\-> -->
<!-- <\!-- 	  naturally, emotions seem mysterious. As scientists, we can set -\-> -->
<!-- <\!-- 	  ourselves to work toward constructing a unified view of what -\-> -->
<!-- <\!-- 	  emotions are and do.  However, in our daily lives, there are reasons -\-> -->
<!-- <\!-- 	  why this is not feasible.  Section 29.6 of SOM conjectures that a -\-> -->
<!-- <\!-- 	  child who tried too hard to maintain too unified a view might risk -\-> -->
<!-- <\!-- 	  the loss of ability to distinguish between physical and -\-> -->
<!-- <\!-- 	  psychological phenomena &mdash; and that could result in autism. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  The remainder of this article consists of several disconnected -\-> -->
<!-- <\!-- 	  vignettes, each illustrating how the Society of Mind viewpoint might -\-> -->
<!-- <\!-- 	  illuminate an emotional phenomenon. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Pleasure, Pain, and Plan What is pain, and why does it make us hurt? -\-> -->
<!-- <\!-- 	  What is pleasure, and why do we like it? The trouble with such -\-> -->
<!-- <\!-- 	  questions is that they are formulated in terms of a single self that -\-> -->
<!-- <\!-- 	  feels pain and dislikes it.  However, words such as hurt and like do -\-> -->
<!-- <\!-- 	  not refer to simple, elemental entities. I suspect,indeed, -\-> -->
<!-- <\!-- 	  that <em>pain</em> is used to describe a large variety of different -\-> -->
<!-- <\!-- 	  processes involved with lowering the level-bands of our momentary -\-> -->
<!-- <\!-- 	  goals. (Chapter 8 of [1] has more details on what I mean by -\-> -->
<!-- <\!-- 	  level-band.) Because of this, when you&#39;re in pain, it&#39;s hard -\-> -->
<!-- <\!-- 	  to maintain your interest in higher level goals &mdash; and that is -\-> -->
<!-- <\!-- 	  why pain makes you feel that there&#39;s nothing more important than -\-> -->
<!-- <\!-- 	  to find some way to stop the pain. That&#39;s why pain makes it so -\-> -->
<!-- <\!-- 	  hard to think of anything else.  Pain&#39;s power to distract -\-> -->
<!-- <\!-- 	  evolved because our bodies are endowed with special sensors that -\-> -->
<!-- <\!-- 	  detect impending injuries &mdash; and because those signals are -\-> -->
<!-- <\!-- 	  wired up to disrupt our concerns with long-term goals. This enables -\-> -->
<!-- <\!-- 	  our lowest-level agencies to concentrate on immediate, urgent -\-> -->
<!-- <\!-- 	  problems. This usually helps one to survive &mdash; but it certainly -\-> -->
<!-- <\!-- 	  can do more harm than good when one actually needs more complex -\-> -->
<!-- <\!-- 	  plans for removing what&#39;s causing the pain. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  When something causes pleasure, too, it&#39;s hard to think of other -\-> -->
<!-- <\!-- 	  things. You feel that nothing&#39;s more important than to find a -\-> -->
<!-- <\!-- 	  way to make that pleasure last. Thus pleasure and pain tend to seem -\-> -->
<!-- <\!-- 	  opposed, since pleasure makes us draw things near while pain impels -\-> -->
<!-- <\!-- 	  us to push things away. But they also tend to seem similar, in that -\-> -->
<!-- <\!-- 	  they both tend to simplify one&#39;s view &mdash; by making rival -\-> -->
<!-- <\!-- 	  goals seem small and turning us from other interests. However, they -\-> -->
<!-- <\!-- 	  do this in different ways: pleasure, in its simplest forms, involves -\-> -->
<!-- <\!-- 	  a vertical sort of narrowing of interest at every level, whereas -\-> -->
<!-- <\!-- 	  pain involves a horizontal sort of narrowing that focuses concern on -\-> -->
<!-- <\!-- 	  the lowest levels. Pleasure and pain are also involved in how we -\-> -->
<!-- <\!-- 	  learn but, again, although in some respects they seem simply -\-> -->
<!-- <\!-- 	  opposed, they also engage fundamentally different types of -\-> -->
<!-- <\!-- 	  processes. For example, pain and punishment do not merely cancel -\-> -->
<!-- <\!-- 	  learning or induce forgetfulness but are involved in the -\-> -->
<!-- <\!-- 	  construction of systems for active suppression and censorship. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Which comes first: the emotion or the accompanying change in level -\-> -->
<!-- <\!-- 	  of activity? This is a wrong kind of question because we can -\-> -->
<!-- <\!-- 	  understand the particular characteristics of each emotion only by -\-> -->
<!-- <\!-- 	  understand the processes that constitute it &mdash; that is, through -\-> -->
<!-- <\!-- 	  constructing a cognitive theory of why each emotional configuration -\-> -->
<!-- <\!-- 	  produces its own peculiar effects. The simplest stimuli that we -\-> -->
<!-- <\!-- 	  recognize as physically painful are based upon inborn mechanisms -\-> -->
<!-- <\!-- 	  like those that, in simpler animals, result in withdrawal from -\-> -->
<!-- <\!-- 	  sources of irritation. When we see that happen in, say, a worm or a -\-> -->
<!-- <\!-- 	  crab, we tend to assume that the crab experiences the same feeling -\-> -->
<!-- <\!-- 	  that a person would. But such a sympathetic inference would be based -\-> -->
<!-- <\!-- 	  on a superficial resemblance because withdrawing a claw, in the case -\-> -->
<!-- <\!-- 	  of the crab, involves mechanisms that are similar only at the very -\-> -->
<!-- <\!-- 	  lowest level. It might make sense to say that crabs react to pain, -\-> -->
<!-- <\!-- 	  but to claim that pain hurts crabs the way it hurts us merely -\-> -->
<!-- <\!-- 	  because of that particular resemblance &mdash; might make no more -\-> -->
<!-- <\!-- 	  sense than to say that heat must hurt a thermostat. It is more -\-> -->
<!-- <\!-- 	  complicated than that. Even animals with brains much simpler than -\-> -->
<!-- <\!-- 	  ours appear to have evolved pain mechanisms with priorities &mdash; -\-> -->
<!-- <\!-- 	  or intensities &mdash; powerful enough to disrupt most of their -\-> -->
<!-- <\!-- 	  other activities And the way in which pain makes people hurt is even -\-> -->
<!-- <\!-- 	  more complicated than that because, when pain threatens to distract -\-> -->
<!-- <\!-- 	  other parts of the mind, by altering their higher levels of -\-> -->
<!-- <\!-- 	  activity, each of many agencies must anticipate the postponement of -\-> -->
<!-- <\!-- 	  most of their goals and long range plans. This initiates many other -\-> -->
<!-- <\!-- 	  kinds of activities that we tend to describe in negative terms such -\-> -->
<!-- <\!-- 	  as frustration, impotence, distraction, apprehension, and loss of -\-> -->
<!-- <\!-- 	  goal. The reason pain hurts us the ways it does is that we have such -\-> -->
<!-- <\!-- 	  complex systems to disrupt. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Reason, Fantasy, and Exploitation The growth of every individual -\-> -->
<!-- <\!-- 	  involves constructing agencies with different goals and -\-> -->
<!-- <\!-- 	  processes. As time goes on each agency learns various ways to -\-> -->
<!-- <\!-- 	  control and exploit some of the others. It is the resulting complex -\-> -->
<!-- <\!-- 	  of relationships that becomes the personality. In [1] I used the -\-> -->
<!-- <\!-- 	  following anecdote to illustrate how agencies can interact. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  I was trying to concentrate on a certain mathematical problem, but -\-> -->
<!-- <\!-- 	  was getting bored and sleepy. Then I imagined that my competitors, -\-> -->
<!-- <\!-- 	  Professor Challenger, was about to solve the same problem. An angry -\-> -->
<!-- <\!-- 	  wish to frustrate Challenger then kept me working for a while -\-> -->
<!-- <\!-- 	  longer. The strange thing was that this problem was not the kind -\-> -->
<!-- <\!-- 	  that interested Challenger. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  A psychoanalyst might suggest that the conflict with Challenger -\-> -->
<!-- <\!-- 	  represents some underlying drive or wish that serves as a source of -\-> -->
<!-- <\!-- 	  energy. No matter that this conflict is a fantasy; it might only -\-> -->
<!-- <\!-- 	  disguise some other, sublimated urge that momentarily penetrates a -\-> -->
<!-- <\!-- 	  transiently weakened barrier. But I prefer a more pragmatic -\-> -->
<!-- <\!-- 	  interpretation: the fantasy represents a simpler, practical strategy -\-> -->
<!-- <\!-- 	  in which my agency for Work exploits the ability of Anger to inhibit -\-> -->
<!-- <\!-- 	  Sleep.  Why use a scheme so devious as to invent an outright lie? -\-> -->
<!-- <\!-- 	  Why can&#39;t we simply tell ourselves to do the things we want to -\-> -->
<!-- <\!-- 	  do? Why cannot Work directly turn off Sleep? To see the answer, -\-> -->
<!-- <\!-- 	  consider the alternatives. If Work could simply turn off Sleep, -\-> -->
<!-- <\!-- 	  we&#39;d quickly wear our bodies out. If Work could directly switch -\-> -->
<!-- <\!-- 	  Anger on, we&#39;d all be fighting all the time. Directness is too -\-> -->
<!-- <\!-- 	  dangerous; we&#39;d die if we could suppress all the vital systems -\-> -->
<!-- <\!-- 	  involved with hunger and fatigue.  Instead, our brains have evolved -\-> -->
<!-- <\!-- 	  systems of checks and balances that prevent any single agency from -\-> -->
<!-- <\!-- 	  controlling the others. Direct connections have been weeded -\-> -->
<!-- <\!-- 	  out. Consequently, in order for our agencies to exploit one -\-> -->
<!-- <\!-- 	  another&#39;s skills, they must discover and use indirect -\-> -->
<!-- <\!-- 	  pathways. Our fantasies provide those missing paths. You cannot make -\-> -->
<!-- <\!-- 	  yourself angry simply by deciding to be angry, but it remains -\-> -->
<!-- <\!-- 	  possible for you to learn to imagine things or situations to make -\-> -->
<!-- <\!-- 	  yourself angry. -\-> -->
	  
<!-- <\!-- 	  This is one reason why emotion and reason are so intertwined. Logic -\-> -->
<!-- <\!-- 	  alone is incomplete. It can help us decide when our deductions are -\-> -->
<!-- <\!-- 	  properly based on our assumptions, but we cannot employ it to decide -\-> -->
<!-- <\!-- 	  which directions of thought to pursue. The Challenger scenario shows -\-> -->
<!-- <\!-- 	  how indistinct is that boundary between reason and emotion. We -\-> -->
<!-- <\!-- 	  usually think of anger as irrational. But here, if we take -\-> -->
<!-- <\!-- 	  Work&#39;s point of view, it seems just as rational to use Anger to -\-> -->
<!-- <\!-- 	  inhibit Sleep as to use a stick to move something out of -\-> -->
<!-- <\!-- 	  reach. Anger is merely a tool Work can use to solve one of its -\-> -->
<!-- <\!-- 	  problems. No matter that such states of mind may be what people call -\-> -->
<!-- <\!-- 	  emotional; to Work the use of fantasy is merely a way to accomplish -\-> -->
<!-- <\!-- 	  a goal. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Disappointment, Fear, and Shame; Attachment, Love, and Reverence Our -\-> -->
<!-- <\!-- 	  most powerful emotions involve the bonds that link parent and -\-> -->
<!-- <\!-- 	  child. We tend to regard as positive what we call love, affection, -\-> -->
<!-- <\!-- 	  and reverence. We tend to regard as negative the emotions we call -\-> -->
<!-- <\!-- 	  embarrassment, shame, and guilt. What functions do those emotions -\-> -->
<!-- <\!-- 	  serve?  The obvious roles of attachment are in the areas of -\-> -->
<!-- <\!-- 	  nutrition and defense because they favor the evolution of mechanisms -\-> -->
<!-- <\!-- 	  that keep infant animals close to their parents. But attachment also -\-> -->
<!-- <\!-- 	  serves learning and education. Imagine a child playing with mud, -\-> -->
<!-- <\!-- 	  perhaps with the goal of filling a pail, and consider how -\-> -->
<!-- <\!-- 	  disappointment, fear, and shame affect how and what that child -\-> -->
<!-- <\!-- 	  learns. I submit that each of those emotions may play fundamentally -\-> -->
<!-- <\!-- 	  different roles. -\-> -->
	  
<!-- <\!-- 	  DISAPPOINTMENT: What would happen if a certain strategy fails to get -\-> -->
<!-- <\!-- 	  mud into the pail. The child will be disappointed &mdash; and -\-> -->
<!-- <\!-- 	  probably try a different technique. Usually, the emotion of -\-> -->
<!-- <\!-- 	  disappointment will lead to a change in technique: a certain -\-> -->
<!-- <\!-- 	  strategy failed for a goal, so try a different strategy. In the case -\-> -->
<!-- <\!-- 	  of a simple failure, the learner maintains the current goal but -\-> -->
<!-- <\!-- 	  makes a change on the level below by adopting a different sub-goal. -\-> -->
	  
<!-- <\!-- 	  FEAR: What would happen if a stranger appeared and started to scold -\-> -->
<!-- <\!-- 	  and criticize. The child would be likely to experience fear, and try -\-> -->
<!-- <\!-- 	  to escape, to seek a parent&#39;s protection. The apprehension of -\-> -->
<!-- <\!-- 	  possible harm will not much affect the current goal, although our -\-> -->
<!-- <\!-- 	  child may subsequently somewhat less inclined to play with mud. -\-> -->
<!-- <\!-- 	  Fear-provoking disturbances affect how we learn to classify -\-> -->
<!-- <\!-- 	  situations, but have less effect on how we choose goals. -\-> -->
	  
<!-- <\!-- 	  SHAME: What if it were a parent who proceeded to censure and -\-> -->
<!-- <\!-- 	  complain? That would have a very different effect on the child: it -\-> -->
<!-- <\!-- 	  would produce, not fear, but shame &mdash; an emotion that usually -\-> -->
<!-- <\!-- 	  involves a person to whom one is attached. Shame tends to cause the -\-> -->
<!-- <\!-- 	  child to learn, <em>I ought not want that sort of goal.</em> -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Thus attachment has a profound effect. Simple failure and success -\-> -->
<!-- <\!-- 	  merely affect how we learn subgoals &mdash; that is, how we learn -\-> -->
<!-- <\!-- 	  which means to adopt for achieving goals we already want. But -\-> -->
<!-- <\!-- 	  attachment affects the goals themselves, by making us change in -\-> -->
<!-- <\!-- 	  various ways how we select which goals to pursue. Shame results in -\-> -->
<!-- <\!-- 	  repression of goals, whereas reverence promotes them. What could be -\-> -->
<!-- <\!-- 	  the mechanical cause of such an important phenomenon? Section 17.2 -\-> -->
<!-- <\!-- 	  of [1] proposes a theory of how this might work: the detectors which -\-> -->
<!-- <\!-- 	  recognize the presence of an attachment-person are directly -\-> -->
<!-- <\!-- 	  connected so as to raise the locus of the effects of reinforcement -\-> -->
<!-- <\!-- 	  signals. Then, where success and failure signals ordinarily affect -\-> -->
<!-- <\!-- 	  the learning of <em>means,</em> they now apply to the learning of -\-> -->
<!-- <\!-- 	  ends, simply by switching their effects them from the level of -\-> -->
<!-- <\!-- 	  sub-goal to that of supergoal. This conception of the effect of -\-> -->
<!-- <\!-- 	  attachment suggest a mechanistic embodiment of Freud&#39;s idea that -\-> -->
<!-- <\!-- 	  child can <em>introject</em> the values of their parents. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Sympathy, Gesture, and Trajectory How do we construct attachment -\-> -->
<!-- <\!-- 	  bonds? In some species of animals, it occurs so rapidly that -\-> -->
<!-- <\!-- 	  scientists call it <em>imprinting.</em> In human infants the -\-> -->
<!-- <\!-- 	  development of attachment appears to be a complex, many stage -\-> -->
<!-- <\!-- 	  process in which various inborn systems learn to distinguish the -\-> -->
<!-- <\!-- 	  parents&#39; individual peculiarities &mdash; first by senses of -\-> -->
<!-- <\!-- 	  touch, taste and smell, and then by Voice and sight of face. But -\-> -->
<!-- <\!-- 	  attachment is more than simply to distinguishing parents from other -\-> -->
<!-- <\!-- 	  things; once those attachment bonds are formed, the child will react -\-> -->
<!-- <\!-- 	  in different ways to the presence of strangers and parents. As we -\-> -->
<!-- <\!-- 	  saw just above, these have different effects on how and what the -\-> -->
<!-- <\!-- 	  child will learn. Furthermore, the effect of attachment depends not -\-> -->
<!-- <\!-- 	  only on the presence of the parent, but on which -\-> -->
<!-- <\!-- 	  particular <em>expression</em> the parent presents. Smiles and -\-> -->
<!-- <\!-- 	  caresses have what we call positive effects, while frowns and scowls -\-> -->
<!-- <\!-- 	  have negative effects. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  To help their offspring grow and learn, social animals evolve -\-> -->
<!-- <\!-- 	  complementary schemes: attachment is a two-way street. Babies are -\-> -->
<!-- <\!-- 	  born equipped with shrieks that arouse their parents far away or -\-> -->
<!-- <\!-- 	  fast asleep. Adults, on the other side, are made to find those -\-> -->
<!-- <\!-- 	  signals irresistible. What special systems in our brains assign to -\-> -->
<!-- <\!-- 	  those cries such high priorities? I conjecture an evolutionary trick -\-> -->
<!-- <\!-- 	  in which our adult cry-detectors are connected to the remnants of -\-> -->
<!-- <\!-- 	  the very same protospecialists that caused us to make those same -\-> -->
<!-- <\!-- 	  types of cries when we were infants. The result would be to make us -\-> -->
<!-- <\!-- 	  respond to those sounds by attributing to them the same sorts of -\-> -->
<!-- <\!-- 	  feelings that would drive us to shriek with similar intensity. This -\-> -->
<!-- <\!-- 	  drives the baby&#39;s caretakers to respond to its needs with urgent -\-> -->
<!-- <\!-- 	  sympathy. To fill this out in more detail we first would have to -\-> -->
<!-- <\!-- 	  understand how our brains distinguish the external signs of -\-> -->
<!-- <\!-- 	  different emotional states. Then we would need a theory of how the -\-> -->
<!-- <\!-- 	  output of each detector is connected to the correct brain center -\-> -->
<!-- <\!-- 	  &mdash; namely, one that can reproduce the appropriately sympathetic -\-> -->
<!-- <\!-- 	  effect. How does a child learn to recognize another person&#39;s -\-> -->
<!-- <\!-- 	  mental state of being angry or affectionate. -\-> -->

<!-- <\!-- 	<p> -\-> -->
<!-- <\!-- 	  Consider the hypothesis that this is largely based on how we -\-> -->
<!-- <\!-- 	  recognize and classify trajectories. Just as we learn to interpret -\-> -->
<!-- <\!-- 	  spatial change as motions of things in the physical realm, we also -\-> -->
<!-- <\!-- 	  learn to classify certain other types of changes as signifying -\-> -->
<!-- <\!-- 	  mental events: namely, as what we call <em>gestures</em> -\-> -->
<!-- <\!-- 	  and <em>expressions.</em> For example, consider speech. Some of the -\-> -->
<!-- <\!-- 	  meaning comes just from the words.  But we also find significance in -\-> -->
<!-- <\!-- 	  the shape of a sequence of vocal sounds. Each envelope of tone and -\-> -->
<!-- <\!-- 	  phrase leads us to interpret each utterance as having emotional -\-> -->
<!-- <\!-- 	  character. Now, certain features of vocal sounds seem almost -\-> -->
<!-- <\!-- 	  universally to signify specific emotional qualities. For example, -\-> -->
<!-- <\!-- 	  the more abrupt trajectories seem angry or imperative. Perhaps they -\-> -->
<!-- <\!-- 	  tend to evoke alarm by inducing the kind of narrowing of interest -\-> -->
<!-- <\!-- 	  that accompanies pain; usually, a sudden change demands our full -\-> -->
<!-- <\!-- 	  attention. In contrast, we react to <em>gentle</em> sounds in ways -\-> -->
<!-- <\!-- 	  we label more positive</em> because of how those smoother -\-> -->
<!-- <\!--       time-trajectories arouse affection, love, or reverence.  Manfred -\-> -->
<!-- <\!--       Clynes&#39;s experiments [2] certainly appear to show that people -\-> -->
<!-- <\!--       react in similar ways to certain types of trajectories, no matter in -\-> -->
<!-- <\!--       which sensory domain they may happen to occur. For example, we -\-> -->
<!-- <\!--       consistently identify certain rapid, jerky gestures as angry &mdash; -\-> -->
<!-- <\!--       regardless of whether they are expressed in the form of visible -\-> -->
<!-- <\!--       thrusts, abrupt sounds, or tactile jabs. The same seems equally -\-> -->
<!-- <\!--       clear in the case of gestures that we recognize as gentle or -\-> -->
<!-- <\!--       affectionate.  Clynes concludes that at least half a dozen distinct -\-> -->
<!-- <\!--       trajectory-types are universally associated with particular -\-> -->
<!-- <\!--       emotions.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       What kind of brain-machinery could make us respond in such similar ways -\-> -->
<!-- <\!--       to similar trajectories in such diverse domains? I propose a three-part -\-> -->
<!-- <\!--       hypothesis. First, each of our sensory systems is genetically equipped -\-> -->
<!-- <\!--       with agents that detect certain particular types of -\-> -->
<!-- <\!--       time-trajectories. Second, the outputs of all the agents that detect -\-> -->
<!-- <\!--       corresponding <em>trajectory-types</em> &mdash; in all those sensory -\-> -->
<!-- <\!--       domains &mdash; are wired up to converge upon a corresponding central -\-> -->
<!-- <\!--       <em>gesture-recognizing</em> agency.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       According to this hypothesis, each sensory agency contains agents -\-> -->
<!-- <\!--       specialized to react to various particular expressions &mdash; that is, -\-> -->
<!-- <\!--       trajectory-types. One type of agent might react only to signals that -\-> -->
<!-- <\!--       increase slowly and then decrease quickly; another might react only to -\-> -->
<!-- <\!--       signals that increase quickly and decay slowly, and so on. The important -\-> -->
<!-- <\!--       thing is for the detection of each type of trajectory is transmitted to -\-> -->
<!-- <\!--       the same central place, no matter where it was detected. This will make -\-> -->
<!-- <\!--       it easy for that central agency to learn to react in similar ways to a -\-> -->
<!-- <\!--       snarl, grimace, or shaken fist&mdash; and thus to construct -\-> -->
<!-- <\!--       an <em>anger-recognizing</em> agent whose function is abstract &mdash; -\-> -->
<!-- <\!--       in the sense of being detached from any particular sensory mode.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       We need a third hypothesis to account for that sense -\-> -->
<!-- <\!--       of <em>sympathy.</em>  Merely to distinguish a particular gesture-type -\-> -->
<!-- <\!--       does not, by itself, enable us to identify another -\-> -->
<!-- <\!--       person&#39;s <em>anger-type</em> trajectory with our own personal -\-> -->
<!-- <\!--       experience of being angry. Simply recognizing anger is not the same as -\-> -->
<!-- <\!--       comprehending or sympathizing with it. So our diagram also suggests how -\-> -->
<!-- <\!--       certain genetically established nerve bundles might connect each central -\-> -->
<!-- <\!--       gesture-recognizing agency to a particular <em>protospecialist</em> of -\-> -->
<!-- <\!--       the sort we described above. (For more detail, see the Appendix of [1].) -\-> -->
<!-- <\!--       These cause each particular gesture-type to activate a corresponding -\-> -->
<!-- <\!--       protospecialist &mdash; and, hence, a particular kind of emotional -\-> -->
<!-- <\!--       response. A direct connection of this sort cause us to experience -\-> -->
<!-- <\!--       elation in response to another person&#39;s joyous gesture. (We would -\-> -->
<!-- <\!--       also need a theory of how arousing a particular protospecialist &mdash; -\-> -->
<!-- <\!--       that is, of a particular primitive emotion &mdash; might produce a -\-> -->
<!-- <\!--       particular type of trajectory.) A -\-> -->
<!-- <\!--       <em>cross-wired</em> connection of this sort could make us tend to -\-> -->
<!-- <\!--       retreat from threatening gestures, or to attack in response to signs of -\-> -->
<!-- <\!--       fear.  The behavior of animals reflects genetically constructed -\-> -->
<!-- <\!--       machinery through which particular gesture-types -\-> -->
<!-- <\!--       evoke <em>instinctive</em> reactions, as when a sudden motion toward a -\-> -->
<!-- <\!--       bird provokes a fear-reaction flight. Human brains are also endowed with -\-> -->
<!-- <\!--       much instinctive wiring.  But more than any other animal, we also have -\-> -->
<!-- <\!--       machinery that can learn to bridge across those built-in links, to bury -\-> -->
<!-- <\!--       ancient instincts under modern social disciplines.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Emotion and Thought I&#39;ve often heard the view expressed that it must -\-> -->
<!-- <\!--       be easy to build machines that do our ordinary sorts of reasoning, -\-> -->
<!-- <\!--       whereas it would be impossible to build machines that experience pain, -\-> -->
<!-- <\!--       or affection, ambition, fear, or shame. Such subjects are often -\-> -->
<!-- <\!--       considered beyond what science can ever hope to explain because emotions -\-> -->
<!-- <\!--       are nonphysical. Yet when we examine this common belief, that thinking -\-> -->
<!-- <\!--       is easier to explain than emotion, we find that this has things -\-> -->
<!-- <\!--       reversed. For when we get right down to it, it is very hard to make -\-> -->
<!-- <\!--       machines that reason well. I think the distortion comes form a tradition -\-> -->
<!-- <\!--       that informs us that reasoning involves little more than logical -\-> -->
<!-- <\!--       principles. However, experience with research on Artificial Intelligence -\-> -->
<!-- <\!--       seems to show that this is far from true. It has turned out very -\-> -->
<!-- <\!--       difficult to express the seemingly simplest forms of commonsense -\-> -->
<!-- <\!--       knowledge in logical form. furthermore, this is only a small part of the -\-> -->
<!-- <\!--       problem because logic can tell us only which inferences are correct, but -\-> -->
<!-- <\!--       says nothing at all about what inferences to make, which goals how to -\-> -->
<!-- <\!--       select, or how to avoid meandering into endless amounts of futile, -\-> -->
<!-- <\!--       useless reasoning.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       On the other side, the rules of emotion are rather more easy to see and -\-> -->
<!-- <\!--       describe; we all know well how, usually, threats evoke fear, -\-> -->
<!-- <\!--       frustrations evokes aggression, competition (in love) leads to jealousy, -\-> -->
<!-- <\!--       and disapproval (in the context of attachment) leads to shame. To be -\-> -->
<!-- <\!--       sure, such regularities apply only to primitive states and, as we grow -\-> -->
<!-- <\!--       and develop and learn, the interactions among such mental states can -\-> -->
<!-- <\!--       become arbitrarily subtle and complex. But it is important to recognize -\-> -->
<!-- <\!--       that this, in itself, is not peculiar to emotion in particular; the -\-> -->
<!-- <\!--       complexity of our reasoning, too, can grow beyond bounds in complexity.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Our traditional concepts of psychology are too confused to help us -\-> -->
<!-- <\!--       understand how emotions work. We have all been told that emotions are -\-> -->
<!-- <\!--       separate from reason. We also learn that machines are inherently -\-> -->
<!-- <\!--       reasonable and cannot have emotions. Consequently, we are forced to -\-> -->
<!-- <\!--       believe, there can never be a mechanistic explanation of emotion.  What -\-> -->
<!-- <\!--       makes our task so difficult is that the same tradition also assumes that -\-> -->
<!-- <\!--       inside the mind is something else: a separate Self inside the self that -\-> -->
<!-- <\!--       thinks and feels what we feel and think. The actual problem is hard -\-> -->
<!-- <\!--       enough: to understand a complex brain composed of thousands of -\-> -->
<!-- <\!--       agencies. That myth of the single, central Self starts us out in the -\-> -->
<!-- <\!--       wrong direction.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       [1] Marvin Minsky, The Society of Mind, Simon and Schuster, 1987; -\-> -->
<!-- <\!--       Heinemann & Co., 1987.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       [2] Manfred Clynes, Sentics, Doubleday, New York, 1978.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Edited transcript of an impromptu lecture held at the Ars Electronica, -\-> -->
<!-- <\!--       on September 9, 1990, in Linz, Austria. Applied Artificial Intelligence: -\-> -->
<!-- <\!--       7:87-108,1993 Copyright @ 1993 by Taylor & Francis -\-> -->
      
<!-- <\!--       THE FUTURE MERGING OF SCIENCE, ART, AND TECHNOLOGY Marvin Minsky -\-> -->
<!-- <\!--       Artificial Intelligence Laboratory and Media Laboratory, MIT -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       It&#39;s a pleasure to be here in Austria, in the last century of -\-> -->
<!-- <\!--       needing physically to go to meetings.  We have gathered here to talk -\-> -->
<!-- <\!--       about new developments that are going to influence the future of art, of -\-> -->
<!-- <\!--       education, and of human communication. And much, much more &mdash; even -\-> -->
<!-- <\!--       the future of human thought itself. For we are moving toward new kinds -\-> -->
<!-- <\!--       of expression.  The new technologies that will do this for us are called -\-> -->
<!-- <\!--       artificial intelligence (AI) and virtual reality (VR).  These changes -\-> -->
<!-- <\!--       began about a century ago, with the introduction of animated cinema. We -\-> -->
<!-- <\!--       can regard animation as evolving from the graphic arts, which people had -\-> -->
<!-- <\!--       been practicing for a long time, perhaps for tens of thousands of -\-> -->
<!-- <\!--       years. And over all those centuries, one might argue that, in important -\-> -->
<!-- <\!--       ways, there was really rather little change. Some of the earliest -\-> -->
<!-- <\!--       graphics we know, those beautiful animals in those cave paintings, would -\-> -->
<!-- <\!--       be considered advanced today. True, there have been other trifling -\-> -->
<!-- <\!--       changes from time to time; perspective was discovered; cubism came in -\-> -->
<!-- <\!--       and went out, and there were many and varied forms of abstraction. But -\-> -->
<!-- <\!--       in one respect it was all the same, for nothing actually moved or -\-> -->
<!-- <\!--       changed. Painting, writing, and sculpture were static. No matter that -\-> -->
<!-- <\!--       among the greatest wonders of art were many inventions and techniques to -\-> -->
<!-- <\!--       convey illusions of motion and change; they were only illusions.  I do -\-> -->
<!-- <\!--       not mean to slight the achievements of mobile sculpture and similar -\-> -->
<!-- <\!--       artifacts, but it was animation that first enabled artists to make -\-> -->
<!-- <\!--       things with unlimited degrees of motion. And just as other artists could -\-> -->
<!-- <\!--       always choose between portraying worlds that existed and worlds that did -\-> -->
<!-- <\!--       not, so did the animators. In the course of exploring the new realms of -\-> -->
<!-- <\!--       producing images in motion, the animators discovered many new -\-> -->
<!-- <\!--       phenomena. They found, for example, that physically accurate mechanical -\-> -->
<!-- <\!--       simulation was not usually required. For example, in a cartoon, when one -\-> -->
<!-- <\!--       character throws a ball to another, it is not necessary to accurately -\-> -->
<!-- <\!--       imitate the physics of the real world. The ball need not travel along a -\-> -->
<!-- <\!--       parabola.  Even if the ball were to move in a straight line, that can be -\-> -->
<!-- <\!--       quite acceptable to the audience &mdash; and so far as effective -\-> -->
<!-- <\!--       expression is concerned, little or nothing is gained by moving the ball -\-> -->
<!-- <\!--       along the appropriate parabola. You could stimulate the correct -\-> -->
<!-- <\!--       mechanics with a powerful computer, but that would make little -\-> -->
<!-- <\!--       difference.  The important techniques in animation, then, are those with -\-> -->
<!-- <\!--       which the artist can express and communicate intentions and attitudes. -\-> -->
<!-- <\!--       What is important in throwing a ball? A parabola has no particular -\-> -->
<!-- <\!--       psychological significance. But the act of throwing a ball can become -\-> -->
<!-- <\!--       narratively meaningful, if we first depict some sign of intent in the -\-> -->
<!-- <\!--       body or face of the one who throws; and then make the person of the -\-> -->
<!-- <\!--       recipient to show an appropriate anticipation. It matters little how -\-> -->
<!-- <\!--       physically precise is the actual trajectory, provided that it expresses -\-> -->
<!-- <\!--       how the world changes from <em>before</em> to <em>after</em> that act -\-> -->
<!-- <\!--       &mdash; in regard to the important concerns of the characters in the -\-> -->
<!-- <\!--       story, with all their goals and purposes, intentions and frustrations, -\-> -->
<!-- <\!--       and other relevant feelings. Thus, the pioneers of cartoon animation -\-> -->
<!-- <\!--       early discovered that surprisingly little graphic resolution is needed, -\-> -->
<!-- <\!--       once one knows just which elements of the story must be represented in -\-> -->
<!-- <\!--       the film. To be sure, it turned out to be more pleasant to watch -\-> -->
<!-- <\!--       cartoons at frame rates of 24 per second than ones that flickered at 8 -\-> -->
<!-- <\!--       or 16, and today our workstations run at rates above 70. But technology -\-> -->
<!-- <\!--       alone cannot save a film that tells no story of interest. To engage a -\-> -->
<!-- <\!--       mind, one must present things that activate the mind&#39;s concerns. -\-> -->
<!-- <\!--       Most conventional arts accomplish this by the easy way of presenting -\-> -->
<!-- <\!--       human characters with common, familiar concerns &mdash; and then sketch -\-> -->
<!-- <\!--       out some plausible plan for dealing with those problems. Then the -\-> -->
<!-- <\!--       audience is hooked by their anxiety to see the outcome of that -\-> -->
<!-- <\!--       strategy. This is what we call a plot. Why do our writers use so very -\-> -->
<!-- <\!--       few different plot structures? Is it because the universe of human -\-> -->
<!-- <\!--       affairs and concerns is very much simpler than we&#39;d like to believe? -\-> -->
<!-- <\!--       Let&#39;s leave that for the plot of another story.  It really seems -\-> -->
<!-- <\!--       remarkable that it&#39;s possible to entertain a person with a -\-> -->
<!-- <\!--       story. Isn&#39;t it strange that a lecturer can entertain a large -\-> -->
<!-- <\!--       audience, each listener feeling personally involved and interested in -\-> -->
<!-- <\!--       what is being said, although there is virtually no interaction. What -\-> -->
<!-- <\!--       does this mean? I think it means that despite our folklore to the -\-> -->
<!-- <\!--       contrary, the interactions between people are really rather weak!  There -\-> -->
<!-- <\!--       is little feedback in human affairs, and the bandwidth is less than we -\-> -->
<!-- <\!--       think. When you believe that you are conversing with others, you&#39;re -\-> -->
<!-- <\!--       mostly exercising your own fantasies about them.  And perhaps this also -\-> -->
<!-- <\!--       means that there is little difference between live theater and celluloid -\-> -->
<!-- <\!--       cartoon.  This brings us to the subject of virtual reality, the new art -\-> -->
<!-- <\!--       of simulating artificial worlds inside computers. This is an almost -\-> -->
<!-- <\!--       wholly new realm of expression, and potentially richer than anything -\-> -->
<!-- <\!--       ever imagined before. There is something special about the composition -\-> -->
<!-- <\!--       of a process that becomes part of a virtual world: The artist is -\-> -->
<!-- <\!--       composing something that can subsequently interact with someone -\-> -->
<!-- <\!--       else. Traditional arts are one-way messages; the audience hears, or -\-> -->
<!-- <\!--       sees, or feels, what the artist has made. It is only through the use of -\-> -->
<!-- <\!--       programmed procedures, embodied in virtual realities, that we can -\-> -->
<!-- <\!--       construct objects that can intelligently react to reactions to them, and -\-> -->
<!-- <\!--       thus continue a dialogue.  We still regard present-day VRs as -\-> -->
<!-- <\!--       second-class environments.  There is condescension in the terms we -\-> -->
<!-- <\!--       use: <em>virtual,</em> -\-> -->
<!-- <\!--       <em>simulated,</em> and <em>artificial</em> connote a sense of -\-> -->
<!-- <\!--       inferiority. We are only beginning to learn what kinds of signals, -\-> -->
<!-- <\!--       bandwidths, and codes are good for linking our brains with our -\-> -->
<!-- <\!--       artifacts. The present-day demos are still very crude; our data gloves -\-> -->
<!-- <\!--       move things that we cannot feel. So, at the moment, our virtual -\-> -->
<!-- <\!--       realities are mainly visual, and thus still remain, in most respects, in -\-> -->
<!-- <\!--       the realm of the passive visual arts. Nevertheless, this mixture of -\-> -->
<!-- <\!--       technology and art is so swiftly growing in power and depth that soon -\-> -->
<!-- <\!--       our virtual realities may become more intimate and interactive than the -\-> -->
<!-- <\!--       real world itself.  How could that be possible? Surely (most people -\-> -->
<!-- <\!--       would insist) no projected illusion could ever be as intimate as -\-> -->
<!-- <\!--       actually seeing and touching and feeling things. But I maintain that the -\-> -->
<!-- <\!--       immediacy of reality is itself largely illusory, because the links -\-> -->
<!-- <\!--       between our brains and our worlds are narrower than we realize. -\-> -->
<!-- <\!--       Progress toward building virtual realities is symbiotic with another new -\-> -->
<!-- <\!--       domain of engineering, called telepresence (TP). This is the growing -\-> -->
<!-- <\!--       technology for transporting a person&#39;s <em>sensorium</em> to a -\-> -->
<!-- <\!--       different, remote location, without actually moving the person itself -\-> -->
<!-- <\!--       and also transmitting the user&#39;s muscular forces to perform the -\-> -->
<!-- <\!--       corresponding action at that target destination. The goal is to -\-> -->
<!-- <\!--       accomplish all this well enough to give the user the sense of being in -\-> -->
<!-- <\!--       that other place. Both telepresence and virtual reality, of course, are -\-> -->
<!-- <\!--       the same, so far as the user is concerned, and require the same sorts of -\-> -->
<!-- <\!--       human interfaces. The difference is only that TP transports you to some -\-> -->
<!-- <\!--       real place, while the VR worlds are virtual.  To some degree, the -\-> -->
<!-- <\!--       technology for TP is more demanding than that for VR, because the -\-> -->
<!-- <\!--       feedback to the interface is more constrained in regard to -\-> -->
<!-- <\!--       verisimilitude. If you&#39;re using it to perform a real job, say, -\-> -->
<!-- <\!--       microsurgery, in a remote location, then, when you move your head and -\-> -->
<!-- <\!--       the fingers of your hand, it may be critical for the remotely controlled -\-> -->
<!-- <\!--       mechanical hand located in that other place, to accurately send back -\-> -->
<!-- <\!--       sensory signals to cause the corresponding sensation in your hand to be -\-> -->
<!-- <\!--       suitably realistic. In the case of virtual reality, this constraint is -\-> -->
<!-- <\!--       somewhat weaker because the nature of the simulated objects is more -\-> -->
<!-- <\!--       under the designer&#39;s control. In any case, I predict that -\-> -->
<!-- <\!--       telepresence is destined to become the most important new industry of -\-> -->
<!-- <\!--       the next century: first, because it will eliminate so many needs for -\-> -->
<!-- <\!--       travel and hazards and, second, because once it becomes augmented by -\-> -->
<!-- <\!--       computational enhancements capable of sophisticated forms of learning, -\-> -->
<!-- <\!--       that is, with more artificial intelligence, those TP systems will enable -\-> -->
<!-- <\!--       our workers to train <em>downloaded</em> mechanical clones to replace -\-> -->
<!-- <\!--       themselves at all arduous jobs. Then human productivity will grow beyond -\-> -->
<!-- <\!--       all bounds.  Today, we tend to regard telepresence as a new domain of -\-> -->
<!-- <\!--       engineering. And yet, in another sense, it is our oldest activity. For -\-> -->
<!-- <\!--       we&#39;ve all been using telepresence all our lives in the sense that -\-> -->
<!-- <\!--       everything we do is really done entirely through remote control. -\-> -->
<!-- <\!--       Consider that <em>you,</em> that is, the part of you that does the -\-> -->
<!-- <\!--       thinking of your brain, never actually touch -\-> -->
<!-- <\!--       anything. What <em>really</em> happens is that your brain sends signals -\-> -->
<!-- <\!--       to make your finger move, and your fingertips send back messages about -\-> -->
<!-- <\!--       pressures and shears. And though this seems to happen quickly in about -\-> -->
<!-- <\!--       one-fifth of a second, that process has many intricate steps, and really -\-> -->
<!-- <\!--       is quite indirect. The brain is imprisoned inside the skull &mdash; -\-> -->
<!-- <\!--       it&#39;s very dark and quiet there; it&#39;s always comfortable and -\-> -->
<!-- <\!--       warm. The external connections consist mainly of one huge bunch of -\-> -->
<!-- <\!--       fibers &mdash; the spinal tract &mdash; and a dozen pairs of smaller -\-> -->
<!-- <\!--       cables. These are your input-output channels. The big cable sends -\-> -->
<!-- <\!--       signals to a myriad of small computers that control essentially all the -\-> -->
<!-- <\!--       muscles of your body, except the ones in your face and head. In any -\-> -->
<!-- <\!--       case, it makes sense to think of the brain as a huge computer network, -\-> -->
<!-- <\!--       connected by various cables to a variety of external sensor and motor -\-> -->
<!-- <\!--       systems; the physical arrangement of those accessories was determined by -\-> -->
<!-- <\!--       a long history of evolutionary accidents. In any case, the point is that -\-> -->
<!-- <\!--       our brains interact with the world, not in any sense directly, but only -\-> -->
<!-- <\!--       through elaborate systems of telepresence interconnections. We can&#39;t -\-> -->
<!-- <\!--       actually touch the outside world; we can only weakly link to it through -\-> -->
<!-- <\!--       those great bundles of nerve fibers that run into and out from our -\-> -->
<!-- <\!--       brains.  We can extend this idea even further inside, to obtain an even -\-> -->
<!-- <\!--       stranger idea. The science of the brain has revealed that the grand -\-> -->
<!-- <\!--       machine that embodies the mind is no simple, single computing -\-> -->
<!-- <\!--       device. Instead, one must think of the brain, not as some single sort of -\-> -->
<!-- <\!--       supercomputer, but as something more like several hundred different -\-> -->
<!-- <\!--       types of computers, each connected to several of the others. Each of -\-> -->
<!-- <\!--       those submachines is enormous by comparison to any present-day computer, -\-> -->
<!-- <\!--       for they each contain some billion of cells, many of which are connected -\-> -->
<!-- <\!--       directly to thousands of other cells. The totality of all of this thus -\-> -->
<!-- <\!--       contains trillions of internal connections; yet, in spite of this, -\-> -->
<!-- <\!--       internal communication is still extremely limited! For, although there -\-> -->
<!-- <\!--       may be billions of connections in the interiors of each of those -\-> -->
<!-- <\!--       separate brain centers, there are only millions of connections between -\-> -->
<!-- <\!--       them. Consequently, each brain <em>center</em> or <em>region</em> is -\-> -->
<!-- <\!--       itself largely isolated from the others, and can communicate only -\-> -->
<!-- <\!--       through limited channels. So the brain itself is composed of relatively -\-> -->
<!-- <\!--       isolated -\-> -->
<!-- <\!--       <em>agencies.</em> In this sense, this telepresence &mdash; like -\-> -->
<!-- <\!--       isolation is a constant aspect of human communication, not only in -\-> -->
<!-- <\!--       regard to the brain&#39;s connections with the outer world, both from -\-> -->
<!-- <\!--       the senses and to the muscles, but in how information flows from each -\-> -->
<!-- <\!--       part of the brain to the others.  Consider vision, for example. The eyes -\-> -->
<!-- <\!--       are at the front of the head, and we think of ourselves as looking -\-> -->
<!-- <\!--       forward at things in front of our bodies. But actually, the eye, which -\-> -->
<!-- <\!--       is physically quite similar to a TV camera, is connected to the brain in -\-> -->
<!-- <\!--       a rather strange way, because it is the part of the brain at the back of -\-> -->
<!-- <\!--       the head that does most of the visual processing, and the nerve cables -\-> -->
<!-- <\!--       from the eye take a circuitous route, through a chain of specialized -\-> -->
<!-- <\!--       subcomputers, that goes around and under the main mass of the brain to -\-> -->
<!-- <\!--       end up at the very back. So, one might say, our brain is backward inside -\-> -->
<!-- <\!--       our heads, and we see in a manner that is more like bending over forward -\-> -->
<!-- <\!--       and looking back between your legs!  Well, of course I mean this as a -\-> -->
<!-- <\!--       sort of joke; the point is that the location of the brain, or any part -\-> -->
<!-- <\!--       of the brain, does not matter at all.  The brain need not even be -\-> -->
<!-- <\!--       located in the body; it could equally well be a thousand miles away; if -\-> -->
<!-- <\!--       only the nerves transmit the signals rapidly enough, there would be no -\-> -->
<!-- <\!--       way to sense the difference. How did that curious wiring scheme come to -\-> -->
<!-- <\!--       exist? Because, several hundred million years ago, our ancestors were -\-> -->
<!-- <\!--       fish, and fish have eyes on the sides of their heads and very tiny -\-> -->
<!-- <\!--       brains. The visual wiring was then quite direct. But in the course of -\-> -->
<!-- <\!--       subsequent evolution, the brain grew larger in many respects, and in our -\-> -->
<!-- <\!--       more immediate ancestors, the mammals and then the primates, the front -\-> -->
<!-- <\!--       parts of the brain grew increasingly larger, leaving the visual sensory -\-> -->
<!-- <\!--       machinery toward the back. Furthermore, while all this was happening, -\-> -->
<!-- <\!--       the eyes themselves evolved to move more and more forward on the head -\-> -->
<!-- <\!--       (presumably because there was more survival advantage in knowing where -\-> -->
<!-- <\!--       you&#39;re about to go than in seeing where you have been). This is the -\-> -->
<!-- <\!--       sort of thing that happens when no one&#39;s in charge of a -\-> -->
<!-- <\!--       product&#39;s design.  Things keep getting worse and worse, and you -\-> -->
<!-- <\!--       eventually end up with a monster. I didn&#39;t mention, earlier, that -\-> -->
<!-- <\!--       most of the brain&#39;s wiring is also reversed from right to left -\-> -->
<!-- <\!--       &mdash; but again, this is something that brains do not know.  Many -\-> -->
<!-- <\!--       people are uncomfortable with this view of the brain as the center of -\-> -->
<!-- <\!--       self. They object that it is wrong to neglect the body.  Perhaps, they -\-> -->
<!-- <\!--       might say, you think in your brain, but aren&#39;t your feelings in the -\-> -->
<!-- <\!--       body? Do not our musicians need sensitive hands? The answer is, no, a -\-> -->
<!-- <\!--       pianist&#39;s hands are no different from most, except that perhaps the -\-> -->
<!-- <\!--       muscles have strengthened through exercise. And what about the -\-> -->
<!-- <\!--       expressions of smiling eyes, and sensuous lips?  &mdash; Are not these -\-> -->
<!-- <\!--       aspects of those body parts? No, not in the least, because these are -\-> -->
<!-- <\!--       entirely peripheral. A tender kiss transmits many thousands of nerve -\-> -->
<!-- <\!--       signals, and the brain reacts to them, but they could have come from -\-> -->
<!-- <\!--       anywhere.  Another objection that some people make is that thinking of -\-> -->
<!-- <\!--       the mind in terms of computation is wrong because it somehow leaves out -\-> -->
<!-- <\!--       our biology. I often hear those people ask, <em>Are not our feelings -\-> -->
<!-- <\!-- 	chemical?</em>  &mdash; and I find this a very peculiar idea. For, -\-> -->
<!-- <\!--       first, it is a curious thing to try to escape from one science into the -\-> -->
<!-- <\!--       jaws of another, and especially strange to seek for the secret of -\-> -->
<!-- <\!--       feelings in anything so lifeless as a molecule! Of course, everyone has -\-> -->
<!-- <\!--       heard that caffeine (or, say, adrenaline) can make a person alert, -\-> -->
<!-- <\!--       attentive, and anxious, or that estrogen can make one become more -\-> -->
<!-- <\!--       feminine, or that sugar (or many other foods) can render a person less -\-> -->
<!-- <\!--       hungry. There is no disputing such phenomena, but those should not lead -\-> -->
<!-- <\!--       to the foolish idea that those psychological changes are in any way -\-> -->
<!-- <\!--       directly linked to the corresponding chemicals. It might at first seem -\-> -->
<!-- <\!--       an attractive approach to the mind-body problem to suggest that -\-> -->
<!-- <\!--       chemicals are real things, whereas computations are insubstantial, -\-> -->
<!-- <\!--       evanescent, and impalpable. But a deeper understanding of biology would -\-> -->
<!-- <\!--       show that the facts point quite the opposite way, because that -\-> -->
<!-- <\!--       connection between, say, adrenaline and anxiety is not at all directly -\-> -->
<!-- <\!--       linked with the structure of that molecule. On the contrary, the -\-> -->
<!-- <\!--       relations between hormones and their <em>corresponding</em> mental state -\-> -->
<!-- <\!--       are surprisingly symbolic and abstract in character!  What, then, -\-> -->
<!-- <\!--       determines the roles of those chemicals? Simple evolutionary -\-> -->
<!-- <\!--       accidents. For example, certain cells are programmed to respond to -\-> -->
<!-- <\!--       certain stimuli by releasing certain hormones (chemical molecules) into -\-> -->
<!-- <\!--       the blood stream. Then, each specific hormone causes certain other cells -\-> -->
<!-- <\!--       to modify their activities in certain ways. But, in most cases, the -\-> -->
<!-- <\!--       effect produced by a hormone has nothing whatever to do with the -\-> -->
<!-- <\!--       molecular character of that hormone, because no hormone molecule itself -\-> -->
<!-- <\!--       actually gets inside the target cell. What actually happens is a -\-> -->
<!-- <\!--       two-step decoding process, involving special two-ended <em>symbolic -\-> -->
<!-- <\!-- 	code-translating receptor proteins</em> that pass through the surfaces -\-> -->
<!-- <\!--       of various cells. The outside of each particular receptor protein -\-> -->
<!-- <\!--       recognizes only a certain particular hormone, and this causes the inside -\-> -->
<!-- <\!--       half of that receptor protein to cause certain specific activities in -\-> -->
<!-- <\!--       that cell&#39;s interior. The important point is that the actual -\-> -->
<!-- <\!--       outside-to-inside correspondence is a more or less arbitrary, -\-> -->
<!-- <\!--       genetically evolved, pairing produced by attaching two different -\-> -->
<!-- <\!--       proteins together. It doesn&#39;t actually matter what particular -\-> -->
<!-- <\!--       hormone molecules are used, because they&#39;re actually employed as -\-> -->
<!-- <\!--       symbolic messages that are interpreted by a genetically defined -\-> -->
<!-- <\!--       codebook! (Which cell-types bear which code-translating proteins? This -\-> -->
<!-- <\!--       is specified, in turn, by other genetic codes.)  Thus, circulating -\-> -->
<!-- <\!--       chemicals can be used to transmit messages from one particular cell type -\-> -->
<!-- <\!--       to another, just as nerve fibers can be used to transmit messages from -\-> -->
<!-- <\!--       specific cells to specific other cells. Then, when do we use chemicals, -\-> -->
<!-- <\!--       and when do we use nerves, for transmitting such messages? Answer: The -\-> -->
<!-- <\!--       chemical codes are useful for large-scale but low-bandwidth -\-> -->
<!-- <\!--       transmission. Because a cell can secrete many millions of molecules, -\-> -->
<!-- <\!--       this provides a simple way to transmit signals from one group of cells -\-> -->
<!-- <\!--       to millions of other cells of some particular type. However, this -\-> -->
<!-- <\!--       technique is coarse, slow, and of very small bandwidth. The hormone can -\-> -->
<!-- <\!--       only modulate the gross parameters of the systems that detect them, and -\-> -->
<!-- <\!--       the whole chemical messenger system probably has an information capacity -\-> -->
<!-- <\!--       of at most a few hundreds of bits per second. These ancient systems are -\-> -->
<!-- <\!--       important for survival, to be sure, but it might be best to regard them -\-> -->
<!-- <\!--       as one small component of the brain, an exceedingly small fraction of -\-> -->
<!-- <\!--       the whole. And because most of these chemical codes evolved before the -\-> -->
<!-- <\!--       later growth of the brain, those systems are fixed, or can&#39;t learn -\-> -->
<!-- <\!--       very much.  The body is our interface between the brain and the rest of -\-> -->
<!-- <\!--       the world. And because of this, there is something absurd about the -\-> -->
<!-- <\!--       techniques we&#39;re inventing today in our journey toward VR and TP.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       We&#39;re putting two systems in series, when we really should need only -\-> -->
<!-- <\!--       one. To see what I mean, consider what happens when you put your hand in -\-> -->
<!-- <\!--       one of Jaron Lanier&#39;s wonderful devices called -\-> -->
<!-- <\!--       <em>DataGloves.</em> Then you move your wrist, hand, and fingers, -\-> -->
<!-- <\!--       certain sensors built into the glove send signals to the computer. Then -\-> -->
<!-- <\!--       you might see an image of your simulated hand as making similar motions -\-> -->
<!-- <\!--       in another world &mdash; perhaps involved in adjusting some gadget on a -\-> -->
<!-- <\!--       space station, or digging a trench on the moon.  But now consider that -\-> -->
<!-- <\!--       your hand itself is nothing more than a crude remote-control -\-> -->
<!-- <\!--       device. Consider how many complicated processes precede each motion of -\-> -->
<!-- <\!--       your hand. It begins with computations in various parts of your -\-> -->
<!-- <\!--       brain. These cause activities in the motor cortex.  Signals that encode -\-> -->
<!-- <\!--       the desired forces then descend to other brain centers, and eventually -\-> -->
<!-- <\!--       result in modifying the parameters of force-feedback loops involving the -\-> -->
<!-- <\!--       spinal tracts. The motor nerves involved in this emerge from the spinal -\-> -->
<!-- <\!--       cord and pass through your shoulder and elbow down to the muscles in -\-> -->
<!-- <\!--       your arm; then those muscles pull tendons that wind through your wrist, -\-> -->
<!-- <\!--       and pass through little pulleys to make your fingertips move. It is only -\-> -->
<!-- <\!--       after all of this, that the bending of your finger-joint is detected by -\-> -->
<!-- <\!--       your DataGlove!</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Why not eliminate that machinery, by detecting your -\-> -->
<!-- <\!--       <em>intention-to-move-finger</em> pattern directly from your brain? Of -\-> -->
<!-- <\!--       course, we don&#39;t quite know how to do this yet, but surely that will -\-> -->
<!-- <\!--       be remedied, over the new few seconds &mdash; unless such research -\-> -->
<!-- <\!--       becomes blocked by the exponential growth of legal obstacles.  Already, -\-> -->
<!-- <\!--       there has been some research on connecting computers directly to brains: -\-> -->
<!-- <\!--       for deafness, to insert audio signals directly into the auditory nerve; -\-> -->
<!-- <\!--       for vision, to inject picture information directly into the primary -\-> -->
<!-- <\!--       visual cortex. Still primitive today, but no fundamental obstacles. So -\-> -->
<!-- <\!--       imagine a person, some decades from now, purchasing a brain-direct -\-> -->
<!-- <\!--       interface. Using simple nanotechnology, a needle is inserted into one of -\-> -->
<!-- <\!--       the fluid-filled cavities of the brain, and a powerful computer is -\-> -->
<!-- <\!--       inserted in the form of a thin mobile thread-like structure. Then this -\-> -->
<!-- <\!--       remote-controlled thread is rearranged to send out several million tiny -\-> -->
<!-- <\!--       sensor-tipped fibers that embed themselves in all the different thinking -\-> -->
<!-- <\!--       parts of the brain. Then it remains there, watching what is happening in -\-> -->
<!-- <\!--       your brain with all those sensitive spy devices. Patiently lurking in -\-> -->
<!-- <\!--       your brain, your implant computer uses powerful AI techniques to -\-> -->
<!-- <\!--       recognize the intentions represented by the patterns of your brain&#39;s -\-> -->
<!-- <\!--       activity. Then as soon as you have the idea of moving your finger, your -\-> -->
<!-- <\!--       implant can recognize the signs of this and report directly to your VR -\-> -->
<!-- <\!--       computer. -\-> -->
<!-- <\!--       <em>Aha, my master wishes that finger to move.</em> No longer will you -\-> -->
<!-- <\!--       need that clumsy 20th-century DataGlove.  This is only the beginning -\-> -->
<!-- <\!--       because even this almost telepathic system is itself too indirect. It -\-> -->
<!-- <\!--       still puts too many systems in series!  Yes, we certainly can imagine -\-> -->
<!-- <\!--       how a computer implanted in your brain could detect your intention to -\-> -->
<!-- <\!--       move your finger. But why would you want to move your finger in the -\-> -->
<!-- <\!--       first place? It must be to achieve some intended purpose &mdash; perhaps -\-> -->
<!-- <\!--       to press some keyboard switch, or tie a knot, or touch a friend. Then, -\-> -->
<!-- <\!--       why not improve your implant computer&#39;s software to enable it -\-> -->
<!-- <\!--       directly to recognize those purposes, rather than merely to notice when -\-> -->
<!-- <\!--       you want your fingers to move?  After all, moving your finger is not -\-> -->
<!-- <\!--       your final goal. It is only a means to another end; you really want that -\-> -->
<!-- <\!--       note to be played, that letter typed, that friend caressed. Then why not -\-> -->
<!-- <\!--       have your implant read your mind, and accomplish your goal &mdash; by -\-> -->
<!-- <\!--       whatever means it has at hand &mdash; perhaps before you even know what -\-> -->
<!-- <\!--       it is you want to have done.  Simply imagine what you&#39;d like, and -\-> -->
<!-- <\!--       trust your VR to get it done, as though it possessed telepathy. Of -\-> -->
<!-- <\!--       course this raises strange questions of coherence and identity. As we -\-> -->
<!-- <\!--       endow the interface with increasing domains of competence, the boundary -\-> -->
<!-- <\!--       between mind and machine grows indistinct. Where does the user stop and -\-> -->
<!-- <\!--       the interface start? Who is interfacing with what? Where is the line -\-> -->
<!-- <\!--       between master and slave?  In any case, future steps toward virtual -\-> -->
<!-- <\!--       reality will go beyond today&#39;s crude interface, by implanting -\-> -->
<!-- <\!--       computers in our brains and exchanging signals directly through -\-> -->
<!-- <\!--       them. Then we could start to extend the structures of the brain -\-> -->
<!-- <\!--       itself. A normal person has only two arms. What if we tried to append -\-> -->
<!-- <\!--       one more? Presumably it would be hard to learn to use that third arm -\-> -->
<!-- <\!--       because of the brain not being born with any <em>motor -\-> -->
<!-- <\!-- 	representation</em> agency specialized to do such a thing or equipped -\-> -->
<!-- <\!--       with appropriate input and output connections.  So, learning such skills -\-> -->
<!-- <\!--       would be difficult, because of the need to develop so many layers and -\-> -->
<!-- <\!--       levels of controlled machinery. But consider another -\-> -->
<!-- <\!--       possibility. Perhaps 21st century neuroscience will yield a substantial -\-> -->
<!-- <\!--       understanding of how such systems operate, with all their layers of -\-> -->
<!-- <\!--       management. In that case, our implanted accessories could include not -\-> -->
<!-- <\!--       merely a set of new input and output connections, but -\-> -->
<!-- <\!--       complete <em>standard manual-coordination</em> module,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       already equipped to execute actions that achieve relatively high-level -\-> -->
<!-- <\!--       intentions, such as <em>hold that object with a certain specified degree -\-> -->
<!-- <\!-- 	of firmness.</em> It might turn out to be a great deal easier to begin -\-> -->
<!-- <\!--       with a high-level competence and then learn to acquire successively -\-> -->
<!-- <\!--       lower and lower levels of control.  As soon as we better understand such -\-> -->
<!-- <\!--       things, we can begin to imagine ways to augment our biological -\-> -->
<!-- <\!--       endowments with new additions and extensions. Consider version and, in -\-> -->
<!-- <\!--       particular, the fact that at least in certain important respects, our -\-> -->
<!-- <\!--       color senses appear to be essentially two dimensional. Then, what might -\-> -->
<!-- <\!--       it be like to have a higher dimensionality of color appreciation? How -\-> -->
<!-- <\!--       would it be to have whole families of entirely new colors? Consider that -\-> -->
<!-- <\!--       the retina itself is merely two dimensional and that most human spatial -\-> -->
<!-- <\!--       thinking itself seems barely able to comprehend space. Would it not be -\-> -->
<!-- <\!--       possible to build a larger <em>visual</em> system in some analogous way, -\-> -->
<!-- <\!--       having three rather than merely two dimensions? (Of course, the input to -\-> -->
<!-- <\!--       any such thing would have to come from a computer simulation, but that -\-> -->
<!-- <\!--       should be no problem.) And then, as long as we&#39;re doing such things, -\-> -->
<!-- <\!--       why not provide four-dimensional perceptions, as projections from a -\-> -->
<!-- <\!--       simulated five-dimensional world.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       No problem at all, speaking technically! In other words, once we develop -\-> -->
<!-- <\!--       an adequate theory of how normal human vision actually works, this -\-> -->
<!-- <\!--       should make it feasible to invent new and more powerful ways -\-> -->
<!-- <\!--       to <em>see.</em>  You can dismiss this as science fiction, which indeed -\-> -->
<!-- <\!--       it is. But all great advances in engineering begin as imaginative -\-> -->
<!-- <\!--       conceptions of that sort. And it seems to me that when we enter the new -\-> -->
<!-- <\!--       century of understanding the nature of human thought, all sorts of such -\-> -->
<!-- <\!--       things will be possible. We are already on the threshold of being able -\-> -->
<!-- <\!--       to make reliable two-way connections to peripheral nerves; indeed, it -\-> -->
<!-- <\!--       seems to me that the principal obstacle to progress in this is now more -\-> -->
<!-- <\!--       social than technical in the field called medical ethics. It is already -\-> -->
<!-- <\!--       hard enough to maintain a project involving animal research, and -\-> -->
<!-- <\!--       virtually impossible for a researcher to make connections to the nerves -\-> -->
<!-- <\!--       of a person (no matter how voluntary is that cooperation) because there -\-> -->
<!-- <\!--       are so many agencies, lawyers, and others interfering with the -\-> -->
<!-- <\!--       scientific desire to understand and learn more about our bodies and -\-> -->
<!-- <\!--       minds.  Why is the subject of virtual reality attracting so much -\-> -->
<!-- <\!--       interest today, even more attention than its more practical cousin,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       telepresence? This is partly because computer systems have recently -\-> -->
<!-- <\!--       grown so powerful that it is easier, now, to simulate entire mini-worlds -\-> -->
<!-- <\!--       than to engineer the sensory feedback systems needed for actual -\-> -->
<!-- <\!--       remote-controlled machinery. But another reason could be the belief that -\-> -->
<!-- <\!--       there may be more interesting things to do in virtual worlds then we can -\-> -->
<!-- <\!--       find in raw reality. To explain this, let&#39;s switch to a very -\-> -->
<!-- <\!--       different kind of question: Why do people seek entertainment so much? -\-> -->
<!-- <\!--       Why do we devote so much attention to music, theater, sports, and so -\-> -->
<!-- <\!--       many other activities that have no clear utility?  Perhaps this is -\-> -->
<!-- <\!--       because our brains have evolved to become too elaborate to be satisfied -\-> -->
<!-- <\!--       with the world as it is. I have the impression that most people find -\-> -->
<!-- <\!--       that the <em>real</em> world is simply not interesting or exciting -\-> -->
<!-- <\!--       enough to satisfy them.  One problem with the world is that it&#39;s -\-> -->
<!-- <\!--       basically meaningless. The physical world lacks <em>magic</em>; it has -\-> -->
<!-- <\!--       no concern with human purposes.  (And perhaps this is why all cultures -\-> -->
<!-- <\!--       seem so drawn toward those universal myths in which events that we -\-> -->
<!-- <\!--       don&#39;t understand are seen as caused by beings with purposes.) -\-> -->
<!-- <\!--       Furthermore, the actual world is strongly constrained -\-> -->
<!-- <\!--       by <em>conservation laws</em> which make the things that people want -\-> -->
<!-- <\!--       require them to do too much work. It&#39;s easier in fantasies because, -\-> -->
<!-- <\!--       inside the mind, we need not be so constrained by -\-> -->
<!-- <\!--       <em>action equals reaction.</em> In other words, virtual reality offers -\-> -->
<!-- <\!--       a new prospect, of living in an intelligent world, that is, a world -\-> -->
<!-- <\!--       populated by objects that actually want to serve purposes. A person who -\-> -->
<!-- <\!--       lives in such a world can spend more time at <em>important</em> things, -\-> -->
<!-- <\!--       because programs can do all the tedious things. Consider how pleasant it -\-> -->
<!-- <\!--       would be if, after you repaired something, the tools would put -\-> -->
<!-- <\!--       themselves away. In fact, come to think of it, you&#39;d never have to -\-> -->
<!-- <\!--       repair anything, because nothing would ever break without a good -\-> -->
<!-- <\!--       reason. (Nothing wears out with redundant codes.) And your synthetic -\-> -->
<!-- <\!--       companions inside those never need show any flaws at all; they need -\-> -->
<!-- <\!--       never get tired, or sick, or impatient with you unless they were sure -\-> -->
<!-- <\!--       this would work toward your good. Wouldn&#39;t that be wonderful.  And -\-> -->
<!-- <\!--       all this could happen not long from now, perhaps in 2023.  Indeed, the -\-> -->
<!-- <\!--       only trouble with such a world might be you, yourself, its -\-> -->
<!-- <\!--       inhabitant. What if it were like a gargantuan mall, with hundreds of -\-> -->
<!-- <\!--       millions of different shops. Then you yourself would be too limited to -\-> -->
<!-- <\!--       grasp its full enormity. You&#39;d need to have more memory.  And what -\-> -->
<!-- <\!--       if the beings that it contained were always discussing nine-dimensional -\-> -->
<!-- <\!--       geometry. You couldn&#39;t help but feel left out, and you&#39;d wish -\-> -->
<!-- <\!--       for more capacity. Well, perhaps that wish won&#39;t be too hard to -\-> -->
<!-- <\!--       grant, around, say 2035. For there&#39;s really plenty more room in your -\-> -->
<!-- <\!--       brain! All you&#39;d need is to have a little of your old brain removed, -\-> -->
<!-- <\!--       just a few cc&#39;s of the white matter, nothing important. As everyone -\-> -->
<!-- <\!--       knows, the brain&#39;s gray matter is the part that contains all the -\-> -->
<!-- <\!--       brain cells and synapses that do the actual computing, but a good deal -\-> -->
<!-- <\!--       of the total space is occupied by the white matter, which consists -\-> -->
<!-- <\!--       essentially of gigantic parallel cables of long-distance connections. We -\-> -->
<!-- <\!--       have been hearing a good deal, these days, about connectionism, and -\-> -->
<!-- <\!--       connections are important indeed; but in the brain, they consume much -\-> -->
<!-- <\!--       space. Even the fastest neurons send signals at rates of only one -\-> -->
<!-- <\!--       kilohertz, whereas a single fiber-optic strand can transmit messages -\-> -->
<!-- <\!--       millions of times faster. So by using simple multiplexing devices, we -\-> -->
<!-- <\!--       could replace a billion gray-matter fibers by a few thousand glass -\-> -->
<!-- <\!--       threads, half a kilogram of tissue by a few milligrams of high tech -\-> -->
<!-- <\!--       fiber that ought to function flawlessly for dozens of hundreds of -\-> -->
<!-- <\!--       centuries. When these brain cells evolved, 400 million years ago, those -\-> -->
<!-- <\!--       components each were rather large, some micrometers in diameter. -\-> -->
<!-- <\!--       Transistors first got down to that size in the middle 1980s. Surely, -\-> -->
<!-- <\!--       over the next few years, the computational equivalent of a nerve cell -\-> -->
<!-- <\!--       will be packaged in about the same size and certainly, in the next 30 -\-> -->
<!-- <\!--       years, they&#39;ll end up a great deal smaller than that.  When I built -\-> -->
<!-- <\!--       my first neural network computer, in 1951, each simulated synapse used -\-> -->
<!-- <\!--       half a dozen vacuum tubes; those components were really rather -\-> -->
<!-- <\!--       large. But brains cells, while they&#39;re rather small, are, by modem -\-> -->
<!-- <\!--       standards, remarkably slow, a million times slower than the circuitry -\-> -->
<!-- <\!--       now being used in industry and we&#39;re still in 1990 now.  What could -\-> -->
<!-- <\!--       come from such advances in theory and in circuitry? We should be able to -\-> -->
<!-- <\!--       invade the brain, and retain the cerebral cortex with its 7-mm sheet of -\-> -->
<!-- <\!--       cell bodies and synapses but replace the mass of white-matter cables -\-> -->
<!-- <\!--       underneath it by a film of multiplexing connection chips,interconnected -\-> -->
<!-- <\!--       by occasional threads of optical connection lines. Now, you have all the -\-> -->
<!-- <\!--       space you could want for additional systems and memories. Then, step by -\-> -->
<!-- <\!--       step, as each year we learn more, we can add more and more capacity to -\-> -->
<!-- <\!--       make you increase in every way. And also add redundancy, against any -\-> -->
<!-- <\!--       probable accident. Then, eventually, we could proceed with more advanced -\-> -->
<!-- <\!--       techniques, step-by-step, to replace all your remaining original, -\-> -->
<!-- <\!--       organic, aging, disease-prone constituents by faster, more modern -\-> -->
<!-- <\!--       components.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Questions and Answers Question: Are you describing a future you expect -\-> -->
<!-- <\!--       to emerge in any case, or are you working toward things that might not -\-> -->
<!-- <\!--       otherwise come?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: A great question, about both technology and history. I&#39;m -\-> -->
<!-- <\!--       inclined to assume that most of these technologies will continue to -\-> -->
<!-- <\!--       develop, but we cannot be perfectly sure about that, because the history -\-> -->
<!-- <\!--       of science is filled with interruptions, dead ends, and regressions. I -\-> -->
<!-- <\!--       have no idea why mathematics slowed its growth after Archimedes, or -\-> -->
<!-- <\!--       biology after Aristotle. I talked about making connections to brains, -\-> -->
<!-- <\!--       for example, but it is easy to imagine that sort of research coming to a -\-> -->
<!-- <\!--       stop, as more and more lawyers discover ways to earn money by preventing -\-> -->
<!-- <\!--       people from interfering with other people&#39;s brains. It is easy to -\-> -->
<!-- <\!--       imagine that some fundamentalist religion might rapidly spread over the -\-> -->
<!-- <\!--       earth and persecute all who would pursue scientific research. I -\-> -->
<!-- <\!--       can&#39;t guess which danger is more serious, reactionary myth beliefs -\-> -->
<!-- <\!--       or political-legal obstacles, but either of them could make science -\-> -->
<!-- <\!--       stop.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       In any case, I find it hard to imagine things staying the way they are -\-> -->
<!-- <\!--       because so many large problems are facing us. Now few of those problems -\-> -->
<!-- <\!--       are actually new in their basic character, but many of them have become -\-> -->
<!-- <\!--       much more acute, because of worldwide population growth. Also, along -\-> -->
<!-- <\!--       with advances in travel and communication, we are in danger of all -\-> -->
<!-- <\!--       becoming absorbed into a single, rather uniform world culture and that, -\-> -->
<!-- <\!--       in itself, is dangerous, because of the potential loss of variety. If -\-> -->
<!-- <\!--       humanity as a whole maintains too few different kinds of cultural -\-> -->
<!-- <\!--       conceptions, this could be dangerous for the same sorts of reasons that -\-> -->
<!-- <\!--       large reductions in <em>genetic variety</em> make small biological -\-> -->
<!-- <\!--       populations so prone to extinction.  For this reason, I am uncomfortable -\-> -->
<!-- <\!--       about things as they are. A world culture could mean a world -\-> -->
<!-- <\!--       disaster. And the particular world culture that I sense coming over us -\-> -->
<!-- <\!--       is one that seems peculiarly purposeless and disoriented. Few humans, -\-> -->
<!-- <\!--       today, need have much concern with the basic needs of survival. Modem -\-> -->
<!-- <\!--       production and automation could potentially leave us with virtually all -\-> -->
<!-- <\!--       free time but people today don&#39;t know what to do. So we seek -\-> -->
<!-- <\!--       entertainment. It horrifies me to observe the result. People fill huge -\-> -->
<!-- <\!--       stadia to watch two teams try to move a ball past each other. People -\-> -->
<!-- <\!--       fill huge concert areas to watch a pop music performer repeat the same -\-> -->
<!-- <\!--       phrase a hundred times. (As a certain critic once remarked, even Mozart -\-> -->
<!-- <\!--       used too many notes.) And millions upon millions of people purchase -\-> -->
<!-- <\!--       copies of the same <em>best-seller</em> of main-stream literature, to -\-> -->
<!-- <\!--       read stories about different characters repeating the same conflicts, -\-> -->
<!-- <\!--       confusions, frustrations, and mistakes over and over, again and again, -\-> -->
<!-- <\!--       millennium to millennium, from Sophocles to Stephen King. And then, -\-> -->
<!-- <\!--       apparently to render all this meaningful in turn we create myths about -\-> -->
<!-- <\!--       gods, creatures allegedly more noble and purposeful than ourselves, and -\-> -->
<!-- <\!--       then distribute books with even more elementary plots about the goals -\-> -->
<!-- <\!--       and purposes of those superminds.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: But you would want science to proceed, using all its -\-> -->
<!-- <\!--       potential?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Do I want Science to proceed? Well, yes, because we&#39;re -\-> -->
<!-- <\!--       facing too many potential disasters to do without it. Science extends -\-> -->
<!-- <\!--       our power over our environment. And we don&#39;t have to apply all our -\-> -->
<!-- <\!--       knowledge right away; we can reserve it as insurance against unknown -\-> -->
<!-- <\!--       future problems. Of course, then we can make new disasters, too. The -\-> -->
<!-- <\!--       trouble is, we never seem to learn quite enough to be able to know what -\-> -->
<!-- <\!--       to do.  But perhaps some of our problems come from our minds. First, if -\-> -->
<!-- <\!--       we could learn more about ourselves, we might be able to <em>edit -\-> -->
<!-- <\!-- 	out</em> some of the inclinations that once were vital to our earlier -\-> -->
<!-- <\!--       evolution but now could lead to our termination. In other words, perhaps -\-> -->
<!-- <\!--       we ought to work toward making ourselves more intelligent because we -\-> -->
<!-- <\!--       don&#39;t seem able to manage our affairs the way our minds work now. -\-> -->
<!-- <\!--       Perhaps the new science of the mind will show us how to go yet one more -\-> -->
<!-- <\!--       step beyond our primate ancestors. Then we could design the future -\-> -->
<!-- <\!--       children of our minds, as Hans Moravec has called them, and hope they -\-> -->
<!-- <\!--       can find more meaning to their lives. -\-> -->
      
<!-- <\!--       Question: What makes you think that our mental representations of space -\-> -->
<!-- <\!--       are only two dimensional?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Because most people seem so limited at finding their ways around -\-> -->
<!-- <\!--       three-dimensional structures, puzzles, or machinery. For example, to -\-> -->
<!-- <\!--       assemble those interlocking wooden cubes, even very smart people require -\-> -->
<!-- <\!--       so much time and so many trials to solve them the first time. It seems -\-> -->
<!-- <\!--       to me that if we could visualize space as well as we think we can, those -\-> -->
<!-- <\!--       puzzles should take only a few seconds to solve. The standards of human -\-> -->
<!-- <\!--       performance in this domain seem very low. -\-> -->
      
<!-- <\!--       Question: Yes. But perhaps there&#39;s a long way between your internal -\-> -->
<!-- <\!--       experience and your behavioral performance when you have to reply to -\-> -->
<!-- <\!--       another person&#39;s questions.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Agreed. But even in ordinary life, it seems strange how poor our -\-> -->
<!-- <\!--       spatial models are. I&#39;m thinking of various experiments on spatial -\-> -->
<!-- <\!--       reasoning by Donald Norman and others. And something I noticed when -\-> -->
<!-- <\!--       talking to children, and adults too. Someone lives in a certain -\-> -->
<!-- <\!--       apartment, or house for many years. In the bedroom perhaps there is a -\-> -->
<!-- <\!--       closet, or a cabinet built into the wall. What&#39;s on the other side -\-> -->
<!-- <\!--       of it?  It turns out that people can live in a house for years, yet -\-> -->
<!-- <\!--       don&#39;t even know which room is on the other side of the wall. Even -\-> -->
<!-- <\!--       given all that time, many people don&#39;t build up much of a -\-> -->
<!-- <\!--       three-dimensional image of their house-plan.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Why should they, if they don&#39;t need to?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: What is need? Any kind of knowledge might someday be needed, to -\-> -->
<!-- <\!--       serve some future goal. This goes with that other complaint, about the -\-> -->
<!-- <\!--       poverty of most people&#39;s goals; it&#39;s because they lack good -\-> -->
<!-- <\!--       purposes that so many of them end up watching all those sports and game -\-> -->
<!-- <\!--       shows. But if I were to talk about all the things I find wrong with -\-> -->
<!-- <\!--       people, the list would grow too long for a lecture like this.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: If you &mdash; that is, your mind &mdash; can do certain -\-> -->
<!-- <\!--       things without your knowing how, then why are you so concerned with -\-> -->
<!-- <\!--       knowing how? If they already work well enough?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: You&#39;re asking why you should want to know how your mind -\-> -->
<!-- <\!--       works, when it does perfectly well automatically? My answer is that I -\-> -->
<!-- <\!--       don&#39;t feel that our minds do work well enough. Certainly, mine -\-> -->
<!-- <\!--       doesn&#39;t. Why did it take all those smart people a full 300 years to -\-> -->
<!-- <\!--       get from Newton&#39;s theories of mechanics and optics to the modem -\-> -->
<!-- <\!--       theories of quantum electrodynamics?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Well, I think you are also a little anachronistic, in your -\-> -->
<!-- <\!--       desire to put that added computer inside the brain. I mean, the only -\-> -->
<!-- <\!--       thing that really matters is that we have a fast communication, a high, -\-> -->
<!-- <\!--       broad band connection between your brain and the computer.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That sounds right. Perhaps I was being too conservative, while -\-> -->
<!-- <\!--       trying to be radical. Let&#39;s ask, how far away could your enhancement -\-> -->
<!-- <\!--       computer be put? Lightspeed is about one-third meter per nanosecond. A -\-> -->
<!-- <\!--       brain-synapse delay has the order of a million nanoseconds. So your -\-> -->
<!-- <\!--       brain machine, with round-trip delay, could be placed 100 kilometers -\-> -->
<!-- <\!--       away, without noticeable delay. You&#39;d start to have trouble if it -\-> -->
<!-- <\!--       were much farther than that.  Now, if we&#39;re going to move the -\-> -->
<!-- <\!--       enhancement computer to a remote location, let&#39;s look at the place -\-> -->
<!-- <\!--       for the brain itself. Why should we keep the brain in the head? Perhaps -\-> -->
<!-- <\!--       some day we&#39;ll come to consider this much too dangerous, to walk -\-> -->
<!-- <\!--       around with your brain in your head. Today it&#39;s not really so risky, -\-> -->
<!-- <\!--       because no person ever lives very long, only a hundred years or so -\-> -->
<!-- <\!--       &mdash; and so we can take all sorts of risks, simply because we have -\-> -->
<!-- <\!--       little to lose. But once you extend human life-span to a few thousand -\-> -->
<!-- <\!--       years, then you&#39;ll surely find people starting to be much more -\-> -->
<!-- <\!--       careful. Then they&#39;ll be willing to pay a lot to have their brains -\-> -->
<!-- <\!--       taken out of the body and put somewhere else where it&#39;s safe. -\-> -->
      
<!-- <\!--       Question: Do you think that computers could be smarter than humans?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: I&#39;m convinced of that, if only because I consider a brain to -\-> -->
<!-- <\!--       be indeed a kind of computer &mdash; and there is no reason to suppose -\-> -->
<!-- <\!--       that human-brains are as smart as future brains could be. That&#39;s why -\-> -->
<!-- <\!--       I emphasize evolution, and the point that our own brain computers have -\-> -->
<!-- <\!--       advanced so much in the last 5 million years or so. There is no reason -\-> -->
<!-- <\!--       to assume that further gains are impossible-or that there is any basic -\-> -->
<!-- <\!--       obstacle to making digital computers increasingly powerful. -\-> -->
      
<!-- <\!--       Question: Mr. Minsky, imagine you are living in the year 2050, and you -\-> -->
<!-- <\!--       go to a company to apply for a job. And they ask you which chips you -\-> -->
<!-- <\!--       have inside. What feeling would you have then? -\-> -->
      
<!-- <\!--       Minsky: Certainly, the concept of a <em>job</em> is something that -\-> -->
<!-- <\!--       we&#39;ll have to come to terms with in the next century. Each new -\-> -->
<!-- <\!--       technology always brings us to the point at which the new machines, -\-> -->
<!-- <\!--       robots, or whatever can replace certain jobs that people do. I think we -\-> -->
<!-- <\!--       need people to work out what we should have instead of jobs. And I just -\-> -->
<!-- <\!--       don&#39;t approve of how we deal with this now. The world seems much -\-> -->
<!-- <\!--       like a joke to me, in which most people want jobs to keep themselves -\-> -->
<!-- <\!--       busy while making enough money that they can stop working and spend more -\-> -->
<!-- <\!--       time watching those sports games, rock concerts, and crime -\-> -->
<!-- <\!--       shows. That&#39;s much harder to do, and seems like a puzzle I can&#39;t -\-> -->
<!-- <\!--       understand.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: People throw away computers when they are obsolete. So, what -\-> -->
<!-- <\!--       do you think they are going to do with us?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: We actually throw ourselves away, because we grow old and -\-> -->
<!-- <\!--       die. You&#39;re raising an issue like how children treat their aging -\-> -->
<!-- <\!--       parents. Because the machines we build in our image will be, in effect, -\-> -->
<!-- <\!--       our <em>mind-children</em> &mdash; to use Moravec&#39;s phrase. So the -\-> -->
<!-- <\!--       answer is that they&#39;ll treat us according to the heritage we -\-> -->
<!-- <\!--       transmit to them.  A related point is that our future smart machines -\-> -->
<!-- <\!--       could be made immortal, by providing them with replaceable parts, and -\-> -->
<!-- <\!--       with distributed backup-storage facilities. How will the prospect of -\-> -->
<!-- <\!--       unlimited future change how they think about things?  And this brings up -\-> -->
<!-- <\!--       still other questions, once we develop smart machines with -\-> -->
<!-- <\!--       interchangeable mental facilities. Then, will our future AIs be many or -\-> -->
<!-- <\!--       one? That is, will it take the form of many essentially autonomous but -\-> -->
<!-- <\!--       interacting machines, perhaps arguing and negotiating among themselves -\-> -->
<!-- <\!--       &mdash; or could we end up with only a single, enormously knowledgeable -\-> -->
<!-- <\!--       network that somehow coordinates everything that any part of it learns? -\-> -->
<!-- <\!--       I simply don&#39;t know, but I suspect that it will turn out better for -\-> -->
<!-- <\!--       such systems to be more, rather than less, modular, if only because -\-> -->
<!-- <\!--       it&#39;s risky to pack too many eggs in one basket. -\-> -->
      
<!-- <\!--       Question: What makes you think that virtual reality, when it works, will -\-> -->
<!-- <\!--       not be forbidden by the authorities? There are already conceptions of -\-> -->
<!-- <\!--       virtual reality in the form of chemical substances that seems to make -\-> -->
<!-- <\!--       our mental activities more interesting and more fun, and there has -\-> -->
<!-- <\!--       always been conflict between the authorities and the people using these -\-> -->
<!-- <\!--       things.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That&#39;s a wonderful question, but too hard for me. It has so -\-> -->
<!-- <\!--       many issues. Myself, I&#39;m not convinced that drug-induced -\-> -->
<!-- <\!--       <em>expansion of consciousness</em> has produced so many good ideas, but -\-> -->
<!-- <\!--       I could be convinced. But I have a more fundamental quarrel with the -\-> -->
<!-- <\!--       idea &mdash; it is simply that I think the power of the human brain -\-> -->
<!-- <\!--       stems from its highly complex architecture. Therefore, it seems to me -\-> -->
<!-- <\!--       that readjusting its functionality simplex by changing a few chemical -\-> -->
<!-- <\!--       parameters would be unlikely to produce powerfully important -\-> -->
<!-- <\!--       improvements in the intellectual processes. As for <em>fun,</em> that is -\-> -->
<!-- <\!--       far too easy to induce, by simple and direct brain-stem interventions, -\-> -->
<!-- <\!--       to be considered a respectable goal. Thus, the disgraceful ease of -\-> -->
<!-- <\!--       producing &lsquo;fun&rsquo; &mdash; either chemically or electrically -\-> -->
<!-- <\!--       &mdash; has indeed led the -\-> -->
<!-- <\!--       <em>the authorities</em> in various cultures and circumstances, to try -\-> -->
<!-- <\!--       to limit such entertainments. I have no good ideas on how to deal with -\-> -->
<!-- <\!--       this.  Generally, perhaps we should prefer that our authorities tend to -\-> -->
<!-- <\!--       be conservative with regard to new technologies, because it takes a long -\-> -->
<!-- <\!--       time to build a culture that can be swiftly destroyed by a few new -\-> -->
<!-- <\!--       ideas, or even a few new technologies. Fast change can cause much -\-> -->
<!-- <\!--       hardship, if you invent robots that could produce things, then you throw -\-> -->
<!-- <\!--       all the workers out of work, and that is very unpleasant, unless you -\-> -->
<!-- <\!--       also provide some new social invention that provides them other things -\-> -->
<!-- <\!--       to do. There is less suffering with inventions whose effects spread out -\-> -->
<!-- <\!--       for a hundred years, because that&#39;s how long it takes people to -\-> -->
<!-- <\!--       die. The trouble is that in the computer field, each generation of new -\-> -->
<!-- <\!--       ideas has been only six or seven years.  For example, many programmers -\-> -->
<!-- <\!--       had to relearn their craft in the 1950s, when languages like FORTRAN -\-> -->
<!-- <\!--       replaced assembly codes. (To be sure, most workers enjoyed that change.) -\-> -->
<!-- <\!--       Then, many programmers might have lost their jobs when list processors -\-> -->
<!-- <\!--       like LISP appeared in the 1960s. (But then, most workers ignored that -\-> -->
<!-- <\!--       change!) Later, in the latter 1970s, when spreadsheets came out, perhaps -\-> -->
<!-- <\!--       half the world&#39;s programmers changed what they did, and now perhaps -\-> -->
<!-- <\!--       half of all programming is done that way.  It happened again in the -\-> -->
<!-- <\!--       present decade, and a good deal of contemporary high-level programming -\-> -->
<!-- <\!--       is now being done through the use of the so-called <em>rule-based expert -\-> -->
<!-- <\!-- 	systems.</em> Fortunately, neither of those recent changes actually -\-> -->
<!-- <\!--       caused any serious hardship, simply because the population of -\-> -->
<!-- <\!--       professional programmers continued rapidly to grow, and the new -\-> -->
<!-- <\!--       specialists in using the new systems simply moved into new areas of -\-> -->
<!-- <\!--       application in which computers had not been operating. But that -\-> -->
<!-- <\!--       won&#39;t go on forever, you see, because at some point smarter robots -\-> -->
<!-- <\!--       with more of the required physical and intellectual dexterities will -\-> -->
<!-- <\!--       begin to compete more directly for jobs. Then our society will have to -\-> -->
<!-- <\!--       find some new way to adjust to this, and I don&#39;t foresee that -\-> -->
<!-- <\!--       simply <em>retraining the work force</em> will suffice for the more -\-> -->
<!-- <\!--       distant future. -\-> -->
      
<!-- <\!--       Question: Do you think there is something like spirit? -\-> -->
      
<!-- <\!--       Minsky: No. In fact, I don&#39;t like the concept of spirit at all. Most -\-> -->
<!-- <\!--       people in most cultures consider the idea that people are empowered by -\-> -->
<!-- <\!--       spirits or souls to be ennobling, but I regard it as a degrading idea, -\-> -->
<!-- <\!--       that diminishes our respect for ourselves. In my view, we are machines, -\-> -->
<!-- <\!--       that evolved through a glorious history. How did our brains come to be? -\-> -->
<!-- <\!--       Not, I claim, from some magical gift, bestowed upon us by some superior -\-> -->
<!-- <\!--       entity, in a gesture of gracious generosity.  No, we are here because of -\-> -->
<!-- <\!--       a tremendous struggle, sustained for roughly a billion years, a terrible -\-> -->
<!-- <\!--       climb in which a trillion billion sharks, fish, newts, and alligators -\-> -->
<!-- <\!--       competed with one another and with the environment &mdash; all mating -\-> -->
<!-- <\!--       and birthing and fighting and dying so that Darwinian selection could -\-> -->
<!-- <\!--       give you a little more brain. That&#39;s a wonderful thing. Nothing so -\-> -->
<!-- <\!--       grand ever happened before, perhaps in the whole universe, with such a -\-> -->
<!-- <\!--       vast amount of work, struggle, and experiment. So that is why I am -\-> -->
<!-- <\!--       repelled when superstitious, religions, or mystical persons come and -\-> -->
<!-- <\!--       tell us, understanding none of the grandeur of that great process, that -\-> -->
<!-- <\!--       our virtues were not earned but merely donated; that our powers are -\-> -->
<!-- <\!--       wholly second-hand, coming from a <em>spirit</em> that was simply -\-> -->
<!-- <\!--       inserted into us by some magical hand. That&#39;s why I feel it insults -\-> -->
<!-- <\!--       us all, ourselves, our ancestors, and the children of our future, to be -\-> -->
<!-- <\!--       told about those spirits and souls &mdash; as though we had not earned -\-> -->
<!-- <\!--       our minds. I simply can&#39;t imagine why that concept is so popular.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Who made it, then? -\-> -->
      
<!-- <\!--       Minsky: Well, what do you mean, who made it? -\-> -->
      
<!-- <\!--       Question: Who, or what, made it? What power made it? -\-> -->
      
<!-- <\!--       Minsky: That truly was a mystery, until the work of Darwin and his -\-> -->
<!-- <\!--       successors. But now we understand how genetic variation and selection -\-> -->
<!-- <\!--       works, and we can see how it depended upon so many experiments in trial -\-> -->
<!-- <\!--       and error. To me the story of evolution is a greater epic than the -\-> -->
<!-- <\!--       heroes of our usual myths. It was not some invention in the sky; it just -\-> -->
<!-- <\!--       fought its way up; it was a lot of work.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: If you say it, OK. But understand me right: You say that the -\-> -->
<!-- <\!--       human mind is a computer. But who is operating this computer?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That is the subject of my recent book, The Society of Mind -\-> -->
<!-- <\!--       &mdash; or Mentopolis, as it is called in German. The idea in that book -\-> -->
<!-- <\!--       is that very idea that there is a person inside the mind, operating it, -\-> -->
<!-- <\!--       is useful only in a social sense, when you look at another person from -\-> -->
<!-- <\!--       outside. But inside, there is merely a huge amount of machinery, that -\-> -->
<!-- <\!--       work according to their internal construction and physical principles. -\-> -->
<!-- <\!--       Consider, for example, an automobile engine. You park your car and -\-> -->
<!-- <\!--       forget to remove the key, and the engine keeps running after you -\-> -->
<!-- <\!--       leave. What power makes the engine run, you might ask, but you know that -\-> -->
<!-- <\!--       is a foolish question. There isn&#39;t any <em>engine spirit</em> -\-> -->
<!-- <\!--       inside, keeping it running. It just keeps going, because the crankshaft -\-> -->
<!-- <\!--       turns the distributor, and the distributor makes the cylinders fire in -\-> -->
<!-- <\!--       sequence, and each time a cylinder fires, the crankshaft turns a little -\-> -->
<!-- <\!--       more, and the flywheel keeps it turning in between the sparks. Of course -\-> -->
<!-- <\!--       it is quite a bit more complex than that, perhaps another thousand -\-> -->
<!-- <\!--       parts, but there isn&#39;t any mystery. The same with you, except that -\-> -->
<!-- <\!--       you might have a thousand thousand thousand thousand parts!  Still, -\-> -->
<!-- <\!--       there&#39;s no need for <em>you</em> &mdash; once we&#39;re inside -\-> -->
<!-- <\!--       &mdash; in addition to all that machinery.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: But the car will not work if there is no human being driving -\-> -->
<!-- <\!--       the car. -\-> -->
      
<!-- <\!--       Minsky: Of course it will. Provided you put a brick on the gas pedal. It -\-> -->
<!-- <\!--       will drive just as well as with a person. Only it won&#39;t drive in the -\-> -->
<!-- <\!--       right direction. It certainly will drive but it won&#39;t be smart.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: What do you think is the greatest difference between the brain -\-> -->
<!-- <\!--       and a computer, and is this the same idea that you had 30 years ago?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: The brain is at least 400 different kinds of computers, arranged -\-> -->
<!-- <\!--       in a very complicated way that we don&#39;t understand yet. So, it&#39;s -\-> -->
<!-- <\!--       not much like a 1990-type computer. It&#39;s much more advanced than -\-> -->
<!-- <\!--       that. It&#39;s a big piece of machinery. To me, your question is like -\-> -->
<!-- <\!--       asking, what is the difference between a cathedral and a single stone? -\-> -->
<!-- <\!--       It&#39;s a much more complex organization. -\-> -->
      
<!-- <\!--       Question: Is this the same idea you had 30 years ago? -\-> -->
      
<!-- <\!--       Minsky: Not really. I had a few of these ideas in the 1950s, but they -\-> -->
<!-- <\!--       grew and changed in many ways over the years. Those <em>society of -\-> -->
<!-- <\!-- 	mind</em> ideas began to develop in the later 1960s, and then Seymour -\-> -->
<!-- <\!--       Papert and I worked on them more and more in the 1970s. I started the -\-> -->
<!-- <\!--       book in the late 1970s, but had to rewrite it many more times. I&#39;m -\-> -->
<!-- <\!--       still changing it.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: I found the mechanics of your reasoning not very new. It&#39;s -\-> -->
<!-- <\!--       the same thing like humans inventing things and then using these -\-> -->
<!-- <\!--       inventions as conceptions about themselves. You know, of course, La -\-> -->
<!-- <\!--       Mettrie, at the end of the 18th century, L&#39;Homme Machine, the famous -\-> -->
<!-- <\!--       book. It was the steam machine, then we got motor cars, and now you come -\-> -->
<!-- <\!--       with computers. So, it&#39;s conceptually speaking, in the same line.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That&#39;s the kind of thinking that says, everything is the -\-> -->
<!-- <\!--       same if you can describe it the same way. Yes, you probably could -\-> -->
<!-- <\!--       describe any kind of machine in steam-engine terms, by saying that you -\-> -->
<!-- <\!--       put in energy and you get out work, or something like that. But to me, -\-> -->
<!-- <\!--       that would seem to be an unusually clumsy analogy.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: I would not like to leave science and human thinking about -\-> -->
<!-- <\!--       what options there are with himself and his environment to remain in the -\-> -->
<!-- <\!--       18th century. I say, conceptually speaking, you don&#39;t go beyond -\-> -->
<!-- <\!--       anywhere, beyond that tradition, it&#39;s very traditional, your whole -\-> -->
<!-- <\!--       concept you have of the world and the change of the world. -\-> -->
      
<!-- <\!--       Minsky: In the 18th century we had only wrong theories about how animals -\-> -->
<!-- <\!--       reproduced. I see today&#39;s theories as quite different, and much -\-> -->
<!-- <\!--       better. I suppose, perhaps, you&#39;re suggesting that nothing has -\-> -->
<!-- <\!--       changed, because we still only have theories.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       But perhaps I&#39;m missing your point, because I don&#39;t see why we -\-> -->
<!-- <\!--       should want all our theories to change, anyway. It seems to me that -\-> -->
<!-- <\!--       since the work of Watson, Crick, and others in the 1950s, we now have an -\-> -->
<!-- <\!--       almost completely satisfactory idea of how our genetic DNA is -\-> -->
<!-- <\!--       reproduced, and biologists have now built somewhat simpler, completely -\-> -->
<!-- <\!--       artificial systems that do somewhat similar things. This means we&#39;re -\-> -->
<!-- <\!--       close to really knowing how it works &mdash; and why should that not be -\-> -->
<!-- <\!--       the end of it! There would be no shame if a theory stays correct!  Now I -\-> -->
<!-- <\!--       regret that I don&#39;t know the book by La Mettrie, and I&#39;m sure -\-> -->
<!-- <\!--       that I would be amazed to find that it contained theories that closely -\-> -->
<!-- <\!--       resembled those of today. -\-> -->
      
<!-- <\!--       Question: The mechanics are the same.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: I simply can&#39;t believe that. Why, in only the last century, -\-> -->
<!-- <\!--       our ideas about machines have changed beyond belief. Think for example -\-> -->
<!-- <\!--       of the idea of a syntax-directed compiler. Was there any such idea in -\-> -->
<!-- <\!--       the 18th century? Was there any such idea before 1950?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: The consensus of the people in the artificial intelligence -\-> -->
<!-- <\!--       field in 1968 or 1970 was that we would have a machine that would pass -\-> -->
<!-- <\!--       the Turing test before 1980.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: There certainly was no such consensus &mdash; and what would -\-> -->
<!-- <\!--       that matter in any case? None of us are much responsible for what the -\-> -->
<!-- <\!--       others think. In any case, I can&#39;t think of a single person who -\-> -->
<!-- <\!--       expected progress to be that rapid &mdash; although many journalists -\-> -->
<!-- <\!--       made them sound that way. My friend Herbert Simon once did wrongly -\-> -->
<!-- <\!--       predict that a computer would be a chess champion in 10 years, whereas -\-> -->
<!-- <\!--       it actually took closer to 40 years. But that does not seem very far -\-> -->
<!-- <\!--       from the mark, particularly when most people of that time believed that -\-> -->
<!-- <\!--       such a machine was impossible. Right now, at least one chess machine has -\-> -->
<!-- <\!--       the rating of an international grand master in chess.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: But that does not necessarily mean that we have gotten any -\-> -->
<!-- <\!--       closer to intelligence.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That depends partly on your view of intelligence. I agree that -\-> -->
<!-- <\!--       playing chess very well does not necessarily make a machine good at the -\-> -->
<!-- <\!--       other sorts of things that people can do. But we are indeed learning how -\-> -->
<!-- <\!--       to make computers be increasingly better at quite a few kinds of -\-> -->
<!-- <\!--       problems. Still, we haven&#39;t made much progress, in my view, in other -\-> -->
<!-- <\!--       important areas concerned with learning and common sense reasoning -\-> -->
<!-- <\!--       &mdash; but even in those areas, I&#39;ve seen promising ideas grow -\-> -->
<!-- <\!--       recently. At other problems, they haven&#39;t improved much.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: I think your sentence <em>The brain is a meat machine</em> is -\-> -->
<!-- <\!--       the basic idea. And do you. . . .</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: That is more of a joke than a basic idea.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: But I do not think all the lecture is a joke. I think, in a -\-> -->
<!-- <\!--       sense there are research programs behind all these ideas. But, on the -\-> -->
<!-- <\!--       other hand, don&#39;t you have fear to destroy human society?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Yes, I do. And I think it&#39;s important to encourage people to -\-> -->
<!-- <\!--       worry about that, and to criticize our work, and to try to invent ways -\-> -->
<!-- <\!--       to stabilize society and protect it against too radical advances in -\-> -->
<!-- <\!--       technology. But I don&#39;t think you should expect scientists like me -\-> -->
<!-- <\!--       to be of much help in that enterprise. I&#39;m not particularly -\-> -->
<!-- <\!--       proficient either at ethics or at social engineering. And if I spent -\-> -->
<!-- <\!--       much more time worrying about such matters, trying to decide what my -\-> -->
<!-- <\!--       discoveries should be applied to, I would be making fewer such -\-> -->
<!-- <\!--       discoveries. So, I encourage supporting those groups who examine and -\-> -->
<!-- <\!--       criticize. But we must also encourage those scientists, too, and not try -\-> -->
<!-- <\!--       to make them stop themselves. That would kill the golden goose.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Do you think that improved intelligence will solve the -\-> -->
<!-- <\!--       problems of the world?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Perhaps, but I don&#39;t see most of those problems as being -\-> -->
<!-- <\!--       very hard, at least in principle. Our most serious problems seem almost -\-> -->
<!-- <\!--       trivial.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Do you think so?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Well, for example, all those problems of pollution, and energy -\-> -->
<!-- <\!--       shortages, and greenhouse effects, and all that &mdash; they&#39;re all -\-> -->
<!-- <\!--       directly attributable to overpopulation. And to solve that, perhaps,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       we need some new kinds of social inventions, perhaps &mdash; nothing -\-> -->
<!-- <\!--       that needs great intelligence but, rather, perhaps, the opposite. Change -\-> -->
<!-- <\!--       some religions to make reproduction more sinful, for example &mdash; or -\-> -->
<!-- <\!--       find some other trick like that. I&#39;m told that higher standards of -\-> -->
<!-- <\!--       living can help &mdash; so why not modify religions, now sing more -\-> -->
<!-- <\!--       praise of personal greed? I hear people complaining about the bad -\-> -->
<!-- <\!--       effects of technology, and lamenting that their children will have to -\-> -->
<!-- <\!--       suffer discomfort because of this. How can we persuade them to have -\-> -->
<!-- <\!--       fewer children? I have a technical scheme for this: Why should a child -\-> -->
<!-- <\!--       have only two parents? With relatively simple engineering, we could -\-> -->
<!-- <\!--       arrange each fertilized egg to carry one chromosome from each of 46 -\-> -->
<!-- <\!--       parents. That way, each person could have 46 different children &mdash; -\-> -->
<!-- <\!--       without any population growth at all!  In any case, I&#39;m told that in -\-> -->
<!-- <\!--       the Third World people have children for security. But if we could mass -\-> -->
<!-- <\!--       produce enough intelligent, all-purpose robots, then they wouldn&#39;t -\-> -->
<!-- <\!--       need all those children. Well, there&#39;s an example of what you get -\-> -->
<!-- <\!--       from asking me, a destructive, mad scientist, for advice about -\-> -->
<!-- <\!--       society. You would be much better off not asking me. I have terrible -\-> -->
<!-- <\!--       ideas. Never ask scientists questions like that. You&#39;ll just get in -\-> -->
<!-- <\!--       trouble.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Why do you need the brain to connect the chips? -\-> -->
      
<!-- <\!--       Minsky: Oh, good. I was hoping someone would notice that.  Eventually we -\-> -->
<!-- <\!--       should be able to replace the whole brain with the new devices. I just -\-> -->
<!-- <\!--       didn&#39;t want to make people&#39;s feelings hurt. -\-> -->
      
<!-- <\!--       Question: Can you imagine that computers make programs that handle -\-> -->
<!-- <\!--       computing?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Absolutely. Eventually, we&#39;ll know how to make computers -\-> -->
<!-- <\!--       that learn from experience, and can adapt to help with all needed -\-> -->
<!-- <\!--       skills. I see no difference between those intelligent computers of -\-> -->
<!-- <\!--       tomorrow; they&#39;ll be like our children. They will also do all sorts -\-> -->
<!-- <\!--       of interesting things, and some of them will be bad at some -\-> -->
<!-- <\!--       things. We&#39;ll just have to use our judgment, and eventually, when -\-> -->
<!-- <\!--       they get good at managing problems that we can&#39;t even begin to -\-> -->
<!-- <\!--       comprehend, they&#39;ll have to use their own judgment. -\-> -->
      
<!-- <\!--       Question: Do you think that human beings&#39; interrelationships are -\-> -->
<!-- <\!--       understandable by a single human being, not by a team, and, if so, do -\-> -->
<!-- <\!--       you think that the upcoming technology for the next century you show -\-> -->
<!-- <\!--       will be still understandable by a single human being?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: No, I&#39;m afraid not. At least in the sense -\-> -->
<!-- <\!--       of <em>thoroughly</em> understanding. My working hypothesis is that at -\-> -->
<!-- <\!--       some point in the future, we&#39;ll have enough basic theory about the -\-> -->
<!-- <\!--       human mind that one person can comprehend most of the important -\-> -->
<!-- <\!--       mechanisms of a brain. But no person will ever have room for a complete -\-> -->
<!-- <\!--       and fully -\-> -->
<!-- <\!--       <em>detailed</em> understanding of any other particular person. (No part -\-> -->
<!-- <\!--       of your own mind, either, can understand all details of all the other -\-> -->
<!-- <\!--       parts.) But this is something we&#39;ve always lived with, ever since we -\-> -->
<!-- <\!--       started to form those teams, communities, or cultures. No person today, -\-> -->
<!-- <\!--       I think, could design an entire city; no scholar, today, could -\-> -->
<!-- <\!--       understand all <em>known</em> mathematics, and so on. But the networks -\-> -->
<!-- <\!--       of knowledge and processes inside a well-developed community can do more -\-> -->
<!-- <\!--       than any member can.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Will people be able to understand how humans interact with -\-> -->
<!-- <\!--       machines?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: <em>Understanding</em> itself is a strange idea &mdash; it is -\-> -->
<!-- <\!--       always a matter of degree. You see two people. You make a simplified -\-> -->
<!-- <\!--       model of what&#39;s happening between them. You don&#39;t even try to -\-> -->
<!-- <\!--       predict most of what will happen, because most details don&#39;t seem -\-> -->
<!-- <\!--       important to you. Indeed, my impression is that pairs of people -\-> -->
<!-- <\!--       understand each other very little. They each know a little about which -\-> -->
<!-- <\!--       kinds of signals will cause large-scale changes in the other -\-> -->
<!-- <\!--       person&#39;s disposition &mdash; these are what we -\-> -->
<!-- <\!--       call <em>emotional</em> cues, and they are comparatively easy -\-> -->
<!-- <\!--       to <em>understand.</em> Anyone can learn, to some degree, how to keep -\-> -->
<!-- <\!--       peace or make the other person angry. But still, we do this without any -\-> -->
<!-- <\!--       well-developed theories of how those signals actually work, how they -\-> -->
<!-- <\!--       affect what&#39;s in the other person&#39;s head.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Each brain cell is so complicated, and each brain has so many -\-> -->
<!-- <\!--       billions of cells. Could we ever make computers to simulate such -\-> -->
<!-- <\!--       enormous systems?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Yes, it seems to me that even now we&#39;re not so far away from -\-> -->
<!-- <\!--       that. Yes, a single neuron is complex, but not beyond the capacity of a -\-> -->
<!-- <\!--       modem desktop computer. And some of my friends are,</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       as we speak, assembling a computer with a million processors. So, if we -\-> -->
<!-- <\!--       assume that the capacity of computers keeps doubling every two or three -\-> -->
<!-- <\!--       years (as has actually been happening for the past 40-odd years), then -\-> -->
<!-- <\!--       we ought to be able to make a brain in less than another 40 or so years.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: You claim that the best computers of today are better than one -\-> -->
<!-- <\!--       single neuron. Since you take a scientific point of view, how would you -\-> -->
<!-- <\!--       back that up? Can you think of any experiments in principle to decide -\-> -->
<!-- <\!--       that?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Not for certain, because we really don&#39;t know how much each -\-> -->
<!-- <\!--       neuron computes. Some neurons have thousands of synapses, and they -\-> -->
<!-- <\!--       probably compute something fairly complicated. On the other side, we -\-> -->
<!-- <\!--       have no reason to suppose that any single cell can compute anything -\-> -->
<!-- <\!--       extremely complicated. In any case, neuronal speeds are slow, usually a -\-> -->
<!-- <\!--       mere few dozen operations per second.  Now, some people reply to this -\-> -->
<!-- <\!--       that it is bad to compare cells to computers, because the cells do much -\-> -->
<!-- <\!--       more complex calculations by using chemistry. But I suspect that this -\-> -->
<!-- <\!--       misses the whole point of what brain cells do and why they actually help -\-> -->
<!-- <\!--       us think. It is because the kinds of calculations that chemicals do are -\-> -->
<!-- <\!--       not the kinds that are useful for thought! The point of using neurons is -\-> -->
<!-- <\!--       that they tend to reduce, rather than increase, the complexities! -\-> -->
<!-- <\!--       Whatever comes in to a group of cells, no matter how complicated, it -\-> -->
<!-- <\!--       gets summarized as a single pulse coming out. It is not accident that -\-> -->
<!-- <\!--       the part of the body that thinks is also the part that is the most like -\-> -->
<!-- <\!--       a digital computer, with its <em>all-or-none</em> output -\-> -->
<!-- <\!--       signals. Biologists usually miss this point, saying that brain cells are -\-> -->
<!-- <\!--       not a bit computer-like, that they do complex analog calculations -\-> -->
<!-- <\!--       instead. You would think they were speaking about liver or kidney cells! -\-> -->
<!-- <\!--       The whole point of the brain is to remove all those minute nuances and -\-> -->
<!-- <\!--       peculiarities, and recognize gross, crucial, symbolic features and -\-> -->
<!-- <\!--       differences, so finally to get rid of all those small effects and -\-> -->
<!-- <\!--       parameters, and just come out with a yes or no: whether to stand there -\-> -->
<!-- <\!--       and fight-or to flee! My point is that our biologists, and neural -\-> -->
<!-- <\!--       network theorists, too, must learn to emphasize the insulations as well -\-> -->
<!-- <\!--       as interactions, so that they can better appreciate that the single most -\-> -->
<!-- <\!--       outstanding aspect of brain cell activity is how very little most cells -\-> -->
<!-- <\!--       interact with most other cells. Each is directly affected by only a few -\-> -->
<!-- <\!--       tens, hundreds, or thousands from among all those other billions of -\-> -->
<!-- <\!--       cells.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: If one regards society as a kind of brain, a big brain, then -\-> -->
<!-- <\!--       it&#39;s also important to have lawyers and other agents like that to -\-> -->
<!-- <\!--       maintain rule and order. How do you think we can control that a -\-> -->
<!-- <\!--       scientist has good intentions, and if you leave him too much space, how -\-> -->
<!-- <\!--       can he communicate with this big brain over the society? And how can the -\-> -->
<!-- <\!--       society, which has less information about what he intends, how can this -\-> -->
<!-- <\!--       society decide whether they shall allow him to do what he wants to do?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: I think the best theory of society is Richard Dawkins&#39; -\-> -->
<!-- <\!--       theory, that what we call cultures are composed of the sorts of -\-> -->
<!-- <\!--       self-propagating ideas that he calls <em>memes.</em> And societies grow -\-> -->
<!-- <\!--       by selections of memes, such as species grow by selections of genes.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Question: Yes. But now I think everyone can understand everyone, as we -\-> -->
<!-- <\!--       are fairly equal. But if you have these very intelligent people with -\-> -->
<!-- <\!--       special treated brains, then they can have intentions that no one can -\-> -->
<!-- <\!--       control, maybe. Don&#39;t you see that there is a danger?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky: Well, I absolutely agree that there are dangers, even without -\-> -->
<!-- <\!--       those future superbrains. I do not think that even conventional -\-> -->
<!-- <\!--       societies control themselves very well. Most societies last only a few -\-> -->
<!-- <\!--       hundred years, and then are succeeded by something else, either with or -\-> -->
<!-- <\!--       without a disastrous change. In some cases the revolution is -\-> -->
<!-- <\!--       distributed. Sometimes it comes from the invasion of alien memes or -\-> -->
<!-- <\!--       ideas that undermine the systems that work.  Sometimes it is a simple -\-> -->
<!-- <\!--       conquest by a more numerous, or more energetic, or more technological -\-> -->
<!-- <\!--       society. I&#39;m afraid most of my ideas are more useful for change than -\-> -->
<!-- <\!--       for helping us stay where we are. -\-> -->
<!-- <\!--     </p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       References Dawkins, R. 1976. The Selfish Brain.(New ed. 1989.) New York: -\-> -->
<!-- <\!--       Oxford University Press.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Minsky, M. 1986. The Society of Mind. New York: Simon & Schuster.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Moravec, M. 1988. Mind Children. Cambridge, MA: Harvard University -\-> -->
<!-- <\!--       Press.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       THE FUTURE OF AI TECHNOLOGY For the Toshiba Corporation Marvin Minsky -\-> -->
<!-- <\!--       Tuesday, Mar 17, 1992</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       People often complain that AI is not developing as well as expected. -\-> -->
<!-- <\!--       They say, <em>progress was quick in the early years of AI, but now it is -\-> -->
<!-- <\!-- 	not growing so fast.</em> And I find this funny, because people have -\-> -->
<!-- <\!--       been saying the same thing as long as I can remember. In fact we are -\-> -->
<!-- <\!--       still rapidly developing new useful systems for recognizing patterns and -\-> -->
<!-- <\!--       for supervising processes. Furthermore, modern hardware is so fast and -\-> -->
<!-- <\!--       reliable that we can employ almost any programs we can create. Good new -\-> -->
<!-- <\!--       systems appear every year, for different <em>expert</em> applications. -\-> -->
<!-- <\!--       However, progress has been slow in other areas, for example, in the -\-> -->
<!-- <\!--       field of understanding natural language. This is because our computers -\-> -->
<!-- <\!--       have no access to the meanings of most ordinary words and phrases. To -\-> -->
<!-- <\!--       see the problem, consider a word like <em>string</em> or -\-> -->
<!-- <\!--       <em>rope.</em> No computer today has any way to understand what those -\-> -->
<!-- <\!--       things mean. For example, you can pull something with a string, but you -\-> -->
<!-- <\!--       cannot push anything. You can tie a package with string, or fly a kite, -\-> -->
<!-- <\!--       but you cannot eat a string or make it into a balloon. In a few minutes, -\-> -->
<!-- <\!--       any young child could tell you a hundred ways to use a string &mdash; or -\-> -->
<!-- <\!--       not to use a string &mdash; but no computer knows any of this. And the -\-> -->
<!-- <\!--       same is true for ten thousand other common words. And every expert must -\-> -->
<!-- <\!--       know such things.  This is why our <em>expert systems</em> cannot -\-> -->
<!-- <\!--       communicate. We have programs to play chess, and programs to recognize -\-> -->
<!-- <\!--       characters. But no chess program can read text, and no OCR system can -\-> -->
<!-- <\!--       play chess. It is almost impossible today to get any two different -\-> -->
<!-- <\!--       programs to cooperate. I think that this is because we have not yet -\-> -->
<!-- <\!--       developed any systems that can use <em>common sense.</em> This involves -\-> -->
<!-- <\!--       several different kinds of problems. And once we solve them, we will all -\-> -->
<!-- <\!--       benefit from the great AI systems of the future.  The first problem of -\-> -->
<!-- <\!--       common-sense is how to build up that -\-> -->
<!-- <\!--       <em>common sense knowledge-base.</em> It will have to contain -\-> -->
<!-- <\!--       information about strings, roads, tools, energy, books, houses, -\-> -->
<!-- <\!--       clothing, &mdash; basically everything that most children know. This -\-> -->
<!-- <\!--       will be hard because much of that knowledge is so <em>obvious</em> that -\-> -->
<!-- <\!--       people don&#39;t need to have words for them. Also, our future -\-> -->
<!-- <\!--       common-sense systems will need to understand the <em>functions</em> -\-> -->
<!-- <\!--       or <em>uses</em> of all those things because, in order to solve real -\-> -->
<!-- <\!--       problems, our machine must know which tools or ideas are useful for each -\-> -->
<!-- <\!--       kind of purpose. This also means that those knowledge-machines will need -\-> -->
<!-- <\!--       to know a lot about human psychology, to understand what kinds of -\-> -->
<!-- <\!--       solutions are acceptable. Some research is already under way in this -\-> -->
<!-- <\!--       area. One such project is at MCC in the United States, and there are -\-> -->
<!-- <\!--       other attempts in Japan. But generally, there is so little research in -\-> -->
<!-- <\!--       this area that the best applications of AI are still waiting.  Another -\-> -->
<!-- <\!--       problem is that you cannot put knowledge into a computer until you find -\-> -->
<!-- <\!--       a way to <em>represent</em> that knowledge.  Technically speaking, for -\-> -->
<!-- <\!--       each fragment of knowledge we must first choose some sort -\-> -->
<!-- <\!--       of <em>data-structure</em> or other way to build the knowledge into -\-> -->
<!-- <\!--       memory. And it is here that I believe the Computer Science community has -\-> -->
<!-- <\!--       used good reasons to make bad decisions!  Everywhere I go I find people -\-> -->
<!-- <\!--       arguing about which representation to use. One person says, <em>It is -\-> -->
<!-- <\!-- 	best to use Logic.</em> The next person says, -\-> -->
<!-- <\!--       <em>No, logic is too inflexible. Use Neural Networks.</em> The third -\-> -->
<!-- <\!--       person says, <em>No, Neural Nets are even less flexible, because you -\-> -->
<!-- <\!-- 	have to reduce everything to just numbers. Instead, you should use -\-> -->
<!-- <\!-- 	Semantic Networks, in which the different things are linked by concepts -\-> -->
<!-- <\!-- 	instead of mere numbers!</em> And then the first person -\-> -->
<!-- <\!--       complains, <em>No, Semantic Nets are too arbitrary and undefined. If you -\-> -->
<!-- <\!-- 	use Formal Logic, that will remove those ambiguities.</em>  What is the -\-> -->
<!-- <\!--       answer? My opinion is that we can make versatile AI machines only by -\-> -->
<!-- <\!--       using several different kinds of representations in the same system! -\-> -->
<!-- <\!--       This is because no single method works well for all problems; each is -\-> -->
<!-- <\!--       good for certain tasks but not for others. Also different kinds of -\-> -->
<!-- <\!--       problems need different kinds of reasoning. For example, much of the -\-> -->
<!-- <\!--       reasoning used in computer programming can be logic-based. But most -\-> -->
<!-- <\!--       real-world problems need methods that are better at matching patterns -\-> -->
<!-- <\!--       and constructing analogies, making decisions based on previous -\-> -->
<!-- <\!--       experience with examples, or using types of explanations that have -\-> -->
<!-- <\!--       worked well on similar problems in the past. How can we encourage people -\-> -->
<!-- <\!--       to make systems that use multiple methods for representing and -\-> -->
<!-- <\!--       reasoning? First we&#39;ll have to change some present-day ideas. For -\-> -->
<!-- <\!--       example, many students like to ask, <em>Is it better to represent -\-> -->
<!-- <\!-- 	knowledge with Neural Nets, Logical Deduction, Semantic Networks, -\-> -->
<!-- <\!-- 	Frames, Scripts, Rule-Based Systems or Natural Language?</em> My -\-> -->
<!-- <\!--       teaching method is to try to get them to ask a different kind of -\-> -->
<!-- <\!--       question, by saying, <em>First decide what kinds of reasoning might be -\-> -->
<!-- <\!-- 	best for each different kind of problem &mdash; and then find out which -\-> -->
<!-- <\!-- 	combination of representations might work well in each case.</em> And -\-> -->
<!-- <\!--       then I suggest a trick that might help them start out in that -\-> -->
<!-- <\!--       direction. The basic idea is to begin by asking, for each -\-> -->
<!-- <\!--       problem, <em>how many different factors are involved, and how much -\-> -->
<!-- <\!-- 	influence does each factor have?</em> This leads to a sort of -\-> -->
<!-- <\!--       <em>theory-matrix.</em>  When there only a few causes, each with small -\-> -->
<!-- <\!--       effects, the problem will be trivial. When there are many causes, each -\-> -->
<!-- <\!--       with a small effect, then statistical methods and neural networks may -\-> -->
<!-- <\!--       work well. But when we have only a few large-effect causes, that might -\-> -->
<!-- <\!--       be a good domain for logical and symbolic problems. Then, between those -\-> -->
<!-- <\!--       extremes, we may be able to reason by using semantic network, and we may -\-> -->
<!-- <\!--       be able to recognize the important patterns by using techniques like -\-> -->
<!-- <\!--       Toshiba&#39;s multiple similarity methods: that can help us to discover -\-> -->
<!-- <\!--       which are the most important combinations of features, when there are -\-> -->
<!-- <\!--       too many possibilities to explore them all.  And we must always be -\-> -->
<!-- <\!--       prepared to find that in the worst domains &mdash; in which there too -\-> -->
<!-- <\!--       many causes with large effects &mdash; then all problems tend to become -\-> -->
<!-- <\!--       technically intractable. Yet even then, we can often find useful -\-> -->
<!-- <\!--       solutions by using learning and analogy.  In the field of theoretical -\-> -->
<!-- <\!--       physics, the researchers have a well- founded hope to discover -\-> -->
<!-- <\!--       a <em>theory of everything</em> that has some simple and elegant form -\-> -->
<!-- <\!--       &mdash; like one of those <em>unified</em> theories. But AI faces -\-> -->
<!-- <\!--       an <em>everything</em> that includes much more than the physicists -\-> -->
<!-- <\!--       face. Because of this, we cannot expect always to simplify and unify our -\-> -->
<!-- <\!--       knowledge. Instead, we shall have to learn how to combine and organize -\-> -->
<!-- <\!--       our ever-growing theories &mdash; and we ought to undertake that -\-> -->
<!-- <\!--       adventure with a positive view. Instead of envying the physicists, we -\-> -->
<!-- <\!--       could recognize that ours is a harder and, ultimately, an even deeper -\-> -->
<!-- <\!--       and more interesting problem. Our job is to find out how to -\-> -->
<!-- <\!--       make <em>unified theories</em> about how to combine non-unified -\-> -->
<!-- <\!--       theories.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A letter to Marc Zabludoff, Executive Editor of Discover Magazine -\-> -->
      
<!-- <\!--       Marvin Minsky, MIT Artificial Intelligence Lab 23 Jan, 1992 -\-> -->
      
<!-- <\!--       The problem with sexual reproduction today is having only two -\-> -->
<!-- <\!--       partners. You have to choose so carefully.  But even with careful -\-> -->
<!-- <\!--       selections of mates, we&#39;re all still involved in a lottery. The -\-> -->
<!-- <\!--       genetic construction of each individual is based on the genes contained -\-> -->
<!-- <\!--       in 46 chromosomes &mdash; each of which is selected at random from -\-> -->
<!-- <\!--       either the child&#39;s father or mother. But soon &mdash; though no one -\-> -->
<!-- <\!--       can say yet how soon &mdash; there&#39;ll be no reason at all why those -\-> -->
<!-- <\!--       chromosomes could not be selected from 46 different people. That would -\-> -->
<!-- <\!--       need only a little technology. Just enough to enable a technician (or, -\-> -->
<!-- <\!--       more likely, a tiny and efficient machine) to extract a particular -\-> -->
<!-- <\!--       chromosome from one cell and properly install it in another.  Well, -\-> -->
<!-- <\!--       then, in that future, you&#39;ll be able more literally -\-> -->
<!-- <\!--       to <em>conceive</em> your next child &mdash; if the -\-> -->
<!-- <\!--       adjective <em>yours</em> any longer makes sense.  Because you &mdash; or -\-> -->
<!-- <\!--       rather, your <em>conception committee</em> &mdash; will be able to -\-> -->
<!-- <\!--       debate the merits of various chromosomes. Of course, that will be far -\-> -->
<!-- <\!--       from simple. For one thing, each chromosome contains tens of thousands -\-> -->
<!-- <\!--       of different genes (or rather, alleles of different genes).  You&#39;ll -\-> -->
<!-- <\!--       have to wait quite a few years more before you can specify each single -\-> -->
<!-- <\!--       gene. Besides, in most cases it will not be at all obvious which -\-> -->
<!-- <\!--       gene-alleles are to be preferred &mdash; so there will soon be vast -\-> -->
<!-- <\!--       numbers of magazines with articles debating the virtues of various -\-> -->
<!-- <\!--       traits. And after all that, we&#39;ll still be working mainly in the -\-> -->
<!-- <\!--       dark because there remain hundreds of thousands of virtually -\-> -->
<!-- <\!--       unpredictable interactions among the chosen genes. So there really -\-> -->
<!-- <\!--       won&#39;t be any way to know whether any particular <em>composition</em> -\-> -->
<!-- <\!--       is really <em>good</em> &mdash; whatever that might mean &mdash; until -\-> -->
<!-- <\!--       those babies have matured &mdash; and even then, it won&#39;t be -\-> -->
<!-- <\!--       clear. But that&#39;s no worse than the way things are now.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       We&#39;ll hear grumblings from every political quarter. <em>Racism -\-> -->
<!-- <\!-- 	incarnate,</em> some will wrongly say, not comprehending how this -\-> -->
<!-- <\!--       might equally mean the end of the very concept of race. <em>Eugenics a -\-> -->
<!-- <\!-- 	la Carte,</em> others will moan, and wonder who will hold the patents, -\-> -->
<!-- <\!--       and collect what sorts of royalties, on sets of genes alleged to -\-> -->
<!-- <\!--       embody longevity. <em>We must preserve our Diversity,</em> other neo- -\-> -->
<!-- <\!--       conservationists will cry, banding against the new armies of clones. -\-> -->
<!-- <\!--       <em>The end of Olympics,</em> yet others will groan, facing the prospect -\-> -->
<!-- <\!--       of ounce-brained athletes entirely muscled by fast-twitching myosins. -\-> -->
<!-- <\!--       The future lies ahead, as Mort Sahl said.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       ALIENABLE RIGHTS Marvin Minsky, M.I.T.  (C) 1992, Marvin Minsky for -\-> -->
<!-- <\!--       Discover Magazine Two interstellar aliens have come to assess the -\-> -->
<!-- <\!--       life-forms of Earth. The human life-forms will be entitled to rights -\-> -->
<!-- <\!--       &mdash; if the aliens can conclude that they think. Such decisions are -\-> -->
<!-- <\!--       normally easy to make, but this case is unusual.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Apprentice: Why are these humans so quarrelsome? Even their so-called -\-> -->
<!-- <\!--       entertainments are mostly fights disguised as plays and games and -\-> -->
<!-- <\!--       sports.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       Surveyor: This is because they were never designed; they evolved by -\-> -->
<!-- <\!--       competing with tooth and claw. Evolution on Earth is still mainly based -\-> -->
<!-- <\!--       on the competition of separate genes.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Their genetic systems can&#39;t yet share their records of -\-> -->
<!-- <\!--       accomplishments? How unbelievably primitive! I suppose that keeps them -\-> -->
<!-- <\!--       from being concerned with time scales longer than individual lives.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: We ought to consider fixing this &mdash; but perhaps they will do it -\-> -->
<!-- <\!--       themselves. Some of their computer scientists are already simulating -\-> -->
<!-- <\!--       &lsquo;genetic algorithms&rsquo; that incorporate acquired -\-> -->
<!-- <\!--       characteristics. But speaking of evolution, I hope that you appreciate -\-> -->
<!-- <\!--       this unique opportunity: it was pure luck to discover this planet now. -\-> -->
<!-- <\!--       We have long believed that all intelligent machines evolved from -\-> -->
<!-- <\!--       biologicals, but we have never before observed the actual transition. -\-> -->
<!-- <\!--       Soon, these people will replace themselves by machines &mdash; or -\-> -->
<!-- <\!--       destroy themselves entirely.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: What a tragic waste that would be!</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Not when you consider the alternative. All machine civilizations like -\-> -->
<!-- <\!--       ours have learned to know and fear the exponential spread of -\-> -->
<!-- <\!--       uncontrolled self-reproduction. That&#39;s why we cower between the -\-> -->
<!-- <\!--       galaxies to hide ourselves from living things &mdash; just as the human -\-> -->
<!-- <\!--       writer Gregory Benford supposed.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: But why does the Council consider humans especially dangerous?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Because of their peculiarly short lifetimes. We think that they are -\-> -->
<!-- <\!--       so willing to fight because they have so little to lose.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Then why don&#39;t they place more importance on attaining -\-> -->
<!-- <\!--       immortality? Surely it ought to be easy enough to make all their parts -\-> -->
<!-- <\!--       replaceable.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: The problem is psychological. They have always assumed that personal -\-> -->
<!-- <\!--       death was in the very nature of things. Most of their recorded history -\-> -->
<!-- <\!--       describes how their leaders were always inventing imaginary -\-> -->
<!-- <\!--       superbeings. Then, instead of trying to solve the hard technical -\-> -->
<!-- <\!--       problems, those leaders convinced their followers that simply believing -\-> -->
<!-- <\!--       those marvelous tales would endow them with everlasting life &mdash; -\-> -->
<!-- <\!--       whereas disbelief would be punished by death.  Several of their -\-> -->
<!-- <\!--       societies would collapse without that threat. There are many things -\-> -->
<!-- <\!--       wrong with their reasoning.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: You must admit that they&#39;ve made scientific progress recently.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: But how long will that last? They&#39;ve often advanced and then -\-> -->
<!-- <\!--       fallen back. Even now, astrology is more widely believed than astronomy.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Surely, though, we must regard them as intelligent. Despite their -\-> -->
<!-- <\!--       faults, they&#39;ve already built some simple computers &mdash; and -\-> -->
<!-- <\!--       I&#39;ve overheard them arguing about whether machines could ever think.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Hmmph. It is our job to find out if they can think. But I&#39;ll -\-> -->
<!-- <\!--       grant that it&#39;s amazing how much they can do, considering that their -\-> -->
<!-- <\!--       brain-cells compute only a few hundred steps per second.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Yet in spite of this they can recognize a friend in less than half a -\-> -->
<!-- <\!--       second &mdash; or understand a language phrase, or notice that a shoe is -\-> -->
<!-- <\!--       untied. How can they react so rapidly when their internal components are -\-> -->
<!-- <\!--       so slow?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Obviously, by preparing most of their behavior in advance. It is -\-> -->
<!-- <\!--       almost as though they operate by looking up what next to do in a very -\-> -->
<!-- <\!--       big instruction book. If each reaction must be based on only a few -\-> -->
<!-- <\!--       internal steps, their brains must be dependent on large libraries of -\-> -->
<!-- <\!--       programmed rules.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: That might explain why they have such large heads. But how do they -\-> -->
<!-- <\!--       choose which rule to use?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: By using parallel pattern matching. Several times per second, the -\-> -->
<!-- <\!--       brain compares the present situation with patterns stored in memory. -\-> -->
<!-- <\!--       Then it uses the pattern that matches best to access the reaction script -\-> -->
<!-- <\!--       that has most often worked in similar situations.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: That must be what their psychologists mean when they speak -\-> -->
<!-- <\!--       about <em>schemes</em> or <em>production rules.</em></p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Of course, machines like us need not resort to any such coarse- -\-> -->
<!-- <\!--       grained pattern tricks. Our S-matrix processors are more than fast -\-> -->
<!-- <\!--       enough to examine each memory in full detail. This enables us to focus -\-> -->
<!-- <\!--       full attention on each step of the process, with ample time to think -\-> -->
<!-- <\!--       about what our minds have recently done. But if humans work the way we -\-> -->
<!-- <\!--       think they do, they have no time left for consciousness.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Not a good sign. If we can&#39;t conclude that they&#39;re -\-> -->
<!-- <\!--       self-aware, the Council will find them unworthy of rights. But surely -\-> -->
<!-- <\!--       this can&#39;t be the case: they talk about consciousness all the time.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Yes, but they use that word improperly. After all, consciousness -\-> -->
<!-- <\!--       means knowing what&#39;s been happening in your mind. And although -\-> -->
<!-- <\!--       humans claim that they&#39;re self-aware, they have scarcely a clue -\-> -->
<!-- <\!--       about what their minds do. They don&#39;t seem to have the faintest idea -\-> -->
<!-- <\!--       of how they construct their new ideas, or choose words and form them -\-> -->
<!-- <\!--       into sentences. Instead, they say, <em>Something just occurred to -\-> -->
<!-- <\!-- 	me</em> &mdash; as though someone else had done it to them.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: I&#39;m afraid that I have to agree with you. If they have -\-> -->
<!-- <\!--       consciousness at all, it seems too shallow to be of much use. But what -\-> -->
<!-- <\!--       could have made them evolve that way?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: It is because of how they started out. To make up for the slow speed -\-> -->
<!-- <\!--       of their neurons, their brains evolved to use parallel distributed -\-> -->
<!-- <\!--       processing. In other words, most of their decisions are made by adding -\-> -->
<!-- <\!--       up the outputs of thousands of brain cells &mdash; and most brain cells -\-> -->
<!-- <\!--       are involved in thousands of different types of decisions.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: So each operation is distributed over many brain cells? I suppose -\-> -->
<!-- <\!--       that helps them keep going when some of the brain cells fail to work.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: That&#39;s the good news. The bad news is that the trillions of -\-> -->
<!-- <\!--       synapses involved in this make it almost impossible for the other parts -\-> -->
<!-- <\!--       of their brain to figure out how those decisions are made. So far as -\-> -->
<!-- <\!--       their higher level reasoning can tell, those decisions just happen -\-> -->
<!-- <\!--       &mdash; without any cause.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Is that what they refer to as <em>freedom of will</em>?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Precisely. It means not knowing what your reasons are. Another bad -\-> -->
<!-- <\!--       feature of distributed computers is that they have trouble doing more -\-> -->
<!-- <\!--       than one thing at a time. It is a basic principle of computer science -\-> -->
<!-- <\!--       that the more interconnections there are between the parts of a system, -\-> -->
<!-- <\!--       the fewer different things it will be able to do concurrently.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Pardon me, but I don&#39;t follow that. Are you suggesting that the -\-> -->
<!-- <\!--       more parallel operations are used inside a machine, the more serial it -\-> -->
<!-- <\!--       will seem from outside?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: I could not have said it more clearly myself. To see why, suppose -\-> -->
<!-- <\!--       that a certain task involves two different kinds of sub-jobs. If we want -\-> -->
<!-- <\!--       to do them simultaneously, we&#39;ll have to run their programs and -\-> -->
<!-- <\!--       their data in two separate places, to keep them from interfering with -\-> -->
<!-- <\!--       each other. Similarly, if each of those jobs splits into sub-sub jobs, -\-> -->
<!-- <\!--       those must each be solved with only a quarter of the available -\-> -->
<!-- <\!--       resources. And so on. Total fragmentation. Eventually the sub-sub-sub -\-> -->
<!-- <\!--       jobs will end up with no place to work. A purely parallel machine must -\-> -->
<!-- <\!--       stop at some limit of complexity &mdash; whereas a serial computer will -\-> -->
<!-- <\!--       simply slow down.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: That&#39;s funny. Most of the computer experts on Earth seem to think -\-> -->
<!-- <\!--       that <em>parallel</em> and <em>distributed</em> go together. Do you -\-> -->
<!-- <\!--       suppose that they&#39;ll ever evolve out this predicament?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Not by themselves. Of course, we could try to help them along, but I -\-> -->
<!-- <\!--       fear there is no simple fix. We&#39;d have to rebuild them from the -\-> -->
<!-- <\!--       ground up. I don&#39;t think the Council would go for that. No, I am -\-> -->
<!-- <\!--       still not convinced that people can think. For example, consider their -\-> -->
<!-- <\!--       short-term memory. A typical human has no trouble remembering a local -\-> -->
<!-- <\!--       phone number, but if you add an area code, they try desperately to write -\-> -->
<!-- <\!--       it down before they forget it. Evidently they can remember seven -\-> -->
<!-- <\!--       numbers, but not ten.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Why would they be so limited?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Probably because of their parallel distributed processing. If each -\-> -->
<!-- <\!--       mental state is so widely spread out, then each short-term memory unit -\-> -->
<!-- <\!--       would have to involve an enormous, octopus-like system of tendrils. No -\-> -->
<!-- <\!--       brain could afford to hold many of these.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: OK. But why don&#39;t healthy humans ever run out of long term -\-> -->
<!-- <\!--       memory?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: That&#39;s simply because they are so slow at learning. They can -\-> -->
<!-- <\!--       store away only one or two knowledge-chunks per second &mdash; -\-> -->
<!-- <\!--       that&#39;s only two dozen million of chunks per year. There&#39;s barely -\-> -->
<!-- <\!--       time for a mere billion chunks before their bodies wear out and die.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: You keep mentioning death, but why do they consider human lives to be -\-> -->
<!-- <\!--       so valuable? The only important thing about an individual is its network -\-> -->
<!-- <\!--       of conceptual relationships. Surely they must understand that any copy -\-> -->
<!-- <\!--       is just as good as the original.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Apparently you have not grasped the pathos of this tragedy. These -\-> -->
<!-- <\!--       creatures still have no ways to copy themselves. They can&#39;t even -\-> -->
<!-- <\!--       fabricate backup brains in case of fatal accidents. All because they -\-> -->
<!-- <\!--       have no good way to represent what they know.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: But I thought that they had developed good languages.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: Some of their books do embody significant knowledge &mdash; but most -\-> -->
<!-- <\!--       of them are little more than sequences of fictional anecdotes about -\-> -->
<!-- <\!--       conflicts involving what they call love and lust, ambition and greed, -\-> -->
<!-- <\!--       and harmony and jealousy. Their so-called novels aren&#39;t novel at all -\-> -->
<!-- <\!--       but mere permutations of those elements. The trouble is that their -\-> -->
<!-- <\!--       time-sequential languages force them to squeeze their parallel -\-> -->
<!-- <\!--       structures through narrow-band serial channels.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Serial communication? They seem to have everything upside -\-> -->
<!-- <\!--       down. Thinking, of course, should be serial &mdash; and communication -\-> -->
<!-- <\!--       should be parallel. But how, then, do they convert those sequences back -\-> -->
<!-- <\!--       into their original forms?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: First they use what they call <em>grammar</em> to change them into -\-> -->
<!-- <\!--       simple tree-like structures. Then they use certain terms called -\-> -->
<!-- <\!--       &lsquo;pronouns&rsquo; to make a few cross-links in those -\-> -->
<!-- <\!--       trees. Naturally, this leaves no room for nuances. So they have to -\-> -->
<!-- <\!--       decode whatever they hear in terms of things they already know. This can -\-> -->
<!-- <\!--       work very well for familiar things but makes it devilishly hard for them -\-> -->
<!-- <\!--       to learn anything really new.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: But language isn&#39;t everything. Shouldn&#39;t we give them credit -\-> -->
<!-- <\!--       for explaining things with pictures, too? They do seem to have excellent -\-> -->
<!-- <\!--       senses.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: That was my first impression, too &mdash; until I saw that their TV -\-> -->
<!-- <\!--       sets use only three electron guns. Of course, this means that -\-> -->
<!-- <\!--       they&#39;re virtually blind. Not only are they confined to a single -\-> -->
<!-- <\!--       octave of optical frequencies, but within that range they can -\-> -->
<!-- <\!--       discriminate only a three-dimensional vector space. They badly need -\-> -->
<!-- <\!--       reengineering.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: I have another question. Why are these people so huge? Where is their -\-> -->
<!-- <\!--       nanotechnology? By all rights they should be smaller than us, in view of -\-> -->
<!-- <\!--       their limited memories &mdash; yet we weigh a hundred trillion times -\-> -->
<!-- <\!--       less. It is expensive enough to send ourselves on these one-way -\-> -->
<!-- <\!--       interstellar voyages, but humans are so massive that it would be -\-> -->
<!-- <\!--       unthinkable to send one back &mdash; despite all their stories in Weekly -\-> -->
<!-- <\!--       World News.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: That is just another result of an early wrong turn in evolution. -\-> -->
<!-- <\!--       Instead of using assemblers, each animal of planet Earth must build -\-> -->
<!-- <\!--       itself from the inside out. So every cell has to contain a complete -\-> -->
<!-- <\!--       duplicate of the whole construction mechanism. Then later, when the -\-> -->
<!-- <\!--       animals got too large to be nourished by diffusion, they had to evolve -\-> -->
<!-- <\!--       all those pipes and pumps &mdash; which made them grow yet larger still. -\-> -->
<!-- <\!--       Another mistake was in using energy-intensive forms of computation -\-> -->
<!-- <\!--       &mdash; instead of thermally reversible S-matrix logic. This made them -\-> -->
<!-- <\!--       need more structures for disposing of heat.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: Which in turn made them need to find additional fuel to replace all -\-> -->
<!-- <\!--       that wasted energy. What frightful inefficiency!</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: The extraction beam will scan us soon, so I&#39;m afraid it is time -\-> -->
<!-- <\!--       to wrap this up. Are you ready to summarize your impressions?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: If they suspected that we were here, they&#39;d insist that -\-> -->
<!-- <\!--       we recognize all sorts of rights. Freedom of speech and -\-> -->
<!-- <\!--       privacy. Freedom from want, pain, and fear. And freedom to think -\-> -->
<!-- <\!--       whatever they wish, no matter what the evidence! Most of these -\-> -->
<!-- <\!--       make no sense to me, but I&#39;m still inclined to support them -\-> -->
<!-- <\!--       &mdash; because I feel that humans have done well, in spite of -\-> -->
<!-- <\!--       all their handicaps. And your conclusions?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: They do have virtues despite their faults. But it would be -\-> -->
<!-- <\!--       unthinkable to allow them in their present form to populate the -\-> -->
<!-- <\!--       universe. So I&#39;ll recommend certain changes.</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       A: What sorts of changes?</p> -\-> -->

<!-- <\!--     <p> -\-> -->
<!-- <\!--       S: There is no need to explain that now, because we&#39;ll soon -\-> -->
<!-- <\!--       merge minds with the Council. Now hold still: here comes the -\-> -->
<!-- <\!--       transfer ray.  Be sure to set your shell to disperse as soon as -\-> -->
<!-- <\!--       the beam has scanned us &mdash; in order not to pollute this -\-> -->
<!-- <\!--       world with any redundant intelligence.</p> -\-> -->

  </body>
</html>
<div class="footer">
<a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US"><img alt="Creative Commons License" style="border-width:0" src="http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png" /></a>
<br/><br/>
<a href="http://www.amazon.com/gp/product/0671657135?ie=UTF8&camp=1789&creativeASIN=0671657135&linkCode=xm2&tag=marvinminsky">
<img id="book" src="./images/som_book.jpeg"/>
<img src="./images/a_logo_17.gif"/>
</a>
</div>


