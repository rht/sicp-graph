<div class="chapnav">

<span class="prev">Previous: [visual
ambiguity](./som-20.3.html)</span><span class="next">Next:
[micronemes](./som-20.5.html)</span><span
class="contents">[Contents](index.html)</span>
<div class="titlebar">

Society of Mind
===============

</div>

</div>

*20.4* locking-in and weeding-out
---------------------------------

Most language-words are linked to many different polynemes, which
correspond to the many *meaning-senses* of each word. To arouse so many
polynemes at once would often lead to conflicts as each tries to set
one's agencies into different states at the same time. If there are no
other contextual clues, some of these conflicts would be resolved in
accord with their connection strengths. For example, upon hearing *The
astronomer married the star,* a playwright would tend to give priority
to the theatrical sense of *star,* whereas an astronomer would think
first of a distant sun, other things being equal.

But other things are not usually equal. At every moment a person's mind
is already involved with some *context* in which many agents are
actively aroused. Because of this, as each new word arouses different
polynemes, these will compete to change the states of those agents. Some
of those changes will gain support as certain combinations of agents
reinforce one another. Others that lose support and are left to stand
alone will tend to weaken, and most ambiguities will thus be weeded out.
In a few cycles, the entire system will firmly *lock in* on one
meaning-sense for each word and firmly suppress the rest.

A computer program that actually worked this way was developed by Jordan
Pollack and David Waltz. When applied to the sentence, *John shot two
bucks,* and supplied with the faintest context clue, the program would
indeed usually settle into a single, consistent interpretation. In other
words, after a few cycles, the agents ended up in a pattern of mutually
supporting activities in which only one sense of each word remained
strongly active while all the other meaning- senses were suppressed.
Thereafter, whether this *alliance* of word-senses was involved with
hunting or with gambling, it became so self-supporting that it could
resist any subsequent small signal from outside. In effect, the system
had found a stable, unambiguous interpretation of the sentence.

What can be done if such a system settles on a wrong interpretation?
Suppose, for example, that an *outdoors* clue had already made the
system decide that John was hunting, but later it was told that John was
gambling in the woods. Since a single new context clue might not be able
to overcome an established alliance of meaning-senses, it might be
necessary for some higher-level agency to start the system out afresh.
What if the end result of locking-in were unacceptable to other
agencies? Simply repeating the process would only lead to making the
same mistake again. One way to prevent that would be to record which
meaning-senses were adopted in the previous cycle and suppress them
temporarily at the start of the next cycle. This would probably produce
a new interpretation.

There is no guarantee that this method will always find an
interpretation that yields a meaning consistent with all the words of
the sentence. Then, if the locking-in process should fail, the listener
will be confused. There are other methods that one could attempt, for
example, to imagine a new context and then restart the ring-closing
process. But no single method will always work. To use the power of
language, one must acquire many different ways to understand.

<div class="footer">

[![Creative Commons
License](http://i.creativecommons.org/l/by-nc-sa/3.0/80x15.png)](http://creativecommons.org/licenses/by-nc-sa/3.0/deed.en_US)\
\
[![](./images/som_book.jpeg){#book}
![](./images/a_logo_17.gif)](http://www.amazon.com/gp/product/0671657135?ie=UTF8&camp=1789&creativeASIN=0671657135&linkCode=xm2&tag=marvinminsky)

</div>
